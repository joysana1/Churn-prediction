{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "df = pd.read_csv(\"churn-data-3333.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.627417</td>\n",
       "      <td>38.743098</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>30.563784</td>\n",
       "      <td>18.976177</td>\n",
       "      <td>11.426839</td>\n",
       "      <td>26.099822</td>\n",
       "      <td>17.899749</td>\n",
       "      <td>6.192680</td>\n",
       "      <td>29.285780</td>\n",
       "      <td>17.078784</td>\n",
       "      <td>4.636264</td>\n",
       "      <td>4.324555</td>\n",
       "      <td>1.464102</td>\n",
       "      <td>1.286335</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.688161</td>\n",
       "      <td>38.743098</td>\n",
       "      <td>8.198039</td>\n",
       "      <td>23.424398</td>\n",
       "      <td>20.181073</td>\n",
       "      <td>8.482366</td>\n",
       "      <td>25.964263</td>\n",
       "      <td>18.297783</td>\n",
       "      <td>6.153527</td>\n",
       "      <td>29.899843</td>\n",
       "      <td>18.297783</td>\n",
       "      <td>4.767570</td>\n",
       "      <td>5.402702</td>\n",
       "      <td>1.464102</td>\n",
       "      <td>1.847077</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.409400</td>\n",
       "      <td>38.743098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.202564</td>\n",
       "      <td>19.354157</td>\n",
       "      <td>10.865458</td>\n",
       "      <td>20.018174</td>\n",
       "      <td>18.976177</td>\n",
       "      <td>4.418723</td>\n",
       "      <td>23.502941</td>\n",
       "      <td>18.396078</td>\n",
       "      <td>3.411100</td>\n",
       "      <td>4.985700</td>\n",
       "      <td>2.472136</td>\n",
       "      <td>1.627671</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.330303</td>\n",
       "      <td>38.398020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.606358</td>\n",
       "      <td>14.852300</td>\n",
       "      <td>12.268847</td>\n",
       "      <td>13.735311</td>\n",
       "      <td>16.761663</td>\n",
       "      <td>2.586938</td>\n",
       "      <td>26.064212</td>\n",
       "      <td>16.867962</td>\n",
       "      <td>3.953150</td>\n",
       "      <td>3.138093</td>\n",
       "      <td>3.291503</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.828427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.320508</td>\n",
       "      <td>38.743098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.822471</td>\n",
       "      <td>19.260292</td>\n",
       "      <td>8.647065</td>\n",
       "      <td>22.355697</td>\n",
       "      <td>20.090722</td>\n",
       "      <td>5.102112</td>\n",
       "      <td>25.342275</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.356099</td>\n",
       "      <td>1.464102</td>\n",
       "      <td>1.304542</td>\n",
       "      <td>1.464102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  area_code  number_vmail_messages  total_day_minutes  \\\n",
       "0       20.627417  38.743098               8.000000          30.563784   \n",
       "1       18.688161  38.743098               8.198039          23.424398   \n",
       "2       21.409400  38.743098               0.000000          29.202564   \n",
       "3       16.330303  38.398020               0.000000          32.606358   \n",
       "4       15.320508  38.743098               0.000000          23.822471   \n",
       "\n",
       "   total_day_calls  total_day_charge  total_eve_minutes  total_eve_calls  \\\n",
       "0        18.976177         11.426839          26.099822        17.899749   \n",
       "1        20.181073          8.482366          25.964263        18.297783   \n",
       "2        19.354157         10.865458          20.018174        18.976177   \n",
       "3        14.852300         12.268847          13.735311        16.761663   \n",
       "4        19.260292          8.647065          22.355697        20.090722   \n",
       "\n",
       "   total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0          6.192680            29.285780          17.078784   \n",
       "1          6.153527            29.899843          18.297783   \n",
       "2          4.418723            23.502941          18.396078   \n",
       "3          2.586938            26.064212          16.867962   \n",
       "4          5.102112            25.342275          20.000000   \n",
       "\n",
       "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0            4.636264            4.324555          1.464102   \n",
       "1            4.767570            5.402702          1.464102   \n",
       "2            3.411100            4.985700          2.472136   \n",
       "3            3.953150            3.138093          3.291503   \n",
       "4            3.800000            4.356099          1.464102   \n",
       "\n",
       "   total_intl_charge  number_customer_service_calls  \n",
       "0           1.286335                       0.000000  \n",
       "1           1.847077                       0.000000  \n",
       "2           1.627671                       0.000000  \n",
       "3           0.668333                       0.828427  \n",
       "4           1.304542                       1.464102  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "\n",
    "churn=cat_df['churn']\n",
    "cat_df=cat_df.drop(['churn'], axis=1)\n",
    "cat_df=cat_df.drop(['phone number'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#BOX-COX\n",
    "lemda=0.5\n",
    "num_df=(num_df**lemda)\n",
    "num_df=num_df-1\n",
    "num_df[num_df < 0]=0\n",
    "num_df=num_df.div(lemda)\n",
    "#End BOX-COX\n",
    "#Z-score\n",
    "#num_df=(num_df-num_df.min())/(num_df.std(ddof=0)) ##Z-score\n",
    "\n",
    "#Log\n",
    "#num_df=round(np.log(num_df.add(1)),2)\n",
    "#num_df=num_df.replace([np.inf, -np.inf], np.nan)\n",
    "#End Log\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "X_train=X\n",
    "X_test=X\n",
    "y_train=y\n",
    "y_test=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2620 230 262 221\n",
      "pod:  0.4575569358178054\n",
      "pof:  0.08070175438596491\n",
      "AUC:  0.6884275907159202\n",
      "roc_auc:  0.8360651629072681\n",
      "auc:  0.6884275907159202\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813 37 387 96\n",
      "pod:  0.19875776397515527\n",
      "pof:  0.012982456140350877\n",
      "AUC:  0.5928876539174022\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849 1 473 10\n",
      "pod:  0.020703933747412008\n",
      "pof:  0.0003508771929824561\n",
      "AUC:  0.5101765282772147\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2788 62 397 86\n",
      "pod:  0.17805383022774326\n",
      "pof:  0.02175438596491228\n",
      "AUC:  0.5781497221314155\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)   \n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2848 2 462 21\n",
      "pod:  0.043478260869565216\n",
      "pof:  0.0007017543859649122\n",
      "AUC:  0.5213882532418002\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 241us/step - loss: 0.5054 - acc: 0.8370 - val_loss: 0.4092 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 91us/step - loss: 0.4025 - acc: 0.8595 - val_loss: 0.5112 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 113us/step - loss: 0.3916 - acc: 0.8566 - val_loss: 0.4231 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 95us/step - loss: 0.3849 - acc: 0.8579 - val_loss: 0.4100 - val_acc: 0.8400\n",
      "y2_pred:  [[0.09379867]\n",
      " [0.06402332]\n",
      " [0.18342617]\n",
      " [0.25084698]\n",
      " [0.1547041 ]\n",
      " [0.06265712]\n",
      " [0.06066841]\n",
      " [0.10247794]\n",
      " [0.1126135 ]\n",
      " [0.05955875]\n",
      " [0.14245012]\n",
      " [0.11114389]\n",
      " [0.10678911]\n",
      " [0.11998665]\n",
      " [0.12022486]\n",
      " [0.20064089]\n",
      " [0.14145634]\n",
      " [0.09103647]\n",
      " [0.05215603]\n",
      " [0.17149708]\n",
      " [0.07669172]\n",
      " [0.05967915]\n",
      " [0.09736231]\n",
      " [0.05957919]\n",
      " [0.03212261]\n",
      " [0.07593331]\n",
      " [0.05401325]\n",
      " [0.21774119]\n",
      " [0.12279025]\n",
      " [0.0666877 ]\n",
      " [0.07231441]\n",
      " [0.12384316]\n",
      " [0.14926064]\n",
      " [0.138587  ]\n",
      " [0.06364053]\n",
      " [0.11679122]\n",
      " [0.05937251]\n",
      " [0.06548131]\n",
      " [0.08923021]\n",
      " [0.07223222]\n",
      " [0.09192702]\n",
      " [0.10218874]\n",
      " [0.051698  ]\n",
      " [0.0762578 ]\n",
      " [0.04235792]\n",
      " [0.05243558]\n",
      " [0.2411032 ]\n",
      " [0.10000205]\n",
      " [0.15709406]\n",
      " [0.06231576]\n",
      " [0.15373865]\n",
      " [0.07389462]\n",
      " [0.18781066]\n",
      " [0.10619795]\n",
      " [0.06342319]\n",
      " [0.09610179]\n",
      " [0.07723916]\n",
      " [0.0700312 ]\n",
      " [0.07083988]\n",
      " [0.13986042]\n",
      " [0.16122428]\n",
      " [0.06370658]\n",
      " [0.08971021]\n",
      " [0.1045551 ]\n",
      " [0.11263892]\n",
      " [0.04568058]\n",
      " [0.21178865]\n",
      " [0.08062893]\n",
      " [0.11898965]\n",
      " [0.11218551]\n",
      " [0.18119842]\n",
      " [0.06730562]\n",
      " [0.1637798 ]\n",
      " [0.13847986]\n",
      " [0.160101  ]\n",
      " [0.09589982]\n",
      " [0.19856855]\n",
      " [0.0670419 ]\n",
      " [0.14611757]\n",
      " [0.15718535]\n",
      " [0.06090742]\n",
      " [0.18323275]\n",
      " [0.07753047]\n",
      " [0.09362739]\n",
      " [0.12932992]\n",
      " [0.04228124]\n",
      " [0.1399489 ]\n",
      " [0.09294796]\n",
      " [0.08752406]\n",
      " [0.23258749]\n",
      " [0.0659284 ]\n",
      " [0.10642758]\n",
      " [0.05900294]\n",
      " [0.18873256]\n",
      " [0.1331195 ]\n",
      " [0.11092117]\n",
      " [0.17024234]\n",
      " [0.12446395]\n",
      " [0.13805982]\n",
      " [0.11315778]\n",
      " [0.06156006]\n",
      " [0.2033501 ]\n",
      " [0.05957174]\n",
      " [0.08035716]\n",
      " [0.10680726]\n",
      " [0.14043286]\n",
      " [0.08841419]\n",
      " [0.05056292]\n",
      " [0.03957051]\n",
      " [0.09480155]\n",
      " [0.12396598]\n",
      " [0.17806542]\n",
      " [0.10283512]\n",
      " [0.06970531]\n",
      " [0.05524638]\n",
      " [0.07743233]\n",
      " [0.12287331]\n",
      " [0.22825962]\n",
      " [0.04929695]\n",
      " [0.23409376]\n",
      " [0.16118643]\n",
      " [0.08060211]\n",
      " [0.11219183]\n",
      " [0.13878101]\n",
      " [0.08278507]\n",
      " [0.07297939]\n",
      " [0.08654818]\n",
      " [0.06760216]\n",
      " [0.05116594]\n",
      " [0.08691597]\n",
      " [0.12339094]\n",
      " [0.07090077]\n",
      " [0.1239607 ]\n",
      " [0.18691987]\n",
      " [0.09120232]\n",
      " [0.07056493]\n",
      " [0.07548568]\n",
      " [0.09992054]\n",
      " [0.03872839]\n",
      " [0.15282908]\n",
      " [0.07294688]\n",
      " [0.05147263]\n",
      " [0.09714115]\n",
      " [0.09805971]\n",
      " [0.07386434]\n",
      " [0.3113382 ]\n",
      " [0.05618292]\n",
      " [0.19571644]\n",
      " [0.12151462]\n",
      " [0.08824101]\n",
      " [0.13097921]\n",
      " [0.0583182 ]\n",
      " [0.12193468]\n",
      " [0.0976342 ]\n",
      " [0.3160767 ]\n",
      " [0.08507675]\n",
      " [0.33318067]\n",
      " [0.0411849 ]\n",
      " [0.1540752 ]\n",
      " [0.03827927]\n",
      " [0.06731868]\n",
      " [0.07774439]\n",
      " [0.04889283]\n",
      " [0.07720423]\n",
      " [0.12483874]\n",
      " [0.0757947 ]\n",
      " [0.03294328]\n",
      " [0.08762661]\n",
      " [0.06524378]\n",
      " [0.08870405]\n",
      " [0.23065493]\n",
      " [0.10470989]\n",
      " [0.10796177]\n",
      " [0.06175533]\n",
      " [0.08816856]\n",
      " [0.22913754]\n",
      " [0.10301292]\n",
      " [0.17041507]\n",
      " [0.13762376]\n",
      " [0.11756983]\n",
      " [0.07329893]\n",
      " [0.08875522]\n",
      " [0.0501231 ]\n",
      " [0.1733602 ]\n",
      " [0.11671862]\n",
      " [0.14288929]\n",
      " [0.08281165]\n",
      " [0.17040849]\n",
      " [0.04239905]\n",
      " [0.11647493]\n",
      " [0.07562828]\n",
      " [0.09346506]\n",
      " [0.14001429]\n",
      " [0.10806674]\n",
      " [0.12146893]\n",
      " [0.07642448]\n",
      " [0.05652773]\n",
      " [0.1339198 ]\n",
      " [0.14858636]\n",
      " [0.05373794]\n",
      " [0.08600014]\n",
      " [0.11495396]\n",
      " [0.13704383]\n",
      " [0.10577425]\n",
      " [0.05171841]\n",
      " [0.04626417]\n",
      " [0.23442477]\n",
      " [0.18332973]\n",
      " [0.14368433]\n",
      " [0.18033162]\n",
      " [0.14881516]\n",
      " [0.0980702 ]\n",
      " [0.08441228]\n",
      " [0.04327482]\n",
      " [0.26738816]\n",
      " [0.1289269 ]\n",
      " [0.09159428]\n",
      " [0.08702427]\n",
      " [0.21752056]\n",
      " [0.08231655]\n",
      " [0.11408904]\n",
      " [0.06345972]\n",
      " [0.06771666]\n",
      " [0.11402693]\n",
      " [0.05584127]\n",
      " [0.07359445]\n",
      " [0.13833293]\n",
      " [0.08502463]\n",
      " [0.18024752]\n",
      " [0.08179915]\n",
      " [0.34776756]\n",
      " [0.08184305]\n",
      " [0.15183699]\n",
      " [0.12039506]\n",
      " [0.10823849]\n",
      " [0.10398823]\n",
      " [0.06543931]\n",
      " [0.07001278]\n",
      " [0.035184  ]\n",
      " [0.08500871]\n",
      " [0.13447487]\n",
      " [0.12593278]\n",
      " [0.09197032]\n",
      " [0.11058375]\n",
      " [0.08911741]\n",
      " [0.07735655]\n",
      " [0.03571737]\n",
      " [0.12024647]\n",
      " [0.10357824]\n",
      " [0.05149218]\n",
      " [0.11660206]\n",
      " [0.17424497]\n",
      " [0.19031277]\n",
      " [0.03533396]\n",
      " [0.0978168 ]\n",
      " [0.11100304]\n",
      " [0.05404139]\n",
      " [0.04468533]\n",
      " [0.06063598]\n",
      " [0.07021594]\n",
      " [0.05442336]\n",
      " [0.10768658]\n",
      " [0.09125933]\n",
      " [0.07603693]\n",
      " [0.19507435]\n",
      " [0.04646173]\n",
      " [0.08396304]\n",
      " [0.11967877]\n",
      " [0.03031847]\n",
      " [0.1643146 ]\n",
      " [0.12026489]\n",
      " [0.07191598]\n",
      " [0.0527955 ]\n",
      " [0.08516556]\n",
      " [0.05150416]\n",
      " [0.14432251]\n",
      " [0.12232938]\n",
      " [0.061966  ]\n",
      " [0.06190145]\n",
      " [0.10971954]\n",
      " [0.12372789]\n",
      " [0.1893225 ]\n",
      " [0.06504804]\n",
      " [0.06326401]\n",
      " [0.1180549 ]\n",
      " [0.05641952]\n",
      " [0.13410929]\n",
      " [0.16978922]\n",
      " [0.08182386]\n",
      " [0.11619645]\n",
      " [0.04721722]\n",
      " [0.0658679 ]\n",
      " [0.05775827]\n",
      " [0.06367317]\n",
      " [0.05766776]\n",
      " [0.06961945]\n",
      " [0.08609441]\n",
      " [0.10056168]\n",
      " [0.18236828]\n",
      " [0.0871315 ]\n",
      " [0.14472815]\n",
      " [0.10733962]\n",
      " [0.08302256]\n",
      " [0.07447061]\n",
      " [0.04752636]\n",
      " [0.2020469 ]\n",
      " [0.10214695]\n",
      " [0.38213202]\n",
      " [0.10031095]\n",
      " [0.14737704]\n",
      " [0.21796694]\n",
      " [0.073634  ]\n",
      " [0.12676218]\n",
      " [0.07031029]\n",
      " [0.0855633 ]\n",
      " [0.09107402]\n",
      " [0.05342421]\n",
      " [0.05286676]\n",
      " [0.05004242]\n",
      " [0.09074777]\n",
      " [0.06502634]\n",
      " [0.03804997]\n",
      " [0.06219494]\n",
      " [0.04561213]\n",
      " [0.09493721]\n",
      " [0.02650678]\n",
      " [0.04380289]\n",
      " [0.07805511]\n",
      " [0.19263348]\n",
      " [0.12222003]\n",
      " [0.08510008]\n",
      " [0.08726507]\n",
      " [0.28813884]\n",
      " [0.13450435]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 261us/step - loss: 0.5921 - acc: 0.8387 - val_loss: 0.4340 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 110us/step - loss: 0.4099 - acc: 0.8587 - val_loss: 0.4289 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 108us/step - loss: 0.4011 - acc: 0.8587 - val_loss: 0.4558 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 106us/step - loss: 0.4018 - acc: 0.8570 - val_loss: 0.4257 - val_acc: 0.8450\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 113us/step - loss: 0.3982 - acc: 0.8574 - val_loss: 0.4122 - val_acc: 0.8433\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 123us/step - loss: 0.3977 - acc: 0.8558 - val_loss: 0.4404 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 131us/step - loss: 0.3947 - acc: 0.8595 - val_loss: 0.4411 - val_acc: 0.8500\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 115us/step - loss: 0.3855 - acc: 0.8641 - val_loss: 0.3993 - val_acc: 0.8517\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 121us/step - loss: 0.3841 - acc: 0.8587 - val_loss: 0.3897 - val_acc: 0.8600\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 142us/step - loss: 0.3727 - acc: 0.8616 - val_loss: 0.4092 - val_acc: 0.8483\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 134us/step - loss: 0.3751 - acc: 0.8649 - val_loss: 0.3918 - val_acc: 0.8517\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 134us/step - loss: 0.3669 - acc: 0.8691 - val_loss: 0.3805 - val_acc: 0.8650\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 127us/step - loss: 0.3631 - acc: 0.8695 - val_loss: 0.3736 - val_acc: 0.8683\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 126us/step - loss: 0.3609 - acc: 0.8695 - val_loss: 0.3680 - val_acc: 0.8633\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 128us/step - loss: 0.3542 - acc: 0.8687 - val_loss: 0.3766 - val_acc: 0.8633\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 130us/step - loss: 0.3500 - acc: 0.8691 - val_loss: 0.3540 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "2399/2399 [==============================] - 0s 125us/step - loss: 0.3511 - acc: 0.8741 - val_loss: 0.3572 - val_acc: 0.8633\n",
      "Epoch 18/30\n",
      "2399/2399 [==============================] - 0s 129us/step - loss: 0.3398 - acc: 0.8720 - val_loss: 0.3551 - val_acc: 0.8650\n",
      "Epoch 19/30\n",
      "2399/2399 [==============================] - 0s 128us/step - loss: 0.3410 - acc: 0.8770 - val_loss: 0.3602 - val_acc: 0.8633\n",
      "y2_pred:  [[0.03037778]\n",
      " [0.0395655 ]\n",
      " [0.07972321]\n",
      " [0.03117236]\n",
      " [0.03106213]\n",
      " [0.05689135]\n",
      " [0.05898556]\n",
      " [0.03195795]\n",
      " [0.10190976]\n",
      " [0.1154412 ]\n",
      " [0.02198732]\n",
      " [0.03510186]\n",
      " [0.05148551]\n",
      " [0.02896166]\n",
      " [0.07295024]\n",
      " [0.03230411]\n",
      " [0.0372172 ]\n",
      " [0.02958301]\n",
      " [0.0426321 ]\n",
      " [0.10646755]\n",
      " [0.04459935]\n",
      " [0.05222884]\n",
      " [0.03297633]\n",
      " [0.21146846]\n",
      " [0.12556297]\n",
      " [0.03494343]\n",
      " [0.03918961]\n",
      " [0.03758839]\n",
      " [0.0211964 ]\n",
      " [0.05177578]\n",
      " [0.13127708]\n",
      " [0.5544065 ]\n",
      " [0.14961413]\n",
      " [0.03115982]\n",
      " [0.06726101]\n",
      " [0.12082314]\n",
      " [0.08658814]\n",
      " [0.06273344]\n",
      " [0.28352   ]\n",
      " [0.04544127]\n",
      " [0.06890583]\n",
      " [0.03467935]\n",
      " [0.05929077]\n",
      " [0.02376348]\n",
      " [0.20735252]\n",
      " [0.07709259]\n",
      " [0.24166083]\n",
      " [0.03783438]\n",
      " [0.11314574]\n",
      " [0.03131413]\n",
      " [0.06159139]\n",
      " [0.09257284]\n",
      " [0.07361165]\n",
      " [0.05757383]\n",
      " [0.01894867]\n",
      " [0.10644123]\n",
      " [0.03050914]\n",
      " [0.0252082 ]\n",
      " [0.09641537]\n",
      " [0.09330955]\n",
      " [0.05453065]\n",
      " [0.03651702]\n",
      " [0.02657905]\n",
      " [0.15419641]\n",
      " [0.02438381]\n",
      " [0.03104302]\n",
      " [0.0302341 ]\n",
      " [0.05178908]\n",
      " [0.0494422 ]\n",
      " [0.03221843]\n",
      " [0.12357402]\n",
      " [0.28197667]\n",
      " [0.02783823]\n",
      " [0.08512428]\n",
      " [0.10514051]\n",
      " [0.06738377]\n",
      " [0.03918406]\n",
      " [0.06470677]\n",
      " [0.65257436]\n",
      " [0.14928943]\n",
      " [0.03503561]\n",
      " [0.26515985]\n",
      " [0.06418398]\n",
      " [0.1217033 ]\n",
      " [0.07927844]\n",
      " [0.11144945]\n",
      " [0.05342552]\n",
      " [0.06866071]\n",
      " [0.14824608]\n",
      " [0.03756058]\n",
      " [0.03659493]\n",
      " [0.04116008]\n",
      " [0.06854254]\n",
      " [0.03709042]\n",
      " [0.06246811]\n",
      " [0.02678481]\n",
      " [0.08237687]\n",
      " [0.07866964]\n",
      " [0.12197322]\n",
      " [0.03937152]\n",
      " [0.10205945]\n",
      " [0.02429739]\n",
      " [0.05647495]\n",
      " [0.16524237]\n",
      " [0.01471075]\n",
      " [0.06258506]\n",
      " [0.01172239]\n",
      " [0.05270219]\n",
      " [0.016013  ]\n",
      " [0.0395925 ]\n",
      " [0.03549111]\n",
      " [0.02803966]\n",
      " [0.05442697]\n",
      " [0.04875776]\n",
      " [0.04057169]\n",
      " [0.06340066]\n",
      " [0.03825182]\n",
      " [0.03551131]\n",
      " [0.03058192]\n",
      " [0.04621911]\n",
      " [0.46078274]\n",
      " [0.18076116]\n",
      " [0.04847792]\n",
      " [0.05460548]\n",
      " [0.0410004 ]\n",
      " [0.03160003]\n",
      " [0.10738802]\n",
      " [0.09035516]\n",
      " [0.0709593 ]\n",
      " [0.04427081]\n",
      " [0.02770925]\n",
      " [0.11579114]\n",
      " [0.04028592]\n",
      " [0.04352352]\n",
      " [0.02523354]\n",
      " [0.01981211]\n",
      " [0.10409358]\n",
      " [0.11296195]\n",
      " [0.09713471]\n",
      " [0.04665387]\n",
      " [0.03040922]\n",
      " [0.03112254]\n",
      " [0.0345495 ]\n",
      " [0.05268729]\n",
      " [0.023902  ]\n",
      " [0.06040663]\n",
      " [0.04906583]\n",
      " [0.04591665]\n",
      " [0.02623957]\n",
      " [0.04401124]\n",
      " [0.06500158]\n",
      " [0.02203941]\n",
      " [0.09994808]\n",
      " [0.06027243]\n",
      " [0.07290474]\n",
      " [0.04559296]\n",
      " [0.03349125]\n",
      " [0.0813061 ]\n",
      " [0.10091335]\n",
      " [0.05586818]\n",
      " [0.41393524]\n",
      " [0.06275132]\n",
      " [0.03113154]\n",
      " [0.04958943]\n",
      " [0.28593105]\n",
      " [0.0219532 ]\n",
      " [0.11458549]\n",
      " [0.02279884]\n",
      " [0.32473254]\n",
      " [0.04509503]\n",
      " [0.02920407]\n",
      " [0.05009857]\n",
      " [0.08352938]\n",
      " [0.05891114]\n",
      " [0.03066549]\n",
      " [0.15406278]\n",
      " [0.07725367]\n",
      " [0.12038216]\n",
      " [0.03764585]\n",
      " [0.02951467]\n",
      " [0.02030846]\n",
      " [0.0492321 ]\n",
      " [0.07048315]\n",
      " [0.04320407]\n",
      " [0.04772148]\n",
      " [0.03953207]\n",
      " [0.0780966 ]\n",
      " [0.10499996]\n",
      " [0.12024373]\n",
      " [0.08863792]\n",
      " [0.03911513]\n",
      " [0.14123383]\n",
      " [0.03151599]\n",
      " [0.05393904]\n",
      " [0.03923905]\n",
      " [0.06303003]\n",
      " [0.03942102]\n",
      " [0.04230163]\n",
      " [0.07944387]\n",
      " [0.04191849]\n",
      " [0.17738026]\n",
      " [0.19780001]\n",
      " [0.05920279]\n",
      " [0.09268874]\n",
      " [0.04751343]\n",
      " [0.0527404 ]\n",
      " [0.01910332]\n",
      " [0.060029  ]\n",
      " [0.42240605]\n",
      " [0.10408857]\n",
      " [0.135443  ]\n",
      " [0.03589767]\n",
      " [0.28745398]\n",
      " [0.28170612]\n",
      " [0.01914558]\n",
      " [0.1367051 ]\n",
      " [0.11124486]\n",
      " [0.11839008]\n",
      " [0.125296  ]\n",
      " [0.0434545 ]\n",
      " [0.05175853]\n",
      " [0.05325633]\n",
      " [0.06590456]\n",
      " [0.02533892]\n",
      " [0.05000824]\n",
      " [0.03388822]\n",
      " [0.02938989]\n",
      " [0.01830602]\n",
      " [0.02941781]\n",
      " [0.03766781]\n",
      " [0.03104165]\n",
      " [0.07096228]\n",
      " [0.0330829 ]\n",
      " [0.07758814]\n",
      " [0.12661177]\n",
      " [0.08996549]\n",
      " [0.02811977]\n",
      " [0.16830555]\n",
      " [0.01815516]\n",
      " [0.05281213]\n",
      " [0.06640741]\n",
      " [0.07195434]\n",
      " [0.10120526]\n",
      " [0.07165268]\n",
      " [0.02936763]\n",
      " [0.02378091]\n",
      " [0.03936747]\n",
      " [0.15754193]\n",
      " [0.0352993 ]\n",
      " [0.07987675]\n",
      " [0.0743078 ]\n",
      " [0.05872616]\n",
      " [0.08077013]\n",
      " [0.03142732]\n",
      " [0.14526609]\n",
      " [0.03508288]\n",
      " [0.06101972]\n",
      " [0.03621766]\n",
      " [0.03663757]\n",
      " [0.03489682]\n",
      " [0.03875592]\n",
      " [0.02110016]\n",
      " [0.09885609]\n",
      " [0.03046304]\n",
      " [0.05313441]\n",
      " [0.02088413]\n",
      " [0.05727974]\n",
      " [0.05827272]\n",
      " [0.03599113]\n",
      " [0.07822567]\n",
      " [0.02499661]\n",
      " [0.7930758 ]\n",
      " [0.06498361]\n",
      " [0.02242467]\n",
      " [0.03126788]\n",
      " [0.02074417]\n",
      " [0.03908971]\n",
      " [0.10765254]\n",
      " [0.12400344]\n",
      " [0.05875999]\n",
      " [0.03850415]\n",
      " [0.01921535]\n",
      " [0.10040659]\n",
      " [0.04547158]\n",
      " [0.04529697]\n",
      " [0.8713691 ]\n",
      " [0.05090535]\n",
      " [0.04600865]\n",
      " [0.04798323]\n",
      " [0.11020657]\n",
      " [0.03621921]\n",
      " [0.06168321]\n",
      " [0.05389345]\n",
      " [0.11401558]\n",
      " [0.02757657]\n",
      " [0.17412242]\n",
      " [0.05715105]\n",
      " [0.09702849]\n",
      " [0.07174537]\n",
      " [0.09615734]\n",
      " [0.03132489]\n",
      " [0.06718516]\n",
      " [0.03098747]\n",
      " [0.02268103]\n",
      " [0.05154493]\n",
      " [0.04095617]\n",
      " [0.05531019]\n",
      " [0.0321328 ]\n",
      " [0.03763133]\n",
      " [0.07796437]\n",
      " [0.02392605]\n",
      " [0.03389311]\n",
      " [0.06718016]\n",
      " [0.03292426]\n",
      " [0.07243696]\n",
      " [0.62783736]\n",
      " [0.14922947]\n",
      " [0.04624933]\n",
      " [0.00944668]\n",
      " [0.03550175]\n",
      " [0.01848212]\n",
      " [0.06908828]\n",
      " [0.03677261]\n",
      " [0.08653715]\n",
      " [0.0304625 ]\n",
      " [0.05736253]\n",
      " [0.5259406 ]\n",
      " [0.044155  ]\n",
      " [0.46355715]\n",
      " [0.25708476]\n",
      " [0.09598958]\n",
      " [0.26472726]\n",
      " [0.14897136]\n",
      " [0.06332377]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.10204081632653061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 420us/step - loss: 0.4313 - acc: 0.8520 - val_loss: 0.4198 - val_acc: 0.8450\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 109us/step - loss: 0.3952 - acc: 0.8629 - val_loss: 0.4059 - val_acc: 0.8517\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 116us/step - loss: 0.3841 - acc: 0.8662 - val_loss: 0.4258 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 113us/step - loss: 0.3830 - acc: 0.8695 - val_loss: 0.4188 - val_acc: 0.8533\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 130us/step - loss: 0.3788 - acc: 0.8704 - val_loss: 0.3872 - val_acc: 0.8667\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 105us/step - loss: 0.3640 - acc: 0.8770 - val_loss: 0.3809 - val_acc: 0.8617\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 114us/step - loss: 0.3537 - acc: 0.8825 - val_loss: 0.4009 - val_acc: 0.8450\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 112us/step - loss: 0.3605 - acc: 0.8779 - val_loss: 0.3691 - val_acc: 0.8683\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 121us/step - loss: 0.3508 - acc: 0.8833 - val_loss: 0.3559 - val_acc: 0.8700\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 117us/step - loss: 0.3435 - acc: 0.8850 - val_loss: 0.3529 - val_acc: 0.8733\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 113us/step - loss: 0.3452 - acc: 0.8812 - val_loss: 0.3537 - val_acc: 0.8717\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 128us/step - loss: 0.3492 - acc: 0.8779 - val_loss: 0.3529 - val_acc: 0.8700\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 116us/step - loss: 0.3398 - acc: 0.8850 - val_loss: 0.3556 - val_acc: 0.8650\n",
      "y2_pred:  [[0.07733771]\n",
      " [0.22698024]\n",
      " [0.09044227]\n",
      " [0.2198205 ]\n",
      " [0.09402996]\n",
      " [0.09714186]\n",
      " [0.09783208]\n",
      " [0.08512837]\n",
      " [0.07958412]\n",
      " [0.12188286]\n",
      " [0.08010158]\n",
      " [0.10455796]\n",
      " [0.21414554]\n",
      " [0.10174641]\n",
      " [0.16457513]\n",
      " [0.10030383]\n",
      " [0.11052051]\n",
      " [0.11208487]\n",
      " [0.09782299]\n",
      " [0.13551307]\n",
      " [0.09613174]\n",
      " [0.13575616]\n",
      " [0.300605  ]\n",
      " [0.10136998]\n",
      " [0.07566211]\n",
      " [0.1965416 ]\n",
      " [0.11240795]\n",
      " [0.11723414]\n",
      " [0.3047809 ]\n",
      " [0.14855611]\n",
      " [0.12589678]\n",
      " [0.16716641]\n",
      " [0.09094974]\n",
      " [0.1787943 ]\n",
      " [0.3084631 ]\n",
      " [0.17530644]\n",
      " [0.08560675]\n",
      " [0.09360504]\n",
      " [0.11696953]\n",
      " [0.121914  ]\n",
      " [0.11720967]\n",
      " [0.11454535]\n",
      " [0.3182937 ]\n",
      " [0.09283087]\n",
      " [0.14498988]\n",
      " [0.1025632 ]\n",
      " [0.13933286]\n",
      " [0.11456108]\n",
      " [0.17874923]\n",
      " [0.14815718]\n",
      " [0.10771918]\n",
      " [0.08785504]\n",
      " [0.12267849]\n",
      " [0.08063358]\n",
      " [0.07998082]\n",
      " [0.09367731]\n",
      " [0.11074448]\n",
      " [0.09940156]\n",
      " [0.11137545]\n",
      " [0.1328223 ]\n",
      " [0.11266559]\n",
      " [0.24280024]\n",
      " [0.09486362]\n",
      " [0.13803294]\n",
      " [0.5199672 ]\n",
      " [0.25334132]\n",
      " [0.14275587]\n",
      " [0.12621576]\n",
      " [0.17880514]\n",
      " [0.14073345]\n",
      " [0.08150685]\n",
      " [0.11412761]\n",
      " [0.10101068]\n",
      " [0.11867255]\n",
      " [0.09124976]\n",
      " [0.12491649]\n",
      " [0.1574345 ]\n",
      " [0.07415536]\n",
      " [0.17329305]\n",
      " [0.10457027]\n",
      " [0.19087929]\n",
      " [0.10559785]\n",
      " [0.08276489]\n",
      " [0.14689231]\n",
      " [0.07303724]\n",
      " [0.11188829]\n",
      " [0.12334734]\n",
      " [0.1155118 ]\n",
      " [0.11548358]\n",
      " [0.1192987 ]\n",
      " [0.09065327]\n",
      " [0.18549916]\n",
      " [0.14813018]\n",
      " [0.11853719]\n",
      " [0.18582398]\n",
      " [0.10465062]\n",
      " [0.08797491]\n",
      " [0.08940762]\n",
      " [0.69164324]\n",
      " [0.11815646]\n",
      " [0.42143145]\n",
      " [0.14963263]\n",
      " [0.16681314]\n",
      " [0.11017066]\n",
      " [0.08635935]\n",
      " [0.11824855]\n",
      " [0.12107968]\n",
      " [0.10610074]\n",
      " [0.0716913 ]\n",
      " [0.1445821 ]\n",
      " [0.12308982]\n",
      " [0.43385354]\n",
      " [0.47653368]\n",
      " [0.08706617]\n",
      " [0.12027383]\n",
      " [0.22588196]\n",
      " [0.14577013]\n",
      " [0.8109681 ]\n",
      " [0.43577713]\n",
      " [0.67767525]\n",
      " [0.10228106]\n",
      " [0.14639363]\n",
      " [0.06112766]\n",
      " [0.12312838]\n",
      " [0.10171536]\n",
      " [0.14459789]\n",
      " [0.07944798]\n",
      " [0.1091589 ]\n",
      " [0.10418272]\n",
      " [0.10227668]\n",
      " [0.06821787]\n",
      " [0.13472348]\n",
      " [0.1041967 ]\n",
      " [0.12594941]\n",
      " [0.09435835]\n",
      " [0.66950077]\n",
      " [0.8243767 ]\n",
      " [0.0848954 ]\n",
      " [0.09090593]\n",
      " [0.12269941]\n",
      " [0.11045334]\n",
      " [0.08150789]\n",
      " [0.10067943]\n",
      " [0.10174334]\n",
      " [0.12992579]\n",
      " [0.08657381]\n",
      " [0.10587007]\n",
      " [0.93276095]\n",
      " [0.16323692]\n",
      " [0.11943039]\n",
      " [0.11044481]\n",
      " [0.1297631 ]\n",
      " [0.09261608]\n",
      " [0.13611385]\n",
      " [0.08736187]\n",
      " [0.12398419]\n",
      " [0.08762091]\n",
      " [0.11583489]\n",
      " [0.1283631 ]\n",
      " [0.09032071]\n",
      " [0.10596576]\n",
      " [0.12854505]\n",
      " [0.16579235]\n",
      " [0.25579977]\n",
      " [0.93059057]\n",
      " [0.0741348 ]\n",
      " [0.21811205]\n",
      " [0.10863864]\n",
      " [0.07335415]\n",
      " [0.15069553]\n",
      " [0.09534535]\n",
      " [0.07361346]\n",
      " [0.1633543 ]\n",
      " [0.18586871]\n",
      " [0.11132658]\n",
      " [0.10341707]\n",
      " [0.14574087]\n",
      " [0.07978934]\n",
      " [0.14823407]\n",
      " [0.15241483]\n",
      " [0.40688103]\n",
      " [0.12485659]\n",
      " [0.11302099]\n",
      " [0.14089075]\n",
      " [0.14051181]\n",
      " [0.15842342]\n",
      " [0.11258313]\n",
      " [0.08049369]\n",
      " [0.08874497]\n",
      " [0.16618097]\n",
      " [0.07911405]\n",
      " [0.7301783 ]\n",
      " [0.1337089 ]\n",
      " [0.1169951 ]\n",
      " [0.15636191]\n",
      " [0.13503698]\n",
      " [0.08968276]\n",
      " [0.10720217]\n",
      " [0.09319389]\n",
      " [0.14205888]\n",
      " [0.13031873]\n",
      " [0.1387425 ]\n",
      " [0.15028659]\n",
      " [0.15134475]\n",
      " [0.13282472]\n",
      " [0.13831705]\n",
      " [0.11525941]\n",
      " [0.08448094]\n",
      " [0.05154073]\n",
      " [0.4506913 ]\n",
      " [0.43728757]\n",
      " [0.08452719]\n",
      " [0.11671823]\n",
      " [0.15425792]\n",
      " [0.06611878]\n",
      " [0.04516277]\n",
      " [0.1724399 ]\n",
      " [0.09548438]\n",
      " [0.10146371]\n",
      " [0.14357626]\n",
      " [0.09015286]\n",
      " [0.10040376]\n",
      " [0.12075183]\n",
      " [0.12697372]\n",
      " [0.10188282]\n",
      " [0.1050587 ]\n",
      " [0.1670832 ]\n",
      " [0.11658835]\n",
      " [0.11161077]\n",
      " [0.07902426]\n",
      " [0.12706324]\n",
      " [0.10752788]\n",
      " [0.12587717]\n",
      " [0.21048251]\n",
      " [0.1102182 ]\n",
      " [0.22443733]\n",
      " [0.6126663 ]\n",
      " [0.10269079]\n",
      " [0.10294342]\n",
      " [0.13793358]\n",
      " [0.14231426]\n",
      " [0.16776699]\n",
      " [0.1387235 ]\n",
      " [0.37958106]\n",
      " [0.11545759]\n",
      " [0.0503971 ]\n",
      " [0.5844069 ]\n",
      " [0.15393656]\n",
      " [0.14039028]\n",
      " [0.21687832]\n",
      " [0.65866184]\n",
      " [0.09300476]\n",
      " [0.07882035]\n",
      " [0.16920567]\n",
      " [0.607988  ]\n",
      " [0.15324852]\n",
      " [0.09927404]\n",
      " [0.15185553]\n",
      " [0.07871822]\n",
      " [0.08211792]\n",
      " [0.11833039]\n",
      " [0.17529714]\n",
      " [0.1470834 ]\n",
      " [0.13561827]\n",
      " [0.26708746]\n",
      " [0.11783502]\n",
      " [0.1215148 ]\n",
      " [0.34894153]\n",
      " [0.12753278]\n",
      " [0.12044093]\n",
      " [0.11584708]\n",
      " [0.22452015]\n",
      " [0.08131266]\n",
      " [0.08045289]\n",
      " [0.12260339]\n",
      " [0.12814844]\n",
      " [0.13609439]\n",
      " [0.13250333]\n",
      " [0.80554485]\n",
      " [0.13289398]\n",
      " [0.13120165]\n",
      " [0.23797667]\n",
      " [0.07174987]\n",
      " [0.13483223]\n",
      " [0.10868225]\n",
      " [0.07563627]\n",
      " [0.08367273]\n",
      " [0.12361768]\n",
      " [0.06347704]\n",
      " [0.14423743]\n",
      " [0.06039047]\n",
      " [0.12633619]\n",
      " [0.35367405]\n",
      " [0.71520406]\n",
      " [0.15234956]\n",
      " [0.16086835]\n",
      " [0.09698689]\n",
      " [0.06510764]\n",
      " [0.14109823]\n",
      " [0.07436815]\n",
      " [0.11075738]\n",
      " [0.45324647]\n",
      " [0.13898045]\n",
      " [0.184894  ]\n",
      " [0.19119114]\n",
      " [0.10633263]\n",
      " [0.12116876]\n",
      " [0.6136217 ]\n",
      " [0.19455084]\n",
      " [0.14402536]\n",
      " [0.8151047 ]\n",
      " [0.16845623]\n",
      " [0.09399819]\n",
      " [0.14140251]\n",
      " [0.99492687]\n",
      " [0.11004823]\n",
      " [0.4211543 ]\n",
      " [0.59507847]\n",
      " [0.11412057]\n",
      " [0.10975894]\n",
      " [0.18103054]\n",
      " [0.14239371]\n",
      " [0.8938271 ]\n",
      " [0.11102512]\n",
      " [0.10426486]\n",
      " [0.10855171]\n",
      " [0.16296923]\n",
      " [0.16252542]\n",
      " [0.1841099 ]\n",
      " [0.07861426]\n",
      " [0.15810575]\n",
      " [0.12660438]\n",
      " [0.13472816]\n",
      " [0.51694   ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 411us/step - loss: 0.4866 - acc: 0.8458 - val_loss: 0.4664 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.4348 - acc: 0.8583 - val_loss: 0.4458 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.4184 - acc: 0.8583 - val_loss: 0.4430 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 114us/step - loss: 0.4144 - acc: 0.8583 - val_loss: 0.4361 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.4108 - acc: 0.8583 - val_loss: 0.4348 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.4102 - acc: 0.8583 - val_loss: 0.4308 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 101us/step - loss: 0.4030 - acc: 0.8583 - val_loss: 0.4259 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 117us/step - loss: 0.3963 - acc: 0.8583 - val_loss: 0.4269 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3942 - acc: 0.8583 - val_loss: 0.4243 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3895 - acc: 0.8583 - val_loss: 0.4092 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 130us/step - loss: 0.3870 - acc: 0.8583 - val_loss: 0.4067 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3777 - acc: 0.8583 - val_loss: 0.4062 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 107us/step - loss: 0.3772 - acc: 0.8579 - val_loss: 0.4275 - val_acc: 0.8417\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3770 - acc: 0.8592 - val_loss: 0.4026 - val_acc: 0.8417\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3695 - acc: 0.8579 - val_loss: 0.3902 - val_acc: 0.8417\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 97us/step - loss: 0.3682 - acc: 0.8592 - val_loss: 0.3841 - val_acc: 0.8417\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 106us/step - loss: 0.3564 - acc: 0.8579 - val_loss: 0.3725 - val_acc: 0.8550\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3540 - acc: 0.8629 - val_loss: 0.3731 - val_acc: 0.8500\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3478 - acc: 0.8642 - val_loss: 0.3550 - val_acc: 0.8550\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 106us/step - loss: 0.3364 - acc: 0.8658 - val_loss: 0.3679 - val_acc: 0.8567\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 105us/step - loss: 0.3447 - acc: 0.8600 - val_loss: 0.3654 - val_acc: 0.8417\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3355 - acc: 0.8725 - val_loss: 0.3476 - val_acc: 0.8583\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3316 - acc: 0.8721 - val_loss: 0.3494 - val_acc: 0.8533\n",
      "Epoch 24/30\n",
      "2400/2400 [==============================] - 0s 121us/step - loss: 0.3323 - acc: 0.8629 - val_loss: 0.3521 - val_acc: 0.8517\n",
      "Epoch 25/30\n",
      "2400/2400 [==============================] - 0s 116us/step - loss: 0.3263 - acc: 0.8654 - val_loss: 0.3360 - val_acc: 0.8533\n",
      "Epoch 26/30\n",
      "2400/2400 [==============================] - 0s 132us/step - loss: 0.3204 - acc: 0.8683 - val_loss: 0.3298 - val_acc: 0.8700\n",
      "Epoch 27/30\n",
      "2400/2400 [==============================] - 0s 125us/step - loss: 0.3178 - acc: 0.8708 - val_loss: 0.3331 - val_acc: 0.8700\n",
      "Epoch 28/30\n",
      "2400/2400 [==============================] - 0s 129us/step - loss: 0.3111 - acc: 0.8775 - val_loss: 0.3217 - val_acc: 0.8650\n",
      "Epoch 29/30\n",
      "2400/2400 [==============================] - 0s 124us/step - loss: 0.3103 - acc: 0.8746 - val_loss: 0.3318 - val_acc: 0.8600\n",
      "Epoch 30/30\n",
      "2400/2400 [==============================] - 0s 130us/step - loss: 0.3059 - acc: 0.8713 - val_loss: 0.3409 - val_acc: 0.8500\n",
      "y2_pred:  [[1.43347979e-02]\n",
      " [8.46989155e-02]\n",
      " [2.13049710e-01]\n",
      " [9.67183709e-03]\n",
      " [2.25359410e-01]\n",
      " [4.39248621e-01]\n",
      " [2.58454382e-02]\n",
      " [5.90663254e-02]\n",
      " [1.76495314e-03]\n",
      " [2.27143168e-02]\n",
      " [2.97582269e-01]\n",
      " [4.52019274e-02]\n",
      " [1.86017752e-02]\n",
      " [3.75681490e-01]\n",
      " [1.16306871e-01]\n",
      " [1.23242199e-01]\n",
      " [2.71638036e-02]\n",
      " [7.25479126e-02]\n",
      " [3.77809703e-02]\n",
      " [2.58802474e-02]\n",
      " [1.37586802e-01]\n",
      " [1.83952093e-01]\n",
      " [1.63930953e-02]\n",
      " [9.21748579e-02]\n",
      " [3.11199158e-01]\n",
      " [1.44424081e-01]\n",
      " [2.20001817e-01]\n",
      " [7.62741864e-02]\n",
      " [8.42618346e-02]\n",
      " [1.69295371e-02]\n",
      " [2.63253272e-01]\n",
      " [2.20025480e-02]\n",
      " [1.72844857e-01]\n",
      " [2.74966061e-02]\n",
      " [1.04270935e-01]\n",
      " [3.16493511e-02]\n",
      " [2.33709514e-02]\n",
      " [2.59323716e-02]\n",
      " [3.58910561e-02]\n",
      " [1.72036320e-01]\n",
      " [1.32480264e-03]\n",
      " [2.20951974e-01]\n",
      " [1.49961054e-01]\n",
      " [2.92253792e-02]\n",
      " [5.35179079e-02]\n",
      " [2.17639029e-01]\n",
      " [4.02407050e-02]\n",
      " [1.28638268e-01]\n",
      " [3.47990394e-01]\n",
      " [2.55535245e-01]\n",
      " [1.10771596e-01]\n",
      " [2.21598387e-01]\n",
      " [4.48093116e-02]\n",
      " [1.51607990e-02]\n",
      " [2.29280323e-01]\n",
      " [7.25955486e-01]\n",
      " [4.24471259e-01]\n",
      " [7.80875385e-02]\n",
      " [6.25102222e-02]\n",
      " [6.37155771e-02]\n",
      " [1.97591186e-02]\n",
      " [3.31701040e-02]\n",
      " [6.02691174e-01]\n",
      " [4.75976169e-01]\n",
      " [2.23435789e-01]\n",
      " [2.82247961e-02]\n",
      " [1.22691184e-01]\n",
      " [1.86888576e-01]\n",
      " [2.82873809e-02]\n",
      " [5.39749265e-02]\n",
      " [5.43768883e-01]\n",
      " [6.46640062e-02]\n",
      " [5.78194261e-02]\n",
      " [3.93509865e-02]\n",
      " [2.53112912e-02]\n",
      " [2.98451364e-01]\n",
      " [5.68728149e-02]\n",
      " [2.70426273e-02]\n",
      " [1.00726545e-01]\n",
      " [1.04950458e-01]\n",
      " [5.25870919e-02]\n",
      " [6.95113242e-02]\n",
      " [1.34243876e-01]\n",
      " [8.73198211e-02]\n",
      " [2.83132792e-02]\n",
      " [3.94917727e-01]\n",
      " [9.43421721e-02]\n",
      " [1.58784688e-02]\n",
      " [1.83202147e-01]\n",
      " [2.71634579e-01]\n",
      " [8.94083381e-02]\n",
      " [2.69163013e-01]\n",
      " [5.76811552e-01]\n",
      " [6.93763196e-01]\n",
      " [3.82052243e-01]\n",
      " [3.02728087e-01]\n",
      " [1.90021664e-01]\n",
      " [2.34841406e-02]\n",
      " [1.38861895e-01]\n",
      " [1.62591934e-02]\n",
      " [1.85841680e-01]\n",
      " [8.36929083e-02]\n",
      " [1.66545808e-02]\n",
      " [4.17001843e-02]\n",
      " [8.00138116e-02]\n",
      " [6.46402538e-02]\n",
      " [1.13733470e-01]\n",
      " [4.82509136e-02]\n",
      " [4.17313546e-01]\n",
      " [7.97463953e-02]\n",
      " [3.61600518e-02]\n",
      " [1.02062017e-01]\n",
      " [4.51223552e-01]\n",
      " [2.27640569e-01]\n",
      " [1.45023763e-01]\n",
      " [1.33450896e-01]\n",
      " [5.01852334e-02]\n",
      " [1.20174736e-01]\n",
      " [3.81910503e-02]\n",
      " [3.84704769e-02]\n",
      " [1.73369259e-01]\n",
      " [7.69871175e-02]\n",
      " [3.46196145e-01]\n",
      " [3.86726320e-01]\n",
      " [4.06696558e-01]\n",
      " [5.46256840e-01]\n",
      " [7.87296593e-02]\n",
      " [1.45890713e-02]\n",
      " [1.91579700e-01]\n",
      " [8.77304673e-02]\n",
      " [1.34732604e-01]\n",
      " [5.80253303e-02]\n",
      " [6.57026231e-01]\n",
      " [3.43638957e-02]\n",
      " [6.15439415e-02]\n",
      " [3.84661853e-02]\n",
      " [3.93061042e-02]\n",
      " [1.18462026e-01]\n",
      " [1.81930244e-01]\n",
      " [8.85897875e-03]\n",
      " [1.00624323e-01]\n",
      " [1.86493456e-01]\n",
      " [9.72515345e-03]\n",
      " [3.53349745e-02]\n",
      " [7.32437372e-02]\n",
      " [7.65945792e-01]\n",
      " [4.68482673e-02]\n",
      " [4.37161624e-02]\n",
      " [6.79958165e-02]\n",
      " [1.85792744e-01]\n",
      " [3.37390751e-01]\n",
      " [3.78059447e-02]\n",
      " [3.61057222e-02]\n",
      " [1.45933926e-02]\n",
      " [9.38501954e-03]\n",
      " [1.31446213e-01]\n",
      " [3.70218754e-02]\n",
      " [3.32970321e-01]\n",
      " [4.07732725e-02]\n",
      " [1.52434707e-02]\n",
      " [4.02573466e-01]\n",
      " [2.87314057e-02]\n",
      " [3.32021713e-02]\n",
      " [8.28766227e-02]\n",
      " [2.08681703e-01]\n",
      " [8.05422068e-02]\n",
      " [8.28133225e-02]\n",
      " [1.15963221e-02]\n",
      " [6.27318323e-02]\n",
      " [2.27317721e-01]\n",
      " [2.83191204e-02]\n",
      " [2.77665347e-01]\n",
      " [1.93489820e-01]\n",
      " [2.73302197e-03]\n",
      " [3.63236070e-02]\n",
      " [1.89764410e-01]\n",
      " [7.95733333e-02]\n",
      " [2.09959447e-01]\n",
      " [1.60799921e-02]\n",
      " [1.94051296e-01]\n",
      " [1.57304108e-02]\n",
      " [1.04582548e-01]\n",
      " [2.53768623e-01]\n",
      " [3.65031898e-01]\n",
      " [6.45736456e-02]\n",
      " [5.77789545e-02]\n",
      " [2.21869648e-02]\n",
      " [4.27486897e-02]\n",
      " [5.90329766e-02]\n",
      " [5.54195940e-01]\n",
      " [9.61613417e-01]\n",
      " [8.72234464e-01]\n",
      " [2.18284428e-02]\n",
      " [2.98880458e-01]\n",
      " [5.12755811e-02]\n",
      " [7.28178322e-01]\n",
      " [2.92279720e-02]\n",
      " [2.80165374e-02]\n",
      " [5.63941896e-02]\n",
      " [1.24516755e-01]\n",
      " [4.91623580e-02]\n",
      " [1.68291926e-02]\n",
      " [6.09570622e-01]\n",
      " [3.58256340e-01]\n",
      " [7.83661008e-03]\n",
      " [7.14421272e-03]\n",
      " [5.79631925e-01]\n",
      " [6.26781881e-02]\n",
      " [6.65188432e-01]\n",
      " [2.46422738e-01]\n",
      " [1.41107500e-01]\n",
      " [5.22948682e-01]\n",
      " [2.15539157e-01]\n",
      " [5.86824119e-02]\n",
      " [2.18448758e-01]\n",
      " [5.15899718e-01]\n",
      " [2.86208630e-01]\n",
      " [5.30900955e-02]\n",
      " [2.29494542e-01]\n",
      " [1.27575308e-01]\n",
      " [3.69146466e-01]\n",
      " [5.47729135e-02]\n",
      " [3.23104858e-02]\n",
      " [5.09858429e-02]\n",
      " [9.10772085e-02]\n",
      " [2.08924115e-02]\n",
      " [1.30176544e-02]\n",
      " [1.32100731e-01]\n",
      " [9.59603190e-02]\n",
      " [2.36984283e-01]\n",
      " [8.15365314e-02]\n",
      " [1.27706528e-02]\n",
      " [1.16074264e-01]\n",
      " [2.65949249e-01]\n",
      " [1.38168156e-01]\n",
      " [1.53821528e-01]\n",
      " [6.51169598e-01]\n",
      " [9.29735601e-02]\n",
      " [3.46835852e-01]\n",
      " [5.00796139e-01]\n",
      " [6.49643660e-01]\n",
      " [8.44580233e-02]\n",
      " [5.96134067e-02]\n",
      " [2.43070215e-01]\n",
      " [7.34107971e-01]\n",
      " [2.31947601e-02]\n",
      " [4.09914643e-01]\n",
      " [1.71744347e-01]\n",
      " [3.88446450e-02]\n",
      " [1.26697242e-01]\n",
      " [1.85977042e-01]\n",
      " [8.93554330e-01]\n",
      " [8.55485797e-02]\n",
      " [1.13543153e-01]\n",
      " [1.26310945e-01]\n",
      " [7.35454261e-02]\n",
      " [3.80005330e-01]\n",
      " [5.18524647e-02]\n",
      " [6.21124804e-02]\n",
      " [1.37655050e-01]\n",
      " [3.96077067e-01]\n",
      " [2.18753815e-02]\n",
      " [3.40515375e-02]\n",
      " [3.15212905e-02]\n",
      " [4.17803228e-02]\n",
      " [3.96202207e-02]\n",
      " [2.08518475e-01]\n",
      " [4.90462780e-03]\n",
      " [1.34622037e-01]\n",
      " [4.26393420e-01]\n",
      " [6.58171535e-01]\n",
      " [4.30107623e-01]\n",
      " [6.57643378e-02]\n",
      " [1.54256821e-04]\n",
      " [2.92905927e-01]\n",
      " [6.84312284e-02]\n",
      " [5.27297378e-01]\n",
      " [1.01104259e-01]\n",
      " [9.72697735e-02]\n",
      " [8.08244348e-02]\n",
      " [5.58748841e-01]\n",
      " [1.79614395e-01]\n",
      " [9.37325597e-01]\n",
      " [5.07518351e-01]\n",
      " [2.56010592e-02]\n",
      " [2.54325181e-01]\n",
      " [4.91323769e-02]\n",
      " [7.39511847e-02]\n",
      " [2.14208066e-01]\n",
      " [3.28043699e-02]\n",
      " [1.52602404e-01]\n",
      " [1.18733376e-01]\n",
      " [7.51865804e-02]\n",
      " [2.45107174e-01]\n",
      " [6.95137322e-01]\n",
      " [1.10929191e-01]\n",
      " [1.69766247e-02]\n",
      " [5.73862374e-01]\n",
      " [2.70406604e-01]\n",
      " [1.04690373e-01]\n",
      " [6.22141540e-01]\n",
      " [2.04166681e-01]\n",
      " [2.32042372e-02]\n",
      " [7.92162299e-01]\n",
      " [1.47239238e-01]\n",
      " [3.30695212e-02]\n",
      " [5.70829868e-01]\n",
      " [2.22319543e-01]\n",
      " [6.96230590e-01]\n",
      " [4.88462806e-01]\n",
      " [1.94397897e-01]\n",
      " [3.66518021e-01]\n",
      " [7.09627330e-01]\n",
      " [1.83825552e-01]\n",
      " [1.84655726e-01]\n",
      " [3.53014767e-01]\n",
      " [5.43928146e-01]\n",
      " [6.29363120e-01]\n",
      " [1.09071434e-01]\n",
      " [3.55555892e-01]\n",
      " [8.26898575e-01]\n",
      " [2.54503876e-01]\n",
      " [7.47068524e-02]\n",
      " [1.37084037e-01]\n",
      " [2.62945652e-01]\n",
      " [8.56660664e-01]\n",
      " [3.51747006e-01]\n",
      " [4.39035118e-01]\n",
      " [9.23697129e-02]\n",
      " [2.45216459e-01]\n",
      " [6.90981299e-02]\n",
      " [3.62331152e-01]\n",
      " [1.01699643e-02]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.]]\n",
      "pod 1st:  0.3125\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 458us/step - loss: 0.4954 - acc: 0.8421 - val_loss: 0.4388 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 131us/step - loss: 0.4134 - acc: 0.8583 - val_loss: 0.4664 - val_acc: 0.8400\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 119us/step - loss: 0.4147 - acc: 0.8583 - val_loss: 0.4413 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 145us/step - loss: 0.4132 - acc: 0.8588 - val_loss: 0.4333 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 115us/step - loss: 0.4044 - acc: 0.8583 - val_loss: 0.4237 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 114us/step - loss: 0.3982 - acc: 0.8583 - val_loss: 0.4122 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3874 - acc: 0.8575 - val_loss: 0.3965 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3789 - acc: 0.8579 - val_loss: 0.3868 - val_acc: 0.8433\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3702 - acc: 0.8612 - val_loss: 0.3968 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 118us/step - loss: 0.3736 - acc: 0.8583 - val_loss: 0.3708 - val_acc: 0.8433\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 123us/step - loss: 0.3592 - acc: 0.8604 - val_loss: 0.3584 - val_acc: 0.8433\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 116us/step - loss: 0.3554 - acc: 0.8646 - val_loss: 0.3634 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3585 - acc: 0.8592 - val_loss: 0.3582 - val_acc: 0.8367\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 114us/step - loss: 0.3559 - acc: 0.8629 - val_loss: 0.3714 - val_acc: 0.8383\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 114us/step - loss: 0.3481 - acc: 0.8662 - val_loss: 0.3439 - val_acc: 0.8583\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3445 - acc: 0.8642 - val_loss: 0.3530 - val_acc: 0.8500\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 113us/step - loss: 0.3399 - acc: 0.8662 - val_loss: 0.3572 - val_acc: 0.8567\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 114us/step - loss: 0.3453 - acc: 0.8583 - val_loss: 0.3484 - val_acc: 0.8600\n",
      "y2_pred:  [[0.06753734]\n",
      " [0.07691488]\n",
      " [0.29699916]\n",
      " [0.2151697 ]\n",
      " [0.11697587]\n",
      " [0.49855796]\n",
      " [0.10271731]\n",
      " [0.1492013 ]\n",
      " [0.41603857]\n",
      " [0.11006376]\n",
      " [0.17453015]\n",
      " [0.38187826]\n",
      " [0.05428728]\n",
      " [0.20232907]\n",
      " [0.39555418]\n",
      " [0.05470094]\n",
      " [0.10616359]\n",
      " [0.05417567]\n",
      " [0.18114233]\n",
      " [0.31607533]\n",
      " [0.07644266]\n",
      " [0.03128356]\n",
      " [0.33177525]\n",
      " [0.5036443 ]\n",
      " [0.09482577]\n",
      " [0.01878464]\n",
      " [0.05236569]\n",
      " [0.56917197]\n",
      " [0.11915448]\n",
      " [0.08795303]\n",
      " [0.04771513]\n",
      " [0.05462372]\n",
      " [0.03821138]\n",
      " [0.26429695]\n",
      " [0.11488178]\n",
      " [0.03645837]\n",
      " [0.07887661]\n",
      " [0.11582008]\n",
      " [0.04826751]\n",
      " [0.11944389]\n",
      " [0.26222277]\n",
      " [0.03842372]\n",
      " [0.20895845]\n",
      " [0.12337607]\n",
      " [0.02176863]\n",
      " [0.20470324]\n",
      " [0.04409075]\n",
      " [0.18424818]\n",
      " [0.2164788 ]\n",
      " [0.10582218]\n",
      " [0.4118844 ]\n",
      " [0.25595564]\n",
      " [0.08502138]\n",
      " [0.04195347]\n",
      " [0.12366465]\n",
      " [0.01059058]\n",
      " [0.05412635]\n",
      " [0.04006949]\n",
      " [0.11910504]\n",
      " [0.05592728]\n",
      " [0.5895639 ]\n",
      " [0.02798286]\n",
      " [0.10438031]\n",
      " [0.07559589]\n",
      " [0.03707904]\n",
      " [0.08811072]\n",
      " [0.01057521]\n",
      " [0.01506701]\n",
      " [0.10913068]\n",
      " [0.6655221 ]\n",
      " [0.05715159]\n",
      " [0.0146116 ]\n",
      " [0.07580265]\n",
      " [0.2656508 ]\n",
      " [0.09846506]\n",
      " [0.09143582]\n",
      " [0.2017487 ]\n",
      " [0.18634334]\n",
      " [0.06751436]\n",
      " [0.3997051 ]\n",
      " [0.13874152]\n",
      " [0.06788754]\n",
      " [0.14637044]\n",
      " [0.03236434]\n",
      " [0.15503249]\n",
      " [0.04977182]\n",
      " [0.28509092]\n",
      " [0.03369498]\n",
      " [0.09538063]\n",
      " [0.03817892]\n",
      " [0.15672863]\n",
      " [0.07219085]\n",
      " [0.17020395]\n",
      " [0.04965022]\n",
      " [0.41727704]\n",
      " [0.04929534]\n",
      " [0.30927664]\n",
      " [0.03632426]\n",
      " [0.06533039]\n",
      " [0.08786497]\n",
      " [0.1914629 ]\n",
      " [0.06038588]\n",
      " [0.06298316]\n",
      " [0.07531574]\n",
      " [0.34812292]\n",
      " [0.562217  ]\n",
      " [0.01570231]\n",
      " [0.03207457]\n",
      " [0.06110644]\n",
      " [0.06863663]\n",
      " [0.12772858]\n",
      " [0.03778034]\n",
      " [0.04434243]\n",
      " [0.3820877 ]\n",
      " [0.14582852]\n",
      " [0.07989559]\n",
      " [0.03537062]\n",
      " [0.15861833]\n",
      " [0.34302548]\n",
      " [0.38985673]\n",
      " [0.01202992]\n",
      " [0.12657934]\n",
      " [0.05606398]\n",
      " [0.43489406]\n",
      " [0.28317004]\n",
      " [0.06114411]\n",
      " [0.07390621]\n",
      " [0.05786869]\n",
      " [0.0931924 ]\n",
      " [0.04361525]\n",
      " [0.07212341]\n",
      " [0.0161376 ]\n",
      " [0.03986579]\n",
      " [0.13850537]\n",
      " [0.5187775 ]\n",
      " [0.06032139]\n",
      " [0.22762969]\n",
      " [0.05010656]\n",
      " [0.29257947]\n",
      " [0.00427639]\n",
      " [0.08311275]\n",
      " [0.10864136]\n",
      " [0.25498706]\n",
      " [0.01069573]\n",
      " [0.17574954]\n",
      " [0.63788456]\n",
      " [0.05691206]\n",
      " [0.00786424]\n",
      " [0.15404138]\n",
      " [0.19301102]\n",
      " [0.3185283 ]\n",
      " [0.05653536]\n",
      " [0.03661287]\n",
      " [0.11979148]\n",
      " [0.1939052 ]\n",
      " [0.344573  ]\n",
      " [0.09172577]\n",
      " [0.01586199]\n",
      " [0.13669759]\n",
      " [0.27513835]\n",
      " [0.10966513]\n",
      " [0.27214396]\n",
      " [0.04636437]\n",
      " [0.36742485]\n",
      " [0.10197091]\n",
      " [0.07093892]\n",
      " [0.04607803]\n",
      " [0.05245775]\n",
      " [0.2608677 ]\n",
      " [0.21572632]\n",
      " [0.06559646]\n",
      " [0.02391219]\n",
      " [0.34982643]\n",
      " [0.32829607]\n",
      " [0.06674129]\n",
      " [0.15015009]\n",
      " [0.38811073]\n",
      " [0.07398763]\n",
      " [0.18219852]\n",
      " [0.16997689]\n",
      " [0.39117962]\n",
      " [0.08278239]\n",
      " [0.0655483 ]\n",
      " [0.43400776]\n",
      " [0.04905203]\n",
      " [0.12075609]\n",
      " [0.12148383]\n",
      " [0.09031507]\n",
      " [0.14221033]\n",
      " [0.05308497]\n",
      " [0.48462096]\n",
      " [0.03067929]\n",
      " [0.15424687]\n",
      " [0.07043988]\n",
      " [0.03267902]\n",
      " [0.12170172]\n",
      " [0.02212027]\n",
      " [0.1472835 ]\n",
      " [0.46636266]\n",
      " [0.11352545]\n",
      " [0.2494148 ]\n",
      " [0.01770496]\n",
      " [0.38327885]\n",
      " [0.12322262]\n",
      " [0.30239296]\n",
      " [0.03159925]\n",
      " [0.09975404]\n",
      " [0.24492908]\n",
      " [0.01414973]\n",
      " [0.19378838]\n",
      " [0.27004117]\n",
      " [0.06087869]\n",
      " [0.04137868]\n",
      " [0.16987127]\n",
      " [0.01566824]\n",
      " [0.05131412]\n",
      " [0.10659266]\n",
      " [0.18338841]\n",
      " [0.10505539]\n",
      " [0.07722604]\n",
      " [0.12534678]\n",
      " [0.07849362]\n",
      " [0.02582863]\n",
      " [0.04117772]\n",
      " [0.28830537]\n",
      " [0.14930028]\n",
      " [0.18075907]\n",
      " [0.03359559]\n",
      " [0.24307331]\n",
      " [0.04889703]\n",
      " [0.0115546 ]\n",
      " [0.08432254]\n",
      " [0.0362764 ]\n",
      " [0.08854723]\n",
      " [0.04770735]\n",
      " [0.1432432 ]\n",
      " [0.11914381]\n",
      " [0.02679658]\n",
      " [0.05005947]\n",
      " [0.26228607]\n",
      " [0.05032331]\n",
      " [0.08860573]\n",
      " [0.08531651]\n",
      " [0.0871318 ]\n",
      " [0.21703097]\n",
      " [0.10901284]\n",
      " [0.0476819 ]\n",
      " [0.02973491]\n",
      " [0.09424558]\n",
      " [0.02817461]\n",
      " [0.41078648]\n",
      " [0.02612209]\n",
      " [0.1627636 ]\n",
      " [0.52338755]\n",
      " [0.01235184]\n",
      " [0.07113588]\n",
      " [0.06918433]\n",
      " [0.03940529]\n",
      " [0.66728246]\n",
      " [0.14632419]\n",
      " [0.44025147]\n",
      " [0.06381154]\n",
      " [0.20208365]\n",
      " [0.15715119]\n",
      " [0.05254367]\n",
      " [0.06309867]\n",
      " [0.39001495]\n",
      " [0.2966463 ]\n",
      " [0.03060743]\n",
      " [0.14490795]\n",
      " [0.03266755]\n",
      " [0.05444866]\n",
      " [0.06717306]\n",
      " [0.20717382]\n",
      " [0.1317119 ]\n",
      " [0.62587893]\n",
      " [0.10370314]\n",
      " [0.259053  ]\n",
      " [0.36448884]\n",
      " [0.32279164]\n",
      " [0.29558638]\n",
      " [0.13266847]\n",
      " [0.10771075]\n",
      " [0.05386996]\n",
      " [0.1601941 ]\n",
      " [0.22279537]\n",
      " [0.24002331]\n",
      " [0.08921245]\n",
      " [0.11940747]\n",
      " [0.25678477]\n",
      " [0.04238707]\n",
      " [0.11399648]\n",
      " [0.14626366]\n",
      " [0.076884  ]\n",
      " [0.1104123 ]\n",
      " [0.09710854]\n",
      " [0.5417441 ]\n",
      " [0.2183288 ]\n",
      " [0.14013463]\n",
      " [0.10642523]\n",
      " [0.22395876]\n",
      " [0.5895333 ]\n",
      " [0.26267463]\n",
      " [0.46293104]\n",
      " [0.28312135]\n",
      " [0.32378158]\n",
      " [0.6980196 ]\n",
      " [0.35766542]\n",
      " [0.14266539]\n",
      " [0.23341984]\n",
      " [0.22965693]\n",
      " [0.6427527 ]\n",
      " [0.31764865]\n",
      " [0.39139113]\n",
      " [0.53630775]\n",
      " [0.05072114]\n",
      " [0.02460861]\n",
      " [0.1668401 ]\n",
      " [0.66052866]\n",
      " [0.27206546]\n",
      " [0.4654508 ]\n",
      " [0.1487512 ]\n",
      " [0.5338152 ]\n",
      " [0.32114738]\n",
      " [0.38515747]\n",
      " [0.2780441 ]\n",
      " [0.06802189]\n",
      " [0.29943117]\n",
      " [0.09501579]\n",
      " [0.6485731 ]\n",
      " [0.47283983]\n",
      " [0.09265651]\n",
      " [0.2721018 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 456us/step - loss: 0.4183 - acc: 0.8583 - val_loss: 0.4352 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 120us/step - loss: 0.4073 - acc: 0.8583 - val_loss: 0.4347 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 133us/step - loss: 0.4002 - acc: 0.8583 - val_loss: 0.4232 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 122us/step - loss: 0.3964 - acc: 0.8583 - val_loss: 0.4195 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 123us/step - loss: 0.3913 - acc: 0.8583 - val_loss: 0.4530 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 123us/step - loss: 0.3974 - acc: 0.8583 - val_loss: 0.4170 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 124us/step - loss: 0.3855 - acc: 0.8579 - val_loss: 0.4147 - val_acc: 0.8467\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 129us/step - loss: 0.3820 - acc: 0.8579 - val_loss: 0.4317 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 127us/step - loss: 0.3811 - acc: 0.8583 - val_loss: 0.4092 - val_acc: 0.8450\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 126us/step - loss: 0.3796 - acc: 0.8600 - val_loss: 0.4020 - val_acc: 0.8383\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 150us/step - loss: 0.3725 - acc: 0.8633 - val_loss: 0.4200 - val_acc: 0.8400\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 133us/step - loss: 0.3716 - acc: 0.8600 - val_loss: 0.3950 - val_acc: 0.8450\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 153us/step - loss: 0.3673 - acc: 0.8592 - val_loss: 0.3941 - val_acc: 0.8433\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 132us/step - loss: 0.3617 - acc: 0.8588 - val_loss: 0.3927 - val_acc: 0.8483\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 126us/step - loss: 0.3598 - acc: 0.8617 - val_loss: 0.3854 - val_acc: 0.8517\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 132us/step - loss: 0.3534 - acc: 0.8662 - val_loss: 0.3790 - val_acc: 0.8400\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.3533 - acc: 0.8617 - val_loss: 0.3863 - val_acc: 0.8450\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 120us/step - loss: 0.3569 - acc: 0.8633 - val_loss: 0.3927 - val_acc: 0.8467\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3415 - acc: 0.8675 - val_loss: 0.3823 - val_acc: 0.8483\n",
      "y2_pred:  [[0.02735895]\n",
      " [0.08379152]\n",
      " [0.11517373]\n",
      " [0.21061262]\n",
      " [0.13978615]\n",
      " [0.04838622]\n",
      " [0.5985726 ]\n",
      " [0.03285426]\n",
      " [0.3556469 ]\n",
      " [0.67541504]\n",
      " [0.03053018]\n",
      " [0.3191416 ]\n",
      " [0.05783033]\n",
      " [0.21591291]\n",
      " [0.1866506 ]\n",
      " [0.09772676]\n",
      " [0.03208539]\n",
      " [0.03028029]\n",
      " [0.07378805]\n",
      " [0.05051255]\n",
      " [0.22875613]\n",
      " [0.02040151]\n",
      " [0.08742839]\n",
      " [0.13976079]\n",
      " [0.0448879 ]\n",
      " [0.40808797]\n",
      " [0.05414048]\n",
      " [0.18806875]\n",
      " [0.16026902]\n",
      " [0.02942148]\n",
      " [0.21011034]\n",
      " [0.02293417]\n",
      " [0.06742719]\n",
      " [0.03284532]\n",
      " [0.07705605]\n",
      " [0.23093778]\n",
      " [0.17618299]\n",
      " [0.03590548]\n",
      " [0.12875333]\n",
      " [0.06580848]\n",
      " [0.05590141]\n",
      " [0.0831041 ]\n",
      " [0.13374355]\n",
      " [0.03364715]\n",
      " [0.02544212]\n",
      " [0.13034621]\n",
      " [0.05497855]\n",
      " [0.20988816]\n",
      " [0.26779413]\n",
      " [0.04387027]\n",
      " [0.07866248]\n",
      " [0.09066194]\n",
      " [0.07413048]\n",
      " [0.05392238]\n",
      " [0.22698978]\n",
      " [0.06767511]\n",
      " [0.3127682 ]\n",
      " [0.09996626]\n",
      " [0.49025598]\n",
      " [0.04998514]\n",
      " [0.05895671]\n",
      " [0.06408846]\n",
      " [0.42207658]\n",
      " [0.1585981 ]\n",
      " [0.5563593 ]\n",
      " [0.1872775 ]\n",
      " [0.12053061]\n",
      " [0.32928008]\n",
      " [0.44586775]\n",
      " [0.05446193]\n",
      " [0.05148828]\n",
      " [0.07604918]\n",
      " [0.1213502 ]\n",
      " [0.05061963]\n",
      " [0.2398515 ]\n",
      " [0.05233619]\n",
      " [0.10291612]\n",
      " [0.03388813]\n",
      " [0.1806305 ]\n",
      " [0.02978209]\n",
      " [0.43275395]\n",
      " [0.29328966]\n",
      " [0.04326111]\n",
      " [0.08750123]\n",
      " [0.03954324]\n",
      " [0.16066784]\n",
      " [0.10916293]\n",
      " [0.1122573 ]\n",
      " [0.17361024]\n",
      " [0.12937364]\n",
      " [0.01368091]\n",
      " [0.26732737]\n",
      " [0.03877077]\n",
      " [0.09981939]\n",
      " [0.14901   ]\n",
      " [0.05235371]\n",
      " [0.03146857]\n",
      " [0.0491437 ]\n",
      " [0.220348  ]\n",
      " [0.1306856 ]\n",
      " [0.15696096]\n",
      " [0.10627285]\n",
      " [0.03460234]\n",
      " [0.2234258 ]\n",
      " [0.20084399]\n",
      " [0.05703211]\n",
      " [0.2119154 ]\n",
      " [0.09878096]\n",
      " [0.05521283]\n",
      " [0.10141897]\n",
      " [0.23274127]\n",
      " [0.01095742]\n",
      " [0.29653594]\n",
      " [0.14820921]\n",
      " [0.02735367]\n",
      " [0.0592294 ]\n",
      " [0.11382768]\n",
      " [0.5942331 ]\n",
      " [0.19265181]\n",
      " [0.07573536]\n",
      " [0.00772166]\n",
      " [0.04116273]\n",
      " [0.02020374]\n",
      " [0.11611718]\n",
      " [0.03788114]\n",
      " [0.01393622]\n",
      " [0.04933986]\n",
      " [0.01785302]\n",
      " [0.1348305 ]\n",
      " [0.01934129]\n",
      " [0.00462529]\n",
      " [0.12472266]\n",
      " [0.0248639 ]\n",
      " [0.06648263]\n",
      " [0.16959801]\n",
      " [0.02282181]\n",
      " [0.05211821]\n",
      " [0.01098841]\n",
      " [0.6793268 ]\n",
      " [0.0054253 ]\n",
      " [0.07072142]\n",
      " [0.32642466]\n",
      " [0.21738866]\n",
      " [0.028909  ]\n",
      " [0.70695823]\n",
      " [0.12801683]\n",
      " [0.5882813 ]\n",
      " [0.45475334]\n",
      " [0.22186118]\n",
      " [0.09583616]\n",
      " [0.06997719]\n",
      " [0.3289724 ]\n",
      " [0.05399153]\n",
      " [0.05259684]\n",
      " [0.04380769]\n",
      " [0.12920523]\n",
      " [0.06341672]\n",
      " [0.07165691]\n",
      " [0.13808271]\n",
      " [0.06070647]\n",
      " [0.04345709]\n",
      " [0.1403169 ]\n",
      " [0.23020715]\n",
      " [0.05569506]\n",
      " [0.31027964]\n",
      " [0.29421845]\n",
      " [0.20825908]\n",
      " [0.17671695]\n",
      " [0.02613792]\n",
      " [0.07175404]\n",
      " [0.26130524]\n",
      " [0.01605573]\n",
      " [0.15991983]\n",
      " [0.07295114]\n",
      " [0.10279787]\n",
      " [0.08213261]\n",
      " [0.00996926]\n",
      " [0.13441443]\n",
      " [0.01450223]\n",
      " [0.00189215]\n",
      " [0.56796557]\n",
      " [0.02530041]\n",
      " [0.02700725]\n",
      " [0.14580813]\n",
      " [0.01610261]\n",
      " [0.07901815]\n",
      " [0.04126495]\n",
      " [0.02613118]\n",
      " [0.06524503]\n",
      " [0.43278903]\n",
      " [0.07800898]\n",
      " [0.0595794 ]\n",
      " [0.11973342]\n",
      " [0.07069066]\n",
      " [0.39336753]\n",
      " [0.2216866 ]\n",
      " [0.10560989]\n",
      " [0.4524145 ]\n",
      " [0.23303598]\n",
      " [0.23106036]\n",
      " [0.3854441 ]\n",
      " [0.32189304]\n",
      " [0.13145176]\n",
      " [0.07262215]\n",
      " [0.6670054 ]\n",
      " [0.01095316]\n",
      " [0.03294533]\n",
      " [0.0954276 ]\n",
      " [0.17367822]\n",
      " [0.28263962]\n",
      " [0.49221638]\n",
      " [0.0112192 ]\n",
      " [0.13013193]\n",
      " [0.50577265]\n",
      " [0.14917833]\n",
      " [0.03066319]\n",
      " [0.06981021]\n",
      " [0.06298816]\n",
      " [0.03616318]\n",
      " [0.0441727 ]\n",
      " [0.2824691 ]\n",
      " [0.00750607]\n",
      " [0.34348926]\n",
      " [0.4362077 ]\n",
      " [0.2775069 ]\n",
      " [0.20381233]\n",
      " [0.20273775]\n",
      " [0.02773049]\n",
      " [0.08116341]\n",
      " [0.16917613]\n",
      " [0.42312717]\n",
      " [0.0052425 ]\n",
      " [0.22875032]\n",
      " [0.1515815 ]\n",
      " [0.26967326]\n",
      " [0.03335491]\n",
      " [0.20812133]\n",
      " [0.15819952]\n",
      " [0.0096983 ]\n",
      " [0.1362538 ]\n",
      " [0.00897515]\n",
      " [0.19129506]\n",
      " [0.04135665]\n",
      " [0.21466583]\n",
      " [0.44137806]\n",
      " [0.04901943]\n",
      " [0.0089938 ]\n",
      " [0.1361737 ]\n",
      " [0.15073362]\n",
      " [0.13269868]\n",
      " [0.2440609 ]\n",
      " [0.29151934]\n",
      " [0.12129119]\n",
      " [0.05436707]\n",
      " [0.2778464 ]\n",
      " [0.22087985]\n",
      " [0.16060302]\n",
      " [0.49992147]\n",
      " [0.20076934]\n",
      " [0.03252533]\n",
      " [0.08849382]\n",
      " [0.1074529 ]\n",
      " [0.21756294]\n",
      " [0.07312384]\n",
      " [0.09839016]\n",
      " [0.3586231 ]\n",
      " [0.41007182]\n",
      " [0.19865584]\n",
      " [0.01498187]\n",
      " [0.00986427]\n",
      " [0.08291781]\n",
      " [0.02018479]\n",
      " [0.17585665]\n",
      " [0.11090717]\n",
      " [0.27766994]\n",
      " [0.08855489]\n",
      " [0.02643386]\n",
      " [0.22754535]\n",
      " [0.11010832]\n",
      " [0.06242108]\n",
      " [0.08805227]\n",
      " [0.06101868]\n",
      " [0.09189886]\n",
      " [0.04715702]\n",
      " [0.11673129]\n",
      " [0.14454433]\n",
      " [0.10859323]\n",
      " [0.21838269]\n",
      " [0.13263994]\n",
      " [0.15730268]\n",
      " [0.01547366]\n",
      " [0.08716387]\n",
      " [0.00414336]\n",
      " [0.09587669]\n",
      " [0.30862218]\n",
      " [0.01817662]\n",
      " [0.08479685]\n",
      " [0.08901668]\n",
      " [0.06107992]\n",
      " [0.17363653]\n",
      " [0.07248485]\n",
      " [0.0788379 ]\n",
      " [0.30777374]\n",
      " [0.05712593]\n",
      " [0.31042743]\n",
      " [0.18398085]\n",
      " [0.14151993]\n",
      " [0.04376581]\n",
      " [0.10902134]\n",
      " [0.41088617]\n",
      " [0.36885047]\n",
      " [0.04751396]\n",
      " [0.11364472]\n",
      " [0.5676162 ]\n",
      " [0.08873615]\n",
      " [0.1799429 ]\n",
      " [0.37709764]\n",
      " [0.49366784]\n",
      " [0.3760545 ]\n",
      " [0.8393331 ]\n",
      " [0.48269182]\n",
      " [0.489601  ]\n",
      " [0.29874855]\n",
      " [0.663949  ]\n",
      " [0.33128938]\n",
      " [0.30033436]\n",
      " [0.23551238]\n",
      " [0.78384125]\n",
      " [0.09935704]\n",
      " [0.20003507]\n",
      " [0.58464223]\n",
      " [0.569825  ]\n",
      " [0.03701587]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "pod 1st:  0.14583333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 609us/step - loss: 0.4476 - acc: 0.8500 - val_loss: 0.4298 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 144us/step - loss: 0.4006 - acc: 0.8571 - val_loss: 0.4236 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 138us/step - loss: 0.3898 - acc: 0.8579 - val_loss: 0.4223 - val_acc: 0.8467\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 115us/step - loss: 0.3977 - acc: 0.8575 - val_loss: 0.4065 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3876 - acc: 0.8579 - val_loss: 0.3918 - val_acc: 0.8433\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 120us/step - loss: 0.3758 - acc: 0.8596 - val_loss: 0.3795 - val_acc: 0.8500\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 123us/step - loss: 0.3675 - acc: 0.8612 - val_loss: 0.3727 - val_acc: 0.8600\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 114us/step - loss: 0.3615 - acc: 0.8579 - val_loss: 0.3558 - val_acc: 0.8550\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3639 - acc: 0.8637 - val_loss: 0.3515 - val_acc: 0.8500\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 119us/step - loss: 0.3435 - acc: 0.8646 - val_loss: 0.3431 - val_acc: 0.8600\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 118us/step - loss: 0.3475 - acc: 0.8642 - val_loss: 0.3431 - val_acc: 0.8700\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 113us/step - loss: 0.3314 - acc: 0.8700 - val_loss: 0.3287 - val_acc: 0.8550\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 117us/step - loss: 0.3246 - acc: 0.8671 - val_loss: 0.3309 - val_acc: 0.8567\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 122us/step - loss: 0.3197 - acc: 0.8717 - val_loss: 0.3285 - val_acc: 0.8550\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3134 - acc: 0.8796 - val_loss: 0.3155 - val_acc: 0.8717\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3027 - acc: 0.8808 - val_loss: 0.3132 - val_acc: 0.8817\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3062 - acc: 0.8787 - val_loss: 0.3023 - val_acc: 0.8783\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 116us/step - loss: 0.3021 - acc: 0.8825 - val_loss: 0.3023 - val_acc: 0.8783\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.2936 - acc: 0.8825 - val_loss: 0.2960 - val_acc: 0.8783\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.2915 - acc: 0.8867 - val_loss: 0.2959 - val_acc: 0.8833\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 143us/step - loss: 0.2866 - acc: 0.8908 - val_loss: 0.2965 - val_acc: 0.8817\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.2922 - acc: 0.8833 - val_loss: 0.3112 - val_acc: 0.8733\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 130us/step - loss: 0.2909 - acc: 0.8808 - val_loss: 0.2998 - val_acc: 0.8700\n",
      "y2_pred:  [[0.05313632]\n",
      " [0.18406793]\n",
      " [0.2021859 ]\n",
      " [0.12011769]\n",
      " [0.72354335]\n",
      " [0.03845641]\n",
      " [0.08404452]\n",
      " [0.0754438 ]\n",
      " [0.09174776]\n",
      " [0.0212816 ]\n",
      " [0.02983409]\n",
      " [0.0582709 ]\n",
      " [0.00331578]\n",
      " [0.13948008]\n",
      " [0.0686188 ]\n",
      " [0.42780012]\n",
      " [0.11907208]\n",
      " [0.05647326]\n",
      " [0.05089349]\n",
      " [0.18198878]\n",
      " [0.28520733]\n",
      " [0.29745203]\n",
      " [0.04157996]\n",
      " [0.4644238 ]\n",
      " [0.08283526]\n",
      " [0.07855478]\n",
      " [0.03079143]\n",
      " [0.02796489]\n",
      " [0.1157997 ]\n",
      " [0.07970405]\n",
      " [0.15027216]\n",
      " [0.06218079]\n",
      " [0.13655463]\n",
      " [0.03080902]\n",
      " [0.32010657]\n",
      " [0.0225614 ]\n",
      " [0.06154379]\n",
      " [0.32688066]\n",
      " [0.06753066]\n",
      " [0.02506003]\n",
      " [0.03004968]\n",
      " [0.14877698]\n",
      " [0.20074639]\n",
      " [0.08605409]\n",
      " [0.09747607]\n",
      " [0.07511222]\n",
      " [0.25723922]\n",
      " [0.19007206]\n",
      " [0.10031906]\n",
      " [0.14142057]\n",
      " [0.06693769]\n",
      " [0.04671282]\n",
      " [0.08210257]\n",
      " [0.02625382]\n",
      " [0.09940666]\n",
      " [0.19175354]\n",
      " [0.22452   ]\n",
      " [0.14771068]\n",
      " [0.2718953 ]\n",
      " [0.02725068]\n",
      " [0.14639464]\n",
      " [0.11779806]\n",
      " [0.16813314]\n",
      " [0.08751607]\n",
      " [0.8059423 ]\n",
      " [0.09843868]\n",
      " [0.08118379]\n",
      " [0.01147404]\n",
      " [0.03059667]\n",
      " [0.07943076]\n",
      " [0.09632748]\n",
      " [0.20458767]\n",
      " [0.06551814]\n",
      " [0.02767339]\n",
      " [0.07560307]\n",
      " [0.07040426]\n",
      " [0.04859182]\n",
      " [0.10655841]\n",
      " [0.04015753]\n",
      " [0.3075728 ]\n",
      " [0.0424552 ]\n",
      " [0.06312439]\n",
      " [0.01847193]\n",
      " [0.34046033]\n",
      " [0.05443832]\n",
      " [0.09846488]\n",
      " [0.32908595]\n",
      " [0.19064662]\n",
      " [0.03967804]\n",
      " [0.30607074]\n",
      " [0.24531701]\n",
      " [0.00464606]\n",
      " [0.12446079]\n",
      " [0.11098713]\n",
      " [0.10034975]\n",
      " [0.03737211]\n",
      " [0.03650737]\n",
      " [0.29719216]\n",
      " [0.26828438]\n",
      " [0.06305489]\n",
      " [0.09368673]\n",
      " [0.1071552 ]\n",
      " [0.11227146]\n",
      " [0.22589791]\n",
      " [0.06249988]\n",
      " [0.13927874]\n",
      " [0.01791486]\n",
      " [0.05437431]\n",
      " [0.0598613 ]\n",
      " [0.01978999]\n",
      " [0.01694453]\n",
      " [0.3261128 ]\n",
      " [0.16424686]\n",
      " [0.15619937]\n",
      " [0.03243396]\n",
      " [0.3274446 ]\n",
      " [0.07161152]\n",
      " [0.05958536]\n",
      " [0.38640594]\n",
      " [0.01429015]\n",
      " [0.14431265]\n",
      " [0.02083346]\n",
      " [0.02116424]\n",
      " [0.31950808]\n",
      " [0.08111703]\n",
      " [0.6846551 ]\n",
      " [0.01553363]\n",
      " [0.07301578]\n",
      " [0.30642122]\n",
      " [0.08694401]\n",
      " [0.02069268]\n",
      " [0.23605901]\n",
      " [0.05482933]\n",
      " [0.69428027]\n",
      " [0.08049378]\n",
      " [0.1554288 ]\n",
      " [0.05718583]\n",
      " [0.13470438]\n",
      " [0.12324116]\n",
      " [0.17226547]\n",
      " [0.19408211]\n",
      " [0.06929451]\n",
      " [0.29363763]\n",
      " [0.04868838]\n",
      " [0.07368767]\n",
      " [0.25463176]\n",
      " [0.6143848 ]\n",
      " [0.02776   ]\n",
      " [0.0692746 ]\n",
      " [0.41895494]\n",
      " [0.11567765]\n",
      " [0.20174971]\n",
      " [0.14223248]\n",
      " [0.34925118]\n",
      " [0.43781078]\n",
      " [0.2794494 ]\n",
      " [0.16165227]\n",
      " [0.28705746]\n",
      " [0.08185187]\n",
      " [0.5167988 ]\n",
      " [0.06609839]\n",
      " [0.08066347]\n",
      " [0.16272533]\n",
      " [0.65645474]\n",
      " [0.186773  ]\n",
      " [0.06812906]\n",
      " [0.01213485]\n",
      " [0.01971504]\n",
      " [0.06379747]\n",
      " [0.12084326]\n",
      " [0.02602094]\n",
      " [0.19302592]\n",
      " [0.22481364]\n",
      " [0.14657491]\n",
      " [0.3305044 ]\n",
      " [0.09640166]\n",
      " [0.22959745]\n",
      " [0.06872571]\n",
      " [0.06438625]\n",
      " [0.02808908]\n",
      " [0.03175426]\n",
      " [0.04449373]\n",
      " [0.07757458]\n",
      " [0.02439308]\n",
      " [0.04161137]\n",
      " [0.8146541 ]\n",
      " [0.44525373]\n",
      " [0.09919459]\n",
      " [0.42204785]\n",
      " [0.07364091]\n",
      " [0.08631283]\n",
      " [0.00688127]\n",
      " [0.4125205 ]\n",
      " [0.45715916]\n",
      " [0.02788645]\n",
      " [0.17319953]\n",
      " [0.1604689 ]\n",
      " [0.06080115]\n",
      " [0.21156839]\n",
      " [0.08471164]\n",
      " [0.37564477]\n",
      " [0.34831536]\n",
      " [0.76720524]\n",
      " [0.07754683]\n",
      " [0.1510497 ]\n",
      " [0.02613729]\n",
      " [0.07014841]\n",
      " [0.05061871]\n",
      " [0.41514325]\n",
      " [0.43321085]\n",
      " [0.05427942]\n",
      " [0.5660944 ]\n",
      " [0.4026719 ]\n",
      " [0.04554686]\n",
      " [0.3126753 ]\n",
      " [0.4203987 ]\n",
      " [0.04465511]\n",
      " [0.5598356 ]\n",
      " [0.4461794 ]\n",
      " [0.10484552]\n",
      " [0.08781072]\n",
      " [0.00497246]\n",
      " [0.7963832 ]\n",
      " [0.06346673]\n",
      " [0.22720814]\n",
      " [0.10162309]\n",
      " [0.3443182 ]\n",
      " [0.00921556]\n",
      " [0.12889847]\n",
      " [0.23760974]\n",
      " [0.04708764]\n",
      " [0.05591023]\n",
      " [0.01270381]\n",
      " [0.0460352 ]\n",
      " [0.12416133]\n",
      " [0.06121343]\n",
      " [0.17524073]\n",
      " [0.5376952 ]\n",
      " [0.05217427]\n",
      " [0.01600844]\n",
      " [0.05559027]\n",
      " [0.1053257 ]\n",
      " [0.06741664]\n",
      " [0.13761911]\n",
      " [0.02735761]\n",
      " [0.01480436]\n",
      " [0.1229758 ]\n",
      " [0.17028156]\n",
      " [0.49224567]\n",
      " [0.02629045]\n",
      " [0.00521195]\n",
      " [0.05098644]\n",
      " [0.10847232]\n",
      " [0.04753834]\n",
      " [0.09782088]\n",
      " [0.0316796 ]\n",
      " [0.02125597]\n",
      " [0.48551115]\n",
      " [0.19040784]\n",
      " [0.44382343]\n",
      " [0.4269509 ]\n",
      " [0.15697673]\n",
      " [0.00838053]\n",
      " [0.46839556]\n",
      " [0.02830014]\n",
      " [0.01260734]\n",
      " [0.5114795 ]\n",
      " [0.01324672]\n",
      " [0.0070267 ]\n",
      " [0.11900145]\n",
      " [0.02564883]\n",
      " [0.11968067]\n",
      " [0.06039518]\n",
      " [0.17270648]\n",
      " [0.36703926]\n",
      " [0.14212406]\n",
      " [0.01437855]\n",
      " [0.2253986 ]\n",
      " [0.03317073]\n",
      " [0.05127317]\n",
      " [0.09014437]\n",
      " [0.09556606]\n",
      " [0.76101243]\n",
      " [0.07924667]\n",
      " [0.09736875]\n",
      " [0.02906039]\n",
      " [0.00769603]\n",
      " [0.04450661]\n",
      " [0.60799354]\n",
      " [0.19796348]\n",
      " [0.34682527]\n",
      " [0.15434414]\n",
      " [0.2121872 ]\n",
      " [0.01139724]\n",
      " [0.02971506]\n",
      " [0.08837208]\n",
      " [0.1091384 ]\n",
      " [0.07852414]\n",
      " [0.13270938]\n",
      " [0.03243268]\n",
      " [0.10753337]\n",
      " [0.04518455]\n",
      " [0.18463024]\n",
      " [0.02397513]\n",
      " [0.19960779]\n",
      " [0.74914575]\n",
      " [0.41857487]\n",
      " [0.652001  ]\n",
      " [0.7792504 ]\n",
      " [0.3204913 ]\n",
      " [0.03973931]\n",
      " [0.69061863]\n",
      " [0.50489324]\n",
      " [0.01243329]\n",
      " [0.38269988]\n",
      " [0.3128358 ]\n",
      " [0.01963618]\n",
      " [0.71040994]\n",
      " [0.6368489 ]\n",
      " [0.51557636]\n",
      " [0.19935498]\n",
      " [0.06127512]\n",
      " [0.6438243 ]\n",
      " [0.7415036 ]\n",
      " [0.35506842]\n",
      " [0.01787335]\n",
      " [0.13538107]\n",
      " [0.19734162]\n",
      " [0.47585037]\n",
      " [0.17758101]\n",
      " [0.59418017]\n",
      " [0.32353336]\n",
      " [0.7528737 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 493us/step - loss: 0.4592 - acc: 0.8583 - val_loss: 0.4373 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.4175 - acc: 0.8583 - val_loss: 0.4697 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.4179 - acc: 0.8583 - val_loss: 0.4266 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 99us/step - loss: 0.4023 - acc: 0.8583 - val_loss: 0.4209 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3979 - acc: 0.8583 - val_loss: 0.4059 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 97us/step - loss: 0.4033 - acc: 0.8583 - val_loss: 0.4013 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 116us/step - loss: 0.3970 - acc: 0.8588 - val_loss: 0.3971 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 106us/step - loss: 0.3919 - acc: 0.8588 - val_loss: 0.3985 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 105us/step - loss: 0.3771 - acc: 0.8588 - val_loss: 0.3808 - val_acc: 0.8517\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 104us/step - loss: 0.3853 - acc: 0.8608 - val_loss: 0.4259 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3812 - acc: 0.8583 - val_loss: 0.3751 - val_acc: 0.8450\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 96us/step - loss: 0.3677 - acc: 0.8600 - val_loss: 0.3779 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3724 - acc: 0.8575 - val_loss: 0.3695 - val_acc: 0.8433\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 104us/step - loss: 0.3640 - acc: 0.8600 - val_loss: 0.3722 - val_acc: 0.8417\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3636 - acc: 0.8592 - val_loss: 0.3738 - val_acc: 0.8433\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 105us/step - loss: 0.3637 - acc: 0.8612 - val_loss: 0.3643 - val_acc: 0.8433\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 100us/step - loss: 0.3532 - acc: 0.8625 - val_loss: 0.3595 - val_acc: 0.8483\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3539 - acc: 0.8633 - val_loss: 0.3647 - val_acc: 0.8433\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3554 - acc: 0.8608 - val_loss: 0.3489 - val_acc: 0.8450\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 117us/step - loss: 0.3504 - acc: 0.8600 - val_loss: 0.3496 - val_acc: 0.8433\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 117us/step - loss: 0.3487 - acc: 0.8625 - val_loss: 0.3538 - val_acc: 0.8433\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.3540 - acc: 0.8617 - val_loss: 0.3499 - val_acc: 0.8400\n",
      "y2_pred:  [[0.12786177]\n",
      " [0.29698452]\n",
      " [0.13943589]\n",
      " [0.04511327]\n",
      " [0.17681208]\n",
      " [0.08783358]\n",
      " [0.11721247]\n",
      " [0.44385818]\n",
      " [0.20736596]\n",
      " [0.18058777]\n",
      " [0.11922908]\n",
      " [0.29056528]\n",
      " [0.03058445]\n",
      " [0.24925068]\n",
      " [0.06614581]\n",
      " [0.16742954]\n",
      " [0.18408331]\n",
      " [0.10612959]\n",
      " [0.1227321 ]\n",
      " [0.05221549]\n",
      " [0.0827122 ]\n",
      " [0.06539333]\n",
      " [0.07592204]\n",
      " [0.07746693]\n",
      " [0.09710369]\n",
      " [0.07731175]\n",
      " [0.05893514]\n",
      " [0.29886782]\n",
      " [0.07312459]\n",
      " [0.02836221]\n",
      " [0.0469054 ]\n",
      " [0.03271347]\n",
      " [0.2026824 ]\n",
      " [0.05448949]\n",
      " [0.31263846]\n",
      " [0.12397036]\n",
      " [0.14622381]\n",
      " [0.13661855]\n",
      " [0.0233992 ]\n",
      " [0.11779279]\n",
      " [0.08658618]\n",
      " [0.20462245]\n",
      " [0.18143305]\n",
      " [0.05306065]\n",
      " [0.03740042]\n",
      " [0.2684636 ]\n",
      " [0.12175137]\n",
      " [0.3775683 ]\n",
      " [0.05452311]\n",
      " [0.05919695]\n",
      " [0.0596506 ]\n",
      " [0.03856695]\n",
      " [0.34784698]\n",
      " [0.07318684]\n",
      " [0.2816283 ]\n",
      " [0.10130993]\n",
      " [0.1696471 ]\n",
      " [0.15320772]\n",
      " [0.17848745]\n",
      " [0.0313631 ]\n",
      " [0.10310975]\n",
      " [0.17187378]\n",
      " [0.0635978 ]\n",
      " [0.01768851]\n",
      " [0.04771739]\n",
      " [0.3069307 ]\n",
      " [0.21560642]\n",
      " [0.0540463 ]\n",
      " [0.07755643]\n",
      " [0.01995695]\n",
      " [0.02446079]\n",
      " [0.22387609]\n",
      " [0.29367274]\n",
      " [0.36781195]\n",
      " [0.08935738]\n",
      " [0.05881694]\n",
      " [0.07736424]\n",
      " [0.03318945]\n",
      " [0.07960862]\n",
      " [0.129726  ]\n",
      " [0.15124786]\n",
      " [0.03560516]\n",
      " [0.00936702]\n",
      " [0.07791224]\n",
      " [0.07315531]\n",
      " [0.12528145]\n",
      " [0.08422872]\n",
      " [0.08336258]\n",
      " [0.07097635]\n",
      " [0.04390046]\n",
      " [0.00233075]\n",
      " [0.05035299]\n",
      " [0.04798049]\n",
      " [0.03555414]\n",
      " [0.134505  ]\n",
      " [0.1328083 ]\n",
      " [0.04724836]\n",
      " [0.05070803]\n",
      " [0.13541344]\n",
      " [0.25731546]\n",
      " [0.07089609]\n",
      " [0.1599308 ]\n",
      " [0.08953327]\n",
      " [0.11778739]\n",
      " [0.1574105 ]\n",
      " [0.04949903]\n",
      " [0.05262932]\n",
      " [0.0443725 ]\n",
      " [0.09022868]\n",
      " [0.04202387]\n",
      " [0.38359833]\n",
      " [0.11341661]\n",
      " [0.10773072]\n",
      " [0.09355363]\n",
      " [0.18263009]\n",
      " [0.24629623]\n",
      " [0.02944827]\n",
      " [0.29404312]\n",
      " [0.04876953]\n",
      " [0.05219942]\n",
      " [0.0462248 ]\n",
      " [0.02784333]\n",
      " [0.37443188]\n",
      " [0.04600701]\n",
      " [0.0540885 ]\n",
      " [0.32558143]\n",
      " [0.05696684]\n",
      " [0.07244137]\n",
      " [0.15168512]\n",
      " [0.10967177]\n",
      " [0.0298067 ]\n",
      " [0.2533267 ]\n",
      " [0.02863285]\n",
      " [0.03757137]\n",
      " [0.08187231]\n",
      " [0.06827316]\n",
      " [0.25493163]\n",
      " [0.05831364]\n",
      " [0.0706656 ]\n",
      " [0.03262386]\n",
      " [0.03999051]\n",
      " [0.14463183]\n",
      " [0.06324029]\n",
      " [0.0866718 ]\n",
      " [0.0978463 ]\n",
      " [0.0581868 ]\n",
      " [0.31475258]\n",
      " [0.06117612]\n",
      " [0.25448698]\n",
      " [0.07296568]\n",
      " [0.0373072 ]\n",
      " [0.1298598 ]\n",
      " [0.09184504]\n",
      " [0.02980345]\n",
      " [0.07864407]\n",
      " [0.29728097]\n",
      " [0.03696039]\n",
      " [0.07007456]\n",
      " [0.15155822]\n",
      " [0.2958814 ]\n",
      " [0.04111239]\n",
      " [0.08647627]\n",
      " [0.04881394]\n",
      " [0.05738437]\n",
      " [0.06236649]\n",
      " [0.1485602 ]\n",
      " [0.06821218]\n",
      " [0.09831187]\n",
      " [0.13123557]\n",
      " [0.09669757]\n",
      " [0.09174821]\n",
      " [0.08965632]\n",
      " [0.09066409]\n",
      " [0.04914746]\n",
      " [0.0513716 ]\n",
      " [0.06163919]\n",
      " [0.2653196 ]\n",
      " [0.11764744]\n",
      " [0.0256418 ]\n",
      " [0.04553211]\n",
      " [0.05196008]\n",
      " [0.23825681]\n",
      " [0.03377786]\n",
      " [0.21187797]\n",
      " [0.12689507]\n",
      " [0.12593171]\n",
      " [0.03192917]\n",
      " [0.10134208]\n",
      " [0.04639632]\n",
      " [0.07301939]\n",
      " [0.16274369]\n",
      " [0.10657904]\n",
      " [0.15610248]\n",
      " [0.07904723]\n",
      " [0.09703508]\n",
      " [0.13291258]\n",
      " [0.06987336]\n",
      " [0.04822287]\n",
      " [0.1336751 ]\n",
      " [0.16553658]\n",
      " [0.07773545]\n",
      " [0.06409585]\n",
      " [0.35363066]\n",
      " [0.352418  ]\n",
      " [0.04739586]\n",
      " [0.36498272]\n",
      " [0.02629945]\n",
      " [0.10385948]\n",
      " [0.05907506]\n",
      " [0.07682526]\n",
      " [0.10763556]\n",
      " [0.03127709]\n",
      " [0.15475085]\n",
      " [0.10885546]\n",
      " [0.06126145]\n",
      " [0.1515437 ]\n",
      " [0.07837692]\n",
      " [0.15601873]\n",
      " [0.19386211]\n",
      " [0.5059158 ]\n",
      " [0.10090742]\n",
      " [0.13928401]\n",
      " [0.04312551]\n",
      " [0.06156287]\n",
      " [0.04551253]\n",
      " [0.04830095]\n",
      " [0.14372194]\n",
      " [0.01341069]\n",
      " [0.0507046 ]\n",
      " [0.05431724]\n",
      " [0.04013607]\n",
      " [0.06004772]\n",
      " [0.0949603 ]\n",
      " [0.38420406]\n",
      " [0.48176485]\n",
      " [0.25690943]\n",
      " [0.01722386]\n",
      " [0.15876022]\n",
      " [0.29500335]\n",
      " [0.12812945]\n",
      " [0.05819672]\n",
      " [0.06263983]\n",
      " [0.06752586]\n",
      " [0.12133721]\n",
      " [0.0535962 ]\n",
      " [0.06948379]\n",
      " [0.05738121]\n",
      " [0.16121486]\n",
      " [0.13603637]\n",
      " [0.0571382 ]\n",
      " [0.21455109]\n",
      " [0.18507457]\n",
      " [0.12153301]\n",
      " [0.16408983]\n",
      " [0.03754282]\n",
      " [0.07613042]\n",
      " [0.06452733]\n",
      " [0.11628768]\n",
      " [0.4444454 ]\n",
      " [0.03163809]\n",
      " [0.41997   ]\n",
      " [0.33074236]\n",
      " [0.04251474]\n",
      " [0.23378211]\n",
      " [0.05564901]\n",
      " [0.09047237]\n",
      " [0.09733137]\n",
      " [0.02873945]\n",
      " [0.12190518]\n",
      " [0.22924012]\n",
      " [0.34131184]\n",
      " [0.07463822]\n",
      " [0.09453899]\n",
      " [0.28277257]\n",
      " [0.12865305]\n",
      " [0.07456395]\n",
      " [0.04136449]\n",
      " [0.05945498]\n",
      " [0.16989037]\n",
      " [0.08829805]\n",
      " [0.56539553]\n",
      " [0.04890302]\n",
      " [0.03337288]\n",
      " [0.19950205]\n",
      " [0.0571951 ]\n",
      " [0.24237317]\n",
      " [0.06921124]\n",
      " [0.08665979]\n",
      " [0.08587357]\n",
      " [0.21180272]\n",
      " [0.19049871]\n",
      " [0.07512778]\n",
      " [0.10534847]\n",
      " [0.12532493]\n",
      " [0.20539784]\n",
      " [0.16833544]\n",
      " [0.1329583 ]\n",
      " [0.12105766]\n",
      " [0.05385384]\n",
      " [0.11315173]\n",
      " [0.06023449]\n",
      " [0.07435396]\n",
      " [0.21596685]\n",
      " [0.12596536]\n",
      " [0.04857004]\n",
      " [0.06667268]\n",
      " [0.22824994]\n",
      " [0.04886162]\n",
      " [0.07035244]\n",
      " [0.09080729]\n",
      " [0.11320865]\n",
      " [0.5814724 ]\n",
      " [0.4307189 ]\n",
      " [0.28920496]\n",
      " [0.04220134]\n",
      " [0.1352708 ]\n",
      " [0.08896765]\n",
      " [0.46357208]\n",
      " [0.10569975]\n",
      " [0.14164636]\n",
      " [0.3451175 ]\n",
      " [0.3275112 ]\n",
      " [0.3228152 ]\n",
      " [0.4279061 ]\n",
      " [0.03743979]\n",
      " [0.14085662]\n",
      " [0.25436205]\n",
      " [0.5068727 ]\n",
      " [0.31961665]\n",
      " [0.24990042]\n",
      " [0.14050607]\n",
      " [0.19307707]\n",
      " [0.10743009]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 483us/step - loss: 0.4846 - acc: 0.8512 - val_loss: 0.5269 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 107us/step - loss: 0.4083 - acc: 0.8629 - val_loss: 0.4527 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 106us/step - loss: 0.3932 - acc: 0.8629 - val_loss: 0.4509 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3983 - acc: 0.8625 - val_loss: 0.4465 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3792 - acc: 0.8625 - val_loss: 0.4450 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3906 - acc: 0.8612 - val_loss: 0.4229 - val_acc: 0.8317\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 107us/step - loss: 0.3727 - acc: 0.8721 - val_loss: 0.4308 - val_acc: 0.8300\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 104us/step - loss: 0.3697 - acc: 0.8688 - val_loss: 0.4148 - val_acc: 0.8350\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 112us/step - loss: 0.3681 - acc: 0.8688 - val_loss: 0.4173 - val_acc: 0.8333\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3615 - acc: 0.8733 - val_loss: 0.4058 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3587 - acc: 0.8708 - val_loss: 0.4135 - val_acc: 0.8383\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3588 - acc: 0.8754 - val_loss: 0.4473 - val_acc: 0.8333\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 110us/step - loss: 0.3540 - acc: 0.8733 - val_loss: 0.4125 - val_acc: 0.8400\n",
      "y2_pred:  [[0.08541411]\n",
      " [0.20315635]\n",
      " [0.16160491]\n",
      " [0.12234724]\n",
      " [0.19445947]\n",
      " [0.39322576]\n",
      " [0.17192131]\n",
      " [0.13023835]\n",
      " [0.15190816]\n",
      " [0.14899796]\n",
      " [0.15518448]\n",
      " [0.09354302]\n",
      " [0.15060318]\n",
      " [0.16804874]\n",
      " [0.13733956]\n",
      " [0.11937979]\n",
      " [0.1752297 ]\n",
      " [0.10309303]\n",
      " [0.21510792]\n",
      " [0.14239708]\n",
      " [0.1298492 ]\n",
      " [0.22000575]\n",
      " [0.157648  ]\n",
      " [0.21133924]\n",
      " [0.07458282]\n",
      " [0.18847612]\n",
      " [0.14341143]\n",
      " [0.17204922]\n",
      " [0.18065047]\n",
      " [0.14810407]\n",
      " [0.42853945]\n",
      " [0.10965016]\n",
      " [0.2955556 ]\n",
      " [0.16172129]\n",
      " [0.1330995 ]\n",
      " [0.11443993]\n",
      " [0.08570576]\n",
      " [0.11795282]\n",
      " [0.31956673]\n",
      " [0.14596206]\n",
      " [0.14613396]\n",
      " [0.15537828]\n",
      " [0.25376397]\n",
      " [0.19630828]\n",
      " [0.1275791 ]\n",
      " [0.19585377]\n",
      " [0.11103618]\n",
      " [0.05834243]\n",
      " [0.14915428]\n",
      " [0.13187256]\n",
      " [0.17336464]\n",
      " [0.14605796]\n",
      " [0.09142169]\n",
      " [0.16384879]\n",
      " [0.1394597 ]\n",
      " [0.14618164]\n",
      " [0.52831626]\n",
      " [0.13076374]\n",
      " [0.10645294]\n",
      " [0.13513374]\n",
      " [0.13997623]\n",
      " [0.5272879 ]\n",
      " [0.16610298]\n",
      " [0.1249131 ]\n",
      " [0.13602266]\n",
      " [0.7804091 ]\n",
      " [0.2714578 ]\n",
      " [0.11410788]\n",
      " [0.17116013]\n",
      " [0.18879056]\n",
      " [0.12811637]\n",
      " [0.07812846]\n",
      " [0.08871067]\n",
      " [0.08100206]\n",
      " [0.16240919]\n",
      " [0.19815287]\n",
      " [0.09617564]\n",
      " [0.05098051]\n",
      " [0.13422701]\n",
      " [0.13487473]\n",
      " [0.39086577]\n",
      " [0.07327396]\n",
      " [0.1010159 ]\n",
      " [0.09853265]\n",
      " [0.11912394]\n",
      " [0.06804529]\n",
      " [0.2543281 ]\n",
      " [0.10817677]\n",
      " [0.18959433]\n",
      " [0.12886703]\n",
      " [0.19902498]\n",
      " [0.16269225]\n",
      " [0.11253521]\n",
      " [0.2807421 ]\n",
      " [0.15179712]\n",
      " [0.1796599 ]\n",
      " [0.1443916 ]\n",
      " [0.17123574]\n",
      " [0.15125892]\n",
      " [0.16359478]\n",
      " [0.10552379]\n",
      " [0.1656619 ]\n",
      " [0.143329  ]\n",
      " [0.15321779]\n",
      " [0.16500953]\n",
      " [0.15550292]\n",
      " [0.09651574]\n",
      " [0.13679457]\n",
      " [0.19091895]\n",
      " [0.06726894]\n",
      " [0.2087627 ]\n",
      " [0.12059796]\n",
      " [0.09514782]\n",
      " [0.13789648]\n",
      " [0.33173805]\n",
      " [0.21914238]\n",
      " [0.0792914 ]\n",
      " [0.42940542]\n",
      " [0.15350324]\n",
      " [0.08851084]\n",
      " [0.24155092]\n",
      " [0.33173734]\n",
      " [0.12516987]\n",
      " [0.15819076]\n",
      " [0.0915018 ]\n",
      " [0.16364735]\n",
      " [0.1388917 ]\n",
      " [0.5476804 ]\n",
      " [0.18967354]\n",
      " [0.17868263]\n",
      " [0.12332627]\n",
      " [0.27311277]\n",
      " [0.19318157]\n",
      " [0.22139207]\n",
      " [0.08482659]\n",
      " [0.15702426]\n",
      " [0.49127102]\n",
      " [0.18666974]\n",
      " [0.08888733]\n",
      " [0.28376245]\n",
      " [0.12386709]\n",
      " [0.13672435]\n",
      " [0.07042196]\n",
      " [0.1435821 ]\n",
      " [0.14071399]\n",
      " [0.06365621]\n",
      " [0.22775021]\n",
      " [0.16682202]\n",
      " [0.2539716 ]\n",
      " [0.20521292]\n",
      " [0.12533566]\n",
      " [0.20813131]\n",
      " [0.17065665]\n",
      " [0.08168048]\n",
      " [0.30371588]\n",
      " [0.19264987]\n",
      " [0.17769063]\n",
      " [0.4731826 ]\n",
      " [0.10515371]\n",
      " [0.14388445]\n",
      " [0.11180535]\n",
      " [0.20099384]\n",
      " [0.10959017]\n",
      " [0.13457334]\n",
      " [0.15359396]\n",
      " [0.14794713]\n",
      " [0.25233763]\n",
      " [0.08089247]\n",
      " [0.14496952]\n",
      " [0.09522685]\n",
      " [0.200791  ]\n",
      " [0.18455327]\n",
      " [0.6236517 ]\n",
      " [0.15850699]\n",
      " [0.16051495]\n",
      " [0.13868886]\n",
      " [0.15497321]\n",
      " [0.15768155]\n",
      " [0.06444603]\n",
      " [0.23936304]\n",
      " [0.09255412]\n",
      " [0.2032491 ]\n",
      " [0.12869006]\n",
      " [0.11245745]\n",
      " [0.16380233]\n",
      " [0.12245461]\n",
      " [0.1298565 ]\n",
      " [0.13222149]\n",
      " [0.12450013]\n",
      " [0.10910249]\n",
      " [0.24188617]\n",
      " [0.04747441]\n",
      " [0.16192913]\n",
      " [0.16664428]\n",
      " [0.1017763 ]\n",
      " [0.12102735]\n",
      " [0.426354  ]\n",
      " [0.12254739]\n",
      " [0.14180577]\n",
      " [0.13921118]\n",
      " [0.25869352]\n",
      " [0.14453441]\n",
      " [0.13634646]\n",
      " [0.12132093]\n",
      " [0.17485493]\n",
      " [0.09132051]\n",
      " [0.24231416]\n",
      " [0.22314721]\n",
      " [0.08659926]\n",
      " [0.30523163]\n",
      " [0.12988165]\n",
      " [0.0658173 ]\n",
      " [0.1042968 ]\n",
      " [0.2509529 ]\n",
      " [0.13491184]\n",
      " [0.18581668]\n",
      " [0.10814077]\n",
      " [0.27984244]\n",
      " [0.11742204]\n",
      " [0.15277532]\n",
      " [0.18882054]\n",
      " [0.15131217]\n",
      " [0.14644158]\n",
      " [0.12745866]\n",
      " [0.172667  ]\n",
      " [0.0839656 ]\n",
      " [0.12846339]\n",
      " [0.06899464]\n",
      " [0.08305448]\n",
      " [0.36247712]\n",
      " [0.12720507]\n",
      " [0.09407741]\n",
      " [0.11640176]\n",
      " [0.14496407]\n",
      " [0.1693945 ]\n",
      " [0.17253974]\n",
      " [0.05013672]\n",
      " [0.2696577 ]\n",
      " [0.13793209]\n",
      " [0.04845235]\n",
      " [0.15935123]\n",
      " [0.64393795]\n",
      " [0.15514383]\n",
      " [0.15389588]\n",
      " [0.54456866]\n",
      " [0.13278458]\n",
      " [0.07166246]\n",
      " [0.1182228 ]\n",
      " [0.12966818]\n",
      " [0.15870297]\n",
      " [0.1710057 ]\n",
      " [0.14513978]\n",
      " [0.19866866]\n",
      " [0.14693078]\n",
      " [0.17971253]\n",
      " [0.16024017]\n",
      " [0.18175644]\n",
      " [0.58471876]\n",
      " [0.26858628]\n",
      " [0.26914462]\n",
      " [0.07705197]\n",
      " [0.0948025 ]\n",
      " [0.05654725]\n",
      " [0.09842893]\n",
      " [0.12157813]\n",
      " [0.35087836]\n",
      " [0.10086668]\n",
      " [0.13218766]\n",
      " [0.09327477]\n",
      " [0.5625165 ]\n",
      " [0.10977224]\n",
      " [0.12540185]\n",
      " [0.05478895]\n",
      " [0.1652605 ]\n",
      " [0.22626299]\n",
      " [0.5715996 ]\n",
      " [0.07727218]\n",
      " [0.11473697]\n",
      " [0.16109025]\n",
      " [0.1840676 ]\n",
      " [0.36268514]\n",
      " [0.1009618 ]\n",
      " [0.5722661 ]\n",
      " [0.16112661]\n",
      " [0.13574088]\n",
      " [0.4923044 ]\n",
      " [0.12550399]\n",
      " [0.14484426]\n",
      " [0.10176638]\n",
      " [0.13974404]\n",
      " [0.12228826]\n",
      " [0.19377428]\n",
      " [0.2641025 ]\n",
      " [0.11445144]\n",
      " [0.13628009]\n",
      " [0.28772485]\n",
      " [0.05661771]\n",
      " [0.36274055]\n",
      " [0.14050323]\n",
      " [0.21920487]\n",
      " [0.14116362]\n",
      " [0.15201694]\n",
      " [0.19520181]\n",
      " [0.12945914]\n",
      " [0.30018932]\n",
      " [0.13718262]\n",
      " [0.26814276]\n",
      " [0.16563064]\n",
      " [0.14561582]\n",
      " [0.07463422]\n",
      " [0.1963523 ]\n",
      " [0.16140664]\n",
      " [0.12606809]\n",
      " [0.29972062]\n",
      " [0.2012566 ]\n",
      " [0.18125719]\n",
      " [0.13709825]\n",
      " [0.102741  ]\n",
      " [0.11028063]\n",
      " [0.17805663]\n",
      " [0.18375745]\n",
      " [0.37657413]\n",
      " [0.15298194]\n",
      " [0.10470748]\n",
      " [0.15634266]\n",
      " [0.08504295]\n",
      " [0.2174316 ]\n",
      " [0.09294432]\n",
      " [0.17156781]\n",
      " [0.18369901]\n",
      " [0.07988711]\n",
      " [0.10592987]\n",
      " [0.18082553]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.14583333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 485us/step - loss: 0.4796 - acc: 0.8517 - val_loss: 0.5019 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.4286 - acc: 0.8629 - val_loss: 0.5053 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 106us/step - loss: 0.4009 - acc: 0.8629 - val_loss: 0.4707 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 106us/step - loss: 0.3993 - acc: 0.8629 - val_loss: 0.4652 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.4003 - acc: 0.8629 - val_loss: 0.4854 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 107us/step - loss: 0.4004 - acc: 0.8629 - val_loss: 0.4647 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 109us/step - loss: 0.3950 - acc: 0.8629 - val_loss: 0.4529 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3949 - acc: 0.8629 - val_loss: 0.4669 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 111us/step - loss: 0.3896 - acc: 0.8629 - val_loss: 0.4495 - val_acc: 0.8233\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 108us/step - loss: 0.3883 - acc: 0.8629 - val_loss: 0.4417 - val_acc: 0.8233\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.3822 - acc: 0.8629 - val_loss: 0.4548 - val_acc: 0.8233\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3782 - acc: 0.8625 - val_loss: 0.4349 - val_acc: 0.8233\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 144us/step - loss: 0.3750 - acc: 0.8629 - val_loss: 0.4241 - val_acc: 0.8233\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.3677 - acc: 0.8633 - val_loss: 0.4328 - val_acc: 0.8233\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 137us/step - loss: 0.3607 - acc: 0.8629 - val_loss: 0.4808 - val_acc: 0.8233\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 138us/step - loss: 0.3636 - acc: 0.8658 - val_loss: 0.4122 - val_acc: 0.8250\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 136us/step - loss: 0.3641 - acc: 0.8650 - val_loss: 0.4155 - val_acc: 0.8233\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 147us/step - loss: 0.3636 - acc: 0.8658 - val_loss: 0.4214 - val_acc: 0.8483\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 131us/step - loss: 0.3462 - acc: 0.8683 - val_loss: 0.3839 - val_acc: 0.8533\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 138us/step - loss: 0.3439 - acc: 0.8688 - val_loss: 0.4918 - val_acc: 0.8250\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3385 - acc: 0.8671 - val_loss: 0.4290 - val_acc: 0.8233\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 135us/step - loss: 0.3390 - acc: 0.8688 - val_loss: 0.3865 - val_acc: 0.8300\n",
      "y2_pred:  [[0.15609625]\n",
      " [0.07140508]\n",
      " [0.39061216]\n",
      " [0.05968338]\n",
      " [0.1568135 ]\n",
      " [0.16171011]\n",
      " [0.04920372]\n",
      " [0.18226552]\n",
      " [0.08314094]\n",
      " [0.30179316]\n",
      " [0.16232511]\n",
      " [0.00951728]\n",
      " [0.06129512]\n",
      " [0.08919576]\n",
      " [0.05519712]\n",
      " [0.02560863]\n",
      " [0.04274672]\n",
      " [0.2452853 ]\n",
      " [0.11574903]\n",
      " [0.3583334 ]\n",
      " [0.09210804]\n",
      " [0.03571662]\n",
      " [0.01968229]\n",
      " [0.10488388]\n",
      " [0.06391731]\n",
      " [0.07566506]\n",
      " [0.29912484]\n",
      " [0.21090966]\n",
      " [0.06160185]\n",
      " [0.02664661]\n",
      " [0.22272572]\n",
      " [0.55708414]\n",
      " [0.02043828]\n",
      " [0.0785591 ]\n",
      " [0.05649391]\n",
      " [0.3376487 ]\n",
      " [0.20638728]\n",
      " [0.06934869]\n",
      " [0.03184637]\n",
      " [0.08942211]\n",
      " [0.07175305]\n",
      " [0.02669495]\n",
      " [0.12988022]\n",
      " [0.19909579]\n",
      " [0.09407234]\n",
      " [0.43213338]\n",
      " [0.1498757 ]\n",
      " [0.1588209 ]\n",
      " [0.07301903]\n",
      " [0.19396517]\n",
      " [0.17909867]\n",
      " [0.16076693]\n",
      " [0.13667351]\n",
      " [0.03362277]\n",
      " [0.08271492]\n",
      " [0.16380489]\n",
      " [0.20373711]\n",
      " [0.03975829]\n",
      " [0.06788254]\n",
      " [0.03199318]\n",
      " [0.24838549]\n",
      " [0.15934834]\n",
      " [0.06581897]\n",
      " [0.07638559]\n",
      " [0.32096922]\n",
      " [0.14062154]\n",
      " [0.1690034 ]\n",
      " [0.0266847 ]\n",
      " [0.13722098]\n",
      " [0.04010361]\n",
      " [0.3067428 ]\n",
      " [0.01728317]\n",
      " [0.15065852]\n",
      " [0.06910539]\n",
      " [0.04229605]\n",
      " [0.00334644]\n",
      " [0.11897656]\n",
      " [0.03801769]\n",
      " [0.06052405]\n",
      " [0.22418994]\n",
      " [0.08354539]\n",
      " [0.3665704 ]\n",
      " [0.28750986]\n",
      " [0.07675505]\n",
      " [0.07845634]\n",
      " [0.331087  ]\n",
      " [0.35738233]\n",
      " [0.06366318]\n",
      " [0.03132698]\n",
      " [0.07618701]\n",
      " [0.04038185]\n",
      " [0.0277957 ]\n",
      " [0.08643118]\n",
      " [0.15827912]\n",
      " [0.10503161]\n",
      " [0.01639023]\n",
      " [0.1724374 ]\n",
      " [0.11273924]\n",
      " [0.06862625]\n",
      " [0.02462152]\n",
      " [0.15902421]\n",
      " [0.00621524]\n",
      " [0.0398514 ]\n",
      " [0.13739198]\n",
      " [0.14465603]\n",
      " [0.2281245 ]\n",
      " [0.01549473]\n",
      " [0.03982294]\n",
      " [0.01828137]\n",
      " [0.09741962]\n",
      " [0.03861159]\n",
      " [0.05318016]\n",
      " [0.3925542 ]\n",
      " [0.27257314]\n",
      " [0.07793206]\n",
      " [0.32418633]\n",
      " [0.23372445]\n",
      " [0.11255962]\n",
      " [0.03129542]\n",
      " [0.02417889]\n",
      " [0.06805012]\n",
      " [0.04372266]\n",
      " [0.16424572]\n",
      " [0.10111982]\n",
      " [0.2039764 ]\n",
      " [0.28820544]\n",
      " [0.13116941]\n",
      " [0.2788078 ]\n",
      " [0.06577617]\n",
      " [0.02779058]\n",
      " [0.08564958]\n",
      " [0.35407722]\n",
      " [0.3222886 ]\n",
      " [0.06065938]\n",
      " [0.16582099]\n",
      " [0.08836278]\n",
      " [0.01760662]\n",
      " [0.13136274]\n",
      " [0.17531148]\n",
      " [0.04524586]\n",
      " [0.61035335]\n",
      " [0.11737826]\n",
      " [0.17026737]\n",
      " [0.05740672]\n",
      " [0.33526844]\n",
      " [0.25737768]\n",
      " [0.0905641 ]\n",
      " [0.2865404 ]\n",
      " [0.26993695]\n",
      " [0.09467527]\n",
      " [0.05720893]\n",
      " [0.13781095]\n",
      " [0.15299287]\n",
      " [0.1449284 ]\n",
      " [0.024638  ]\n",
      " [0.08815452]\n",
      " [0.24529445]\n",
      " [0.46220818]\n",
      " [0.1646604 ]\n",
      " [0.09865126]\n",
      " [0.1485601 ]\n",
      " [0.1185683 ]\n",
      " [0.0422349 ]\n",
      " [0.15594211]\n",
      " [0.09828457]\n",
      " [0.05274048]\n",
      " [0.1229991 ]\n",
      " [0.11832523]\n",
      " [0.2526183 ]\n",
      " [0.32149953]\n",
      " [0.01510701]\n",
      " [0.1110785 ]\n",
      " [0.20672923]\n",
      " [0.11611024]\n",
      " [0.00315186]\n",
      " [0.11480671]\n",
      " [0.07338029]\n",
      " [0.0236935 ]\n",
      " [0.16193381]\n",
      " [0.10595316]\n",
      " [0.2562439 ]\n",
      " [0.33527663]\n",
      " [0.11379862]\n",
      " [0.16597125]\n",
      " [0.07261667]\n",
      " [0.09952879]\n",
      " [0.15288493]\n",
      " [0.03852326]\n",
      " [0.36988392]\n",
      " [0.3375879 ]\n",
      " [0.5442749 ]\n",
      " [0.13935444]\n",
      " [0.03223395]\n",
      " [0.08390313]\n",
      " [0.05850863]\n",
      " [0.04918438]\n",
      " [0.10391045]\n",
      " [0.25577876]\n",
      " [0.02264336]\n",
      " [0.0491403 ]\n",
      " [0.38463992]\n",
      " [0.04636595]\n",
      " [0.13961649]\n",
      " [0.06973439]\n",
      " [0.12456307]\n",
      " [0.3642046 ]\n",
      " [0.02353832]\n",
      " [0.15896839]\n",
      " [0.2022501 ]\n",
      " [0.26715547]\n",
      " [0.32058403]\n",
      " [0.07998943]\n",
      " [0.00484911]\n",
      " [0.04058576]\n",
      " [0.3536101 ]\n",
      " [0.01831415]\n",
      " [0.03755546]\n",
      " [0.06158033]\n",
      " [0.1373072 ]\n",
      " [0.04438436]\n",
      " [0.09758279]\n",
      " [0.05231047]\n",
      " [0.17952636]\n",
      " [0.19616666]\n",
      " [0.3507293 ]\n",
      " [0.14505571]\n",
      " [0.20755431]\n",
      " [0.11710164]\n",
      " [0.39772195]\n",
      " [0.08863017]\n",
      " [0.04889247]\n",
      " [0.01491779]\n",
      " [0.08233452]\n",
      " [0.04214957]\n",
      " [0.01166597]\n",
      " [0.0263674 ]\n",
      " [0.026474  ]\n",
      " [0.17214975]\n",
      " [0.2817172 ]\n",
      " [0.04252473]\n",
      " [0.10032645]\n",
      " [0.2700078 ]\n",
      " [0.04634798]\n",
      " [0.65885746]\n",
      " [0.14790565]\n",
      " [0.19032267]\n",
      " [0.09397098]\n",
      " [0.10890579]\n",
      " [0.11527982]\n",
      " [0.1417925 ]\n",
      " [0.08650795]\n",
      " [0.18268234]\n",
      " [0.13392866]\n",
      " [0.03631032]\n",
      " [0.046828  ]\n",
      " [0.4716794 ]\n",
      " [0.24798718]\n",
      " [0.08056292]\n",
      " [0.18748957]\n",
      " [0.13054666]\n",
      " [0.16551426]\n",
      " [0.05566823]\n",
      " [0.06834993]\n",
      " [0.10068244]\n",
      " [0.02098238]\n",
      " [0.3193022 ]\n",
      " [0.11076033]\n",
      " [0.14699385]\n",
      " [0.2643791 ]\n",
      " [0.19547692]\n",
      " [0.22639135]\n",
      " [0.11047956]\n",
      " [0.3175562 ]\n",
      " [0.32396483]\n",
      " [0.09223846]\n",
      " [0.01261809]\n",
      " [0.06840464]\n",
      " [0.06255057]\n",
      " [0.14040932]\n",
      " [0.11759451]\n",
      " [0.09683034]\n",
      " [0.05743676]\n",
      " [0.09645969]\n",
      " [0.09254742]\n",
      " [0.01710466]\n",
      " [0.04616717]\n",
      " [0.06058165]\n",
      " [0.26780015]\n",
      " [0.02322078]\n",
      " [0.0587503 ]\n",
      " [0.03115228]\n",
      " [0.06816751]\n",
      " [0.09452373]\n",
      " [0.07566726]\n",
      " [0.04519615]\n",
      " [0.18746829]\n",
      " [0.07246834]\n",
      " [0.15295327]\n",
      " [0.09544122]\n",
      " [0.10567644]\n",
      " [0.02448466]\n",
      " [0.16912591]\n",
      " [0.3413161 ]\n",
      " [0.03347525]\n",
      " [0.57434577]\n",
      " [0.15462872]\n",
      " [0.00404263]\n",
      " [0.3758082 ]\n",
      " [0.12642628]\n",
      " [0.45272917]\n",
      " [0.06636426]\n",
      " [0.0955382 ]\n",
      " [0.21368891]\n",
      " [0.04685217]\n",
      " [0.11255193]\n",
      " [0.03175861]\n",
      " [0.02470294]\n",
      " [0.24474996]\n",
      " [0.07333618]\n",
      " [0.08481285]\n",
      " [0.75941885]\n",
      " [0.06563678]\n",
      " [0.6243112 ]\n",
      " [0.25202107]\n",
      " [0.08979198]\n",
      " [0.14452732]\n",
      " [0.05121458]\n",
      " [0.09214959]\n",
      " [0.01173254]\n",
      " [0.2573237 ]\n",
      " [0.20898414]\n",
      " [0.26660657]\n",
      " [0.16847508]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.10416666666666667\n",
      "pod:  [0.0, 0.10204081632653061, 0.2857142857142857, 0.3125, 0.1875, 0.14583333333333334, 0.4375, 0.0625, 0.14583333333333334, 0.10416666666666667]\n",
      "pof:  [0.0, 0.0035087719298245615, 0.02456140350877193, 0.08070175438596491, 0.031578947368421054, 0.031578947368421054, 0.02456140350877193, 0.0035087719298245615, 0.014035087719298246, 0.007017543859649123]\n",
      "auc:  [0.5, 0.549266022198353, 0.6305764411027568, 0.6158991228070175, 0.5779605263157894, 0.557127192982456, 0.706469298245614, 0.5294956140350877, 0.5658991228070175, 0.5485745614035088]\n",
      "tn mean:  278.7\n",
      "fp mean:  6.3\n",
      "fn mean:  39.7\n",
      "tp mean:  8.6\n"
     ]
    }
   ],
   "source": [
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(X_train,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=X_train.iloc[train_index], X_train.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print ('tn mean: ',sum(tn_list) / len(tn_list))\n",
    "print ('fp mean: ',sum(fp_list) / len(fp_list))\n",
    "print ('fn mean: ',sum(fn_list) / len(fn_list))\n",
    "print ('tp mean: ',sum(tp_list) / len(tp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 758us/step - loss: 0.5134 - acc: 0.8587 - val_loss: 0.4360 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 181us/step - loss: 0.4048 - acc: 0.8587 - val_loss: 0.4262 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 178us/step - loss: 0.3973 - acc: 0.8587 - val_loss: 0.4218 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 172us/step - loss: 0.3901 - acc: 0.8587 - val_loss: 0.4118 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 172us/step - loss: 0.3868 - acc: 0.8587 - val_loss: 0.4063 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 894us/step - loss: 0.5551 - acc: 0.8203 - val_loss: 0.4324 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 1s 234us/step - loss: 0.4069 - acc: 0.8587 - val_loss: 0.4293 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 182us/step - loss: 0.4023 - acc: 0.8587 - val_loss: 0.4238 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 183us/step - loss: 0.3942 - acc: 0.8587 - val_loss: 0.4319 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 198us/step - loss: 0.3881 - acc: 0.8587 - val_loss: 0.4131 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 871us/step - loss: 0.5074 - acc: 0.8537 - val_loss: 0.4328 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 182us/step - loss: 0.4029 - acc: 0.8587 - val_loss: 0.4346 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 186us/step - loss: 0.4005 - acc: 0.8587 - val_loss: 0.4192 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 187us/step - loss: 0.3905 - acc: 0.8587 - val_loss: 0.4158 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 187us/step - loss: 0.3855 - acc: 0.8587 - val_loss: 0.4272 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 931us/step - loss: 0.5222 - acc: 0.8538 - val_loss: 0.4501 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 178us/step - loss: 0.4053 - acc: 0.8583 - val_loss: 0.4267 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 183us/step - loss: 0.3981 - acc: 0.8583 - val_loss: 0.4445 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 189us/step - loss: 0.3924 - acc: 0.8583 - val_loss: 0.4271 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 205us/step - loss: 0.3805 - acc: 0.8583 - val_loss: 0.4035 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 1ms/step - loss: 0.5407 - acc: 0.8183 - val_loss: 0.4396 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 194us/step - loss: 0.4036 - acc: 0.8583 - val_loss: 0.4405 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 183us/step - loss: 0.3974 - acc: 0.8583 - val_loss: 0.4212 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 196us/step - loss: 0.3928 - acc: 0.8583 - val_loss: 0.4110 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 191us/step - loss: 0.3837 - acc: 0.8583 - val_loss: 0.4069 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5146 - acc: 0.8371 - val_loss: 0.4354 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 220us/step - loss: 0.4041 - acc: 0.8583 - val_loss: 0.4432 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 207us/step - loss: 0.4004 - acc: 0.8583 - val_loss: 0.4223 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 219us/step - loss: 0.3920 - acc: 0.8583 - val_loss: 0.4148 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 207us/step - loss: 0.3892 - acc: 0.8583 - val_loss: 0.4071 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.4988 - acc: 0.8583 - val_loss: 0.4338 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 195us/step - loss: 0.4017 - acc: 0.8583 - val_loss: 0.4260 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 196us/step - loss: 0.3936 - acc: 0.8583 - val_loss: 0.4154 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 192us/step - loss: 0.3886 - acc: 0.8583 - val_loss: 0.4139 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 192us/step - loss: 0.3803 - acc: 0.8583 - val_loss: 0.4098 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.5320 - acc: 0.8583 - val_loss: 0.4344 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 196us/step - loss: 0.4061 - acc: 0.8583 - val_loss: 0.4296 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 211us/step - loss: 0.4033 - acc: 0.8583 - val_loss: 0.4242 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 220us/step - loss: 0.3969 - acc: 0.8583 - val_loss: 0.4205 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 225us/step - loss: 0.3916 - acc: 0.8583 - val_loss: 0.4124 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.5094 - acc: 0.8600 - val_loss: 0.4608 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 277us/step - loss: 0.3949 - acc: 0.8629 - val_loss: 0.4889 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 271us/step - loss: 0.3926 - acc: 0.8629 - val_loss: 0.4556 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 267us/step - loss: 0.3871 - acc: 0.8629 - val_loss: 0.4444 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 262us/step - loss: 0.3798 - acc: 0.8629 - val_loss: 0.4294 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.4995 - acc: 0.8625 - val_loss: 0.4751 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 252us/step - loss: 0.3936 - acc: 0.8629 - val_loss: 0.4564 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 285us/step - loss: 0.3916 - acc: 0.8629 - val_loss: 0.4499 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 257us/step - loss: 0.3823 - acc: 0.8629 - val_loss: 0.4409 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 294us/step - loss: 0.3742 - acc: 0.8629 - val_loss: 0.4414 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "tn mean:  285.0\n",
      "fp mean:  0.0\n",
      "fn mean:  48.3\n",
      "tp mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "def get_RNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    import pandas as pd\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Dropout, LSTM, GRU\n",
    "    from keras.layers import Embedding\n",
    "    max_features = 10000 # number of words to consider as features\n",
    "    import numpy as np\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(X_train,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=X_train.iloc[train_index], X_train.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_RNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    \n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print ('tn mean: ',sum(tn_list) / len(tn_list))\n",
    "print ('fp mean: ',sum(fp_list) / len(fp_list))\n",
    "print ('fn mean: ',sum(fn_list) / len(fn_list))\n",
    "print ('tp mean: ',sum(tp_list) / len(tp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 3s 1ms/step - loss: 2.2776 - acc: 0.8587 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 1s 301us/step - loss: 2.2776 - acc: 0.8587 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 1s 304us/step - loss: 2.2776 - acc: 0.8587 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 1s 314us/step - loss: 2.2776 - acc: 0.8587 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 1s 278us/step - loss: 2.2776 - acc: 0.8587 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "y22_pred:  [[-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 3s 1ms/step - loss: 0.4417 - acc: 0.8587 - val_loss: 0.4390 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 1s 296us/step - loss: 0.4065 - acc: 0.8587 - val_loss: 0.4278 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 1s 278us/step - loss: 0.3983 - acc: 0.8587 - val_loss: 0.4213 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 1s 290us/step - loss: 0.3924 - acc: 0.8587 - val_loss: 0.4162 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 1s 291us/step - loss: 0.3865 - acc: 0.8587 - val_loss: 0.4108 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 3s 1ms/step - loss: 1.7803 - acc: 0.8587 - val_loss: 0.6518 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 1s 266us/step - loss: 0.5022 - acc: 0.8587 - val_loss: 0.5286 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 1s 299us/step - loss: 0.4444 - acc: 0.8587 - val_loss: 0.4726 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 1s 300us/step - loss: 0.4201 - acc: 0.8587 - val_loss: 0.4490 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 1s 307us/step - loss: 0.4064 - acc: 0.8587 - val_loss: 0.4369 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 1.3531 - acc: 0.8583 - val_loss: 0.6128 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 321us/step - loss: 0.5243 - acc: 0.8583 - val_loss: 0.5261 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 322us/step - loss: 0.4587 - acc: 0.8583 - val_loss: 0.4865 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 334us/step - loss: 0.4294 - acc: 0.8583 - val_loss: 0.4593 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 331us/step - loss: 0.4094 - acc: 0.8583 - val_loss: 0.4396 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.7228 - acc: 0.8583 - val_loss: 0.5701 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 389us/step - loss: 0.4687 - acc: 0.8583 - val_loss: 0.4988 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 359us/step - loss: 0.4394 - acc: 0.8583 - val_loss: 0.4741 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 363us/step - loss: 0.4213 - acc: 0.8583 - val_loss: 0.4543 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 427us/step - loss: 0.4089 - acc: 0.8583 - val_loss: 0.4417 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 2.2834 - acc: 0.8583 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 273us/step - loss: 2.2834 - acc: 0.8583 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 280us/step - loss: 2.2834 - acc: 0.8583 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 290us/step - loss: 2.2834 - acc: 0.8583 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 291us/step - loss: 2.2834 - acc: 0.8583 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "y22_pred:  [[-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 2.2792 - acc: 0.8583 - val_loss: 2.5520 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 339us/step - loss: 2.2782 - acc: 0.8583 - val_loss: 2.5359 - val_acc: 0.8417\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 1s 328us/step - loss: 2.2781 - acc: 0.8583 - val_loss: 2.5373 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 295us/step - loss: 2.2780 - acc: 0.8583 - val_loss: 2.5343 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 307us/step - loss: 2.2470 - acc: 0.8583 - val_loss: 2.3322 - val_acc: 0.8417\n",
      "y22_pred:  [[-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [ 0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.4765 - acc: 0.8583 - val_loss: 0.4644 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 275us/step - loss: 0.4136 - acc: 0.8583 - val_loss: 0.4433 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 279us/step - loss: 0.4027 - acc: 0.8583 - val_loss: 0.4341 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 290us/step - loss: 0.3972 - acc: 0.8583 - val_loss: 0.4287 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 277us/step - loss: 0.3927 - acc: 0.8583 - val_loss: 0.4249 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.4257 - acc: 0.8629 - val_loss: 0.4896 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 303us/step - loss: 0.3996 - acc: 0.8629 - val_loss: 0.4714 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 316us/step - loss: 0.3922 - acc: 0.8629 - val_loss: 0.4675 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 349us/step - loss: 0.3876 - acc: 0.8629 - val_loss: 0.4620 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 319us/step - loss: 0.3831 - acc: 0.8629 - val_loss: 0.4579 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 19, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 18, 32)            8224      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 3, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,290,337\n",
      "Trainable params: 1,290,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 4s 1ms/step - loss: 0.6104 - acc: 0.8629 - val_loss: 0.5752 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 1s 284us/step - loss: 0.4569 - acc: 0.8629 - val_loss: 0.5303 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 1s 290us/step - loss: 0.4249 - acc: 0.8629 - val_loss: 0.5015 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 1s 290us/step - loss: 0.4090 - acc: 0.8629 - val_loss: 0.4813 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 1s 282us/step - loss: 0.4007 - acc: 0.8629 - val_loss: 0.4728 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "tn mean:  285.0\n",
      "fp mean:  0.0\n",
      "fn mean:  48.3\n",
      "tp mean:  0.0\n"
     ]
    }
   ],
   "source": [
    "#CNN - 1D CNN\n",
    "def get_CNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras import layers\n",
    "    from keras.optimizers import RMSprop\n",
    "    max_features = 10000 # number of words to consider as features\n",
    "    \n",
    "    model = Sequential()\n",
    "    #model.add(layers.Embedding(max_features, 128, input_length=96))\n",
    "    model.add(layers.Embedding(max_features, 128, input_length=19))\n",
    "    model.add(layers.Conv1D(32, 2, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(5))\n",
    "    model.add(layers.Conv1D(32, 2, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    y22_pred[y22_pred ==2.0]=1\n",
    "   # y22_pred=y22_pred[y22_pred > 1.0]=1\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(X_train,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=X_train.iloc[train_index], X_train.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_CNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print ('tn mean: ',sum(tn_list) / len(tn_list))\n",
    "print ('fp mean: ',sum(fp_list) / len(fp_list))\n",
    "print ('fn mean: ',sum(fn_list) / len(fn_list))\n",
    "print ('tp mean: ',sum(tp_list) / len(tp_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
