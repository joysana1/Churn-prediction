{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"churn-data-3333.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  area_code  number_vmail_messages  total_day_minutes  \\\n",
       "0             128        415                     25              265.1   \n",
       "1             107        415                     26              161.6   \n",
       "2             137        415                      0              243.4   \n",
       "3              84        408                      0              299.4   \n",
       "4              75        415                      0              166.7   \n",
       "\n",
       "   total_day_calls  total_day_charge  total_eve_minutes  total_eve_calls  \\\n",
       "0              110             45.07              197.4               99   \n",
       "1              123             27.47              195.5              103   \n",
       "2              114             41.38              121.2              110   \n",
       "3               71             50.90               61.9               88   \n",
       "4              113             28.34              148.3              122   \n",
       "\n",
       "   total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0             16.78                244.7                 91   \n",
       "1             16.62                254.4                103   \n",
       "2             10.30                162.6                104   \n",
       "3              5.26                196.9                 89   \n",
       "4             12.61                186.9                121   \n",
       "\n",
       "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0               11.01                10.0                 3   \n",
       "1               11.45                13.7                 3   \n",
       "2                7.32                12.2                 5   \n",
       "3                8.86                 6.6                 7   \n",
       "4                8.41                10.1                 3   \n",
       "\n",
       "   total_intl_charge  number_customer_service_calls  \n",
       "0               2.70                              1  \n",
       "1               3.70                              1  \n",
       "2               3.29                              0  \n",
       "3               1.78                              2  \n",
       "4               2.73                              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "\n",
    "churn=cat_df['churn']\n",
    "cat_df=cat_df.drop(['churn'], axis=1)\n",
    "cat_df=cat_df.drop(['phone number'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#BOX-COX\n",
    "#lemda=0.5\n",
    "#num_df=(num_df**lemda)\n",
    "#num_df=num_df-1\n",
    "#num_df[num_df < 0]=0\n",
    "#num_df=num_df.div(lemda)\n",
    "#End BOX-COX\n",
    "#Z-score\n",
    "num_df=(num_df-num_df.min())/(num_df.std(ddof=0)) ##Z-score\n",
    "\n",
    "#Log\n",
    "#num_df=round(np.log(num_df.add(1)),2)\n",
    "#num_df=num_df.replace([np.inf, -np.inf], np.nan)\n",
    "#End Log\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "X_train=X\n",
    "X_test=X\n",
    "y_train=y\n",
    "y_test=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>international_plan</td>\n",
       "      <td>203.244178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number_customer_service_calls</td>\n",
       "      <td>122.233984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number_vmail_messages</td>\n",
       "      <td>45.346680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_day_minutes</td>\n",
       "      <td>42.493620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_day_charge</td>\n",
       "      <td>42.492734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>voice_mail_plan</td>\n",
       "      <td>25.156959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_eve_minutes</td>\n",
       "      <td>7.241018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_eve_charge</td>\n",
       "      <td>7.239392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_intl_calls</td>\n",
       "      <td>5.113190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_intl_charge</td>\n",
       "      <td>4.233468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_intl_minutes</td>\n",
       "      <td>4.231924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>state</td>\n",
       "      <td>1.701057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_night_minutes</td>\n",
       "      <td>1.194975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_night_charge</td>\n",
       "      <td>1.194573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account_length</td>\n",
       "      <td>0.362847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_day_calls</td>\n",
       "      <td>0.226903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_code</td>\n",
       "      <td>0.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_eve_calls</td>\n",
       "      <td>0.056535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_night_calls</td>\n",
       "      <td>0.036649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature      Scores\n",
       "17             international_plan  203.244178\n",
       "15  number_customer_service_calls  122.233984\n",
       "2           number_vmail_messages   45.346680\n",
       "3               total_day_minutes   42.493620\n",
       "5                total_day_charge   42.492734\n",
       "18                voice_mail_plan   25.156959\n",
       "6               total_eve_minutes    7.241018\n",
       "8                total_eve_charge    7.239392\n",
       "13               total_intl_calls    5.113190\n",
       "14              total_intl_charge    4.233468\n",
       "12             total_intl_minutes    4.231924\n",
       "16                          state    1.701057\n",
       "9             total_night_minutes    1.194975\n",
       "11             total_night_charge    1.194573\n",
       "0                  account_length    0.362847\n",
       "4                 total_day_calls    0.226903\n",
       "1                       area_code    0.184453\n",
       "7                 total_eve_calls    0.056535\n",
       "10              total_night_calls    0.036649"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X\n",
    "y_train=y\n",
    "#Univariate Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "select_feature = SelectKBest(chi2, k=15).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                     'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y\n",
    "X_train=X\n",
    "x_train_chi = select_feature.transform(X)\n",
    "x_train_chi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2623 227 224 259\n",
      "pod:  0.5362318840579711\n",
      "pof:  0.07964912280701754\n",
      "AUC:  0.7282913806254768\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.0006579332246575676}\n",
      "GaussianNB(priors=None, var_smoothing=0.0006579332246575676)\n",
      "0.8804880488048805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=5, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "classifier=GaussianNB();\n",
    "#params = {\n",
    "#          \"priors\" : \"None\",\n",
    "#          \"var_smoothing\" : 1e-9\n",
    "#}\n",
    "#create an list of var_smoothing to cross validate\n",
    "#steps = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "grid = GridSearchCV(estimator=classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    " \n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26710 23728 21590 27972\n",
      "pod:  0.5643840038739357\n",
      "pof:  0.4704389547563345\n",
      "AUC:  0.5469725245588006\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2773 77 320 163\n",
      "pod:  0.33747412008281574\n",
      "pof:  0.027017543859649124\n",
      "AUC:  0.6552282881115833\n",
      "accuracy:  0.8808880888088809\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB(priors=None, var_smoothing=0.0006579332246575676)\n",
    "\n",
    "classifier.fit(x_train_chi,y_train)\n",
    "\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=10, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 5)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.54812\n"
     ]
    }
   ],
   "source": [
    " #accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "accuracy=(26836+27976)/(27976+22462+22726+26836)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8628862886288629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},    \n",
    "    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}\n",
    "]\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2774 76 381 102\n",
      "pod:  0.2111801242236025\n",
      "pof:  0.02666666666666667\n",
      "AUC:  0.5922567287784679\n",
      "accuracy:  0.8628862886288629\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.8748874887488749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "param_grid ={\n",
    "   'n_neighbors': [3,5,11,19],\n",
    "   'weights': ['uniform', 'distance'],\n",
    "   'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=3, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 410.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 1993.6min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "# Specify parameters\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 1e-3, 1e-4]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'], \n",
    "                     'gamma': [0.001, 0.01, 0.1, 1, 1e-3, 1e-4], \n",
    "                     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} ]\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2832 18 392 91\n",
      "pod:  0.18840579710144928\n",
      "pof:  0.00631578947368421\n",
      "AUC:  0.5910450038138825\n",
      "accuracy:  0.876987698769877\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "           weights='uniform' )  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2829 21 414 69\n",
      "pod:  0.14285714285714285\n",
      "pof:  0.007368421052631579\n",
      "AUC:  0.5677443609022557\n",
      "accuracy:  0.8694869486948695\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 90, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.9507950795079508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "#clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "#parameters = {'n_estimators': [4, 6, 9], \n",
    "#              'max_features': ['log2', 'sqrt','auto'], \n",
    "#              'criterion': ['entropy', 'gini'],\n",
    "#              'max_depth': [2, 3, 5, 10], \n",
    "#              'min_samples_split': [2, 3, 5],\n",
    "#              'min_samples_leaf': [1,5,8]\n",
    "#             }\n",
    "\n",
    "#model_params = {\n",
    "#    'n_estimators': [50, 150, 250],\n",
    "#    'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "#    'min_samples_split': [2, 4, 6]\n",
    "#}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830 20 141 342\n",
      "pod:  0.7080745341614907\n",
      "pof:  0.007017543859649123\n",
      "AUC:  0.8505284951509208\n",
      "accuracy:  0.9516951695169517\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(\n",
    "bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=90, max_features=3, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=3, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831 19 153 330\n",
      "pod:  0.6832298136645962\n",
      "pof:  0.006666666666666667\n",
      "AUC:  0.8382815734989648\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5e0d0cc5441c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_chi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717 133 130 353\n",
      "pod:  0.7308488612836439\n",
      "pof:  0.04666666666666667\n",
      "AUC:  0.8420910973084886\n",
      "accuracy:  0.9210921092109211\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720 130 126 357\n",
      "pod:  0.7391304347826086\n",
      "pof:  0.0456140350877193\n",
      "AUC:  0.8467581998474447\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810 40 131 352\n",
      "pod:  0.7287784679089027\n",
      "pof:  0.014035087719298246\n",
      "AUC:  0.8573716900948022\n",
      "accuracy:  0.9486948694869487\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#classifier = GradientBoostingClassifier(max_features=None, max_depth=3, criterion='friedman_mse')\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809 41 128 355\n",
      "pod:  0.7349896480331263\n",
      "pof:  0.014385964912280702\n",
      "AUC:  0.8603018415604229\n",
      "accuracy:  0.9492949294929492\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 219us/step - loss: 0.4571 - acc: 0.8479 - val_loss: 0.4307 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 70us/step - loss: 0.4088 - acc: 0.8587 - val_loss: 0.4256 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 73us/step - loss: 0.3985 - acc: 0.8587 - val_loss: 0.4635 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 72us/step - loss: 0.3977 - acc: 0.8587 - val_loss: 0.4432 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 77us/step - loss: 0.3905 - acc: 0.8587 - val_loss: 0.3926 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 70us/step - loss: 0.3685 - acc: 0.8595 - val_loss: 0.3923 - val_acc: 0.8500\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 71us/step - loss: 0.3664 - acc: 0.8620 - val_loss: 0.3955 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 70us/step - loss: 0.3533 - acc: 0.8554 - val_loss: 0.3806 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 75us/step - loss: 0.3442 - acc: 0.8662 - val_loss: 0.3604 - val_acc: 0.8550\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 72us/step - loss: 0.3322 - acc: 0.8704 - val_loss: 0.3451 - val_acc: 0.8567\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 74us/step - loss: 0.3140 - acc: 0.8758 - val_loss: 0.3611 - val_acc: 0.8617\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 68us/step - loss: 0.3164 - acc: 0.8737 - val_loss: 0.3494 - val_acc: 0.8650\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 67us/step - loss: 0.3136 - acc: 0.8737 - val_loss: 0.3890 - val_acc: 0.8467\n",
      "y2_pred:  [[1.91752493e-01]\n",
      " [1.14799589e-01]\n",
      " [5.57557702e-01]\n",
      " [7.12376952e-01]\n",
      " [6.16403282e-01]\n",
      " [5.58648884e-01]\n",
      " [1.30175203e-01]\n",
      " [3.95530879e-01]\n",
      " [1.73829436e-01]\n",
      " [1.95495933e-01]\n",
      " [5.31685472e-01]\n",
      " [4.44306761e-01]\n",
      " [1.02411300e-01]\n",
      " [3.73893440e-01]\n",
      " [4.77251828e-01]\n",
      " [6.15541399e-01]\n",
      " [3.28353643e-02]\n",
      " [1.39265448e-01]\n",
      " [8.29348564e-02]\n",
      " [4.95954156e-01]\n",
      " [6.08135164e-02]\n",
      " [5.31334639e-01]\n",
      " [8.54252875e-02]\n",
      " [1.22809798e-01]\n",
      " [7.29809403e-02]\n",
      " [4.77987796e-01]\n",
      " [7.05519319e-02]\n",
      " [6.32418752e-01]\n",
      " [6.13244236e-01]\n",
      " [1.08986288e-01]\n",
      " [1.47706836e-01]\n",
      " [5.75095296e-01]\n",
      " [1.58060193e-01]\n",
      " [5.42480826e-01]\n",
      " [1.06804878e-01]\n",
      " [1.25058055e-01]\n",
      " [1.69071853e-02]\n",
      " [1.00021333e-01]\n",
      " [1.24534309e-01]\n",
      " [9.68511701e-02]\n",
      " [3.62296075e-01]\n",
      " [5.52154779e-02]\n",
      " [2.92771757e-02]\n",
      " [2.90398359e-01]\n",
      " [2.32584447e-01]\n",
      " [1.24128699e-01]\n",
      " [4.27592963e-01]\n",
      " [1.65939033e-01]\n",
      " [5.70859015e-01]\n",
      " [2.96377242e-02]\n",
      " [3.63549411e-01]\n",
      " [5.06026387e-01]\n",
      " [4.29256260e-01]\n",
      " [2.20808744e-01]\n",
      " [3.25364888e-01]\n",
      " [9.66659188e-02]\n",
      " [1.07385606e-01]\n",
      " [1.05547577e-01]\n",
      " [1.71734244e-01]\n",
      " [4.86120492e-01]\n",
      " [7.69483745e-02]\n",
      " [3.04385722e-02]\n",
      " [3.54313344e-01]\n",
      " [2.84965813e-01]\n",
      " [2.66832590e-01]\n",
      " [5.72181642e-02]\n",
      " [6.03255451e-01]\n",
      " [2.55699396e-01]\n",
      " [2.86321849e-01]\n",
      " [4.56793129e-01]\n",
      " [4.59677368e-01]\n",
      " [3.77199650e-02]\n",
      " [4.68034506e-01]\n",
      " [4.49997038e-01]\n",
      " [4.09955859e-01]\n",
      " [4.15848315e-01]\n",
      " [6.45945430e-01]\n",
      " [5.26742280e-01]\n",
      " [5.65269768e-01]\n",
      " [1.94657505e-01]\n",
      " [2.52315581e-01]\n",
      " [6.31081820e-01]\n",
      " [2.56445110e-01]\n",
      " [3.40484560e-01]\n",
      " [3.45033020e-01]\n",
      " [3.01186442e-02]\n",
      " [3.95092756e-01]\n",
      " [3.21315587e-01]\n",
      " [1.00011408e-01]\n",
      " [4.73381072e-01]\n",
      " [2.24913716e-01]\n",
      " [2.74533927e-01]\n",
      " [3.88754308e-02]\n",
      " [6.00151956e-01]\n",
      " [3.97453785e-01]\n",
      " [5.36936224e-01]\n",
      " [2.22522795e-01]\n",
      " [4.46578503e-01]\n",
      " [5.38161457e-01]\n",
      " [5.10171413e-01]\n",
      " [1.40550643e-01]\n",
      " [9.67141986e-02]\n",
      " [1.30338341e-01]\n",
      " [4.86048758e-02]\n",
      " [8.44419897e-02]\n",
      " [4.86824393e-01]\n",
      " [5.32601297e-01]\n",
      " [1.00076139e-01]\n",
      " [1.33784413e-02]\n",
      " [3.70730102e-01]\n",
      " [1.37948632e-01]\n",
      " [2.38334864e-01]\n",
      " [3.49722087e-01]\n",
      " [4.92534637e-02]\n",
      " [5.59261143e-02]\n",
      " [6.01413310e-01]\n",
      " [1.85172796e-01]\n",
      " [7.03027666e-01]\n",
      " [2.18398690e-01]\n",
      " [4.99027580e-01]\n",
      " [5.34367502e-01]\n",
      " [1.39942557e-01]\n",
      " [3.17909420e-01]\n",
      " [1.38672054e-01]\n",
      " [1.82877094e-01]\n",
      " [1.98432267e-01]\n",
      " [7.37852454e-01]\n",
      " [2.12808669e-01]\n",
      " [1.43786222e-01]\n",
      " [1.38374060e-01]\n",
      " [4.28396821e-01]\n",
      " [2.04998493e-01]\n",
      " [5.68102479e-01]\n",
      " [3.03866148e-01]\n",
      " [8.50557685e-02]\n",
      " [4.22846913e-01]\n",
      " [2.70145923e-01]\n",
      " [2.73793459e-01]\n",
      " [9.88781452e-04]\n",
      " [1.62196875e-01]\n",
      " [1.37272447e-01]\n",
      " [3.37796807e-02]\n",
      " [1.06404632e-01]\n",
      " [5.26863992e-01]\n",
      " [5.46824455e-01]\n",
      " [2.88305342e-01]\n",
      " [1.69596642e-01]\n",
      " [5.97056985e-01]\n",
      " [2.60742605e-01]\n",
      " [8.86935592e-02]\n",
      " [1.17222756e-01]\n",
      " [5.96089363e-02]\n",
      " [4.77128297e-01]\n",
      " [4.80927408e-01]\n",
      " [5.41107357e-01]\n",
      " [6.63654804e-02]\n",
      " [7.92863607e-01]\n",
      " [7.01461434e-02]\n",
      " [5.33024609e-01]\n",
      " [6.07956946e-02]\n",
      " [1.41263425e-01]\n",
      " [4.08597529e-01]\n",
      " [1.14012450e-01]\n",
      " [1.52809143e-01]\n",
      " [3.56935680e-01]\n",
      " [1.18819177e-01]\n",
      " [2.85482407e-02]\n",
      " [2.07167774e-01]\n",
      " [7.37717748e-03]\n",
      " [4.30412650e-01]\n",
      " [4.06332701e-01]\n",
      " [1.77357823e-01]\n",
      " [2.42137879e-01]\n",
      " [2.60298312e-01]\n",
      " [3.67954314e-01]\n",
      " [5.94966292e-01]\n",
      " [1.82773232e-01]\n",
      " [3.04265201e-01]\n",
      " [2.59118855e-01]\n",
      " [5.70493937e-01]\n",
      " [5.04047990e-01]\n",
      " [1.80012316e-01]\n",
      " [7.43025243e-02]\n",
      " [4.04556632e-01]\n",
      " [3.66108209e-01]\n",
      " [5.23746192e-01]\n",
      " [2.45650202e-01]\n",
      " [3.83239508e-01]\n",
      " [1.03222311e-01]\n",
      " [5.50439894e-01]\n",
      " [1.30573630e-01]\n",
      " [2.41869420e-01]\n",
      " [4.93619651e-01]\n",
      " [1.54643267e-01]\n",
      " [2.89218128e-01]\n",
      " [1.34386837e-01]\n",
      " [1.96076840e-01]\n",
      " [5.80411494e-01]\n",
      " [7.23525047e-01]\n",
      " [2.38023102e-02]\n",
      " [3.89578581e-01]\n",
      " [2.81053007e-01]\n",
      " [5.40680528e-01]\n",
      " [1.77347869e-01]\n",
      " [1.14898801e-01]\n",
      " [1.47826761e-01]\n",
      " [3.40236038e-01]\n",
      " [4.48270172e-01]\n",
      " [3.55408311e-01]\n",
      " [3.72076750e-01]\n",
      " [5.16538203e-01]\n",
      " [3.49957317e-01]\n",
      " [9.79398787e-02]\n",
      " [2.07667351e-02]\n",
      " [6.86123610e-01]\n",
      " [2.61690617e-01]\n",
      " [7.01843798e-02]\n",
      " [2.79819995e-01]\n",
      " [4.22172576e-01]\n",
      " [3.09517264e-01]\n",
      " [2.47941583e-01]\n",
      " [7.66493976e-02]\n",
      " [2.45888174e-01]\n",
      " [3.09537649e-01]\n",
      " [5.25608778e-01]\n",
      " [5.45962632e-01]\n",
      " [4.26448911e-01]\n",
      " [1.98154747e-02]\n",
      " [2.04617202e-01]\n",
      " [1.10212177e-01]\n",
      " [7.25558043e-01]\n",
      " [3.52772951e-01]\n",
      " [4.07123744e-01]\n",
      " [4.05584008e-01]\n",
      " [4.38321620e-01]\n",
      " [7.60100126e-01]\n",
      " [7.71753192e-02]\n",
      " [2.46178567e-01]\n",
      " [4.12123203e-02]\n",
      " [3.22500527e-01]\n",
      " [4.54500645e-01]\n",
      " [7.44080126e-01]\n",
      " [5.54950953e-01]\n",
      " [3.26902986e-01]\n",
      " [2.16367543e-01]\n",
      " [1.76564276e-01]\n",
      " [4.12170887e-02]\n",
      " [2.61184275e-01]\n",
      " [3.11040401e-01]\n",
      " [1.70114934e-01]\n",
      " [2.92818844e-01]\n",
      " [4.68038827e-01]\n",
      " [4.38015580e-01]\n",
      " [2.95393467e-02]\n",
      " [3.07387382e-01]\n",
      " [1.20289207e-01]\n",
      " [7.22214580e-02]\n",
      " [1.26146346e-01]\n",
      " [6.45877600e-01]\n",
      " [2.27934986e-01]\n",
      " [9.48982835e-02]\n",
      " [1.11160427e-01]\n",
      " [1.72747195e-01]\n",
      " [2.56248057e-01]\n",
      " [5.30767441e-01]\n",
      " [7.13392496e-02]\n",
      " [1.65313989e-01]\n",
      " [3.49150360e-01]\n",
      " [2.85731554e-02]\n",
      " [6.49642348e-01]\n",
      " [3.74329090e-01]\n",
      " [1.63969606e-01]\n",
      " [6.68052137e-02]\n",
      " [2.22268522e-01]\n",
      " [7.37070441e-02]\n",
      " [2.03674614e-01]\n",
      " [4.26020682e-01]\n",
      " [6.51115179e-02]\n",
      " [1.01475716e-02]\n",
      " [4.23077762e-01]\n",
      " [2.59461552e-01]\n",
      " [4.30491149e-01]\n",
      " [2.19815969e-03]\n",
      " [1.28076524e-01]\n",
      " [3.38349551e-01]\n",
      " [3.37521970e-01]\n",
      " [4.07678455e-01]\n",
      " [1.06866360e-01]\n",
      " [3.91916335e-02]\n",
      " [7.23327339e-01]\n",
      " [5.32031059e-04]\n",
      " [1.05567753e-01]\n",
      " [1.60910815e-01]\n",
      " [3.41833174e-01]\n",
      " [9.71547961e-02]\n",
      " [1.42268300e-01]\n",
      " [1.56162322e-01]\n",
      " [7.37518072e-02]\n",
      " [4.50159907e-01]\n",
      " [2.40963072e-01]\n",
      " [3.25269282e-01]\n",
      " [6.10070944e-01]\n",
      " [1.48545533e-01]\n",
      " [4.68766689e-02]\n",
      " [4.06680107e-02]\n",
      " [3.46130013e-01]\n",
      " [6.30541801e-01]\n",
      " [4.69084352e-01]\n",
      " [3.79504472e-01]\n",
      " [1.94064677e-01]\n",
      " [5.65140665e-01]\n",
      " [1.01955533e-01]\n",
      " [5.37977993e-01]\n",
      " [5.68763912e-02]\n",
      " [3.50878835e-02]\n",
      " [2.00639337e-01]\n",
      " [5.59450984e-02]\n",
      " [1.93226159e-01]\n",
      " [1.22207582e-01]\n",
      " [3.26085150e-01]\n",
      " [1.70873880e-01]\n",
      " [1.01229548e-01]\n",
      " [1.46560639e-01]\n",
      " [9.99416411e-02]\n",
      " [3.03703517e-01]\n",
      " [5.38568795e-02]\n",
      " [5.59300184e-04]\n",
      " [1.75619721e-02]\n",
      " [6.96776450e-01]\n",
      " [5.32426119e-01]\n",
      " [3.06408048e-01]\n",
      " [5.38965642e-01]\n",
      " [6.62274897e-01]\n",
      " [5.27568340e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.6122448979591837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 243us/step - loss: 0.4643 - acc: 0.8462 - val_loss: 0.4457 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.4099 - acc: 0.8583 - val_loss: 0.4694 - val_acc: 0.8400\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 62us/step - loss: 0.4115 - acc: 0.8579 - val_loss: 0.4851 - val_acc: 0.8400\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.4068 - acc: 0.8587 - val_loss: 0.4313 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 59us/step - loss: 0.4024 - acc: 0.8587 - val_loss: 0.4065 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 62us/step - loss: 0.3916 - acc: 0.8591 - val_loss: 0.4135 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3820 - acc: 0.8587 - val_loss: 0.4092 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3791 - acc: 0.8587 - val_loss: 0.3948 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3764 - acc: 0.8591 - val_loss: 0.3932 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 60us/step - loss: 0.3634 - acc: 0.8574 - val_loss: 0.3811 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3630 - acc: 0.8608 - val_loss: 0.3725 - val_acc: 0.8433\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 60us/step - loss: 0.3654 - acc: 0.8604 - val_loss: 0.3797 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 61us/step - loss: 0.3588 - acc: 0.8620 - val_loss: 0.3745 - val_acc: 0.8417\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3542 - acc: 0.8612 - val_loss: 0.3699 - val_acc: 0.8417\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 60us/step - loss: 0.3542 - acc: 0.8604 - val_loss: 0.3807 - val_acc: 0.8433\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3645 - acc: 0.8604 - val_loss: 0.3804 - val_acc: 0.8433\n",
      "Epoch 17/30\n",
      "2399/2399 [==============================] - 0s 59us/step - loss: 0.3482 - acc: 0.8641 - val_loss: 0.3747 - val_acc: 0.8383\n",
      "y2_pred:  [[8.23131204e-02]\n",
      " [3.49411964e-02]\n",
      " [1.49226159e-01]\n",
      " [5.25390506e-02]\n",
      " [2.52698302e-01]\n",
      " [1.52676731e-01]\n",
      " [1.73514545e-01]\n",
      " [1.64199561e-01]\n",
      " [4.22469348e-01]\n",
      " [4.97249067e-02]\n",
      " [7.81179667e-02]\n",
      " [5.55648804e-02]\n",
      " [1.08113527e-01]\n",
      " [7.29705095e-02]\n",
      " [2.44865000e-01]\n",
      " [5.05302250e-02]\n",
      " [1.13049150e-01]\n",
      " [1.38950348e-03]\n",
      " [2.33097076e-02]\n",
      " [2.33858824e-02]\n",
      " [1.40450954e-01]\n",
      " [3.31175327e-03]\n",
      " [2.27813095e-01]\n",
      " [3.51480812e-01]\n",
      " [1.82416886e-01]\n",
      " [3.01826715e-01]\n",
      " [7.93851614e-02]\n",
      " [4.09837961e-02]\n",
      " [5.88217378e-02]\n",
      " [3.85352314e-01]\n",
      " [1.41632944e-01]\n",
      " [1.81366295e-01]\n",
      " [7.31067121e-01]\n",
      " [4.80501056e-02]\n",
      " [7.65037239e-02]\n",
      " [8.31234157e-02]\n",
      " [1.76967859e-01]\n",
      " [2.70780325e-01]\n",
      " [3.00636619e-01]\n",
      " [3.66514564e-01]\n",
      " [9.30825174e-02]\n",
      " [9.45310593e-02]\n",
      " [1.33819878e-01]\n",
      " [8.73794258e-02]\n",
      " [7.51030207e-01]\n",
      " [3.63942325e-01]\n",
      " [6.13491297e-01]\n",
      " [1.37370229e-01]\n",
      " [2.67605364e-01]\n",
      " [3.12885404e-01]\n",
      " [2.73906887e-01]\n",
      " [2.95114040e-01]\n",
      " [1.27069950e-01]\n",
      " [2.91757166e-01]\n",
      " [1.09777898e-01]\n",
      " [1.46167099e-01]\n",
      " [1.78685248e-01]\n",
      " [7.99333155e-02]\n",
      " [6.12814844e-01]\n",
      " [3.40565234e-01]\n",
      " [1.78980172e-01]\n",
      " [1.16097420e-01]\n",
      " [8.02438855e-02]\n",
      " [2.74529696e-01]\n",
      " [2.01080918e-01]\n",
      " [9.07046199e-02]\n",
      " [2.93245912e-02]\n",
      " [1.75712943e-01]\n",
      " [8.48035812e-02]\n",
      " [1.99985474e-01]\n",
      " [5.83374739e-01]\n",
      " [2.60886431e-01]\n",
      " [1.07467353e-01]\n",
      " [2.11080104e-01]\n",
      " [4.49167073e-01]\n",
      " [2.02281266e-01]\n",
      " [2.38791943e-01]\n",
      " [1.40693396e-01]\n",
      " [4.13303077e-01]\n",
      " [6.15163624e-01]\n",
      " [1.29952788e-01]\n",
      " [1.45768195e-01]\n",
      " [3.08332026e-01]\n",
      " [1.01508021e-01]\n",
      " [4.09727395e-02]\n",
      " [2.57173389e-01]\n",
      " [9.09135938e-02]\n",
      " [7.25182593e-01]\n",
      " [1.91433340e-01]\n",
      " [1.94334716e-01]\n",
      " [9.16293561e-02]\n",
      " [6.65349722e-01]\n",
      " [7.47652054e-02]\n",
      " [2.74857581e-02]\n",
      " [1.31335169e-01]\n",
      " [1.36201501e-01]\n",
      " [2.83860624e-01]\n",
      " [1.89644694e-01]\n",
      " [3.95271003e-01]\n",
      " [2.26881534e-01]\n",
      " [1.72443777e-01]\n",
      " [2.18059689e-01]\n",
      " [2.55637527e-01]\n",
      " [2.66314030e-01]\n",
      " [1.73309684e-01]\n",
      " [3.51417571e-01]\n",
      " [5.92917204e-04]\n",
      " [4.09326255e-02]\n",
      " [5.62912226e-03]\n",
      " [2.98573554e-01]\n",
      " [2.84680784e-01]\n",
      " [3.79399359e-02]\n",
      " [2.57500499e-01]\n",
      " [3.81497443e-01]\n",
      " [7.01265931e-02]\n",
      " [4.43074167e-01]\n",
      " [7.80069828e-03]\n",
      " [7.81280696e-02]\n",
      " [1.04629546e-01]\n",
      " [4.18911278e-02]\n",
      " [5.66389441e-01]\n",
      " [2.86008507e-01]\n",
      " [7.72996247e-02]\n",
      " [1.80864036e-01]\n",
      " [1.77435279e-01]\n",
      " [1.04517072e-01]\n",
      " [2.40115196e-01]\n",
      " [1.64412022e-01]\n",
      " [5.62959015e-02]\n",
      " [1.07186407e-01]\n",
      " [6.59184456e-02]\n",
      " [7.69280374e-01]\n",
      " [1.11959547e-01]\n",
      " [1.32459730e-01]\n",
      " [4.50035930e-03]\n",
      " [5.09619713e-06]\n",
      " [3.69180918e-01]\n",
      " [1.74225748e-01]\n",
      " [8.21197629e-02]\n",
      " [1.27167046e-01]\n",
      " [3.51480544e-02]\n",
      " [7.44535327e-02]\n",
      " [2.38289624e-01]\n",
      " [1.06236368e-01]\n",
      " [6.12200499e-02]\n",
      " [1.83562338e-01]\n",
      " [6.00125790e-02]\n",
      " [1.74319863e-01]\n",
      " [1.04566485e-01]\n",
      " [7.06788599e-02]\n",
      " [2.17290431e-01]\n",
      " [5.68608642e-02]\n",
      " [6.91480517e-01]\n",
      " [8.68761837e-02]\n",
      " [1.90204293e-01]\n",
      " [6.12381101e-02]\n",
      " [7.72642195e-02]\n",
      " [4.68893200e-01]\n",
      " [6.96481824e-01]\n",
      " [9.22559202e-02]\n",
      " [4.28134888e-01]\n",
      " [2.73291677e-01]\n",
      " [3.46853733e-02]\n",
      " [1.09956950e-01]\n",
      " [8.24264407e-01]\n",
      " [1.58734858e-01]\n",
      " [9.22689140e-02]\n",
      " [8.19008052e-02]\n",
      " [6.69571936e-01]\n",
      " [3.85164738e-01]\n",
      " [7.79194832e-02]\n",
      " [5.14200330e-03]\n",
      " [8.21590126e-02]\n",
      " [5.07951260e-01]\n",
      " [5.28435111e-02]\n",
      " [3.66848707e-01]\n",
      " [6.71407878e-02]\n",
      " [3.16080302e-01]\n",
      " [1.61254346e-01]\n",
      " [7.73527324e-02]\n",
      " [1.24245882e-04]\n",
      " [2.01241672e-02]\n",
      " [2.60191202e-01]\n",
      " [3.01198483e-01]\n",
      " [2.23107010e-01]\n",
      " [2.31881768e-01]\n",
      " [2.22351581e-01]\n",
      " [2.42787391e-01]\n",
      " [5.14563799e-01]\n",
      " [9.86202061e-02]\n",
      " [1.92515731e-01]\n",
      " [6.70585930e-02]\n",
      " [2.44158357e-01]\n",
      " [1.51884556e-02]\n",
      " [1.81341857e-01]\n",
      " [7.70021379e-02]\n",
      " [1.25507176e-01]\n",
      " [7.86174834e-02]\n",
      " [1.53766513e-01]\n",
      " [8.56865942e-02]\n",
      " [5.82544565e-01]\n",
      " [4.91162837e-02]\n",
      " [5.12177050e-02]\n",
      " [6.02396131e-02]\n",
      " [1.08199626e-01]\n",
      " [1.95710659e-01]\n",
      " [1.25586987e-04]\n",
      " [9.50145721e-02]\n",
      " [8.42176139e-01]\n",
      " [4.46124494e-01]\n",
      " [7.50225782e-02]\n",
      " [6.19048178e-02]\n",
      " [3.60283494e-01]\n",
      " [2.70480752e-01]\n",
      " [2.54831314e-02]\n",
      " [3.24395150e-01]\n",
      " [2.36552328e-01]\n",
      " [5.42170048e-01]\n",
      " [3.35414708e-01]\n",
      " [2.47212857e-01]\n",
      " [2.11141884e-01]\n",
      " [2.34357834e-01]\n",
      " [1.00817651e-01]\n",
      " [1.47532076e-01]\n",
      " [2.33477712e-01]\n",
      " [1.02232933e-01]\n",
      " [1.92118675e-01]\n",
      " [5.17881215e-02]\n",
      " [8.17390084e-02]\n",
      " [1.27861410e-01]\n",
      " [1.02291584e-01]\n",
      " [5.93250573e-01]\n",
      " [6.71559572e-03]\n",
      " [6.24428988e-01]\n",
      " [4.49474484e-01]\n",
      " [6.85226917e-01]\n",
      " [1.26535416e-01]\n",
      " [3.18290591e-02]\n",
      " [2.32283115e-01]\n",
      " [1.42716885e-01]\n",
      " [2.46261686e-01]\n",
      " [2.71904349e-01]\n",
      " [1.60446912e-01]\n",
      " [2.52063811e-01]\n",
      " [4.90110517e-02]\n",
      " [2.43596435e-02]\n",
      " [1.11197203e-01]\n",
      " [2.98877299e-01]\n",
      " [1.37689501e-01]\n",
      " [1.17510438e-01]\n",
      " [1.85587525e-01]\n",
      " [9.15181637e-03]\n",
      " [4.14183825e-01]\n",
      " [1.48773581e-01]\n",
      " [1.98685586e-01]\n",
      " [5.46461940e-02]\n",
      " [2.31863201e-01]\n",
      " [1.72894448e-01]\n",
      " [2.79136062e-01]\n",
      " [1.56048119e-01]\n",
      " [1.95798099e-01]\n",
      " [1.29885435e-01]\n",
      " [3.32981348e-01]\n",
      " [2.22093940e-01]\n",
      " [8.56517851e-02]\n",
      " [5.27658463e-02]\n",
      " [1.58119559e-01]\n",
      " [5.13959348e-01]\n",
      " [1.16745204e-01]\n",
      " [1.02988690e-01]\n",
      " [1.68374538e-01]\n",
      " [5.22226572e-01]\n",
      " [7.14370906e-02]\n",
      " [6.38034940e-02]\n",
      " [1.03372753e-01]\n",
      " [2.22343445e-01]\n",
      " [2.99714565e-01]\n",
      " [1.62015170e-01]\n",
      " [3.23909283e-01]\n",
      " [3.62460047e-01]\n",
      " [1.31929964e-01]\n",
      " [5.40414453e-02]\n",
      " [1.97610736e-01]\n",
      " [8.51347744e-02]\n",
      " [1.49960607e-01]\n",
      " [6.05623662e-01]\n",
      " [8.77118111e-02]\n",
      " [6.79501593e-02]\n",
      " [2.06152141e-01]\n",
      " [5.72139800e-01]\n",
      " [7.06743300e-02]\n",
      " [2.95446724e-01]\n",
      " [2.76405066e-01]\n",
      " [4.72142279e-01]\n",
      " [7.91063011e-02]\n",
      " [1.27322912e-01]\n",
      " [1.30600840e-01]\n",
      " [8.10166001e-02]\n",
      " [1.48653388e-01]\n",
      " [8.05712044e-02]\n",
      " [1.93744928e-01]\n",
      " [1.44302160e-01]\n",
      " [6.27000630e-02]\n",
      " [9.96233225e-02]\n",
      " [2.45118320e-01]\n",
      " [6.03369772e-02]\n",
      " [2.70763755e-01]\n",
      " [1.62530690e-01]\n",
      " [6.98027015e-02]\n",
      " [1.16579235e-01]\n",
      " [4.20990884e-02]\n",
      " [4.74423438e-01]\n",
      " [5.23984134e-02]\n",
      " [2.43349880e-01]\n",
      " [1.41835213e-02]\n",
      " [6.94595218e-01]\n",
      " [5.12968838e-01]\n",
      " [1.14526778e-01]\n",
      " [1.87546015e-04]\n",
      " [1.98771387e-01]\n",
      " [3.52659523e-02]\n",
      " [2.46353328e-01]\n",
      " [1.21379018e-01]\n",
      " [4.92695272e-02]\n",
      " [6.58475161e-02]\n",
      " [7.43414164e-02]\n",
      " [2.08780050e-01]\n",
      " [1.99143857e-01]\n",
      " [1.99128136e-01]\n",
      " [3.70995313e-01]\n",
      " [5.13413370e-01]\n",
      " [2.24344894e-01]\n",
      " [3.89426231e-01]\n",
      " [2.80217290e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.2857142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 259us/step - loss: 0.4813 - acc: 0.8474 - val_loss: 0.4805 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 65us/step - loss: 0.4185 - acc: 0.8587 - val_loss: 0.4869 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.4143 - acc: 0.8595 - val_loss: 0.4288 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3950 - acc: 0.8587 - val_loss: 0.4148 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 66us/step - loss: 0.3758 - acc: 0.8612 - val_loss: 0.4134 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 72us/step - loss: 0.3739 - acc: 0.8587 - val_loss: 0.4014 - val_acc: 0.8433\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 65us/step - loss: 0.3740 - acc: 0.8579 - val_loss: 0.4049 - val_acc: 0.8433\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 62us/step - loss: 0.3656 - acc: 0.8637 - val_loss: 0.3730 - val_acc: 0.8483\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 65us/step - loss: 0.3581 - acc: 0.8645 - val_loss: 0.4075 - val_acc: 0.8450\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3595 - acc: 0.8666 - val_loss: 0.3749 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 64us/step - loss: 0.3487 - acc: 0.8679 - val_loss: 0.3596 - val_acc: 0.8467\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3389 - acc: 0.8691 - val_loss: 0.3658 - val_acc: 0.8450\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 63us/step - loss: 0.3381 - acc: 0.8712 - val_loss: 0.3850 - val_acc: 0.8417\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 64us/step - loss: 0.3280 - acc: 0.8733 - val_loss: 0.4235 - val_acc: 0.8467\n",
      "y2_pred:  [[4.55060005e-02]\n",
      " [4.70594764e-02]\n",
      " [5.01632690e-03]\n",
      " [1.03138983e-01]\n",
      " [5.22703826e-02]\n",
      " [9.04905796e-03]\n",
      " [5.35130501e-04]\n",
      " [6.53761625e-03]\n",
      " [7.74914443e-01]\n",
      " [6.88791275e-04]\n",
      " [1.65811449e-01]\n",
      " [4.82435226e-02]\n",
      " [1.76380426e-01]\n",
      " [1.11209333e-01]\n",
      " [1.05141431e-01]\n",
      " [2.33576298e-02]\n",
      " [1.13567710e-03]\n",
      " [1.56250596e-03]\n",
      " [7.05287158e-02]\n",
      " [7.43454695e-02]\n",
      " [9.98597443e-02]\n",
      " [3.04669142e-04]\n",
      " [3.90372455e-01]\n",
      " [9.41300392e-03]\n",
      " [4.86574531e-01]\n",
      " [2.42862344e-01]\n",
      " [3.94982100e-03]\n",
      " [3.35963070e-02]\n",
      " [2.70967960e-01]\n",
      " [2.68324912e-02]\n",
      " [1.48841262e-01]\n",
      " [9.52079892e-03]\n",
      " [9.25331712e-02]\n",
      " [5.91722131e-03]\n",
      " [1.37059391e-02]\n",
      " [2.64224410e-03]\n",
      " [1.57028437e-03]\n",
      " [9.53048468e-03]\n",
      " [1.09151006e-03]\n",
      " [8.81114602e-03]\n",
      " [3.44793588e-01]\n",
      " [1.95813179e-03]\n",
      " [1.69803083e-01]\n",
      " [6.62952065e-02]\n",
      " [1.59701407e-02]\n",
      " [4.08615470e-02]\n",
      " [3.92211676e-02]\n",
      " [2.51204669e-02]\n",
      " [1.24637038e-01]\n",
      " [4.56203818e-02]\n",
      " [1.39049590e-02]\n",
      " [3.26789796e-01]\n",
      " [1.56603575e-01]\n",
      " [9.14441645e-02]\n",
      " [1.09898657e-01]\n",
      " [5.89340925e-04]\n",
      " [4.39441204e-02]\n",
      " [3.57519686e-02]\n",
      " [3.99625301e-03]\n",
      " [1.50604248e-02]\n",
      " [3.70255113e-03]\n",
      " [8.35850835e-02]\n",
      " [5.46117723e-02]\n",
      " [1.83999538e-04]\n",
      " [4.08703983e-02]\n",
      " [4.32067662e-01]\n",
      " [1.74875855e-02]\n",
      " [8.23610127e-02]\n",
      " [4.02878642e-01]\n",
      " [1.32570177e-01]\n",
      " [5.87525964e-03]\n",
      " [4.97579575e-02]\n",
      " [1.36354566e-02]\n",
      " [9.22313333e-03]\n",
      " [1.05827838e-01]\n",
      " [3.35777700e-02]\n",
      " [7.52398968e-02]\n",
      " [4.54410911e-03]\n",
      " [4.85138893e-02]\n",
      " [3.49279046e-02]\n",
      " [8.96835923e-02]\n",
      " [1.53623879e-01]\n",
      " [2.56880224e-02]\n",
      " [1.73196197e-03]\n",
      " [2.19867826e-01]\n",
      " [7.73194432e-03]\n",
      " [2.77985036e-02]\n",
      " [5.44735193e-02]\n",
      " [1.59107447e-02]\n",
      " [4.73406911e-03]\n",
      " [2.53331959e-02]\n",
      " [1.24472082e-02]\n",
      " [5.25337160e-02]\n",
      " [2.55425930e-01]\n",
      " [1.13109112e-01]\n",
      " [1.97428465e-03]\n",
      " [7.12871552e-05]\n",
      " [1.06605887e-01]\n",
      " [1.67711556e-01]\n",
      " [3.82077694e-03]\n",
      " [3.39373469e-01]\n",
      " [8.54181349e-02]\n",
      " [1.94976032e-02]\n",
      " [8.41145813e-02]\n",
      " [4.07865644e-03]\n",
      " [5.53653121e-01]\n",
      " [1.49428546e-02]\n",
      " [4.02396023e-02]\n",
      " [6.97329938e-02]\n",
      " [1.30123615e-01]\n",
      " [5.11677563e-02]\n",
      " [6.08463228e-01]\n",
      " [5.90444684e-01]\n",
      " [3.15562189e-02]\n",
      " [4.65357304e-03]\n",
      " [2.49702424e-01]\n",
      " [2.97787189e-02]\n",
      " [1.79235309e-01]\n",
      " [1.21353567e-02]\n",
      " [1.99760914e-01]\n",
      " [3.21995616e-02]\n",
      " [9.30839181e-02]\n",
      " [1.18419945e-01]\n",
      " [1.52602494e-02]\n",
      " [2.62741506e-01]\n",
      " [8.45634937e-03]\n",
      " [1.54427528e-01]\n",
      " [1.20401353e-01]\n",
      " [3.31036448e-02]\n",
      " [2.25659013e-02]\n",
      " [9.12347436e-03]\n",
      " [2.66202390e-02]\n",
      " [6.33327961e-02]\n",
      " [1.40979946e-01]\n",
      " [8.14900696e-02]\n",
      " [8.69578123e-03]\n",
      " [8.68888497e-02]\n",
      " [1.49908096e-01]\n",
      " [3.41314077e-03]\n",
      " [3.14265490e-04]\n",
      " [4.39958274e-02]\n",
      " [1.62218511e-02]\n",
      " [5.36618531e-02]\n",
      " [2.36818194e-02]\n",
      " [2.89797485e-02]\n",
      " [3.08936834e-03]\n",
      " [1.52742863e-03]\n",
      " [4.09268737e-01]\n",
      " [3.57940495e-02]\n",
      " [6.65929914e-03]\n",
      " [1.92048550e-02]\n",
      " [1.58393383e-02]\n",
      " [3.47375870e-03]\n",
      " [8.09577107e-03]\n",
      " [4.49078381e-02]\n",
      " [5.05188107e-03]\n",
      " [1.66054964e-02]\n",
      " [4.86589074e-02]\n",
      " [1.29549593e-01]\n",
      " [1.65680051e-03]\n",
      " [1.69253290e-01]\n",
      " [2.34183133e-01]\n",
      " [1.96418226e-01]\n",
      " [8.45999718e-02]\n",
      " [1.99969321e-01]\n",
      " [1.09688342e-02]\n",
      " [8.40758383e-02]\n",
      " [5.59458137e-02]\n",
      " [6.15864992e-04]\n",
      " [9.33587551e-03]\n",
      " [3.86822224e-03]\n",
      " [2.25274503e-01]\n",
      " [1.46771967e-02]\n",
      " [4.54775095e-01]\n",
      " [9.76586342e-02]\n",
      " [3.11277807e-02]\n",
      " [8.10125470e-03]\n",
      " [1.95639729e-02]\n",
      " [2.72434056e-02]\n",
      " [6.61537051e-03]\n",
      " [3.00828516e-02]\n",
      " [1.69374675e-01]\n",
      " [4.95013595e-03]\n",
      " [6.61674798e-01]\n",
      " [2.01934546e-01]\n",
      " [4.00464237e-02]\n",
      " [5.32031059e-03]\n",
      " [7.65951574e-02]\n",
      " [4.00614738e-03]\n",
      " [1.95019543e-02]\n",
      " [2.06074119e-03]\n",
      " [2.02581525e-01]\n",
      " [2.67527103e-02]\n",
      " [3.21268439e-02]\n",
      " [4.71952856e-02]\n",
      " [3.25285792e-02]\n",
      " [1.07855171e-01]\n",
      " [3.01045537e-01]\n",
      " [1.37748420e-02]\n",
      " [1.67097449e-02]\n",
      " [2.58420408e-02]\n",
      " [4.07069236e-01]\n",
      " [3.68535519e-03]\n",
      " [3.35642993e-01]\n",
      " [5.87144494e-03]\n",
      " [1.74802542e-03]\n",
      " [8.65537822e-02]\n",
      " [8.48084688e-04]\n",
      " [1.62054360e-01]\n",
      " [3.12499404e-01]\n",
      " [9.83098149e-02]\n",
      " [2.06948221e-02]\n",
      " [5.08359075e-03]\n",
      " [3.99629176e-02]\n",
      " [6.89752996e-02]\n",
      " [8.23625922e-03]\n",
      " [1.69472694e-02]\n",
      " [6.36441708e-02]\n",
      " [1.25080347e-04]\n",
      " [3.73369455e-03]\n",
      " [1.59137428e-01]\n",
      " [2.13243067e-02]\n",
      " [6.10589981e-03]\n",
      " [4.74724472e-02]\n",
      " [1.79052353e-04]\n",
      " [4.65619564e-01]\n",
      " [1.39464408e-01]\n",
      " [1.27081841e-01]\n",
      " [4.06304002e-03]\n",
      " [1.39020503e-01]\n",
      " [4.73496318e-03]\n",
      " [5.10504842e-03]\n",
      " [7.18909502e-03]\n",
      " [2.76184946e-01]\n",
      " [1.62506104e-01]\n",
      " [9.83542204e-03]\n",
      " [2.42951840e-01]\n",
      " [1.54244006e-02]\n",
      " [8.02513957e-03]\n",
      " [1.22091174e-03]\n",
      " [1.49398029e-01]\n",
      " [2.96288729e-03]\n",
      " [7.06785917e-03]\n",
      " [2.15038061e-01]\n",
      " [1.91189945e-02]\n",
      " [1.06157660e-02]\n",
      " [2.78409123e-02]\n",
      " [4.09624279e-02]\n",
      " [3.97720933e-03]\n",
      " [5.92917204e-04]\n",
      " [4.79555726e-02]\n",
      " [1.05063021e-02]\n",
      " [5.37097454e-03]\n",
      " [7.53828883e-03]\n",
      " [7.10397959e-03]\n",
      " [3.25130522e-02]\n",
      " [2.83575356e-02]\n",
      " [1.53313279e-02]\n",
      " [1.06210709e-02]\n",
      " [2.02926993e-03]\n",
      " [3.31446230e-02]\n",
      " [1.77916139e-01]\n",
      " [8.79395008e-03]\n",
      " [1.93196535e-03]\n",
      " [8.62823427e-02]\n",
      " [1.58453345e-01]\n",
      " [2.46891081e-02]\n",
      " [3.53808969e-01]\n",
      " [2.80040503e-03]\n",
      " [2.21988410e-01]\n",
      " [3.79315019e-03]\n",
      " [7.35855103e-03]\n",
      " [4.22943830e-02]\n",
      " [5.23045361e-02]\n",
      " [1.06255114e-02]\n",
      " [1.66406333e-02]\n",
      " [5.27217984e-02]\n",
      " [3.61978114e-02]\n",
      " [1.81909412e-01]\n",
      " [1.30356252e-02]\n",
      " [2.15780735e-03]\n",
      " [1.77655131e-01]\n",
      " [1.35887891e-01]\n",
      " [4.79261279e-02]\n",
      " [9.75771546e-02]\n",
      " [2.94426680e-02]\n",
      " [1.41724914e-01]\n",
      " [3.31929326e-03]\n",
      " [1.29654974e-01]\n",
      " [3.61152887e-02]\n",
      " [6.24803007e-02]\n",
      " [1.00893080e-02]\n",
      " [1.62603348e-01]\n",
      " [2.99798250e-02]\n",
      " [1.79977179e-01]\n",
      " [4.40931320e-03]\n",
      " [1.53609216e-02]\n",
      " [1.51566684e-01]\n",
      " [1.38422847e-02]\n",
      " [1.11230910e-02]\n",
      " [1.14463270e-02]\n",
      " [2.12012827e-02]\n",
      " [1.10104382e-02]\n",
      " [6.77756071e-02]\n",
      " [1.11920834e-01]\n",
      " [1.07644796e-02]\n",
      " [1.03594571e-01]\n",
      " [1.06357694e-01]\n",
      " [1.66356564e-04]\n",
      " [9.00790095e-03]\n",
      " [1.96672857e-01]\n",
      " [5.00616431e-03]\n",
      " [3.83537412e-02]\n",
      " [4.70733643e-03]\n",
      " [5.76145589e-01]\n",
      " [4.46556270e-01]\n",
      " [3.93437564e-01]\n",
      " [1.92055702e-02]\n",
      " [6.91099763e-02]\n",
      " [8.24949145e-03]\n",
      " [1.17107987e-01]\n",
      " [3.35608125e-02]\n",
      " [1.19803011e-01]\n",
      " [1.26577854e-01]\n",
      " [2.85512507e-02]\n",
      " [1.50082707e-02]\n",
      " [3.13939452e-01]\n",
      " [3.17262113e-02]\n",
      " [1.70567706e-01]\n",
      " [1.80366877e-02]\n",
      " [2.28337467e-01]\n",
      " [7.30432495e-02]\n",
      " [1.50907859e-01]\n",
      " [3.20884675e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.061224489795918366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 298us/step - loss: 0.4293 - acc: 0.8583 - val_loss: 0.4218 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.4004 - acc: 0.8583 - val_loss: 0.4123 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.3828 - acc: 0.8608 - val_loss: 0.3966 - val_acc: 0.8467\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.3723 - acc: 0.8625 - val_loss: 0.3906 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.3518 - acc: 0.8646 - val_loss: 0.3795 - val_acc: 0.8550\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3411 - acc: 0.8708 - val_loss: 0.3484 - val_acc: 0.8700\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 67us/step - loss: 0.3255 - acc: 0.8700 - val_loss: 0.3454 - val_acc: 0.8633\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 79us/step - loss: 0.3184 - acc: 0.8738 - val_loss: 0.3561 - val_acc: 0.8567\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3106 - acc: 0.8792 - val_loss: 0.3353 - val_acc: 0.8667\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3009 - acc: 0.8838 - val_loss: 0.3389 - val_acc: 0.8617\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.3025 - acc: 0.8800 - val_loss: 0.3374 - val_acc: 0.8683\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.2959 - acc: 0.8900 - val_loss: 0.3236 - val_acc: 0.8817\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.2849 - acc: 0.8838 - val_loss: 0.3260 - val_acc: 0.8683\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.2702 - acc: 0.8921 - val_loss: 0.3195 - val_acc: 0.8683\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 92us/step - loss: 0.2645 - acc: 0.8946 - val_loss: 0.3296 - val_acc: 0.8567\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.2588 - acc: 0.8967 - val_loss: 0.3309 - val_acc: 0.8650\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.2723 - acc: 0.8867 - val_loss: 0.3088 - val_acc: 0.8717\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.2691 - acc: 0.8937 - val_loss: 0.3171 - val_acc: 0.8733\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.2545 - acc: 0.8996 - val_loss: 0.3180 - val_acc: 0.8650\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.2546 - acc: 0.9008 - val_loss: 0.3265 - val_acc: 0.8533\n",
      "y2_pred:  [[4.69290316e-02]\n",
      " [4.71168339e-01]\n",
      " [1.69474602e-01]\n",
      " [8.15421343e-04]\n",
      " [6.77416205e-01]\n",
      " [6.68995321e-01]\n",
      " [1.00407392e-01]\n",
      " [2.30928361e-02]\n",
      " [5.42266965e-02]\n",
      " [1.98156536e-02]\n",
      " [6.35806918e-02]\n",
      " [8.35032761e-02]\n",
      " [1.43639445e-02]\n",
      " [2.59072185e-01]\n",
      " [1.53172642e-01]\n",
      " [2.88310289e-01]\n",
      " [2.01367736e-02]\n",
      " [4.42474186e-02]\n",
      " [1.34379864e-02]\n",
      " [1.94786489e-02]\n",
      " [2.89363921e-01]\n",
      " [2.45138168e-01]\n",
      " [2.78155208e-02]\n",
      " [3.05714905e-02]\n",
      " [1.12171769e-02]\n",
      " [8.44853342e-01]\n",
      " [4.24713194e-02]\n",
      " [2.75888741e-02]\n",
      " [4.59608436e-02]\n",
      " [1.31551027e-02]\n",
      " [2.58024633e-01]\n",
      " [2.61051953e-02]\n",
      " [1.24712884e-02]\n",
      " [2.59727836e-02]\n",
      " [7.23630190e-04]\n",
      " [4.57027555e-02]\n",
      " [3.26228738e-02]\n",
      " [5.66690564e-02]\n",
      " [4.56988186e-01]\n",
      " [6.54300272e-01]\n",
      " [8.46153498e-03]\n",
      " [1.55684054e-02]\n",
      " [2.09730446e-01]\n",
      " [1.96510553e-02]\n",
      " [1.06382072e-01]\n",
      " [1.25586689e-01]\n",
      " [1.14446878e-03]\n",
      " [9.76692140e-02]\n",
      " [3.58309686e-01]\n",
      " [3.22002828e-01]\n",
      " [4.78899777e-02]\n",
      " [8.62864852e-02]\n",
      " [3.48785520e-03]\n",
      " [9.84901190e-03]\n",
      " [5.50767183e-02]\n",
      " [4.39167172e-01]\n",
      " [1.95032686e-01]\n",
      " [7.28009045e-01]\n",
      " [8.53132308e-02]\n",
      " [5.65686107e-01]\n",
      " [1.88528299e-02]\n",
      " [3.60019505e-02]\n",
      " [8.25160980e-01]\n",
      " [4.12925690e-01]\n",
      " [6.45364821e-02]\n",
      " [3.74174118e-03]\n",
      " [6.06712997e-02]\n",
      " [4.45669293e-02]\n",
      " [9.19198394e-02]\n",
      " [3.39193344e-02]\n",
      " [5.17441213e-01]\n",
      " [1.62319332e-01]\n",
      " [2.19275057e-02]\n",
      " [3.31392288e-02]\n",
      " [1.67034268e-02]\n",
      " [8.06201160e-01]\n",
      " [6.21151030e-02]\n",
      " [4.41211462e-03]\n",
      " [3.50946486e-02]\n",
      " [6.93364739e-02]\n",
      " [4.94426191e-02]\n",
      " [3.76085043e-02]\n",
      " [2.99044102e-01]\n",
      " [6.51896417e-01]\n",
      " [3.49809229e-02]\n",
      " [9.13574994e-02]\n",
      " [7.52439201e-02]\n",
      " [3.07457447e-02]\n",
      " [4.92581636e-01]\n",
      " [4.30366695e-01]\n",
      " [6.84450150e-01]\n",
      " [1.75400138e-01]\n",
      " [5.09344101e-01]\n",
      " [3.52481544e-01]\n",
      " [3.87614638e-01]\n",
      " [6.03297353e-02]\n",
      " [4.81961548e-01]\n",
      " [7.49289989e-04]\n",
      " [1.47219598e-02]\n",
      " [7.27146864e-02]\n",
      " [9.36792195e-02]\n",
      " [4.38895822e-02]\n",
      " [1.87374055e-02]\n",
      " [3.31223011e-04]\n",
      " [6.42234087e-01]\n",
      " [3.25097442e-02]\n",
      " [1.05060101e-01]\n",
      " [2.62359351e-01]\n",
      " [3.06184411e-01]\n",
      " [1.94470584e-02]\n",
      " [4.07847464e-02]\n",
      " [3.08796763e-02]\n",
      " [6.10766113e-02]\n",
      " [7.67359138e-02]\n",
      " [1.71765089e-02]\n",
      " [7.68651664e-02]\n",
      " [1.01550519e-02]\n",
      " [3.18359137e-02]\n",
      " [3.61282825e-02]\n",
      " [1.18250251e-02]\n",
      " [1.70777857e-01]\n",
      " [3.51586044e-02]\n",
      " [1.39155090e-02]\n",
      " [3.87916327e-01]\n",
      " [1.01165146e-01]\n",
      " [1.62515581e-01]\n",
      " [3.61383855e-02]\n",
      " [5.11527658e-02]\n",
      " [8.71431828e-02]\n",
      " [4.86072898e-02]\n",
      " [7.33668208e-02]\n",
      " [1.33231282e-03]\n",
      " [6.66940153e-01]\n",
      " [1.47607952e-01]\n",
      " [2.57410109e-02]\n",
      " [5.27341962e-02]\n",
      " [3.28245759e-02]\n",
      " [3.16600680e-01]\n",
      " [3.23173106e-02]\n",
      " [2.09965706e-02]\n",
      " [5.03771901e-02]\n",
      " [6.59554899e-02]\n",
      " [1.03566051e-02]\n",
      " [3.65476131e-01]\n",
      " [5.26919961e-03]\n",
      " [1.82426780e-01]\n",
      " [4.41983044e-02]\n",
      " [4.86745238e-02]\n",
      " [1.71461403e-02]\n",
      " [7.93594122e-02]\n",
      " [4.10834342e-01]\n",
      " [3.45241725e-02]\n",
      " [2.50090718e-01]\n",
      " [6.73025846e-03]\n",
      " [8.72009397e-02]\n",
      " [1.05849475e-01]\n",
      " [8.46204162e-03]\n",
      " [5.17689347e-01]\n",
      " [1.43945515e-02]\n",
      " [1.83002353e-02]\n",
      " [1.82846457e-01]\n",
      " [8.58084559e-02]\n",
      " [2.83633173e-02]\n",
      " [1.13327652e-01]\n",
      " [8.85901153e-01]\n",
      " [2.76579976e-01]\n",
      " [9.84041691e-02]\n",
      " [2.48328745e-02]\n",
      " [4.86039132e-01]\n",
      " [8.84381533e-02]\n",
      " [5.61473370e-02]\n",
      " [8.38098526e-02]\n",
      " [3.41447562e-01]\n",
      " [4.77671623e-04]\n",
      " [1.53189003e-02]\n",
      " [1.60472959e-01]\n",
      " [1.15278065e-02]\n",
      " [3.43354344e-01]\n",
      " [3.43146205e-01]\n",
      " [1.98347747e-01]\n",
      " [5.72076440e-03]\n",
      " [5.10445237e-03]\n",
      " [2.59378850e-01]\n",
      " [1.15886629e-01]\n",
      " [2.08446980e-02]\n",
      " [1.30509138e-02]\n",
      " [3.65334749e-02]\n",
      " [1.57564878e-03]\n",
      " [2.53124237e-02]\n",
      " [5.57706594e-01]\n",
      " [6.81148410e-01]\n",
      " [9.62281942e-01]\n",
      " [5.55922687e-02]\n",
      " [2.09501147e-01]\n",
      " [4.02634054e-01]\n",
      " [2.29255319e-01]\n",
      " [2.91869044e-03]\n",
      " [5.94675541e-02]\n",
      " [5.46934903e-02]\n",
      " [2.69749165e-02]\n",
      " [1.78286135e-02]\n",
      " [4.93645668e-04]\n",
      " [7.81873822e-01]\n",
      " [2.23592401e-01]\n",
      " [3.64151597e-03]\n",
      " [1.57285929e-01]\n",
      " [1.31878465e-01]\n",
      " [3.61583740e-01]\n",
      " [6.69048429e-01]\n",
      " [3.26657355e-01]\n",
      " [4.99894321e-02]\n",
      " [3.35586935e-01]\n",
      " [5.65147996e-02]\n",
      " [1.61085129e-01]\n",
      " [6.38534725e-02]\n",
      " [4.46197838e-01]\n",
      " [3.13504934e-02]\n",
      " [7.53754675e-02]\n",
      " [3.91289949e-01]\n",
      " [5.74185848e-02]\n",
      " [2.44596839e-01]\n",
      " [4.55808640e-03]\n",
      " [1.10822529e-01]\n",
      " [6.07839227e-02]\n",
      " [4.16943133e-02]\n",
      " [2.31062472e-02]\n",
      " [2.34198570e-03]\n",
      " [2.79951096e-02]\n",
      " [4.09648269e-01]\n",
      " [7.61949420e-01]\n",
      " [9.03599262e-02]\n",
      " [1.44119561e-02]\n",
      " [2.57680714e-02]\n",
      " [2.96582222e-01]\n",
      " [9.82388556e-02]\n",
      " [1.01658016e-01]\n",
      " [3.65590453e-01]\n",
      " [4.85547781e-02]\n",
      " [4.77854908e-01]\n",
      " [8.30708325e-01]\n",
      " [4.98909682e-01]\n",
      " [2.78127491e-02]\n",
      " [1.25833452e-02]\n",
      " [6.37304187e-02]\n",
      " [6.05485499e-01]\n",
      " [2.33507454e-02]\n",
      " [5.16434312e-01]\n",
      " [4.59212035e-01]\n",
      " [3.37086916e-02]\n",
      " [5.12822270e-02]\n",
      " [3.47102463e-01]\n",
      " [5.14371157e-01]\n",
      " [1.30257308e-02]\n",
      " [2.22760439e-02]\n",
      " [5.70639968e-02]\n",
      " [3.80374759e-01]\n",
      " [4.71258581e-01]\n",
      " [5.75847626e-02]\n",
      " [5.84645569e-02]\n",
      " [8.82185996e-02]\n",
      " [8.43035877e-02]\n",
      " [3.53155136e-02]\n",
      " [3.04062665e-02]\n",
      " [4.10876572e-02]\n",
      " [2.22182572e-02]\n",
      " [1.19338632e-02]\n",
      " [4.08600718e-01]\n",
      " [3.66361052e-01]\n",
      " [2.61294425e-01]\n",
      " [3.93412471e-01]\n",
      " [7.74449706e-01]\n",
      " [8.90172303e-01]\n",
      " [1.25781566e-01]\n",
      " [7.53132403e-02]\n",
      " [8.27734232e-01]\n",
      " [3.69563699e-03]\n",
      " [7.71828532e-01]\n",
      " [5.78904450e-02]\n",
      " [4.07532752e-02]\n",
      " [4.29250002e-02]\n",
      " [1.29406750e-01]\n",
      " [4.97813702e-01]\n",
      " [2.43224502e-01]\n",
      " [2.89803743e-01]\n",
      " [7.06428289e-03]\n",
      " [7.01220930e-02]\n",
      " [5.75161874e-01]\n",
      " [1.79193616e-02]\n",
      " [7.05380321e-01]\n",
      " [1.91332400e-02]\n",
      " [4.13992226e-01]\n",
      " [2.57670283e-02]\n",
      " [2.09198892e-02]\n",
      " [1.88945800e-01]\n",
      " [4.06412363e-01]\n",
      " [5.21713495e-03]\n",
      " [4.25508767e-01]\n",
      " [4.93665785e-01]\n",
      " [2.78591216e-02]\n",
      " [1.26123697e-01]\n",
      " [6.72749281e-01]\n",
      " [6.08118176e-02]\n",
      " [1.64433420e-02]\n",
      " [1.32516801e-01]\n",
      " [8.03163052e-01]\n",
      " [6.72623515e-03]\n",
      " [6.62327051e-01]\n",
      " [8.00543666e-01]\n",
      " [8.93665016e-01]\n",
      " [4.86504436e-01]\n",
      " [9.02117133e-01]\n",
      " [5.71188688e-01]\n",
      " [7.59739876e-01]\n",
      " [2.90188015e-01]\n",
      " [5.26181757e-01]\n",
      " [2.65486777e-01]\n",
      " [1.60330027e-01]\n",
      " [1.72140688e-01]\n",
      " [3.46350461e-01]\n",
      " [9.65261638e-01]\n",
      " [9.21165526e-01]\n",
      " [8.68214011e-01]\n",
      " [3.14842582e-01]\n",
      " [5.00061512e-02]\n",
      " [2.06726879e-01]\n",
      " [8.45763326e-01]\n",
      " [9.79260802e-02]\n",
      " [7.72819221e-01]\n",
      " [5.21225989e-01]\n",
      " [6.66170180e-01]\n",
      " [5.40465772e-01]\n",
      " [4.16069478e-01]\n",
      " [6.81304485e-02]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 353us/step - loss: 0.4194 - acc: 0.8575 - val_loss: 0.4180 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3994 - acc: 0.8583 - val_loss: 0.4176 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 77us/step - loss: 0.3947 - acc: 0.8583 - val_loss: 0.4049 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 79us/step - loss: 0.3936 - acc: 0.8583 - val_loss: 0.4133 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 74us/step - loss: 0.3921 - acc: 0.8592 - val_loss: 0.4089 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 64us/step - loss: 0.3847 - acc: 0.8583 - val_loss: 0.3926 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3867 - acc: 0.8588 - val_loss: 0.3896 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3791 - acc: 0.8583 - val_loss: 0.3944 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 80us/step - loss: 0.3706 - acc: 0.8592 - val_loss: 0.3794 - val_acc: 0.8450\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3660 - acc: 0.8612 - val_loss: 0.3760 - val_acc: 0.8433\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3700 - acc: 0.8600 - val_loss: 0.3781 - val_acc: 0.8450\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3566 - acc: 0.8604 - val_loss: 0.3780 - val_acc: 0.8433\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3591 - acc: 0.8621 - val_loss: 0.3823 - val_acc: 0.8433\n",
      "y2_pred:  [[0.06984398]\n",
      " [0.054932  ]\n",
      " [0.1454243 ]\n",
      " [0.09797281]\n",
      " [0.03046486]\n",
      " [0.22890481]\n",
      " [0.01865357]\n",
      " [0.0256291 ]\n",
      " [0.29427862]\n",
      " [0.04027534]\n",
      " [0.25092202]\n",
      " [0.2983362 ]\n",
      " [0.02428705]\n",
      " [0.04477155]\n",
      " [0.05490211]\n",
      " [0.00919968]\n",
      " [0.03467593]\n",
      " [0.03495073]\n",
      " [0.03381172]\n",
      " [0.03225869]\n",
      " [0.02987087]\n",
      " [0.02583969]\n",
      " [0.02829838]\n",
      " [0.18141472]\n",
      " [0.16752961]\n",
      " [0.05673113]\n",
      " [0.02169231]\n",
      " [0.25912184]\n",
      " [0.06438768]\n",
      " [0.01657286]\n",
      " [0.13509795]\n",
      " [0.05457595]\n",
      " [0.2040511 ]\n",
      " [0.112198  ]\n",
      " [0.02561924]\n",
      " [0.09092879]\n",
      " [0.05084682]\n",
      " [0.00468683]\n",
      " [0.0194298 ]\n",
      " [0.0364652 ]\n",
      " [0.14561969]\n",
      " [0.02802655]\n",
      " [0.08629602]\n",
      " [0.20813817]\n",
      " [0.09451544]\n",
      " [0.0395146 ]\n",
      " [0.03216007]\n",
      " [0.01644188]\n",
      " [0.03222907]\n",
      " [0.08408952]\n",
      " [0.13964882]\n",
      " [0.1141862 ]\n",
      " [0.04694399]\n",
      " [0.0367063 ]\n",
      " [0.03519762]\n",
      " [0.03673545]\n",
      " [0.01925012]\n",
      " [0.00522003]\n",
      " [0.00635388]\n",
      " [0.1201601 ]\n",
      " [0.5569115 ]\n",
      " [0.0169678 ]\n",
      " [0.15048918]\n",
      " [0.05510581]\n",
      " [0.02447748]\n",
      " [0.02068418]\n",
      " [0.0162966 ]\n",
      " [0.01699549]\n",
      " [0.00763732]\n",
      " [0.5719702 ]\n",
      " [0.1220555 ]\n",
      " [0.05925858]\n",
      " [0.07812718]\n",
      " [0.06612676]\n",
      " [0.09915477]\n",
      " [0.02314058]\n",
      " [0.32500085]\n",
      " [0.00534663]\n",
      " [0.01071793]\n",
      " [0.1683563 ]\n",
      " [0.02220383]\n",
      " [0.01976252]\n",
      " [0.11922288]\n",
      " [0.08540154]\n",
      " [0.04397941]\n",
      " [0.03004128]\n",
      " [0.04890653]\n",
      " [0.05714148]\n",
      " [0.0464865 ]\n",
      " [0.08887139]\n",
      " [0.02414662]\n",
      " [0.0115222 ]\n",
      " [0.01533663]\n",
      " [0.06302923]\n",
      " [0.29911864]\n",
      " [0.01631355]\n",
      " [0.23475268]\n",
      " [0.03680596]\n",
      " [0.16513634]\n",
      " [0.00699577]\n",
      " [0.01849386]\n",
      " [0.01286897]\n",
      " [0.07721862]\n",
      " [0.0082815 ]\n",
      " [0.08845761]\n",
      " [0.55714405]\n",
      " [0.01265526]\n",
      " [0.01552898]\n",
      " [0.10423213]\n",
      " [0.02584979]\n",
      " [0.28455615]\n",
      " [0.0211454 ]\n",
      " [0.0983882 ]\n",
      " [0.1513325 ]\n",
      " [0.20555544]\n",
      " [0.01157555]\n",
      " [0.01089236]\n",
      " [0.05657259]\n",
      " [0.1457161 ]\n",
      " [0.04243359]\n",
      " [0.1211327 ]\n",
      " [0.06200993]\n",
      " [0.0281868 ]\n",
      " [0.37832087]\n",
      " [0.05443862]\n",
      " [0.02601027]\n",
      " [0.11251646]\n",
      " [0.03387409]\n",
      " [0.02799729]\n",
      " [0.01370004]\n",
      " [0.00687015]\n",
      " [0.03957611]\n",
      " [0.03806308]\n",
      " [0.02924177]\n",
      " [0.34005374]\n",
      " [0.00429261]\n",
      " [0.32221007]\n",
      " [0.05300409]\n",
      " [0.17978066]\n",
      " [0.08485439]\n",
      " [0.00387815]\n",
      " [0.03169063]\n",
      " [0.03885233]\n",
      " [0.14963466]\n",
      " [0.04668927]\n",
      " [0.60717016]\n",
      " [0.01161963]\n",
      " [0.21855679]\n",
      " [0.0195134 ]\n",
      " [0.04821876]\n",
      " [0.12423578]\n",
      " [0.05150414]\n",
      " [0.00752255]\n",
      " [0.03127122]\n",
      " [0.231608  ]\n",
      " [0.32668477]\n",
      " [0.05076075]\n",
      " [0.0285458 ]\n",
      " [0.01512632]\n",
      " [0.07416615]\n",
      " [0.02779895]\n",
      " [0.0861831 ]\n",
      " [0.12520492]\n",
      " [0.18093017]\n",
      " [0.06655779]\n",
      " [0.01507473]\n",
      " [0.02027896]\n",
      " [0.13255155]\n",
      " [0.0882788 ]\n",
      " [0.03625435]\n",
      " [0.04317972]\n",
      " [0.23079142]\n",
      " [0.2716713 ]\n",
      " [0.11382124]\n",
      " [0.07612589]\n",
      " [0.07818067]\n",
      " [0.21332464]\n",
      " [0.07894447]\n",
      " [0.134673  ]\n",
      " [0.12641612]\n",
      " [0.16146588]\n",
      " [0.08999854]\n",
      " [0.21510205]\n",
      " [0.35969484]\n",
      " [0.16130176]\n",
      " [0.04485837]\n",
      " [0.1000891 ]\n",
      " [0.02638406]\n",
      " [0.07633904]\n",
      " [0.02705151]\n",
      " [0.18704936]\n",
      " [0.07346624]\n",
      " [0.0427449 ]\n",
      " [0.05584773]\n",
      " [0.04955506]\n",
      " [0.05111787]\n",
      " [0.06634778]\n",
      " [0.08591372]\n",
      " [0.17103857]\n",
      " [0.06540954]\n",
      " [0.12646157]\n",
      " [0.01677769]\n",
      " [0.43316606]\n",
      " [0.03975511]\n",
      " [0.15614858]\n",
      " [0.02336681]\n",
      " [0.18583062]\n",
      " [0.43719402]\n",
      " [0.07820046]\n",
      " [0.11402506]\n",
      " [0.10283148]\n",
      " [0.12519425]\n",
      " [0.00731269]\n",
      " [0.25548226]\n",
      " [0.01933214]\n",
      " [0.03400293]\n",
      " [0.01289025]\n",
      " [0.10539341]\n",
      " [0.05927554]\n",
      " [0.02740216]\n",
      " [0.03363883]\n",
      " [0.04835209]\n",
      " [0.02691218]\n",
      " [0.00899458]\n",
      " [0.24867365]\n",
      " [0.09177595]\n",
      " [0.16129419]\n",
      " [0.21911007]\n",
      " [0.04755074]\n",
      " [0.00548688]\n",
      " [0.01882863]\n",
      " [0.01940989]\n",
      " [0.00222811]\n",
      " [0.02734476]\n",
      " [0.04955611]\n",
      " [0.09255406]\n",
      " [0.08513075]\n",
      " [0.04984483]\n",
      " [0.01224265]\n",
      " [0.1079894 ]\n",
      " [0.07815942]\n",
      " [0.03630432]\n",
      " [0.02696183]\n",
      " [0.06896272]\n",
      " [0.02698135]\n",
      " [0.01936433]\n",
      " [0.01090136]\n",
      " [0.01477778]\n",
      " [0.03353673]\n",
      " [0.07938987]\n",
      " [0.16242132]\n",
      " [0.03042695]\n",
      " [0.03591305]\n",
      " [0.3607322 ]\n",
      " [0.05459744]\n",
      " [0.04243389]\n",
      " [0.06120366]\n",
      " [0.1795803 ]\n",
      " [0.4364146 ]\n",
      " [0.10512376]\n",
      " [0.19852826]\n",
      " [0.01030183]\n",
      " [0.08188674]\n",
      " [0.11700359]\n",
      " [0.1016883 ]\n",
      " [0.01707083]\n",
      " [0.33335286]\n",
      " [0.1096454 ]\n",
      " [0.01491979]\n",
      " [0.08274943]\n",
      " [0.06019831]\n",
      " [0.03892159]\n",
      " [0.14202628]\n",
      " [0.03806567]\n",
      " [0.02050012]\n",
      " [0.43915346]\n",
      " [0.01275402]\n",
      " [0.06641248]\n",
      " [0.2301082 ]\n",
      " [0.06846717]\n",
      " [0.10755348]\n",
      " [0.02660421]\n",
      " [0.13434577]\n",
      " [0.02303982]\n",
      " [0.10051906]\n",
      " [0.04571143]\n",
      " [0.00470486]\n",
      " [0.05210271]\n",
      " [0.07702103]\n",
      " [0.16039953]\n",
      " [0.0085068 ]\n",
      " [0.14658457]\n",
      " [0.20240965]\n",
      " [0.00905606]\n",
      " [0.05238295]\n",
      " [0.371359  ]\n",
      " [0.40205407]\n",
      " [0.18550226]\n",
      " [0.3408777 ]\n",
      " [0.36622775]\n",
      " [0.53403366]\n",
      " [0.56431305]\n",
      " [0.16752711]\n",
      " [0.18141466]\n",
      " [0.07932407]\n",
      " [0.13032186]\n",
      " [0.32970738]\n",
      " [0.07928133]\n",
      " [0.10852534]\n",
      " [0.03759882]\n",
      " [0.340516  ]\n",
      " [0.42448306]\n",
      " [0.05364707]\n",
      " [0.15766114]\n",
      " [0.36800283]\n",
      " [0.07051441]\n",
      " [0.11157838]\n",
      " [0.07794198]\n",
      " [0.68022203]\n",
      " [0.18477672]\n",
      " [0.25674856]\n",
      " [0.34022105]\n",
      " [0.18681777]\n",
      " [0.2789461 ]\n",
      " [0.28928906]\n",
      " [0.25655615]\n",
      " [0.11929905]\n",
      " [0.03468063]\n",
      " [0.07350708]\n",
      " [0.5320621 ]\n",
      " [0.23869042]\n",
      " [0.01713797]\n",
      " [0.42974022]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.08333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 366us/step - loss: 0.4569 - acc: 0.8575 - val_loss: 0.4560 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.4214 - acc: 0.8583 - val_loss: 0.4356 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3955 - acc: 0.8583 - val_loss: 0.4079 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3861 - acc: 0.8612 - val_loss: 0.3987 - val_acc: 0.8467\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3643 - acc: 0.8658 - val_loss: 0.4164 - val_acc: 0.8467\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3729 - acc: 0.8608 - val_loss: 0.3763 - val_acc: 0.8483\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 77us/step - loss: 0.3521 - acc: 0.8658 - val_loss: 0.3474 - val_acc: 0.8600\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3355 - acc: 0.8767 - val_loss: 0.3707 - val_acc: 0.8600\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3325 - acc: 0.8750 - val_loss: 0.3419 - val_acc: 0.8700\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3179 - acc: 0.8767 - val_loss: 0.3291 - val_acc: 0.8733\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3267 - acc: 0.8713 - val_loss: 0.3354 - val_acc: 0.8583\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3053 - acc: 0.8812 - val_loss: 0.3366 - val_acc: 0.8617\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3051 - acc: 0.8783 - val_loss: 0.3269 - val_acc: 0.8650\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.3018 - acc: 0.8800 - val_loss: 0.3337 - val_acc: 0.8667\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 74us/step - loss: 0.3013 - acc: 0.8792 - val_loss: 0.3179 - val_acc: 0.8750\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.2928 - acc: 0.8812 - val_loss: 0.3071 - val_acc: 0.8717\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.2903 - acc: 0.8821 - val_loss: 0.3390 - val_acc: 0.8717\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.2816 - acc: 0.8892 - val_loss: 0.3297 - val_acc: 0.8600\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.2938 - acc: 0.8762 - val_loss: 0.3134 - val_acc: 0.8800\n",
      "y2_pred:  [[0.10061288]\n",
      " [0.01145563]\n",
      " [0.03575778]\n",
      " [0.07334822]\n",
      " [0.05679736]\n",
      " [0.01663774]\n",
      " [0.17966193]\n",
      " [0.02246642]\n",
      " [0.04641345]\n",
      " [0.6772518 ]\n",
      " [0.02787358]\n",
      " [0.15111938]\n",
      " [0.02042222]\n",
      " [0.01937601]\n",
      " [0.03529516]\n",
      " [0.04143468]\n",
      " [0.01675543]\n",
      " [0.099637  ]\n",
      " [0.04317692]\n",
      " [0.02041489]\n",
      " [0.1076079 ]\n",
      " [0.00900415]\n",
      " [0.01667356]\n",
      " [0.03047389]\n",
      " [0.02279776]\n",
      " [0.05084091]\n",
      " [0.00833407]\n",
      " [0.01479927]\n",
      " [0.0438816 ]\n",
      " [0.065833  ]\n",
      " [0.04083359]\n",
      " [0.06900582]\n",
      " [0.04091522]\n",
      " [0.03257754]\n",
      " [0.01696023]\n",
      " [0.01774052]\n",
      " [0.02890253]\n",
      " [0.15379283]\n",
      " [0.02865046]\n",
      " [0.02118149]\n",
      " [0.02868953]\n",
      " [0.02088174]\n",
      " [0.05646509]\n",
      " [0.0086962 ]\n",
      " [0.00102991]\n",
      " [0.03759012]\n",
      " [0.02285978]\n",
      " [0.08965221]\n",
      " [0.0066773 ]\n",
      " [0.16497734]\n",
      " [0.37734857]\n",
      " [0.01269975]\n",
      " [0.01941502]\n",
      " [0.04098156]\n",
      " [0.0159038 ]\n",
      " [0.04733858]\n",
      " [0.05224779]\n",
      " [0.04952404]\n",
      " [0.10245216]\n",
      " [0.01817617]\n",
      " [0.01798368]\n",
      " [0.11680838]\n",
      " [0.15066165]\n",
      " [0.10626   ]\n",
      " [0.08108804]\n",
      " [0.02547193]\n",
      " [0.47035915]\n",
      " [0.1233297 ]\n",
      " [0.04372206]\n",
      " [0.00902706]\n",
      " [0.04755411]\n",
      " [0.0251886 ]\n",
      " [0.00620571]\n",
      " [0.06286296]\n",
      " [0.07706934]\n",
      " [0.02490413]\n",
      " [0.02784285]\n",
      " [0.01857606]\n",
      " [0.01405755]\n",
      " [0.0228515 ]\n",
      " [0.01437742]\n",
      " [0.3657066 ]\n",
      " [0.03401002]\n",
      " [0.0220007 ]\n",
      " [0.02139822]\n",
      " [0.02674466]\n",
      " [0.04090986]\n",
      " [0.01144964]\n",
      " [0.02630115]\n",
      " [0.02971014]\n",
      " [0.03610158]\n",
      " [0.14415279]\n",
      " [0.00330171]\n",
      " [0.43384513]\n",
      " [0.05817482]\n",
      " [0.2846494 ]\n",
      " [0.04033226]\n",
      " [0.01620212]\n",
      " [0.07315022]\n",
      " [0.02645531]\n",
      " [0.03432336]\n",
      " [0.19673094]\n",
      " [0.09869191]\n",
      " [0.3138007 ]\n",
      " [0.04780242]\n",
      " [0.03858206]\n",
      " [0.03664985]\n",
      " [0.05740619]\n",
      " [0.05927762]\n",
      " [0.03084275]\n",
      " [0.02300337]\n",
      " [0.01200229]\n",
      " [0.12695274]\n",
      " [0.0546203 ]\n",
      " [0.01390976]\n",
      " [0.00771749]\n",
      " [0.26262897]\n",
      " [0.23860249]\n",
      " [0.05374888]\n",
      " [0.03683254]\n",
      " [0.0065324 ]\n",
      " [0.04932564]\n",
      " [0.0047574 ]\n",
      " [0.02585539]\n",
      " [0.09419429]\n",
      " [0.01592678]\n",
      " [0.02217618]\n",
      " [0.00469819]\n",
      " [0.0566    ]\n",
      " [0.01974463]\n",
      " [0.08137682]\n",
      " [0.06325638]\n",
      " [0.04776958]\n",
      " [0.02376243]\n",
      " [0.05189231]\n",
      " [0.00935543]\n",
      " [0.0163525 ]\n",
      " [0.00897765]\n",
      " [0.14725408]\n",
      " [0.03797624]\n",
      " [0.30462348]\n",
      " [0.02852145]\n",
      " [0.13278866]\n",
      " [0.01086241]\n",
      " [0.02757934]\n",
      " [0.07384178]\n",
      " [0.08741993]\n",
      " [0.10070443]\n",
      " [0.02074507]\n",
      " [0.06047177]\n",
      " [0.03049266]\n",
      " [0.6919895 ]\n",
      " [0.15380067]\n",
      " [0.17027625]\n",
      " [0.03266913]\n",
      " [0.05302799]\n",
      " [0.02631086]\n",
      " [0.01886532]\n",
      " [0.05086151]\n",
      " [0.03805572]\n",
      " [0.05474517]\n",
      " [0.04391265]\n",
      " [0.01040354]\n",
      " [0.01776966]\n",
      " [0.05430949]\n",
      " [0.03457773]\n",
      " [0.01882601]\n",
      " [0.0310533 ]\n",
      " [0.00120747]\n",
      " [0.4997149 ]\n",
      " [0.83866465]\n",
      " [0.01935726]\n",
      " [0.21173835]\n",
      " [0.01175275]\n",
      " [0.29437974]\n",
      " [0.04979986]\n",
      " [0.03360885]\n",
      " [0.00579473]\n",
      " [0.03313595]\n",
      " [0.02411488]\n",
      " [0.02200857]\n",
      " [0.02858263]\n",
      " [0.01406372]\n",
      " [0.36971074]\n",
      " [0.00731605]\n",
      " [0.04456106]\n",
      " [0.05855486]\n",
      " [0.02529252]\n",
      " [0.01473096]\n",
      " [0.15726689]\n",
      " [0.16893464]\n",
      " [0.07348874]\n",
      " [0.07700032]\n",
      " [0.2852919 ]\n",
      " [0.6741993 ]\n",
      " [0.28895658]\n",
      " [0.14248744]\n",
      " [0.91319644]\n",
      " [0.04800177]\n",
      " [0.21173456]\n",
      " [0.11607093]\n",
      " [0.08440346]\n",
      " [0.05257636]\n",
      " [0.10080585]\n",
      " [0.1531339 ]\n",
      " [0.03115901]\n",
      " [0.03521886]\n",
      " [0.03414294]\n",
      " [0.0735541 ]\n",
      " [0.5439466 ]\n",
      " [0.5849808 ]\n",
      " [0.01744139]\n",
      " [0.13841328]\n",
      " [0.4760457 ]\n",
      " [0.36748427]\n",
      " [0.01069826]\n",
      " [0.00859797]\n",
      " [0.12039578]\n",
      " [0.09397179]\n",
      " [0.08613986]\n",
      " [0.0392524 ]\n",
      " [0.00834796]\n",
      " [0.0805904 ]\n",
      " [0.03520963]\n",
      " [0.40856165]\n",
      " [0.16177037]\n",
      " [0.1284875 ]\n",
      " [0.01273182]\n",
      " [0.02282205]\n",
      " [0.03492454]\n",
      " [0.05017385]\n",
      " [0.00226706]\n",
      " [0.07149494]\n",
      " [0.06991649]\n",
      " [0.00620109]\n",
      " [0.10954028]\n",
      " [0.38126236]\n",
      " [0.06036034]\n",
      " [0.01101875]\n",
      " [0.06133202]\n",
      " [0.02509826]\n",
      " [0.03515148]\n",
      " [0.01234472]\n",
      " [0.03422198]\n",
      " [0.95493245]\n",
      " [0.08778489]\n",
      " [0.1391969 ]\n",
      " [0.01792988]\n",
      " [0.03638896]\n",
      " [0.03041017]\n",
      " [0.03075629]\n",
      " [0.93809605]\n",
      " [0.08860806]\n",
      " [0.04252344]\n",
      " [0.06496534]\n",
      " [0.01889658]\n",
      " [0.01815197]\n",
      " [0.04330811]\n",
      " [0.0703159 ]\n",
      " [0.0603846 ]\n",
      " [0.02848652]\n",
      " [0.02335986]\n",
      " [0.04044563]\n",
      " [0.60672605]\n",
      " [0.04377225]\n",
      " [0.27670753]\n",
      " [0.58619785]\n",
      " [0.18134111]\n",
      " [0.07416764]\n",
      " [0.05014065]\n",
      " [0.01317173]\n",
      " [0.01316002]\n",
      " [0.01987723]\n",
      " [0.02258688]\n",
      " [0.07925138]\n",
      " [0.02601302]\n",
      " [0.01249102]\n",
      " [0.07191601]\n",
      " [0.17175853]\n",
      " [0.09599754]\n",
      " [0.0434047 ]\n",
      " [0.03511676]\n",
      " [0.52727306]\n",
      " [0.10423014]\n",
      " [0.05733085]\n",
      " [0.04437295]\n",
      " [0.16788018]\n",
      " [0.14929178]\n",
      " [0.04544082]\n",
      " [0.14287749]\n",
      " [0.2233302 ]\n",
      " [0.05427071]\n",
      " [0.00695127]\n",
      " [0.02403724]\n",
      " [0.0791232 ]\n",
      " [0.02453649]\n",
      " [0.03259075]\n",
      " [0.08606979]\n",
      " [0.0624482 ]\n",
      " [0.03196687]\n",
      " [0.06966445]\n",
      " [0.01843804]\n",
      " [0.69365865]\n",
      " [0.01284036]\n",
      " [0.05856881]\n",
      " [0.22161686]\n",
      " [0.6850734 ]\n",
      " [0.02804092]\n",
      " [0.04424274]\n",
      " [0.4381677 ]\n",
      " [0.1771146 ]\n",
      " [0.19505212]\n",
      " [0.12261948]\n",
      " [0.06080669]\n",
      " [0.04802218]\n",
      " [0.2603582 ]\n",
      " [0.11438262]\n",
      " [0.08358848]\n",
      " [0.06946269]\n",
      " [0.20676789]\n",
      " [0.4263171 ]\n",
      " [0.6279908 ]\n",
      " [0.3072834 ]\n",
      " [0.30709082]\n",
      " [0.47564897]\n",
      " [0.13059649]\n",
      " [0.45417863]\n",
      " [0.3540374 ]\n",
      " [0.52670854]\n",
      " [0.4401522 ]\n",
      " [0.2498578 ]\n",
      " [0.24466202]\n",
      " [0.03355212]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.20833333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 382us/step - loss: 0.4375 - acc: 0.8508 - val_loss: 0.4212 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.4184 - acc: 0.8588 - val_loss: 0.4544 - val_acc: 0.8467\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.4098 - acc: 0.8583 - val_loss: 0.4133 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3914 - acc: 0.8563 - val_loss: 0.4461 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.4026 - acc: 0.8588 - val_loss: 0.3977 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3815 - acc: 0.8588 - val_loss: 0.3844 - val_acc: 0.8467\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3815 - acc: 0.8583 - val_loss: 0.3843 - val_acc: 0.8467\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3739 - acc: 0.8608 - val_loss: 0.3706 - val_acc: 0.8467\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3805 - acc: 0.8637 - val_loss: 0.3683 - val_acc: 0.8467\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.3698 - acc: 0.8571 - val_loss: 0.3638 - val_acc: 0.8500\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.3654 - acc: 0.8625 - val_loss: 0.3666 - val_acc: 0.8500\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3586 - acc: 0.8633 - val_loss: 0.3621 - val_acc: 0.8467\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3549 - acc: 0.8617 - val_loss: 0.3542 - val_acc: 0.8500\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3543 - acc: 0.8625 - val_loss: 0.3698 - val_acc: 0.8500\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 76us/step - loss: 0.3583 - acc: 0.8629 - val_loss: 0.3557 - val_acc: 0.8467\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 74us/step - loss: 0.3502 - acc: 0.8633 - val_loss: 0.3603 - val_acc: 0.8483\n",
      "y2_pred:  [[8.52269828e-02]\n",
      " [6.92619681e-02]\n",
      " [1.24264121e-01]\n",
      " [9.36751664e-02]\n",
      " [1.39108598e-02]\n",
      " [2.18955457e-01]\n",
      " [2.09143162e-01]\n",
      " [4.40904796e-02]\n",
      " [1.92209691e-01]\n",
      " [8.50774944e-02]\n",
      " [2.91925788e-01]\n",
      " [1.15494817e-01]\n",
      " [1.22365296e-01]\n",
      " [1.77008450e-01]\n",
      " [2.66272843e-01]\n",
      " [3.33772451e-01]\n",
      " [2.41018295e-01]\n",
      " [1.25873983e-02]\n",
      " [1.98351443e-01]\n",
      " [1.78952515e-01]\n",
      " [2.73296893e-01]\n",
      " [4.04978037e-01]\n",
      " [7.26047456e-02]\n",
      " [2.53433168e-01]\n",
      " [3.15738797e-01]\n",
      " [2.70540714e-01]\n",
      " [4.33981717e-02]\n",
      " [4.98914421e-02]\n",
      " [2.40419149e-01]\n",
      " [1.63358510e-01]\n",
      " [1.98423296e-01]\n",
      " [1.89184189e-01]\n",
      " [2.24067211e-01]\n",
      " [2.14781612e-01]\n",
      " [7.80586600e-02]\n",
      " [8.56255591e-02]\n",
      " [1.20021582e-01]\n",
      " [2.01010644e-01]\n",
      " [9.86472964e-02]\n",
      " [1.01649821e-01]\n",
      " [1.41846985e-01]\n",
      " [8.72727931e-02]\n",
      " [1.41843021e-01]\n",
      " [9.30436254e-02]\n",
      " [2.67915279e-01]\n",
      " [8.40698481e-02]\n",
      " [2.51023352e-01]\n",
      " [8.32565725e-02]\n",
      " [9.39992368e-02]\n",
      " [2.66800553e-01]\n",
      " [1.97760373e-01]\n",
      " [5.63362241e-02]\n",
      " [6.72755241e-02]\n",
      " [2.73264647e-02]\n",
      " [1.06343508e-01]\n",
      " [1.41146570e-01]\n",
      " [1.95065886e-01]\n",
      " [1.99610889e-01]\n",
      " [4.26098019e-01]\n",
      " [5.08098304e-02]\n",
      " [1.92096889e-01]\n",
      " [8.36070478e-02]\n",
      " [1.54481292e-01]\n",
      " [1.83768928e-01]\n",
      " [4.29499745e-01]\n",
      " [8.04525018e-02]\n",
      " [1.67734563e-01]\n",
      " [1.48243487e-01]\n",
      " [1.80230588e-01]\n",
      " [1.03825152e-01]\n",
      " [6.84659183e-02]\n",
      " [1.58506751e-01]\n",
      " [2.99615562e-02]\n",
      " [1.33237988e-01]\n",
      " [9.50731635e-02]\n",
      " [9.71564054e-02]\n",
      " [9.61813927e-02]\n",
      " [1.74297005e-01]\n",
      " [3.80309820e-02]\n",
      " [3.36158633e-01]\n",
      " [2.31554598e-01]\n",
      " [1.38281941e-01]\n",
      " [1.69655800e-01]\n",
      " [1.12933397e-01]\n",
      " [5.59245348e-02]\n",
      " [1.40368283e-01]\n",
      " [1.34821057e-01]\n",
      " [9.81271267e-02]\n",
      " [2.27412254e-01]\n",
      " [1.73514307e-01]\n",
      " [9.88238752e-02]\n",
      " [4.08291817e-06]\n",
      " [9.06304717e-02]\n",
      " [3.03693175e-01]\n",
      " [1.06415123e-01]\n",
      " [4.65480387e-02]\n",
      " [4.02994752e-02]\n",
      " [2.41493672e-01]\n",
      " [2.56879717e-01]\n",
      " [2.39475340e-01]\n",
      " [1.83004975e-01]\n",
      " [3.15923333e-01]\n",
      " [2.36663669e-01]\n",
      " [8.05647373e-02]\n",
      " [9.71585810e-02]\n",
      " [2.36586750e-01]\n",
      " [7.27182329e-02]\n",
      " [2.75143147e-01]\n",
      " [1.16143733e-01]\n",
      " [1.32308900e-02]\n",
      " [1.21348709e-01]\n",
      " [1.78108633e-01]\n",
      " [8.79305005e-02]\n",
      " [1.87214792e-01]\n",
      " [8.16712677e-02]\n",
      " [1.66009516e-01]\n",
      " [9.59872603e-02]\n",
      " [2.45589018e-02]\n",
      " [2.32643396e-01]\n",
      " [1.83442265e-01]\n",
      " [1.84016019e-01]\n",
      " [8.04551840e-02]\n",
      " [6.67694211e-02]\n",
      " [8.25661719e-02]\n",
      " [5.88855445e-02]\n",
      " [7.95889199e-02]\n",
      " [2.52029300e-02]\n",
      " [1.37230664e-01]\n",
      " [1.66871727e-01]\n",
      " [6.45788908e-02]\n",
      " [1.32787704e-01]\n",
      " [2.06886590e-01]\n",
      " [5.26521504e-02]\n",
      " [1.04719996e-01]\n",
      " [6.77810311e-02]\n",
      " [2.67009020e-01]\n",
      " [2.28158653e-01]\n",
      " [1.01223230e-01]\n",
      " [1.69933528e-01]\n",
      " [1.35632515e-01]\n",
      " [1.80590004e-01]\n",
      " [5.33740819e-02]\n",
      " [2.10807949e-01]\n",
      " [5.23540378e-02]\n",
      " [1.26062900e-01]\n",
      " [3.24750215e-01]\n",
      " [3.18431735e-01]\n",
      " [4.19206321e-02]\n",
      " [1.54822081e-01]\n",
      " [1.89249396e-01]\n",
      " [1.13401264e-01]\n",
      " [3.01285505e-01]\n",
      " [6.56812489e-02]\n",
      " [2.16547847e-01]\n",
      " [3.18085402e-01]\n",
      " [1.73672020e-01]\n",
      " [1.07239634e-01]\n",
      " [1.29394531e-01]\n",
      " [8.21122527e-02]\n",
      " [2.11684972e-01]\n",
      " [9.28547382e-02]\n",
      " [6.50663972e-02]\n",
      " [9.34251845e-02]\n",
      " [6.20079517e-01]\n",
      " [2.11207718e-01]\n",
      " [2.49218166e-01]\n",
      " [1.52171046e-01]\n",
      " [9.11143422e-02]\n",
      " [4.33304012e-02]\n",
      " [9.50812995e-02]\n",
      " [1.74580365e-01]\n",
      " [1.83854550e-01]\n",
      " [1.85219496e-01]\n",
      " [6.96217418e-02]\n",
      " [1.45910531e-01]\n",
      " [1.07808262e-01]\n",
      " [1.62975669e-01]\n",
      " [2.99008191e-02]\n",
      " [8.78163278e-02]\n",
      " [1.95992053e-01]\n",
      " [1.19676948e-01]\n",
      " [1.90075338e-02]\n",
      " [3.00544471e-01]\n",
      " [2.67651975e-02]\n",
      " [1.06878936e-01]\n",
      " [3.09358060e-01]\n",
      " [1.47095591e-01]\n",
      " [8.24797750e-02]\n",
      " [1.03139251e-01]\n",
      " [5.42149544e-02]\n",
      " [3.44843864e-02]\n",
      " [1.44923896e-01]\n",
      " [2.13932425e-01]\n",
      " [2.29024559e-01]\n",
      " [3.39000523e-02]\n",
      " [9.24759805e-02]\n",
      " [2.62741923e-01]\n",
      " [2.50220895e-01]\n",
      " [1.49374127e-01]\n",
      " [5.57733476e-02]\n",
      " [8.33244026e-02]\n",
      " [3.36288214e-01]\n",
      " [3.52544487e-01]\n",
      " [2.19990581e-01]\n",
      " [1.15477711e-01]\n",
      " [1.08131737e-01]\n",
      " [6.28412068e-02]\n",
      " [1.41827881e-01]\n",
      " [3.39586616e-01]\n",
      " [1.38251096e-01]\n",
      " [2.96728253e-01]\n",
      " [1.82093948e-01]\n",
      " [1.22257829e-01]\n",
      " [2.73202986e-01]\n",
      " [2.64358699e-01]\n",
      " [3.85584146e-01]\n",
      " [1.85995430e-01]\n",
      " [2.85713255e-01]\n",
      " [3.51653099e-02]\n",
      " [2.80497044e-01]\n",
      " [2.54571736e-01]\n",
      " [3.57627869e-07]\n",
      " [5.77791810e-01]\n",
      " [1.07337862e-01]\n",
      " [1.34701878e-01]\n",
      " [1.42316937e-01]\n",
      " [2.04782754e-01]\n",
      " [1.93597823e-01]\n",
      " [1.37293428e-01]\n",
      " [4.83819962e-01]\n",
      " [3.94338667e-02]\n",
      " [1.36411786e-02]\n",
      " [4.56563532e-02]\n",
      " [1.55655295e-01]\n",
      " [1.03491515e-01]\n",
      " [2.12805152e-01]\n",
      " [2.16394186e-01]\n",
      " [2.12567121e-01]\n",
      " [2.56451994e-01]\n",
      " [3.66617739e-02]\n",
      " [1.10498071e-02]\n",
      " [2.52108097e-01]\n",
      " [9.52620208e-02]\n",
      " [1.53773963e-01]\n",
      " [1.59647822e-01]\n",
      " [1.08322501e-01]\n",
      " [2.06396520e-01]\n",
      " [3.07844937e-01]\n",
      " [1.54893249e-01]\n",
      " [9.78489816e-02]\n",
      " [1.65713698e-01]\n",
      " [1.88179016e-02]\n",
      " [1.03738695e-01]\n",
      " [4.47683632e-02]\n",
      " [6.28460646e-02]\n",
      " [7.14368224e-02]\n",
      " [1.39000416e-01]\n",
      " [3.39699447e-01]\n",
      " [2.71781713e-01]\n",
      " [3.60253692e-01]\n",
      " [3.01345706e-01]\n",
      " [1.52772665e-02]\n",
      " [1.13264471e-01]\n",
      " [3.83036017e-01]\n",
      " [2.02703565e-01]\n",
      " [9.13608074e-02]\n",
      " [3.54260147e-01]\n",
      " [4.23857570e-03]\n",
      " [1.60932541e-06]\n",
      " [3.30579937e-01]\n",
      " [1.59680545e-02]\n",
      " [7.86364079e-02]\n",
      " [3.03350568e-01]\n",
      " [3.21093440e-01]\n",
      " [2.79589981e-01]\n",
      " [1.33261651e-01]\n",
      " [5.10391295e-02]\n",
      " [1.01228595e-01]\n",
      " [5.47424555e-02]\n",
      " [1.21959120e-01]\n",
      " [3.19688022e-02]\n",
      " [2.48929560e-01]\n",
      " [3.85427952e-01]\n",
      " [1.20207071e-01]\n",
      " [1.63200736e-01]\n",
      " [1.87168121e-02]\n",
      " [2.47230798e-01]\n",
      " [1.29504412e-01]\n",
      " [3.59649420e-01]\n",
      " [3.04808617e-01]\n",
      " [1.40879393e-01]\n",
      " [9.91997719e-02]\n",
      " [3.12655747e-01]\n",
      " [5.45983315e-02]\n",
      " [5.49392700e-02]\n",
      " [9.08112824e-02]\n",
      " [1.07209384e-01]\n",
      " [4.22244072e-02]\n",
      " [7.00407326e-02]\n",
      " [6.36618137e-02]\n",
      " [9.89148021e-02]\n",
      " [7.10099638e-02]\n",
      " [2.78840959e-02]\n",
      " [2.44200230e-02]\n",
      " [1.13046139e-01]\n",
      " [2.75881052e-01]\n",
      " [2.04061657e-01]\n",
      " [3.32018077e-01]\n",
      " [4.70448256e-01]\n",
      " [2.42517650e-01]\n",
      " [2.53493696e-01]\n",
      " [2.86933482e-01]\n",
      " [2.98722804e-01]\n",
      " [7.72428215e-02]\n",
      " [2.17959523e-01]\n",
      " [3.11319888e-01]\n",
      " [3.39265764e-02]\n",
      " [6.12395227e-01]\n",
      " [3.73327732e-01]\n",
      " [3.31343234e-01]\n",
      " [2.16384798e-01]\n",
      " [1.09943867e-01]\n",
      " [2.95027375e-01]\n",
      " [4.13508236e-01]\n",
      " [2.36589462e-01]\n",
      " [7.51722455e-02]\n",
      " [2.12485939e-01]\n",
      " [2.26014704e-01]\n",
      " [3.27068388e-01]\n",
      " [3.42185348e-01]\n",
      " [4.03801590e-01]\n",
      " [3.40871066e-01]\n",
      " [3.26165110e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.]]\n",
      "pod 1st:  0.041666666666666664\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 426us/step - loss: 0.4528 - acc: 0.8583 - val_loss: 0.4446 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.4281 - acc: 0.8583 - val_loss: 0.4477 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.4176 - acc: 0.8583 - val_loss: 0.4408 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.4170 - acc: 0.8583 - val_loss: 0.4447 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.4055 - acc: 0.8588 - val_loss: 0.4328 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.4038 - acc: 0.8588 - val_loss: 0.4326 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.3975 - acc: 0.8604 - val_loss: 0.4268 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3955 - acc: 0.8567 - val_loss: 0.4627 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3825 - acc: 0.8608 - val_loss: 0.4057 - val_acc: 0.8450\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 67us/step - loss: 0.3654 - acc: 0.8675 - val_loss: 0.4202 - val_acc: 0.8517\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3659 - acc: 0.8675 - val_loss: 0.3785 - val_acc: 0.8533\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.3506 - acc: 0.8721 - val_loss: 0.3797 - val_acc: 0.8550\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3542 - acc: 0.8704 - val_loss: 0.3838 - val_acc: 0.8583\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.3444 - acc: 0.8738 - val_loss: 0.3660 - val_acc: 0.8583\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3404 - acc: 0.8746 - val_loss: 0.3648 - val_acc: 0.8583\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3348 - acc: 0.8750 - val_loss: 0.4014 - val_acc: 0.8517\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3221 - acc: 0.8746 - val_loss: 0.3849 - val_acc: 0.8617\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3200 - acc: 0.8762 - val_loss: 0.3594 - val_acc: 0.8567\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.3142 - acc: 0.8808 - val_loss: 0.3550 - val_acc: 0.8550\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 74us/step - loss: 0.3120 - acc: 0.8808 - val_loss: 0.3431 - val_acc: 0.8583\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 76us/step - loss: 0.2950 - acc: 0.8829 - val_loss: 0.3582 - val_acc: 0.8633\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 81us/step - loss: 0.2984 - acc: 0.8871 - val_loss: 0.3526 - val_acc: 0.8667\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 76us/step - loss: 0.2869 - acc: 0.8883 - val_loss: 0.3300 - val_acc: 0.8667\n",
      "Epoch 24/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.2802 - acc: 0.8871 - val_loss: 0.3203 - val_acc: 0.8750\n",
      "Epoch 25/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.2800 - acc: 0.8929 - val_loss: 0.3421 - val_acc: 0.8583\n",
      "Epoch 26/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.2817 - acc: 0.8846 - val_loss: 0.3054 - val_acc: 0.8700\n",
      "Epoch 27/30\n",
      "2400/2400 [==============================] - 0s 67us/step - loss: 0.2625 - acc: 0.9029 - val_loss: 0.2965 - val_acc: 0.8833\n",
      "Epoch 28/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.2575 - acc: 0.9000 - val_loss: 0.3097 - val_acc: 0.8600\n",
      "Epoch 29/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.2614 - acc: 0.9000 - val_loss: 0.3120 - val_acc: 0.8817\n",
      "Epoch 30/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.2460 - acc: 0.9050 - val_loss: 0.2961 - val_acc: 0.8833\n",
      "y2_pred:  [[6.64756238e-01]\n",
      " [7.52502084e-02]\n",
      " [3.12144160e-02]\n",
      " [5.61383069e-02]\n",
      " [1.54837668e-02]\n",
      " [2.76445448e-02]\n",
      " [5.98975122e-02]\n",
      " [1.35231256e-01]\n",
      " [6.14150763e-02]\n",
      " [9.34779644e-02]\n",
      " [9.73490357e-01]\n",
      " [1.10660762e-01]\n",
      " [3.36401761e-02]\n",
      " [6.22749329e-02]\n",
      " [5.29368222e-02]\n",
      " [1.42296553e-02]\n",
      " [3.33549380e-02]\n",
      " [3.50440145e-02]\n",
      " [1.29753828e-01]\n",
      " [9.75638628e-04]\n",
      " [2.61392295e-02]\n",
      " [1.86457038e-02]\n",
      " [3.30621898e-02]\n",
      " [5.74237108e-03]\n",
      " [4.78913486e-02]\n",
      " [9.70908999e-03]\n",
      " [5.58789372e-02]\n",
      " [1.99072808e-01]\n",
      " [2.20924616e-02]\n",
      " [1.78970993e-02]\n",
      " [1.43969059e-02]\n",
      " [2.21046805e-02]\n",
      " [5.90279400e-02]\n",
      " [7.71582127e-03]\n",
      " [8.55704427e-01]\n",
      " [3.10420394e-02]\n",
      " [9.98252630e-03]\n",
      " [8.59462142e-01]\n",
      " [1.59710646e-02]\n",
      " [4.32632864e-02]\n",
      " [3.20327580e-02]\n",
      " [1.54458344e-01]\n",
      " [9.26311910e-02]\n",
      " [1.49423480e-02]\n",
      " [4.99919653e-02]\n",
      " [1.41339540e-01]\n",
      " [5.15961409e-01]\n",
      " [2.91519940e-01]\n",
      " [6.53302670e-03]\n",
      " [1.18847102e-01]\n",
      " [1.89191997e-02]\n",
      " [6.28346801e-02]\n",
      " [1.86889917e-01]\n",
      " [5.64797223e-02]\n",
      " [2.31700420e-01]\n",
      " [5.10998666e-02]\n",
      " [6.97703958e-02]\n",
      " [3.68260622e-01]\n",
      " [5.64911962e-02]\n",
      " [5.24889529e-02]\n",
      " [9.05808210e-02]\n",
      " [8.84779096e-02]\n",
      " [2.64379382e-03]\n",
      " [1.39679015e-02]\n",
      " [4.02928889e-02]\n",
      " [8.25766802e-01]\n",
      " [2.62425900e-01]\n",
      " [8.94390643e-02]\n",
      " [5.62241673e-02]\n",
      " [1.71908736e-02]\n",
      " [3.66261601e-03]\n",
      " [2.76435018e-02]\n",
      " [3.83096218e-01]\n",
      " [1.37039959e-01]\n",
      " [4.54405844e-02]\n",
      " [2.45669782e-02]\n",
      " [7.68249333e-02]\n",
      " [1.56858861e-02]\n",
      " [3.87983918e-02]\n",
      " [6.30457401e-02]\n",
      " [1.26784325e-01]\n",
      " [3.49852443e-03]\n",
      " [1.01999044e-02]\n",
      " [3.79512310e-02]\n",
      " [1.06883436e-01]\n",
      " [9.93091166e-02]\n",
      " [7.88459182e-03]\n",
      " [8.07425380e-03]\n",
      " [1.74958408e-02]\n",
      " [2.08622634e-01]\n",
      " [1.88758373e-02]\n",
      " [3.77439857e-02]\n",
      " [6.15557432e-02]\n",
      " [1.36923492e-02]\n",
      " [1.67187154e-02]\n",
      " [1.87972486e-02]\n",
      " [2.78495848e-02]\n",
      " [2.70852149e-02]\n",
      " [3.09484363e-01]\n",
      " [1.17009014e-01]\n",
      " [2.78621912e-03]\n",
      " [9.01191533e-02]\n",
      " [2.36348808e-01]\n",
      " [1.01378560e-03]\n",
      " [3.63687277e-02]\n",
      " [1.20649934e-02]\n",
      " [2.68646002e-01]\n",
      " [7.36857355e-02]\n",
      " [3.51125598e-02]\n",
      " [2.29723155e-02]\n",
      " [2.00613528e-01]\n",
      " [5.03852963e-03]\n",
      " [6.27824664e-03]\n",
      " [2.89813876e-02]\n",
      " [6.87233508e-02]\n",
      " [1.08705223e-01]\n",
      " [3.73014808e-02]\n",
      " [3.23298424e-01]\n",
      " [1.11448318e-01]\n",
      " [7.44453073e-03]\n",
      " [3.66511047e-02]\n",
      " [2.68757343e-02]\n",
      " [1.19582504e-01]\n",
      " [4.54738438e-02]\n",
      " [2.07930207e-02]\n",
      " [1.14139915e-03]\n",
      " [3.79306316e-01]\n",
      " [3.26268971e-02]\n",
      " [6.94160461e-02]\n",
      " [8.38589668e-03]\n",
      " [4.79010642e-02]\n",
      " [3.96365225e-02]\n",
      " [3.10786664e-02]\n",
      " [8.59413445e-02]\n",
      " [8.58711600e-02]\n",
      " [4.12060618e-02]\n",
      " [6.88900948e-02]\n",
      " [1.45503283e-02]\n",
      " [1.67862177e-02]\n",
      " [3.58924270e-03]\n",
      " [5.30835986e-03]\n",
      " [3.37948978e-01]\n",
      " [8.91861320e-03]\n",
      " [6.10799193e-02]\n",
      " [3.62439752e-02]\n",
      " [8.31911385e-01]\n",
      " [3.67028892e-01]\n",
      " [5.59334755e-02]\n",
      " [4.11902964e-02]\n",
      " [3.12041640e-02]\n",
      " [5.54573536e-03]\n",
      " [2.29620934e-02]\n",
      " [1.02293670e-01]\n",
      " [5.79053164e-03]\n",
      " [8.40677619e-02]\n",
      " [1.82113320e-01]\n",
      " [2.10286379e-02]\n",
      " [4.00474668e-03]\n",
      " [3.96133959e-02]\n",
      " [7.61813045e-01]\n",
      " [4.31895256e-03]\n",
      " [4.17909920e-02]\n",
      " [4.62249219e-02]\n",
      " [4.19861376e-02]\n",
      " [2.58041918e-02]\n",
      " [6.33853376e-02]\n",
      " [3.38039994e-02]\n",
      " [2.12976336e-03]\n",
      " [1.71518654e-01]\n",
      " [2.05580592e-02]\n",
      " [4.92300093e-02]\n",
      " [4.70684171e-02]\n",
      " [1.48411721e-01]\n",
      " [8.25834274e-03]\n",
      " [1.49456561e-02]\n",
      " [2.86095828e-01]\n",
      " [6.68551326e-02]\n",
      " [9.50205326e-02]\n",
      " [3.42661738e-02]\n",
      " [5.76543808e-02]\n",
      " [5.48111498e-02]\n",
      " [8.20046306e-01]\n",
      " [3.91885638e-02]\n",
      " [1.69754148e-01]\n",
      " [4.85151112e-02]\n",
      " [5.67502379e-02]\n",
      " [1.78381801e-03]\n",
      " [8.57962966e-02]\n",
      " [3.20297182e-02]\n",
      " [4.93383408e-02]\n",
      " [2.15220302e-01]\n",
      " [8.16771686e-02]\n",
      " [6.50553405e-02]\n",
      " [1.84887052e-02]\n",
      " [1.03467405e-02]\n",
      " [3.30962837e-02]\n",
      " [1.63189977e-01]\n",
      " [2.58659124e-02]\n",
      " [6.79812729e-02]\n",
      " [1.79003835e-01]\n",
      " [3.24268937e-02]\n",
      " [3.56453955e-02]\n",
      " [9.47594643e-01]\n",
      " [6.32262826e-02]\n",
      " [1.14717185e-02]\n",
      " [5.49844742e-01]\n",
      " [2.23284066e-02]\n",
      " [9.52476859e-02]\n",
      " [6.90581679e-01]\n",
      " [2.27308869e-02]\n",
      " [8.56952965e-02]\n",
      " [1.74631774e-02]\n",
      " [3.65073979e-02]\n",
      " [3.10139060e-02]\n",
      " [4.16333377e-02]\n",
      " [2.62736201e-01]\n",
      " [4.05108929e-02]\n",
      " [4.80169952e-02]\n",
      " [4.90974844e-01]\n",
      " [3.01637709e-01]\n",
      " [9.06065106e-03]\n",
      " [4.10324037e-02]\n",
      " [2.28335857e-02]\n",
      " [1.08787984e-01]\n",
      " [1.08259320e-02]\n",
      " [6.09016418e-03]\n",
      " [1.33836746e-01]\n",
      " [1.09456480e-02]\n",
      " [4.76777554e-04]\n",
      " [2.75488496e-02]\n",
      " [7.66114593e-02]\n",
      " [9.43407416e-03]\n",
      " [4.55482006e-02]\n",
      " [6.12655818e-01]\n",
      " [2.83412337e-01]\n",
      " [7.22832382e-02]\n",
      " [2.52943039e-02]\n",
      " [1.22736871e-01]\n",
      " [5.55898845e-01]\n",
      " [5.55066526e-01]\n",
      " [4.39616442e-02]\n",
      " [1.69889927e-02]\n",
      " [3.23682725e-02]\n",
      " [4.96201515e-02]\n",
      " [9.39059258e-03]\n",
      " [2.97705829e-02]\n",
      " [5.34880161e-03]\n",
      " [5.48865914e-01]\n",
      " [7.06664026e-02]\n",
      " [4.84696925e-02]\n",
      " [2.52889991e-02]\n",
      " [1.18697017e-01]\n",
      " [6.97466433e-02]\n",
      " [8.26485753e-02]\n",
      " [4.97594178e-02]\n",
      " [5.47654629e-02]\n",
      " [8.89506936e-02]\n",
      " [3.71351629e-01]\n",
      " [5.19334137e-01]\n",
      " [1.76552832e-02]\n",
      " [8.30437481e-01]\n",
      " [1.90502167e-01]\n",
      " [1.91071928e-02]\n",
      " [7.77933896e-02]\n",
      " [1.92514658e-02]\n",
      " [7.50613928e-01]\n",
      " [5.39623797e-02]\n",
      " [9.87839699e-03]\n",
      " [3.80214483e-01]\n",
      " [6.50435984e-02]\n",
      " [1.24135494e-01]\n",
      " [3.85094285e-02]\n",
      " [2.08402574e-01]\n",
      " [2.54275233e-01]\n",
      " [8.05389881e-02]\n",
      " [5.80003858e-03]\n",
      " [6.14039600e-02]\n",
      " [4.84851003e-03]\n",
      " [9.29543972e-02]\n",
      " [2.01092362e-01]\n",
      " [8.80026579e-01]\n",
      " [2.55178511e-02]\n",
      " [2.70065963e-02]\n",
      " [4.39549983e-02]\n",
      " [6.55344129e-02]\n",
      " [6.34091854e-01]\n",
      " [6.55098557e-02]\n",
      " [7.54187107e-02]\n",
      " [1.55095935e-01]\n",
      " [8.71461034e-02]\n",
      " [1.91390902e-01]\n",
      " [1.43264830e-02]\n",
      " [3.89112234e-02]\n",
      " [6.02804422e-02]\n",
      " [1.22360915e-01]\n",
      " [7.23928511e-02]\n",
      " [7.35163093e-02]\n",
      " [5.89977503e-02]\n",
      " [1.48593783e-02]\n",
      " [8.76486301e-02]\n",
      " [3.82453203e-03]\n",
      " [9.22710001e-02]\n",
      " [2.58053541e-02]\n",
      " [6.94377422e-02]\n",
      " [6.12950325e-03]\n",
      " [3.88019085e-02]\n",
      " [1.63239539e-02]\n",
      " [5.71016788e-01]\n",
      " [8.59352469e-01]\n",
      " [1.90773457e-01]\n",
      " [7.76068866e-02]\n",
      " [6.96491361e-01]\n",
      " [2.64188230e-01]\n",
      " [8.65412951e-01]\n",
      " [3.13638449e-02]\n",
      " [1.63950890e-01]\n",
      " [2.05887258e-02]\n",
      " [5.85251033e-01]\n",
      " [1.59398675e-01]\n",
      " [4.02599871e-01]\n",
      " [1.52714074e-01]\n",
      " [2.79473662e-01]\n",
      " [1.32568121e-01]\n",
      " [3.26218635e-01]\n",
      " [3.10359895e-02]\n",
      " [3.56254578e-02]\n",
      " [4.36581552e-01]\n",
      " [5.52361667e-01]\n",
      " [2.42182478e-01]\n",
      " [7.63805330e-01]\n",
      " [3.02511960e-01]\n",
      " [1.44839868e-01]\n",
      " [2.87767142e-01]]\n",
      "y22_pred:  [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.3958333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 429us/step - loss: 0.4625 - acc: 0.8504 - val_loss: 0.4918 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 74us/step - loss: 0.4119 - acc: 0.8629 - val_loss: 0.4687 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.4194 - acc: 0.8629 - val_loss: 0.4707 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3968 - acc: 0.8629 - val_loss: 0.4554 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3868 - acc: 0.8629 - val_loss: 0.4483 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.3823 - acc: 0.8629 - val_loss: 0.4299 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3788 - acc: 0.8629 - val_loss: 0.4246 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3720 - acc: 0.8629 - val_loss: 0.4259 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3722 - acc: 0.8629 - val_loss: 0.4329 - val_acc: 0.8233\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3612 - acc: 0.8629 - val_loss: 0.4404 - val_acc: 0.8233\n",
      "y2_pred:  [[0.32172656]\n",
      " [0.02468479]\n",
      " [0.00698337]\n",
      " [0.27157366]\n",
      " [0.11725351]\n",
      " [0.14427188]\n",
      " [0.33008108]\n",
      " [0.29794645]\n",
      " [0.01808923]\n",
      " [0.0383521 ]\n",
      " [0.01856732]\n",
      " [0.18744627]\n",
      " [0.07091516]\n",
      " [0.03321573]\n",
      " [0.02581182]\n",
      " [0.02626249]\n",
      " [0.02431014]\n",
      " [0.02074677]\n",
      " [0.05793336]\n",
      " [0.00849465]\n",
      " [0.22616047]\n",
      " [0.07754317]\n",
      " [0.01232958]\n",
      " [0.33659172]\n",
      " [0.33376887]\n",
      " [0.06761628]\n",
      " [0.12186497]\n",
      " [0.04229689]\n",
      " [0.02431354]\n",
      " [0.04511684]\n",
      " [0.19832125]\n",
      " [0.32641613]\n",
      " [0.29747003]\n",
      " [0.04771465]\n",
      " [0.02462658]\n",
      " [0.03352875]\n",
      " [0.07034299]\n",
      " [0.10175687]\n",
      " [0.24072123]\n",
      " [0.03479123]\n",
      " [0.01397672]\n",
      " [0.04692677]\n",
      " [0.19627455]\n",
      " [0.01159802]\n",
      " [0.01194417]\n",
      " [0.03421   ]\n",
      " [0.05676201]\n",
      " [0.12762141]\n",
      " [0.07209304]\n",
      " [0.0642063 ]\n",
      " [0.13108468]\n",
      " [0.0145883 ]\n",
      " [0.02957737]\n",
      " [0.05364594]\n",
      " [0.03074035]\n",
      " [0.1878716 ]\n",
      " [0.36809063]\n",
      " [0.121721  ]\n",
      " [0.07374546]\n",
      " [0.0122332 ]\n",
      " [0.26493794]\n",
      " [0.23226285]\n",
      " [0.11527979]\n",
      " [0.00825825]\n",
      " [0.02446434]\n",
      " [0.25292173]\n",
      " [0.17186591]\n",
      " [0.16050684]\n",
      " [0.02233225]\n",
      " [0.00871801]\n",
      " [0.12616947]\n",
      " [0.2993849 ]\n",
      " [0.00301346]\n",
      " [0.13036218]\n",
      " [0.04645851]\n",
      " [0.02192661]\n",
      " [0.26309305]\n",
      " [0.1832974 ]\n",
      " [0.01826733]\n",
      " [0.3480906 ]\n",
      " [0.2292603 ]\n",
      " [0.17350018]\n",
      " [0.19860432]\n",
      " [0.09745497]\n",
      " [0.05981749]\n",
      " [0.1594708 ]\n",
      " [0.0102292 ]\n",
      " [0.03338784]\n",
      " [0.0190956 ]\n",
      " [0.18093747]\n",
      " [0.06978935]\n",
      " [0.00871074]\n",
      " [0.05902761]\n",
      " [0.28587502]\n",
      " [0.0197632 ]\n",
      " [0.13353878]\n",
      " [0.09669909]\n",
      " [0.03570369]\n",
      " [0.05335215]\n",
      " [0.01359642]\n",
      " [0.06130803]\n",
      " [0.02307448]\n",
      " [0.02032587]\n",
      " [0.03707534]\n",
      " [0.03165191]\n",
      " [0.06376299]\n",
      " [0.10613576]\n",
      " [0.13256514]\n",
      " [0.00670233]\n",
      " [0.0402033 ]\n",
      " [0.01877743]\n",
      " [0.01401448]\n",
      " [0.29552633]\n",
      " [0.17666838]\n",
      " [0.12323382]\n",
      " [0.17996916]\n",
      " [0.05602357]\n",
      " [0.18074375]\n",
      " [0.3420419 ]\n",
      " [0.2055633 ]\n",
      " [0.02491227]\n",
      " [0.16847837]\n",
      " [0.02313036]\n",
      " [0.03607142]\n",
      " [0.05774406]\n",
      " [0.01684764]\n",
      " [0.03608504]\n",
      " [0.2545218 ]\n",
      " [0.04988968]\n",
      " [0.36554864]\n",
      " [0.0558295 ]\n",
      " [0.01616013]\n",
      " [0.11110547]\n",
      " [0.19190559]\n",
      " [0.27768153]\n",
      " [0.05819571]\n",
      " [0.27191532]\n",
      " [0.04027858]\n",
      " [0.15642995]\n",
      " [0.19471022]\n",
      " [0.23156518]\n",
      " [0.00699914]\n",
      " [0.3134225 ]\n",
      " [0.02990451]\n",
      " [0.04026011]\n",
      " [0.10973319]\n",
      " [0.14781925]\n",
      " [0.02215046]\n",
      " [0.03874177]\n",
      " [0.2774861 ]\n",
      " [0.00249335]\n",
      " [0.16266832]\n",
      " [0.01074752]\n",
      " [0.07142985]\n",
      " [0.06251842]\n",
      " [0.03063866]\n",
      " [0.13017446]\n",
      " [0.12046218]\n",
      " [0.00739148]\n",
      " [0.02293867]\n",
      " [0.29716307]\n",
      " [0.36152846]\n",
      " [0.09851879]\n",
      " [0.09355018]\n",
      " [0.01785624]\n",
      " [0.0206373 ]\n",
      " [0.05458826]\n",
      " [0.16975233]\n",
      " [0.0314059 ]\n",
      " [0.10039011]\n",
      " [0.07276806]\n",
      " [0.0490143 ]\n",
      " [0.13932356]\n",
      " [0.0227561 ]\n",
      " [0.07917762]\n",
      " [0.02046281]\n",
      " [0.00605768]\n",
      " [0.04157963]\n",
      " [0.3263765 ]\n",
      " [0.03930715]\n",
      " [0.04971308]\n",
      " [0.2029055 ]\n",
      " [0.13273507]\n",
      " [0.00918001]\n",
      " [0.06834394]\n",
      " [0.13190562]\n",
      " [0.08341581]\n",
      " [0.11143929]\n",
      " [0.07792753]\n",
      " [0.10619676]\n",
      " [0.10836005]\n",
      " [0.19581625]\n",
      " [0.00451484]\n",
      " [0.04322603]\n",
      " [0.30558315]\n",
      " [0.01010728]\n",
      " [0.36967838]\n",
      " [0.34965634]\n",
      " [0.02057776]\n",
      " [0.18455276]\n",
      " [0.03781813]\n",
      " [0.29575968]\n",
      " [0.04675862]\n",
      " [0.00643647]\n",
      " [0.14607543]\n",
      " [0.33618498]\n",
      " [0.12417445]\n",
      " [0.01864988]\n",
      " [0.06761926]\n",
      " [0.21253067]\n",
      " [0.03014067]\n",
      " [0.05213973]\n",
      " [0.01608753]\n",
      " [0.2513954 ]\n",
      " [0.02239272]\n",
      " [0.22148713]\n",
      " [0.055511  ]\n",
      " [0.12630245]\n",
      " [0.18353775]\n",
      " [0.01865304]\n",
      " [0.06407335]\n",
      " [0.00679085]\n",
      " [0.3272715 ]\n",
      " [0.27182555]\n",
      " [0.00928774]\n",
      " [0.02766034]\n",
      " [0.0574559 ]\n",
      " [0.20388803]\n",
      " [0.30271977]\n",
      " [0.08317092]\n",
      " [0.05524418]\n",
      " [0.0658212 ]\n",
      " [0.04600716]\n",
      " [0.04053476]\n",
      " [0.04732481]\n",
      " [0.27783212]\n",
      " [0.11031231]\n",
      " [0.15365314]\n",
      " [0.18151477]\n",
      " [0.32501543]\n",
      " [0.02796134]\n",
      " [0.34541446]\n",
      " [0.10261214]\n",
      " [0.02655321]\n",
      " [0.27110517]\n",
      " [0.01197037]\n",
      " [0.12349665]\n",
      " [0.13613483]\n",
      " [0.05320203]\n",
      " [0.02422994]\n",
      " [0.04247493]\n",
      " [0.3191124 ]\n",
      " [0.02393538]\n",
      " [0.04297215]\n",
      " [0.04412836]\n",
      " [0.03296494]\n",
      " [0.06158161]\n",
      " [0.07196534]\n",
      " [0.0420253 ]\n",
      " [0.27095214]\n",
      " [0.07526311]\n",
      " [0.32441044]\n",
      " [0.28790164]\n",
      " [0.0145323 ]\n",
      " [0.10230514]\n",
      " [0.07850301]\n",
      " [0.12246925]\n",
      " [0.32236883]\n",
      " [0.31749284]\n",
      " [0.23249355]\n",
      " [0.04637796]\n",
      " [0.02521265]\n",
      " [0.21635264]\n",
      " [0.23575392]\n",
      " [0.08874467]\n",
      " [0.32207924]\n",
      " [0.03221685]\n",
      " [0.00770584]\n",
      " [0.00813115]\n",
      " [0.0205566 ]\n",
      " [0.04661098]\n",
      " [0.24070054]\n",
      " [0.34406126]\n",
      " [0.01229113]\n",
      " [0.01113829]\n",
      " [0.20617211]\n",
      " [0.2777679 ]\n",
      " [0.04825106]\n",
      " [0.00817215]\n",
      " [0.00500497]\n",
      " [0.15494096]\n",
      " [0.34280658]\n",
      " [0.08825329]\n",
      " [0.20655614]\n",
      " [0.1626077 ]\n",
      " [0.11457986]\n",
      " [0.02822283]\n",
      " [0.33467248]\n",
      " [0.03412673]\n",
      " [0.0333719 ]\n",
      " [0.00626463]\n",
      " [0.29032084]\n",
      " [0.03600615]\n",
      " [0.01495594]\n",
      " [0.26981735]\n",
      " [0.11783442]\n",
      " [0.01120439]\n",
      " [0.0246309 ]\n",
      " [0.00919196]\n",
      " [0.26303697]\n",
      " [0.11665684]\n",
      " [0.02274266]\n",
      " [0.20646685]\n",
      " [0.11545131]\n",
      " [0.02166578]\n",
      " [0.0408811 ]\n",
      " [0.17621869]\n",
      " [0.15642661]\n",
      " [0.19766644]\n",
      " [0.05119762]\n",
      " [0.18150395]\n",
      " [0.136056  ]\n",
      " [0.15473184]\n",
      " [0.04182324]\n",
      " [0.26074663]\n",
      " [0.09502459]\n",
      " [0.04553512]\n",
      " [0.14361483]\n",
      " [0.00360055]\n",
      " [0.04362842]\n",
      " [0.24375682]\n",
      " [0.13323168]\n",
      " [0.24517432]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 1s 449us/step - loss: 0.4276 - acc: 0.8629 - val_loss: 0.4786 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 76us/step - loss: 0.4162 - acc: 0.8629 - val_loss: 0.4825 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.4054 - acc: 0.8629 - val_loss: 0.4831 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.4002 - acc: 0.8629 - val_loss: 0.4619 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3931 - acc: 0.8629 - val_loss: 0.4691 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3900 - acc: 0.8629 - val_loss: 0.4577 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3822 - acc: 0.8629 - val_loss: 0.4730 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 74us/step - loss: 0.3784 - acc: 0.8629 - val_loss: 0.4570 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3754 - acc: 0.8633 - val_loss: 0.4437 - val_acc: 0.8233\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 77us/step - loss: 0.3686 - acc: 0.8625 - val_loss: 0.4412 - val_acc: 0.8217\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3649 - acc: 0.8646 - val_loss: 0.4424 - val_acc: 0.8233\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3642 - acc: 0.8650 - val_loss: 0.4544 - val_acc: 0.8233\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.3570 - acc: 0.8625 - val_loss: 0.4324 - val_acc: 0.8233\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3495 - acc: 0.8642 - val_loss: 0.4237 - val_acc: 0.8367\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 76us/step - loss: 0.3478 - acc: 0.8629 - val_loss: 0.4228 - val_acc: 0.8350\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3494 - acc: 0.8679 - val_loss: 0.4472 - val_acc: 0.8333\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3414 - acc: 0.8650 - val_loss: 0.4423 - val_acc: 0.8283\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 82us/step - loss: 0.3391 - acc: 0.8658 - val_loss: 0.4186 - val_acc: 0.8383\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 91us/step - loss: 0.3360 - acc: 0.8667 - val_loss: 0.4398 - val_acc: 0.8333\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 90us/step - loss: 0.3307 - acc: 0.8679 - val_loss: 0.4222 - val_acc: 0.8350\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 81us/step - loss: 0.3314 - acc: 0.8667 - val_loss: 0.4019 - val_acc: 0.8367\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.3316 - acc: 0.8637 - val_loss: 0.4334 - val_acc: 0.8283\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3292 - acc: 0.8671 - val_loss: 0.4317 - val_acc: 0.8317\n",
      "Epoch 24/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.3298 - acc: 0.8704 - val_loss: 0.4331 - val_acc: 0.8317\n",
      "y2_pred:  [[9.37209427e-02]\n",
      " [2.98087299e-02]\n",
      " [2.15983719e-01]\n",
      " [3.69088948e-02]\n",
      " [1.33664161e-01]\n",
      " [2.02175200e-01]\n",
      " [6.04355037e-02]\n",
      " [1.57517701e-01]\n",
      " [5.80993295e-02]\n",
      " [2.46074557e-01]\n",
      " [6.91857934e-03]\n",
      " [4.34279442e-04]\n",
      " [4.82490957e-02]\n",
      " [8.00485909e-02]\n",
      " [3.41204703e-02]\n",
      " [2.50917971e-02]\n",
      " [4.95114625e-02]\n",
      " [3.74808848e-01]\n",
      " [1.30099356e-01]\n",
      " [2.92680681e-01]\n",
      " [3.98293734e-02]\n",
      " [1.68272853e-03]\n",
      " [1.28395557e-02]\n",
      " [9.74007547e-02]\n",
      " [5.88207543e-02]\n",
      " [2.99088061e-02]\n",
      " [3.79546076e-01]\n",
      " [1.89139903e-01]\n",
      " [4.85848188e-02]\n",
      " [1.83201730e-02]\n",
      " [2.95034230e-01]\n",
      " [5.53948641e-01]\n",
      " [5.53321838e-03]\n",
      " [2.88213491e-02]\n",
      " [4.68112528e-02]\n",
      " [1.93402469e-01]\n",
      " [2.49618351e-01]\n",
      " [4.05491292e-02]\n",
      " [3.13678980e-02]\n",
      " [5.78178465e-02]\n",
      " [4.26789820e-02]\n",
      " [2.80204713e-02]\n",
      " [7.65008330e-02]\n",
      " [7.83331990e-02]\n",
      " [6.97064698e-02]\n",
      " [3.56830359e-01]\n",
      " [3.09740305e-02]\n",
      " [6.51120245e-02]\n",
      " [6.21807575e-03]\n",
      " [1.42934293e-01]\n",
      " [2.74284184e-01]\n",
      " [1.07389390e-01]\n",
      " [1.10365361e-01]\n",
      " [4.72366810e-05]\n",
      " [4.08197939e-02]\n",
      " [1.20327801e-01]\n",
      " [2.95024514e-01]\n",
      " [3.56100798e-02]\n",
      " [3.33204269e-02]\n",
      " [2.47846246e-02]\n",
      " [2.77289569e-01]\n",
      " [1.85861409e-01]\n",
      " [2.19641626e-02]\n",
      " [8.03421438e-02]\n",
      " [3.06839168e-01]\n",
      " [1.00699276e-01]\n",
      " [1.64092332e-01]\n",
      " [2.37236619e-02]\n",
      " [9.21801329e-02]\n",
      " [2.41171420e-02]\n",
      " [1.74240649e-01]\n",
      " [1.43054426e-02]\n",
      " [1.92472517e-01]\n",
      " [4.52404022e-02]\n",
      " [2.67982185e-02]\n",
      " [9.90331173e-04]\n",
      " [2.02288568e-01]\n",
      " [1.76482797e-02]\n",
      " [1.49816275e-04]\n",
      " [3.69984210e-01]\n",
      " [6.55758381e-02]\n",
      " [3.66347432e-01]\n",
      " [2.31648773e-01]\n",
      " [5.64384460e-02]\n",
      " [4.03990448e-02]\n",
      " [2.69522190e-01]\n",
      " [5.91323018e-01]\n",
      " [3.47467661e-02]\n",
      " [2.98023224e-08]\n",
      " [6.58211708e-02]\n",
      " [2.82991529e-02]\n",
      " [3.71138155e-02]\n",
      " [3.17693055e-02]\n",
      " [3.37794244e-01]\n",
      " [6.75243139e-02]\n",
      " [1.99675560e-06]\n",
      " [1.87415183e-01]\n",
      " [9.61658061e-02]\n",
      " [2.51983702e-02]\n",
      " [6.46680593e-04]\n",
      " [6.85021281e-02]\n",
      " [2.85446644e-04]\n",
      " [3.70180905e-02]\n",
      " [1.96429282e-01]\n",
      " [8.06554854e-02]\n",
      " [1.45227015e-01]\n",
      " [9.57745314e-03]\n",
      " [1.63772404e-02]\n",
      " [1.51442587e-02]\n",
      " [9.03669000e-02]\n",
      " [4.07303870e-02]\n",
      " [2.85221636e-02]\n",
      " [4.34815198e-01]\n",
      " [1.07512116e-01]\n",
      " [8.25849771e-02]\n",
      " [4.54979807e-01]\n",
      " [6.84961379e-02]\n",
      " [9.86702144e-02]\n",
      " [1.45217776e-02]\n",
      " [2.06303596e-02]\n",
      " [9.45490301e-02]\n",
      " [2.80523002e-02]\n",
      " [3.45413387e-01]\n",
      " [4.64233458e-02]\n",
      " [2.11641639e-01]\n",
      " [3.87523711e-01]\n",
      " [7.84021616e-02]\n",
      " [2.46277273e-01]\n",
      " [7.46536851e-02]\n",
      " [4.62063551e-02]\n",
      " [9.48082507e-02]\n",
      " [3.27674985e-01]\n",
      " [3.15104425e-01]\n",
      " [2.52965987e-02]\n",
      " [1.53047353e-01]\n",
      " [7.64160156e-02]\n",
      " [9.21019912e-03]\n",
      " [5.28746843e-03]\n",
      " [1.43857867e-01]\n",
      " [2.25365162e-04]\n",
      " [4.28802073e-01]\n",
      " [7.10267127e-02]\n",
      " [7.20108747e-02]\n",
      " [1.02279246e-01]\n",
      " [4.36292589e-01]\n",
      " [2.80860156e-01]\n",
      " [7.11639822e-02]\n",
      " [4.48945105e-01]\n",
      " [4.07067508e-01]\n",
      " [1.69571221e-01]\n",
      " [1.14957333e-01]\n",
      " [1.01566195e-01]\n",
      " [5.70996106e-02]\n",
      " [2.17828929e-01]\n",
      " [4.58979309e-02]\n",
      " [5.26638925e-02]\n",
      " [2.13723779e-01]\n",
      " [4.20693517e-01]\n",
      " [3.00065070e-01]\n",
      " [1.88766688e-01]\n",
      " [6.75616562e-02]\n",
      " [1.32554203e-01]\n",
      " [4.60618138e-02]\n",
      " [9.85545218e-02]\n",
      " [1.64549261e-01]\n",
      " [3.13678980e-02]\n",
      " [2.45311081e-01]\n",
      " [1.16171867e-01]\n",
      " [7.84828663e-02]\n",
      " [2.26160079e-01]\n",
      " [2.99802423e-03]\n",
      " [9.76338983e-02]\n",
      " [3.46102476e-01]\n",
      " [1.25434548e-01]\n",
      " [3.13678980e-02]\n",
      " [8.10288489e-02]\n",
      " [2.93974578e-02]\n",
      " [1.41591132e-02]\n",
      " [7.77902901e-02]\n",
      " [8.30700099e-02]\n",
      " [3.53598475e-01]\n",
      " [2.74751902e-01]\n",
      " [1.50706053e-01]\n",
      " [1.35821998e-01]\n",
      " [5.01232147e-02]\n",
      " [1.03893489e-01]\n",
      " [1.66759789e-01]\n",
      " [4.11899090e-02]\n",
      " [1.46807164e-01]\n",
      " [4.11117762e-01]\n",
      " [4.08603489e-01]\n",
      " [1.36093557e-01]\n",
      " [6.03533387e-02]\n",
      " [3.29663157e-02]\n",
      " [2.13078558e-02]\n",
      " [5.98657131e-02]\n",
      " [6.96156621e-02]\n",
      " [9.40993726e-02]\n",
      " [1.05307937e-01]\n",
      " [3.91386747e-02]\n",
      " [2.08626091e-01]\n",
      " [5.07515967e-02]\n",
      " [1.45560652e-01]\n",
      " [2.74668038e-02]\n",
      " [2.84702480e-02]\n",
      " [2.75667608e-01]\n",
      " [2.36546993e-02]\n",
      " [1.56193405e-01]\n",
      " [2.40391374e-01]\n",
      " [3.00117195e-01]\n",
      " [3.79171252e-01]\n",
      " [2.60967612e-02]\n",
      " [3.13678980e-02]\n",
      " [4.84850407e-02]\n",
      " [3.88416171e-01]\n",
      " [3.13678980e-02]\n",
      " [3.13678980e-02]\n",
      " [2.77703702e-02]\n",
      " [7.14661479e-02]\n",
      " [3.11330557e-02]\n",
      " [2.48835683e-02]\n",
      " [6.59843981e-02]\n",
      " [2.53313303e-01]\n",
      " [1.47708625e-01]\n",
      " [1.76682383e-01]\n",
      " [3.16705078e-01]\n",
      " [3.06143552e-01]\n",
      " [2.14659572e-02]\n",
      " [4.99007076e-01]\n",
      " [2.15215683e-02]\n",
      " [5.33388555e-02]\n",
      " [6.32572174e-03]\n",
      " [9.91300344e-02]\n",
      " [3.13678980e-02]\n",
      " [5.06041944e-02]\n",
      " [1.87999010e-02]\n",
      " [6.49690628e-06]\n",
      " [2.01348841e-01]\n",
      " [3.54026616e-01]\n",
      " [2.44829059e-02]\n",
      " [1.01924419e-01]\n",
      " [7.36455798e-01]\n",
      " [3.21916640e-02]\n",
      " [4.33309793e-01]\n",
      " [7.29657412e-02]\n",
      " [1.41060144e-01]\n",
      " [4.58328128e-02]\n",
      " [5.48435152e-02]\n",
      " [4.37420309e-02]\n",
      " [4.33556437e-02]\n",
      " [6.25703037e-02]\n",
      " [3.28234136e-01]\n",
      " [9.40587521e-02]\n",
      " [2.69347429e-02]\n",
      " [2.87179053e-02]\n",
      " [4.01596993e-01]\n",
      " [3.73172760e-01]\n",
      " [5.26439250e-02]\n",
      " [8.38372409e-02]\n",
      " [8.11739564e-02]\n",
      " [2.29358912e-01]\n",
      " [4.14622724e-02]\n",
      " [7.33824670e-02]\n",
      " [9.45737958e-02]\n",
      " [3.13678980e-02]\n",
      " [2.63572395e-01]\n",
      " [5.78389764e-02]\n",
      " [1.19474381e-01]\n",
      " [3.94091517e-01]\n",
      " [3.58708203e-01]\n",
      " [1.68072581e-01]\n",
      " [8.72122645e-02]\n",
      " [3.05497468e-01]\n",
      " [1.59421653e-01]\n",
      " [1.15670264e-01]\n",
      " [3.13678980e-02]\n",
      " [3.13678980e-02]\n",
      " [5.47469258e-02]\n",
      " [1.85274601e-01]\n",
      " [4.75256443e-02]\n",
      " [3.20553780e-04]\n",
      " [5.97786903e-02]\n",
      " [1.28200382e-01]\n",
      " [2.27380216e-01]\n",
      " [6.33311272e-03]\n",
      " [4.80700433e-02]\n",
      " [2.78634727e-02]\n",
      " [8.93734992e-02]\n",
      " [3.10836136e-02]\n",
      " [8.27143192e-02]\n",
      " [5.36441803e-06]\n",
      " [5.75716197e-02]\n",
      " [1.03473306e-01]\n",
      " [4.27014232e-02]\n",
      " [2.77392864e-02]\n",
      " [8.67923796e-02]\n",
      " [1.10035330e-01]\n",
      " [4.80034351e-02]\n",
      " [5.33502698e-02]\n",
      " [1.81714267e-01]\n",
      " [2.45428085e-02]\n",
      " [1.84875160e-01]\n",
      " [3.70644152e-01]\n",
      " [2.16999352e-02]\n",
      " [4.85603809e-01]\n",
      " [1.33531272e-01]\n",
      " [0.00000000e+00]\n",
      " [2.56622404e-01]\n",
      " [9.15691555e-02]\n",
      " [6.21150970e-01]\n",
      " [6.11051917e-02]\n",
      " [4.72276509e-02]\n",
      " [1.29576236e-01]\n",
      " [2.21817791e-02]\n",
      " [1.11557424e-01]\n",
      " [1.25238895e-02]\n",
      " [1.42629147e-02]\n",
      " [2.49294579e-01]\n",
      " [1.36058956e-01]\n",
      " [1.10649586e-01]\n",
      " [3.72574031e-01]\n",
      " [2.05950230e-01]\n",
      " [6.10874116e-01]\n",
      " [1.91302121e-01]\n",
      " [4.92822230e-02]\n",
      " [1.32488251e-01]\n",
      " [5.28553128e-02]\n",
      " [9.27435160e-02]\n",
      " [1.04518854e-07]\n",
      " [3.58072579e-01]\n",
      " [1.98172227e-01]\n",
      " [2.27460161e-01]\n",
      " [5.09030484e-02]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.041666666666666664\n",
      "pod:  [0.6122448979591837, 0.2857142857142857, 0.061224489795918366, 0.5, 0.08333333333333333, 0.20833333333333334, 0.041666666666666664, 0.3958333333333333, 0.0, 0.041666666666666664]\n",
      "pof:  [0.11578947368421053, 0.05263157894736842, 0.010526315789473684, 0.08771929824561403, 0.014035087719298246, 0.021052631578947368, 0.0035087719298245615, 0.031578947368421054, 0.0, 0.010526315789473684]\n",
      "auc:  [0.7482277121374866, 0.6165413533834586, 0.5253490870032224, 0.706140350877193, 0.5346491228070175, 0.5936403508771929, 0.5190789473684211, 0.682127192982456, 0.5, 0.5155701754385965]\n",
      "tn_list:  [252, 270, 282, 260, 281, 279, 284, 276, 285, 282]\n",
      "fp_list:  [33, 15, 3, 25, 4, 6, 1, 9, 0, 3]\n",
      "fn_list:  [19, 35, 46, 24, 44, 38, 46, 29, 48, 46]\n",
      "tp_list:  [30, 14, 3, 24, 4, 10, 2, 19, 0, 2]\n",
      "2751 99 375 108\n"
     ]
    }
   ],
   "source": [
    "df_x_train_chi = pd.DataFrame(x_train_chi)\n",
    "df_x_train_chi.head()\n",
    "\n",
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print('tn_list: ',tn_list)\n",
    "print ('fp_list: ',fp_list)\n",
    "print ('fn_list: ',fn_list)\n",
    "print ('tp_list: ',tp_list)\n",
    "\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 725us/step - loss: 0.5320 - acc: 0.8579 - val_loss: 0.4307 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.3988 - acc: 0.8587 - val_loss: 0.4245 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 90us/step - loss: 0.3920 - acc: 0.8587 - val_loss: 0.4170 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 87us/step - loss: 0.3851 - acc: 0.8587 - val_loss: 0.4134 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 86us/step - loss: 0.3805 - acc: 0.8587 - val_loss: 0.4221 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 761us/step - loss: 0.5497 - acc: 0.8237 - val_loss: 0.4336 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.4019 - acc: 0.8587 - val_loss: 0.4453 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.3961 - acc: 0.8587 - val_loss: 0.4216 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 80us/step - loss: 0.3914 - acc: 0.8587 - val_loss: 0.4171 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.3845 - acc: 0.8587 - val_loss: 0.4166 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 783us/step - loss: 0.5249 - acc: 0.8404 - val_loss: 0.4354 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 86us/step - loss: 0.3995 - acc: 0.8587 - val_loss: 0.4289 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.3932 - acc: 0.8587 - val_loss: 0.4189 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 85us/step - loss: 0.3865 - acc: 0.8587 - val_loss: 0.4138 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 84us/step - loss: 0.3798 - acc: 0.8587 - val_loss: 0.4239 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 888us/step - loss: 0.5335 - acc: 0.8250 - val_loss: 0.4324 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.3996 - acc: 0.8583 - val_loss: 0.4257 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.3930 - acc: 0.8583 - val_loss: 0.4237 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 91us/step - loss: 0.3868 - acc: 0.8583 - val_loss: 0.4175 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 105us/step - loss: 0.3801 - acc: 0.8583 - val_loss: 0.4175 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 935us/step - loss: 0.5688 - acc: 0.8242 - val_loss: 0.4385 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.4060 - acc: 0.8583 - val_loss: 0.4311 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3997 - acc: 0.8583 - val_loss: 0.4319 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 82us/step - loss: 0.3927 - acc: 0.8583 - val_loss: 0.4202 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.3885 - acc: 0.8583 - val_loss: 0.4235 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 1ms/step - loss: 0.5302 - acc: 0.8508 - val_loss: 0.4313 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.4014 - acc: 0.8583 - val_loss: 0.4251 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.3965 - acc: 0.8583 - val_loss: 0.4220 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3864 - acc: 0.8583 - val_loss: 0.4214 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 83us/step - loss: 0.3802 - acc: 0.8583 - val_loss: 0.4091 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 1ms/step - loss: 0.5471 - acc: 0.8217 - val_loss: 0.4336 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.4021 - acc: 0.8583 - val_loss: 0.4312 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3967 - acc: 0.8583 - val_loss: 0.4258 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3950 - acc: 0.8583 - val_loss: 0.4269 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.3872 - acc: 0.8583 - val_loss: 0.4155 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5194 - acc: 0.8267 - val_loss: 0.4382 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.4008 - acc: 0.8583 - val_loss: 0.4313 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3950 - acc: 0.8583 - val_loss: 0.4185 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3895 - acc: 0.8583 - val_loss: 0.4147 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3841 - acc: 0.8583 - val_loss: 0.4145 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5332 - acc: 0.8471 - val_loss: 0.4692 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3965 - acc: 0.8629 - val_loss: 0.4590 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3916 - acc: 0.8629 - val_loss: 0.4502 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 90us/step - loss: 0.3827 - acc: 0.8629 - val_loss: 0.4532 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.3816 - acc: 0.8629 - val_loss: 0.4495 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5209 - acc: 0.8546 - val_loss: 0.4588 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3935 - acc: 0.8629 - val_loss: 0.4636 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 90us/step - loss: 0.3872 - acc: 0.8629 - val_loss: 0.4459 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3814 - acc: 0.8629 - val_loss: 0.4388 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.3777 - acc: 0.8629 - val_loss: 0.4467 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2850 0 483 0\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "def get_RNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    import pandas as pd\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Dropout, LSTM, GRU\n",
    "    from keras.layers import Embedding\n",
    "    max_features = 10000 # number of words to consider as features\n",
    "    import numpy as np\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_RNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    \n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
