{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"churn-data-3333.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  area_code  number_vmail_messages  total_day_minutes  \\\n",
       "0             128        415                     25              265.1   \n",
       "1             107        415                     26              161.6   \n",
       "2             137        415                      0              243.4   \n",
       "3              84        408                      0              299.4   \n",
       "4              75        415                      0              166.7   \n",
       "\n",
       "   total_day_calls  total_day_charge  total_eve_minutes  total_eve_calls  \\\n",
       "0              110             45.07              197.4               99   \n",
       "1              123             27.47              195.5              103   \n",
       "2              114             41.38              121.2              110   \n",
       "3               71             50.90               61.9               88   \n",
       "4              113             28.34              148.3              122   \n",
       "\n",
       "   total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0             16.78                244.7                 91   \n",
       "1             16.62                254.4                103   \n",
       "2             10.30                162.6                104   \n",
       "3              5.26                196.9                 89   \n",
       "4             12.61                186.9                121   \n",
       "\n",
       "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0               11.01                10.0                 3   \n",
       "1               11.45                13.7                 3   \n",
       "2                7.32                12.2                 5   \n",
       "3                8.86                 6.6                 7   \n",
       "4                8.41                10.1                 3   \n",
       "\n",
       "   total_intl_charge  number_customer_service_calls  \n",
       "0               2.70                              1  \n",
       "1               3.70                              1  \n",
       "2               3.29                              0  \n",
       "3               1.78                              2  \n",
       "4               2.73                              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "\n",
    "churn=cat_df['churn']\n",
    "cat_df=cat_df.drop(['churn'], axis=1)\n",
    "cat_df=cat_df.drop(['phone number'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#BOX-COX\n",
    "#lemda=0.5\n",
    "#num_df=(num_df**lemda)\n",
    "#num_df=num_df-1\n",
    "#num_df[num_df < 0]=0\n",
    "#num_df=num_df.div(lemda)\n",
    "#End BOX-COX\n",
    "#Z-score\n",
    "#num_df=(num_df-num_df.min())/(num_df.std(ddof=0)) ##Z-score\n",
    "\n",
    "#Log\n",
    "num_df=round(np.log(num_df.add(1)),2)\n",
    "num_df=num_df.replace([np.inf, -np.inf], np.nan)\n",
    "#End Log\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "X_train=X\n",
    "X_test=X\n",
    "y_train=y\n",
    "y_test=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>international_plan</td>\n",
       "      <td>203.244178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number_vmail_messages</td>\n",
       "      <td>80.494379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>voice_mail_plan</td>\n",
       "      <td>25.156959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number_customer_service_calls</td>\n",
       "      <td>23.087955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_day_charge</td>\n",
       "      <td>2.490080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>state</td>\n",
       "      <td>1.701057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_day_minutes</td>\n",
       "      <td>1.679470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_intl_calls</td>\n",
       "      <td>1.640827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_eve_charge</td>\n",
       "      <td>0.607927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_intl_minutes</td>\n",
       "      <td>0.563038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_intl_charge</td>\n",
       "      <td>0.555667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_eve_minutes</td>\n",
       "      <td>0.378399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_night_charge</td>\n",
       "      <td>0.148628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_night_minutes</td>\n",
       "      <td>0.084615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account_length</td>\n",
       "      <td>0.067607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_eve_calls</td>\n",
       "      <td>0.005106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_night_calls</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_day_calls</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_code</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature      Scores\n",
       "17             international_plan  203.244178\n",
       "2           number_vmail_messages   80.494379\n",
       "18                voice_mail_plan   25.156959\n",
       "15  number_customer_service_calls   23.087955\n",
       "5                total_day_charge    2.490080\n",
       "16                          state    1.701057\n",
       "3               total_day_minutes    1.679470\n",
       "13               total_intl_calls    1.640827\n",
       "8                total_eve_charge    0.607927\n",
       "12             total_intl_minutes    0.563038\n",
       "14              total_intl_charge    0.555667\n",
       "6               total_eve_minutes    0.378399\n",
       "11             total_night_charge    0.148628\n",
       "9             total_night_minutes    0.084615\n",
       "0                  account_length    0.067607\n",
       "7                 total_eve_calls    0.005106\n",
       "10              total_night_calls    0.000725\n",
       "4                 total_day_calls    0.000185\n",
       "1                       area_code    0.000182"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X\n",
    "y_train=y\n",
    "#Univariate Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "select_feature = SelectKBest(chi2, k=15).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                     'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y\n",
    "x_train_chi = select_feature.transform(X)\n",
    "x_train_chi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648 202 318 165\n",
      "pod:  0.3416149068322981\n",
      "pof:  0.07087719298245614\n",
      "AUC:  0.635368856924921\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.0006579332246575676}\n",
      "GaussianNB(priors=None, var_smoothing=0.0006579332246575676)\n",
      "0.8591859185918592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=5, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "classifier=GaussianNB();\n",
    "#params = {\n",
    "#          \"priors\" : \"None\",\n",
    "#          \"var_smoothing\" : 1e-9\n",
    "#}\n",
    "#create an list of var_smoothing to cross validate\n",
    "#steps = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "grid = GridSearchCV(estimator=classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    " \n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26710 23728 21590 27972\n",
      "pod:  0.5643840038739357\n",
      "pof:  0.4704389547563345\n",
      "AUC:  0.5469725245588006\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825 25 442 41\n",
      "pod:  0.08488612836438923\n",
      "pof:  0.008771929824561403\n",
      "AUC:  0.5380570992699139\n",
      "accuracy:  0.8598859885988599\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB(priors=None, var_smoothing=0.0006579332246575676)\n",
    "\n",
    "classifier.fit(x_train_chi,y_train)\n",
    "\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=10, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 5)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.54812\n"
     ]
    }
   ],
   "source": [
    " #accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "accuracy=(26836+27976)/(27976+22462+22726+26836)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8610861086108611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  2.0min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},    \n",
    "    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}\n",
    "]\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2799 51 413 70\n",
      "pod:  0.14492753623188406\n",
      "pof:  0.017894736842105262\n",
      "AUC:  0.5635163996948894\n",
      "accuracy:  0.8607860786078608\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression(C=6, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.8631863186318632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "param_grid ={\n",
    "   'n_neighbors': [3,5,11,19],\n",
    "   'weights': ['uniform', 'distance'],\n",
    "   'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=3, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 410.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 1993.6min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "# Specify parameters\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 1e-3, 1e-4]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'], \n",
    "                     'gamma': [0.001, 0.01, 0.1, 1, 1e-3, 1e-4], \n",
    "                     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} ]\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2818 32 431 52\n",
      "pod:  0.10766045548654245\n",
      "pof:  0.011228070175438596\n",
      "AUC:  0.5482161926555519\n",
      "accuracy:  0.8610861086108611\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "           weights='uniform' )  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2827 23 456 27\n",
      "pod:  0.055900621118012424\n",
      "pof:  0.008070175438596491\n",
      "AUC:  0.5239152228397079\n",
      "accuracy:  0.8562856285628563\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.8631863186318632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "#clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "#parameters = {'n_estimators': [4, 6, 9], \n",
    "#              'max_features': ['log2', 'sqrt','auto'], \n",
    "#              'criterion': ['entropy', 'gini'],\n",
    "#              'max_depth': [2, 3, 5, 10], \n",
    "#              'min_samples_split': [2, 3, 5],\n",
    "#              'min_samples_leaf': [1,5,8]\n",
    "#             }\n",
    "\n",
    "#model_params = {\n",
    "#    'n_estimators': [50, 150, 250],\n",
    "#    'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "#    'min_samples_split': [2, 4, 6]\n",
    "#}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 110, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 1000}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=110, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.9510951095109511\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831 19 134 349\n",
      "pod:  0.722567287784679\n",
      "pof:  0.006666666666666667\n",
      "AUC:  0.8579503105590062\n",
      "accuracy:  0.9540954095409541\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(bootstrap= True, max_depth= 110, max_features= 3, min_samples_leaf= 3, min_samples_split= 8, n_estimators= 1000)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849 1 473 10\n",
      "pod:  0.020703933747412008\n",
      "pof:  0.0003508771929824561\n",
      "AUC:  0.5101765282772147\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2724 126 130 353\n",
      "pod:  0.7308488612836439\n",
      "pof:  0.04421052631578947\n",
      "AUC:  0.8433191674839272\n",
      "accuracy:  0.9231923192319232\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2705 145 129 354\n",
      "pod:  0.7329192546583851\n",
      "pof:  0.05087719298245614\n",
      "AUC:  0.8410210308379645\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817 33 126 357\n",
      "pod:  0.7391304347826086\n",
      "pof:  0.011578947368421053\n",
      "AUC:  0.8637757437070938\n",
      "accuracy:  0.9522952295229523\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#classifier = GradientBoostingClassifier(max_features=None, max_depth=3, criterion='friedman_mse')\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27860 22578 18243 31319\n",
      "pod:  0.631915580485049\n",
      "pof:  0.44763868511836313\n",
      "AUC:  0.592138447683343\n",
      "accuracy:  0.59179\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 0s 191us/step - loss: 0.4660 - acc: 0.8458 - val_loss: 0.4316 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 55us/step - loss: 0.4072 - acc: 0.8587 - val_loss: 0.4288 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 78us/step - loss: 0.4102 - acc: 0.8587 - val_loss: 0.4288 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 75us/step - loss: 0.3997 - acc: 0.8587 - val_loss: 0.4171 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3904 - acc: 0.8587 - val_loss: 0.4182 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.3859 - acc: 0.8587 - val_loss: 0.3993 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3776 - acc: 0.8587 - val_loss: 0.3985 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3733 - acc: 0.8608 - val_loss: 0.4238 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3827 - acc: 0.8587 - val_loss: 0.3908 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.3708 - acc: 0.8587 - val_loss: 0.4021 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3715 - acc: 0.8624 - val_loss: 0.3933 - val_acc: 0.8433\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.3697 - acc: 0.8637 - val_loss: 0.3893 - val_acc: 0.8450\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 56us/step - loss: 0.3611 - acc: 0.8612 - val_loss: 0.3833 - val_acc: 0.8433\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 60us/step - loss: 0.3648 - acc: 0.8629 - val_loss: 0.4040 - val_acc: 0.8417\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.3573 - acc: 0.8633 - val_loss: 0.3938 - val_acc: 0.8283\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3606 - acc: 0.8645 - val_loss: 0.3860 - val_acc: 0.8333\n",
      "y2_pred:  [[0.06572959]\n",
      " [0.0805653 ]\n",
      " [0.1608516 ]\n",
      " [0.56669885]\n",
      " [0.5370185 ]\n",
      " [0.47537288]\n",
      " [0.07483208]\n",
      " [0.47513855]\n",
      " [0.10674894]\n",
      " [0.21045136]\n",
      " [0.160835  ]\n",
      " [0.12572521]\n",
      " [0.12677065]\n",
      " [0.21782658]\n",
      " [0.10912523]\n",
      " [0.2535692 ]\n",
      " [0.0404726 ]\n",
      " [0.18808892]\n",
      " [0.08127108]\n",
      " [0.19820094]\n",
      " [0.05935904]\n",
      " [0.18006295]\n",
      " [0.1223793 ]\n",
      " [0.15413165]\n",
      " [0.07473594]\n",
      " [0.17221692]\n",
      " [0.06689158]\n",
      " [0.25685522]\n",
      " [0.11547425]\n",
      " [0.11175576]\n",
      " [0.08361968]\n",
      " [0.19357985]\n",
      " [0.35092747]\n",
      " [0.20323667]\n",
      " [0.05625525]\n",
      " [0.07496074]\n",
      " [0.00609517]\n",
      " [0.11205983]\n",
      " [0.10655749]\n",
      " [0.11195841]\n",
      " [0.18539643]\n",
      " [0.17168853]\n",
      " [0.09318033]\n",
      " [0.11348897]\n",
      " [0.11948043]\n",
      " [0.08357537]\n",
      " [0.2949194 ]\n",
      " [0.20109636]\n",
      " [0.21987617]\n",
      " [0.07770419]\n",
      " [0.16421542]\n",
      " [0.14180514]\n",
      " [0.14059725]\n",
      " [0.14109322]\n",
      " [0.16988224]\n",
      " [0.10286644]\n",
      " [0.15690634]\n",
      " [0.16854006]\n",
      " [0.15430194]\n",
      " [0.17328942]\n",
      " [0.10874188]\n",
      " [0.0842571 ]\n",
      " [0.10789037]\n",
      " [0.12871146]\n",
      " [0.20201033]\n",
      " [0.0949811 ]\n",
      " [0.30718333]\n",
      " [0.33854464]\n",
      " [0.19696167]\n",
      " [0.23337582]\n",
      " [0.25870717]\n",
      " [0.05144274]\n",
      " [0.3001657 ]\n",
      " [0.19173253]\n",
      " [0.09273994]\n",
      " [0.19856423]\n",
      " [0.13902923]\n",
      " [0.18716931]\n",
      " [0.28966805]\n",
      " [0.210644  ]\n",
      " [0.14005896]\n",
      " [0.5187451 ]\n",
      " [0.12314892]\n",
      " [0.05831924]\n",
      " [0.22075048]\n",
      " [0.04298007]\n",
      " [0.2347123 ]\n",
      " [0.15784574]\n",
      " [0.06116554]\n",
      " [0.18845499]\n",
      " [0.1532022 ]\n",
      " [0.08678707]\n",
      " [0.09496918]\n",
      " [0.27627528]\n",
      " [0.25931674]\n",
      " [0.11270231]\n",
      " [0.10912427]\n",
      " [0.3592108 ]\n",
      " [0.19316414]\n",
      " [0.1357413 ]\n",
      " [0.06394133]\n",
      " [0.08641043]\n",
      " [0.10354677]\n",
      " [0.08236355]\n",
      " [0.13089064]\n",
      " [0.3604405 ]\n",
      " [0.13376158]\n",
      " [0.07477477]\n",
      " [0.05226794]\n",
      " [0.20018351]\n",
      " [0.12461197]\n",
      " [0.2360332 ]\n",
      " [0.16588879]\n",
      " [0.08024997]\n",
      " [0.06986567]\n",
      " [0.23689902]\n",
      " [0.21400288]\n",
      " [0.2237786 ]\n",
      " [0.08800116]\n",
      " [0.15678176]\n",
      " [0.16989848]\n",
      " [0.08472806]\n",
      " [0.26646906]\n",
      " [0.21782187]\n",
      " [0.2226451 ]\n",
      " [0.18444797]\n",
      " [0.20784846]\n",
      " [0.15981188]\n",
      " [0.12980908]\n",
      " [0.14563146]\n",
      " [0.2600546 ]\n",
      " [0.19876337]\n",
      " [0.20876834]\n",
      " [0.2671641 ]\n",
      " [0.1524907 ]\n",
      " [0.6248089 ]\n",
      " [0.16663146]\n",
      " [0.22592762]\n",
      " [0.00507954]\n",
      " [0.1255162 ]\n",
      " [0.1087344 ]\n",
      " [0.03037095]\n",
      " [0.13557655]\n",
      " [0.1626113 ]\n",
      " [0.37743288]\n",
      " [0.29370907]\n",
      " [0.13241282]\n",
      " [0.44280392]\n",
      " [0.13601834]\n",
      " [0.12885529]\n",
      " [0.08420157]\n",
      " [0.10600987]\n",
      " [0.18187541]\n",
      " [0.13930944]\n",
      " [0.3224144 ]\n",
      " [0.0575034 ]\n",
      " [0.14703146]\n",
      " [0.05232021]\n",
      " [0.22262174]\n",
      " [0.04064286]\n",
      " [0.10681716]\n",
      " [0.10206226]\n",
      " [0.05714417]\n",
      " [0.18793437]\n",
      " [0.21583536]\n",
      " [0.10051075]\n",
      " [0.05585805]\n",
      " [0.15637952]\n",
      " [0.04161489]\n",
      " [0.15044746]\n",
      " [0.22935733]\n",
      " [0.11289418]\n",
      " [0.20380554]\n",
      " [0.16209131]\n",
      " [0.09569201]\n",
      " [0.24851152]\n",
      " [0.11150888]\n",
      " [0.23967543]\n",
      " [0.1438888 ]\n",
      " [0.37132698]\n",
      " [0.34532994]\n",
      " [0.06568888]\n",
      " [0.05740964]\n",
      " [0.19764361]\n",
      " [0.4991023 ]\n",
      " [0.1350652 ]\n",
      " [0.22275522]\n",
      " [0.3084222 ]\n",
      " [0.1337311 ]\n",
      " [0.15843868]\n",
      " [0.08107868]\n",
      " [0.20222816]\n",
      " [0.21331519]\n",
      " [0.11840308]\n",
      " [0.12816086]\n",
      " [0.06461087]\n",
      " [0.09086093]\n",
      " [0.21836454]\n",
      " [0.61676097]\n",
      " [0.05101615]\n",
      " [0.09761283]\n",
      " [0.2196114 ]\n",
      " [0.24929962]\n",
      " [0.21897367]\n",
      " [0.11855519]\n",
      " [0.05802554]\n",
      " [0.2269172 ]\n",
      " [0.22001472]\n",
      " [0.27944407]\n",
      " [0.19871113]\n",
      " [0.15250778]\n",
      " [0.40953484]\n",
      " [0.08205384]\n",
      " [0.02085471]\n",
      " [0.48986322]\n",
      " [0.22884172]\n",
      " [0.07284597]\n",
      " [0.17741024]\n",
      " [0.2173141 ]\n",
      " [0.12053123]\n",
      " [0.16851336]\n",
      " [0.07450706]\n",
      " [0.17064855]\n",
      " [0.18499523]\n",
      " [0.16318801]\n",
      " [0.13352019]\n",
      " [0.2970159 ]\n",
      " [0.07391867]\n",
      " [0.1695556 ]\n",
      " [0.02736199]\n",
      " [0.6303334 ]\n",
      " [0.29696015]\n",
      " [0.26128522]\n",
      " [0.13646474]\n",
      " [0.3814351 ]\n",
      " [0.3015975 ]\n",
      " [0.10697022]\n",
      " [0.08609682]\n",
      " [0.06397071]\n",
      " [0.14756069]\n",
      " [0.16470805]\n",
      " [0.57456505]\n",
      " [0.18742755]\n",
      " [0.20690346]\n",
      " [0.10963893]\n",
      " [0.09255058]\n",
      " [0.03545171]\n",
      " [0.07666543]\n",
      " [0.3499861 ]\n",
      " [0.08395672]\n",
      " [0.12477294]\n",
      " [0.2670739 ]\n",
      " [0.23631215]\n",
      " [0.02485916]\n",
      " [0.29683873]\n",
      " [0.06720352]\n",
      " [0.13726512]\n",
      " [0.08242062]\n",
      " [0.4449783 ]\n",
      " [0.12962905]\n",
      " [0.05963778]\n",
      " [0.13227424]\n",
      " [0.16138917]\n",
      " [0.18773505]\n",
      " [0.25527748]\n",
      " [0.06964791]\n",
      " [0.13343978]\n",
      " [0.20812988]\n",
      " [0.03417093]\n",
      " [0.6201104 ]\n",
      " [0.12573144]\n",
      " [0.16446769]\n",
      " [0.01349568]\n",
      " [0.16735658]\n",
      " [0.07965863]\n",
      " [0.1728377 ]\n",
      " [0.31691605]\n",
      " [0.1427072 ]\n",
      " [0.01254719]\n",
      " [0.41840154]\n",
      " [0.22575763]\n",
      " [0.21527535]\n",
      " [0.01189741]\n",
      " [0.08001971]\n",
      " [0.23943171]\n",
      " [0.10066342]\n",
      " [0.2628361 ]\n",
      " [0.15700927]\n",
      " [0.05644622]\n",
      " [0.22110763]\n",
      " [0.03493926]\n",
      " [0.10689044]\n",
      " [0.13102677]\n",
      " [0.13487011]\n",
      " [0.0973658 ]\n",
      " [0.11367235]\n",
      " [0.1006377 ]\n",
      " [0.08130285]\n",
      " [0.25921527]\n",
      " [0.16945702]\n",
      " [0.2643572 ]\n",
      " [0.19510278]\n",
      " [0.09602189]\n",
      " [0.07414481]\n",
      " [0.08515972]\n",
      " [0.2283982 ]\n",
      " [0.12588748]\n",
      " [0.31222564]\n",
      " [0.14257851]\n",
      " [0.21518198]\n",
      " [0.23671687]\n",
      " [0.08821285]\n",
      " [0.12364709]\n",
      " [0.04499146]\n",
      " [0.04643178]\n",
      " [0.07341659]\n",
      " [0.04329202]\n",
      " [0.10121366]\n",
      " [0.07841316]\n",
      " [0.4572693 ]\n",
      " [0.08001345]\n",
      " [0.06987354]\n",
      " [0.09316972]\n",
      " [0.10295999]\n",
      " [0.19800347]\n",
      " [0.01636159]\n",
      " [0.00666255]\n",
      " [0.05192956]\n",
      " [0.25021338]\n",
      " [0.21713163]\n",
      " [0.19620313]\n",
      " [0.20789307]\n",
      " [0.63373524]\n",
      " [0.5189369 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1.]]\n",
      "pod 1st:  0.10204081632653061\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 0s 205us/step - loss: 0.4481 - acc: 0.8504 - val_loss: 0.4334 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.4192 - acc: 0.8587 - val_loss: 0.4556 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.4130 - acc: 0.8587 - val_loss: 0.4366 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.4009 - acc: 0.8587 - val_loss: 0.4298 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.4065 - acc: 0.8587 - val_loss: 0.4504 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.4002 - acc: 0.8587 - val_loss: 0.4251 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 56us/step - loss: 0.3981 - acc: 0.8587 - val_loss: 0.4218 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.3939 - acc: 0.8587 - val_loss: 0.4222 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3941 - acc: 0.8587 - val_loss: 0.4297 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3921 - acc: 0.8587 - val_loss: 0.4137 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3847 - acc: 0.8587 - val_loss: 0.4176 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3851 - acc: 0.8599 - val_loss: 0.4185 - val_acc: 0.8433\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3788 - acc: 0.8620 - val_loss: 0.4194 - val_acc: 0.8500\n",
      "y2_pred:  [[1.31561249e-01]\n",
      " [8.95614326e-02]\n",
      " [1.82440430e-01]\n",
      " [1.21220648e-01]\n",
      " [2.78101265e-01]\n",
      " [1.30740404e-01]\n",
      " [2.09676832e-01]\n",
      " [2.24312782e-01]\n",
      " [2.70303607e-01]\n",
      " [3.03635299e-02]\n",
      " [2.71129191e-01]\n",
      " [6.71563148e-02]\n",
      " [2.14238316e-01]\n",
      " [1.55821174e-01]\n",
      " [2.34498888e-01]\n",
      " [1.42281950e-01]\n",
      " [2.01815724e-01]\n",
      " [6.17735684e-02]\n",
      " [5.24060726e-02]\n",
      " [8.67809951e-02]\n",
      " [1.31726831e-01]\n",
      " [4.51684296e-02]\n",
      " [3.29906046e-01]\n",
      " [4.59164858e-01]\n",
      " [2.14102268e-01]\n",
      " [2.86488056e-01]\n",
      " [1.50709480e-01]\n",
      " [1.20111823e-01]\n",
      " [1.56345010e-01]\n",
      " [3.45160484e-01]\n",
      " [2.31775522e-01]\n",
      " [1.14232928e-01]\n",
      " [3.62785995e-01]\n",
      " [3.98978949e-01]\n",
      " [2.17774451e-01]\n",
      " [2.59319782e-01]\n",
      " [2.81357497e-01]\n",
      " [2.89432943e-01]\n",
      " [4.85110462e-01]\n",
      " [3.16170633e-01]\n",
      " [1.64032936e-01]\n",
      " [1.17202044e-01]\n",
      " [1.49997622e-01]\n",
      " [2.36510217e-01]\n",
      " [5.19363999e-01]\n",
      " [1.95492268e-01]\n",
      " [3.18085372e-01]\n",
      " [2.77157038e-01]\n",
      " [3.44314218e-01]\n",
      " [2.30973512e-01]\n",
      " [2.80520201e-01]\n",
      " [2.27357686e-01]\n",
      " [2.57797360e-01]\n",
      " [2.45827287e-01]\n",
      " [2.31812209e-01]\n",
      " [3.80580902e-01]\n",
      " [2.22092956e-01]\n",
      " [2.57630020e-01]\n",
      " [3.60893726e-01]\n",
      " [2.75269091e-01]\n",
      " [1.65254354e-01]\n",
      " [1.08044773e-01]\n",
      " [1.89024091e-01]\n",
      " [2.29845941e-01]\n",
      " [1.60999537e-01]\n",
      " [1.50979191e-01]\n",
      " [1.27944797e-01]\n",
      " [1.22707874e-01]\n",
      " [1.60839945e-01]\n",
      " [2.01026559e-01]\n",
      " [3.28195632e-01]\n",
      " [2.82785654e-01]\n",
      " [1.14726722e-01]\n",
      " [1.77101910e-01]\n",
      " [4.12078917e-01]\n",
      " [2.40116894e-01]\n",
      " [2.53999233e-01]\n",
      " [3.04230034e-01]\n",
      " [2.24331915e-01]\n",
      " [3.26952994e-01]\n",
      " [2.10472703e-01]\n",
      " [1.61677986e-01]\n",
      " [3.27055454e-01]\n",
      " [1.22427851e-01]\n",
      " [1.68008000e-01]\n",
      " [2.84046292e-01]\n",
      " [1.80561960e-01]\n",
      " [3.08668971e-01]\n",
      " [2.36818045e-01]\n",
      " [1.48391813e-01]\n",
      " [1.08201981e-01]\n",
      " [4.91858661e-01]\n",
      " [2.76921183e-01]\n",
      " [1.64797902e-01]\n",
      " [2.01650083e-01]\n",
      " [2.87265629e-01]\n",
      " [2.87049949e-01]\n",
      " [2.91406333e-01]\n",
      " [3.34977925e-01]\n",
      " [2.66251147e-01]\n",
      " [1.12225354e-01]\n",
      " [1.61121994e-01]\n",
      " [2.75353432e-01]\n",
      " [1.99803680e-01]\n",
      " [2.29394168e-01]\n",
      " [3.50486398e-01]\n",
      " [5.61815500e-03]\n",
      " [1.29594088e-01]\n",
      " [1.10706687e-02]\n",
      " [2.90675253e-01]\n",
      " [3.90776217e-01]\n",
      " [2.11828858e-01]\n",
      " [2.87228107e-01]\n",
      " [2.58925736e-01]\n",
      " [1.71166331e-01]\n",
      " [1.31842643e-01]\n",
      " [5.92933297e-02]\n",
      " [9.73043144e-02]\n",
      " [2.04544872e-01]\n",
      " [1.34475440e-01]\n",
      " [2.82626092e-01]\n",
      " [3.06002349e-01]\n",
      " [2.43347734e-01]\n",
      " [2.62342691e-01]\n",
      " [1.07530057e-01]\n",
      " [1.79598331e-01]\n",
      " [2.05323905e-01]\n",
      " [2.97564059e-01]\n",
      " [1.88700289e-01]\n",
      " [2.31125921e-01]\n",
      " [1.38661474e-01]\n",
      " [5.04973292e-01]\n",
      " [1.12741619e-01]\n",
      " [2.76859820e-01]\n",
      " [8.52517188e-02]\n",
      " [7.14004040e-04]\n",
      " [2.85737842e-01]\n",
      " [3.39685500e-01]\n",
      " [1.90180540e-01]\n",
      " [1.84647888e-01]\n",
      " [1.37746632e-01]\n",
      " [1.98396295e-01]\n",
      " [2.13256449e-01]\n",
      " [1.35221452e-01]\n",
      " [1.70641124e-01]\n",
      " [1.68652803e-01]\n",
      " [1.38333082e-01]\n",
      " [2.66757786e-01]\n",
      " [2.20905513e-01]\n",
      " [1.37090743e-01]\n",
      " [1.94643766e-01]\n",
      " [1.16044551e-01]\n",
      " [4.57123607e-01]\n",
      " [1.62366778e-01]\n",
      " [2.28498459e-01]\n",
      " [1.55315965e-01]\n",
      " [1.21618152e-01]\n",
      " [1.76359206e-01]\n",
      " [5.55786312e-01]\n",
      " [1.99710637e-01]\n",
      " [2.68398821e-01]\n",
      " [3.32350552e-01]\n",
      " [8.61441493e-02]\n",
      " [1.88089103e-01]\n",
      " [5.36737978e-01]\n",
      " [2.00940013e-01]\n",
      " [2.11560726e-01]\n",
      " [7.99716711e-02]\n",
      " [5.24557233e-01]\n",
      " [2.86137164e-01]\n",
      " [2.08009690e-01]\n",
      " [1.75055265e-02]\n",
      " [2.03805327e-01]\n",
      " [3.82135570e-01]\n",
      " [1.15342528e-01]\n",
      " [2.64944375e-01]\n",
      " [1.75908357e-01]\n",
      " [3.27345669e-01]\n",
      " [2.35185057e-01]\n",
      " [6.26638830e-02]\n",
      " [3.87012959e-04]\n",
      " [1.31755173e-01]\n",
      " [3.78595322e-01]\n",
      " [2.57471979e-01]\n",
      " [2.83486605e-01]\n",
      " [2.37843692e-01]\n",
      " [2.09712297e-01]\n",
      " [3.44920337e-01]\n",
      " [2.19877958e-01]\n",
      " [3.62814844e-01]\n",
      " [1.83592290e-01]\n",
      " [3.21363032e-01]\n",
      " [2.48435378e-01]\n",
      " [1.76428169e-01]\n",
      " [1.95269167e-01]\n",
      " [3.47810507e-01]\n",
      " [1.77011251e-01]\n",
      " [1.18645102e-01]\n",
      " [1.77175909e-01]\n",
      " [1.47124350e-01]\n",
      " [2.28039384e-01]\n",
      " [4.02530909e-01]\n",
      " [1.49875522e-01]\n",
      " [1.25397950e-01]\n",
      " [2.02805221e-01]\n",
      " [3.17532867e-01]\n",
      " [2.35819817e-03]\n",
      " [1.31008923e-01]\n",
      " [5.69519997e-01]\n",
      " [2.81264901e-01]\n",
      " [2.32258320e-01]\n",
      " [1.81142390e-01]\n",
      " [3.39732498e-01]\n",
      " [3.33692908e-01]\n",
      " [6.94830120e-02]\n",
      " [2.11242557e-01]\n",
      " [1.25977993e-01]\n",
      " [2.98207819e-01]\n",
      " [1.65976763e-01]\n",
      " [3.99998367e-01]\n",
      " [2.98112333e-01]\n",
      " [2.12542236e-01]\n",
      " [2.41703838e-01]\n",
      " [1.58737063e-01]\n",
      " [3.24520320e-01]\n",
      " [1.61060870e-01]\n",
      " [2.51227081e-01]\n",
      " [1.19901478e-01]\n",
      " [1.31313503e-01]\n",
      " [1.49414331e-01]\n",
      " [1.36187911e-01]\n",
      " [3.19497049e-01]\n",
      " [4.60912883e-02]\n",
      " [4.51380312e-01]\n",
      " [1.80913299e-01]\n",
      " [4.05093074e-01]\n",
      " [1.71490073e-01]\n",
      " [2.91500419e-01]\n",
      " [3.85893643e-01]\n",
      " [1.37983054e-01]\n",
      " [2.26928145e-01]\n",
      " [1.55607522e-01]\n",
      " [1.72634661e-01]\n",
      " [2.86300659e-01]\n",
      " [9.80760753e-02]\n",
      " [1.21657908e-01]\n",
      " [1.88284874e-01]\n",
      " [2.04883099e-01]\n",
      " [2.54687488e-01]\n",
      " [3.10549110e-01]\n",
      " [1.82799220e-01]\n",
      " [1.82240307e-01]\n",
      " [3.68158221e-01]\n",
      " [2.48762399e-01]\n",
      " [3.52337718e-01]\n",
      " [1.68633312e-01]\n",
      " [1.34682149e-01]\n",
      " [2.78134465e-01]\n",
      " [3.08335185e-01]\n",
      " [1.98087662e-01]\n",
      " [2.37962782e-01]\n",
      " [1.10292554e-01]\n",
      " [3.72429013e-01]\n",
      " [2.78518736e-01]\n",
      " [1.55650377e-01]\n",
      " [1.11773282e-01]\n",
      " [3.63230616e-01]\n",
      " [4.50803250e-01]\n",
      " [1.91559017e-01]\n",
      " [4.18961078e-01]\n",
      " [2.49472380e-01]\n",
      " [3.17673981e-01]\n",
      " [1.98978364e-01]\n",
      " [1.60629809e-01]\n",
      " [1.60231024e-01]\n",
      " [2.63335228e-01]\n",
      " [2.89749950e-01]\n",
      " [2.28625745e-01]\n",
      " [3.17728430e-01]\n",
      " [3.04679066e-01]\n",
      " [1.15106791e-01]\n",
      " [1.32612616e-01]\n",
      " [3.09455782e-01]\n",
      " [1.90065116e-01]\n",
      " [2.16348588e-01]\n",
      " [3.36287498e-01]\n",
      " [1.90321237e-01]\n",
      " [1.66815251e-01]\n",
      " [2.04085648e-01]\n",
      " [3.01913559e-01]\n",
      " [1.22650117e-01]\n",
      " [2.95335352e-01]\n",
      " [2.34235197e-01]\n",
      " [1.88741535e-01]\n",
      " [2.15293974e-01]\n",
      " [1.18799388e-01]\n",
      " [2.00684607e-01]\n",
      " [2.77789712e-01]\n",
      " [2.37309486e-01]\n",
      " [2.14957982e-01]\n",
      " [3.36450905e-01]\n",
      " [1.56397223e-01]\n",
      " [1.52859986e-01]\n",
      " [1.37913257e-01]\n",
      " [1.43479854e-01]\n",
      " [1.46670491e-01]\n",
      " [3.12990427e-01]\n",
      " [2.28769779e-01]\n",
      " [1.03184432e-01]\n",
      " [2.08044112e-01]\n",
      " [1.12432629e-01]\n",
      " [2.03483373e-01]\n",
      " [1.07036114e-01]\n",
      " [2.68194377e-01]\n",
      " [1.20397687e-01]\n",
      " [3.44158292e-01]\n",
      " [2.78507829e-01]\n",
      " [1.34270579e-01]\n",
      " [2.00791657e-02]\n",
      " [1.63679957e-01]\n",
      " [6.58406019e-02]\n",
      " [1.96831048e-01]\n",
      " [2.56210268e-01]\n",
      " [8.55684280e-02]\n",
      " [1.69232994e-01]\n",
      " [1.68699980e-01]\n",
      " [2.63341010e-01]\n",
      " [1.43230468e-01]\n",
      " [2.51078308e-01]\n",
      " [3.51167619e-01]\n",
      " [3.46389651e-01]\n",
      " [2.33975098e-01]\n",
      " [2.55121291e-01]\n",
      " [2.91316479e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod 1st:  0.12244897959183673\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 224us/step - loss: 0.4494 - acc: 0.8558 - val_loss: 0.4367 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 52us/step - loss: 0.4079 - acc: 0.8587 - val_loss: 0.4487 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 52us/step - loss: 0.4082 - acc: 0.8587 - val_loss: 0.4367 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3946 - acc: 0.8587 - val_loss: 0.4228 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 49us/step - loss: 0.3943 - acc: 0.8587 - val_loss: 0.4379 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3891 - acc: 0.8587 - val_loss: 0.4128 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3876 - acc: 0.8587 - val_loss: 0.4220 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3851 - acc: 0.8587 - val_loss: 0.4018 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3779 - acc: 0.8591 - val_loss: 0.3964 - val_acc: 0.8433\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 50us/step - loss: 0.3823 - acc: 0.8583 - val_loss: 0.4232 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 59us/step - loss: 0.3822 - acc: 0.8595 - val_loss: 0.4147 - val_acc: 0.8400\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 60us/step - loss: 0.3759 - acc: 0.8595 - val_loss: 0.3930 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 46us/step - loss: 0.3759 - acc: 0.8595 - val_loss: 0.4371 - val_acc: 0.8383\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 45us/step - loss: 0.3788 - acc: 0.8591 - val_loss: 0.3935 - val_acc: 0.8383\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.3686 - acc: 0.8587 - val_loss: 0.3946 - val_acc: 0.8433\n",
      "y2_pred:  [[0.14677426]\n",
      " [0.17618078]\n",
      " [0.09956598]\n",
      " [0.19010079]\n",
      " [0.16466397]\n",
      " [0.10762993]\n",
      " [0.06223717]\n",
      " [0.08514526]\n",
      " [0.14912099]\n",
      " [0.09484515]\n",
      " [0.23274985]\n",
      " [0.13253167]\n",
      " [0.23325104]\n",
      " [0.1635657 ]\n",
      " [0.13807395]\n",
      " [0.13393569]\n",
      " [0.15133333]\n",
      " [0.0900923 ]\n",
      " [0.11656755]\n",
      " [0.16046134]\n",
      " [0.23384857]\n",
      " [0.10540676]\n",
      " [0.22794747]\n",
      " [0.14765608]\n",
      " [0.20793477]\n",
      " [0.19922715]\n",
      " [0.21231574]\n",
      " [0.16751927]\n",
      " [0.24520135]\n",
      " [0.12371284]\n",
      " [0.1705834 ]\n",
      " [0.19977123]\n",
      " [0.14428717]\n",
      " [0.09113637]\n",
      " [0.14441371]\n",
      " [0.08960405]\n",
      " [0.08794835]\n",
      " [0.11733171]\n",
      " [0.17085478]\n",
      " [0.08301371]\n",
      " [0.2348471 ]\n",
      " [0.12133002]\n",
      " [0.16656771]\n",
      " [0.13077351]\n",
      " [0.48899952]\n",
      " [0.20255002]\n",
      " [0.19144213]\n",
      " [0.14336744]\n",
      " [0.26612073]\n",
      " [0.14340484]\n",
      " [0.0985865 ]\n",
      " [0.49553743]\n",
      " [0.18727976]\n",
      " [0.11686817]\n",
      " [0.18748742]\n",
      " [0.08046848]\n",
      " [0.1675049 ]\n",
      " [0.25056046]\n",
      " [0.0789524 ]\n",
      " [0.17411941]\n",
      " [0.12094629]\n",
      " [0.18349734]\n",
      " [0.10388762]\n",
      " [0.0463101 ]\n",
      " [0.12455842]\n",
      " [0.26031137]\n",
      " [0.114568  ]\n",
      " [0.32930112]\n",
      " [0.5107045 ]\n",
      " [0.6003862 ]\n",
      " [0.14553267]\n",
      " [0.1769222 ]\n",
      " [0.09018016]\n",
      " [0.11215016]\n",
      " [0.14838246]\n",
      " [0.17728093]\n",
      " [0.17087924]\n",
      " [0.07284564]\n",
      " [0.19729656]\n",
      " [0.15223426]\n",
      " [0.15673506]\n",
      " [0.36172724]\n",
      " [0.08266824]\n",
      " [0.0556789 ]\n",
      " [0.17477748]\n",
      " [0.16241536]\n",
      " [0.2010316 ]\n",
      " [0.17650616]\n",
      " [0.12916827]\n",
      " [0.12312922]\n",
      " [0.08057097]\n",
      " [0.10542902]\n",
      " [0.15603366]\n",
      " [0.2298997 ]\n",
      " [0.20289582]\n",
      " [0.05951247]\n",
      " [0.06112751]\n",
      " [0.20563307]\n",
      " [0.26648706]\n",
      " [0.10011417]\n",
      " [0.23218489]\n",
      " [0.16164806]\n",
      " [0.16598582]\n",
      " [0.25738534]\n",
      " [0.08676907]\n",
      " [0.5556623 ]\n",
      " [0.16350082]\n",
      " [0.17218691]\n",
      " [0.05902892]\n",
      " [0.4039847 ]\n",
      " [0.17715505]\n",
      " [0.44105557]\n",
      " [0.50368977]\n",
      " [0.22499338]\n",
      " [0.09591386]\n",
      " [0.59567165]\n",
      " [0.09910449]\n",
      " [0.19398478]\n",
      " [0.11427471]\n",
      " [0.23258868]\n",
      " [0.19583797]\n",
      " [0.22947547]\n",
      " [0.21425799]\n",
      " [0.14743465]\n",
      " [0.28308678]\n",
      " [0.14599016]\n",
      " [0.13738015]\n",
      " [0.13947728]\n",
      " [0.12007082]\n",
      " [0.26469362]\n",
      " [0.09056801]\n",
      " [0.12655935]\n",
      " [0.07988533]\n",
      " [0.17800832]\n",
      " [0.09416696]\n",
      " [0.11881369]\n",
      " [0.12980154]\n",
      " [0.11193579]\n",
      " [0.08469179]\n",
      " [0.09402898]\n",
      " [0.21355495]\n",
      " [0.08475339]\n",
      " [0.15982884]\n",
      " [0.13124534]\n",
      " [0.13005075]\n",
      " [0.08208039]\n",
      " [0.07660723]\n",
      " [0.24224243]\n",
      " [0.16870865]\n",
      " [0.14728054]\n",
      " [0.16068855]\n",
      " [0.1650306 ]\n",
      " [0.11225012]\n",
      " [0.18412414]\n",
      " [0.14067826]\n",
      " [0.09891328]\n",
      " [0.20002276]\n",
      " [0.17758128]\n",
      " [0.52062905]\n",
      " [0.09286514]\n",
      " [0.20099983]\n",
      " [0.20117673]\n",
      " [0.5620095 ]\n",
      " [0.20529443]\n",
      " [0.17499375]\n",
      " [0.09354797]\n",
      " [0.25644457]\n",
      " [0.14351273]\n",
      " [0.04731685]\n",
      " [0.2505994 ]\n",
      " [0.07304871]\n",
      " [0.09875566]\n",
      " [0.15243143]\n",
      " [0.27328187]\n",
      " [0.3127783 ]\n",
      " [0.15673962]\n",
      " [0.08969924]\n",
      " [0.08328992]\n",
      " [0.17559731]\n",
      " [0.08731461]\n",
      " [0.12645933]\n",
      " [0.13938808]\n",
      " [0.11096916]\n",
      " [0.5603116 ]\n",
      " [0.1933324 ]\n",
      " [0.19960564]\n",
      " [0.09893909]\n",
      " [0.17518589]\n",
      " [0.12024572]\n",
      " [0.16461998]\n",
      " [0.07732797]\n",
      " [0.19356751]\n",
      " [0.16396508]\n",
      " [0.18529227]\n",
      " [0.17741713]\n",
      " [0.20762274]\n",
      " [0.20889145]\n",
      " [0.32370168]\n",
      " [0.05410996]\n",
      " [0.18234262]\n",
      " [0.13881737]\n",
      " [0.44922426]\n",
      " [0.11234069]\n",
      " [0.34568036]\n",
      " [0.07711911]\n",
      " [0.15678594]\n",
      " [0.19163   ]\n",
      " [0.07317668]\n",
      " [0.15081528]\n",
      " [0.42405954]\n",
      " [0.11103263]\n",
      " [0.11249274]\n",
      " [0.12067446]\n",
      " [0.20007342]\n",
      " [0.12327209]\n",
      " [0.09595588]\n",
      " [0.20680648]\n",
      " [0.09973407]\n",
      " [0.07156363]\n",
      " [0.11223441]\n",
      " [0.19599804]\n",
      " [0.18653944]\n",
      " [0.09143439]\n",
      " [0.19757819]\n",
      " [0.06275529]\n",
      " [0.54111326]\n",
      " [0.3029542 ]\n",
      " [0.21112186]\n",
      " [0.14811194]\n",
      " [0.06853437]\n",
      " [0.1094873 ]\n",
      " [0.07867968]\n",
      " [0.18211967]\n",
      " [0.21192741]\n",
      " [0.27924317]\n",
      " [0.09043878]\n",
      " [0.1893613 ]\n",
      " [0.17821297]\n",
      " [0.09727767]\n",
      " [0.09653643]\n",
      " [0.33138353]\n",
      " [0.06173956]\n",
      " [0.06694019]\n",
      " [0.23380846]\n",
      " [0.24306583]\n",
      " [0.08334592]\n",
      " [0.11067504]\n",
      " [0.21532613]\n",
      " [0.12335914]\n",
      " [0.11725235]\n",
      " [0.1700908 ]\n",
      " [0.14147478]\n",
      " [0.12301567]\n",
      " [0.15128973]\n",
      " [0.13446444]\n",
      " [0.30217022]\n",
      " [0.17323929]\n",
      " [0.22921845]\n",
      " [0.14073285]\n",
      " [0.06078136]\n",
      " [0.09961686]\n",
      " [0.18310511]\n",
      " [0.12344027]\n",
      " [0.11845484]\n",
      " [0.1539216 ]\n",
      " [0.56155133]\n",
      " [0.14040413]\n",
      " [0.3244931 ]\n",
      " [0.05511221]\n",
      " [0.21520117]\n",
      " [0.13864595]\n",
      " [0.21133116]\n",
      " [0.10653371]\n",
      " [0.14819849]\n",
      " [0.09949809]\n",
      " [0.15888473]\n",
      " [0.13777483]\n",
      " [0.223046  ]\n",
      " [0.2090868 ]\n",
      " [0.08046108]\n",
      " [0.15000966]\n",
      " [0.16172498]\n",
      " [0.14943147]\n",
      " [0.17229557]\n",
      " [0.21407685]\n",
      " [0.05908254]\n",
      " [0.19540691]\n",
      " [0.05259636]\n",
      " [0.12265489]\n",
      " [0.28746897]\n",
      " [0.11526299]\n",
      " [0.23786235]\n",
      " [0.30210608]\n",
      " [0.1128791 ]\n",
      " [0.24533093]\n",
      " [0.08453804]\n",
      " [0.10766825]\n",
      " [0.13779956]\n",
      " [0.11013666]\n",
      " [0.09158686]\n",
      " [0.07443729]\n",
      " [0.10752234]\n",
      " [0.12627742]\n",
      " [0.18521902]\n",
      " [0.18999135]\n",
      " [0.12023962]\n",
      " [0.16922644]\n",
      " [0.10980436]\n",
      " [0.12608212]\n",
      " [0.15302196]\n",
      " [0.17913693]\n",
      " [0.1128563 ]\n",
      " [0.17862782]\n",
      " [0.07736182]\n",
      " [0.37475815]\n",
      " [0.30577528]\n",
      " [0.2013326 ]\n",
      " [0.1090585 ]\n",
      " [0.27074978]\n",
      " [0.09257671]\n",
      " [0.32748842]\n",
      " [0.26628333]\n",
      " [0.13293388]\n",
      " [0.28160983]\n",
      " [0.09313959]\n",
      " [0.16362858]\n",
      " [0.3557619 ]\n",
      " [0.15586665]\n",
      " [0.2808766 ]\n",
      " [0.19811036]\n",
      " [0.19013348]\n",
      " [0.30401036]\n",
      " [0.24071299]\n",
      " [0.25079224]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.10204081632653061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 294us/step - loss: 0.4277 - acc: 0.8483 - val_loss: 0.4335 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.4037 - acc: 0.8583 - val_loss: 0.4142 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3946 - acc: 0.8583 - val_loss: 0.4112 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3827 - acc: 0.8583 - val_loss: 0.4181 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 51us/step - loss: 0.3865 - acc: 0.8583 - val_loss: 0.4265 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3874 - acc: 0.8583 - val_loss: 0.4060 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 52us/step - loss: 0.3736 - acc: 0.8583 - val_loss: 0.4007 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 51us/step - loss: 0.3699 - acc: 0.8583 - val_loss: 0.3961 - val_acc: 0.8400\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 51us/step - loss: 0.3688 - acc: 0.8579 - val_loss: 0.4482 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 52us/step - loss: 0.3692 - acc: 0.8567 - val_loss: 0.4032 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 51us/step - loss: 0.3588 - acc: 0.8583 - val_loss: 0.4034 - val_acc: 0.8417\n",
      "y2_pred:  [[0.02745515]\n",
      " [0.10453331]\n",
      " [0.10025057]\n",
      " [0.02163762]\n",
      " [0.24794844]\n",
      " [0.22894669]\n",
      " [0.00748968]\n",
      " [0.03671736]\n",
      " [0.06363964]\n",
      " [0.03975394]\n",
      " [0.07829341]\n",
      " [0.17432815]\n",
      " [0.02070642]\n",
      " [0.26308233]\n",
      " [0.0937182 ]\n",
      " [0.24372008]\n",
      " [0.07169601]\n",
      " [0.02683467]\n",
      " [0.01583722]\n",
      " [0.03919208]\n",
      " [0.41591066]\n",
      " [0.17281175]\n",
      " [0.09335044]\n",
      " [0.02940428]\n",
      " [0.2045511 ]\n",
      " [0.07808489]\n",
      " [0.10441729]\n",
      " [0.09164706]\n",
      " [0.12013581]\n",
      " [0.0516316 ]\n",
      " [0.15162003]\n",
      " [0.08870283]\n",
      " [0.10397264]\n",
      " [0.04649806]\n",
      " [0.01239702]\n",
      " [0.09857184]\n",
      " [0.03905272]\n",
      " [0.1192742 ]\n",
      " [0.16480222]\n",
      " [0.03869608]\n",
      " [0.03018266]\n",
      " [0.02917653]\n",
      " [0.06834915]\n",
      " [0.08867556]\n",
      " [0.08065289]\n",
      " [0.18630522]\n",
      " [0.05847079]\n",
      " [0.11520952]\n",
      " [0.06290665]\n",
      " [0.29355383]\n",
      " [0.09934112]\n",
      " [0.12734565]\n",
      " [0.00610772]\n",
      " [0.02387255]\n",
      " [0.0921509 ]\n",
      " [0.4794778 ]\n",
      " [0.16626704]\n",
      " [0.06066409]\n",
      " [0.04720235]\n",
      " [0.06148931]\n",
      " [0.09161469]\n",
      " [0.02854028]\n",
      " [0.10334846]\n",
      " [0.12687272]\n",
      " [0.14294049]\n",
      " [0.20653006]\n",
      " [0.15787989]\n",
      " [0.04622218]\n",
      " [0.02652657]\n",
      " [0.12814862]\n",
      " [0.2505743 ]\n",
      " [0.17809856]\n",
      " [0.03240219]\n",
      " [0.03742602]\n",
      " [0.04670674]\n",
      " [0.14323902]\n",
      " [0.02740046]\n",
      " [0.00393558]\n",
      " [0.06350702]\n",
      " [0.10402903]\n",
      " [0.10861012]\n",
      " [0.10969889]\n",
      " [0.12321097]\n",
      " [0.21820527]\n",
      " [0.09507459]\n",
      " [0.17670551]\n",
      " [0.08171755]\n",
      " [0.00447121]\n",
      " [0.11362615]\n",
      " [0.03665   ]\n",
      " [0.0452182 ]\n",
      " [0.18188351]\n",
      " [0.42315817]\n",
      " [0.16938451]\n",
      " [0.305907  ]\n",
      " [0.12646934]\n",
      " [0.08609301]\n",
      " [0.00133735]\n",
      " [0.23508158]\n",
      " [0.07813331]\n",
      " [0.22962597]\n",
      " [0.14174864]\n",
      " [0.08682337]\n",
      " [0.02160871]\n",
      " [0.09984609]\n",
      " [0.07128423]\n",
      " [0.01760119]\n",
      " [0.12568012]\n",
      " [0.12418497]\n",
      " [0.02266848]\n",
      " [0.07784054]\n",
      " [0.02760568]\n",
      " [0.2595001 ]\n",
      " [0.18995616]\n",
      " [0.0578956 ]\n",
      " [0.11873475]\n",
      " [0.02332383]\n",
      " [0.10125688]\n",
      " [0.08543158]\n",
      " [0.01312077]\n",
      " [0.231033  ]\n",
      " [0.03068137]\n",
      " [0.07579049]\n",
      " [0.25637883]\n",
      " [0.12147126]\n",
      " [0.2560594 ]\n",
      " [0.09929296]\n",
      " [0.01846173]\n",
      " [0.10858518]\n",
      " [0.17292064]\n",
      " [0.02894932]\n",
      " [0.00830501]\n",
      " [0.33411914]\n",
      " [0.17514911]\n",
      " [0.03731084]\n",
      " [0.07626191]\n",
      " [0.01427335]\n",
      " [0.13555723]\n",
      " [0.02868226]\n",
      " [0.01651338]\n",
      " [0.09230912]\n",
      " [0.14865604]\n",
      " [0.02073231]\n",
      " [0.0936076 ]\n",
      " [0.00603861]\n",
      " [0.28635865]\n",
      " [0.03177565]\n",
      " [0.06082329]\n",
      " [0.01923862]\n",
      " [0.24822938]\n",
      " [0.42536455]\n",
      " [0.01620713]\n",
      " [0.26293704]\n",
      " [0.04006734]\n",
      " [0.04496327]\n",
      " [0.25719804]\n",
      " [0.06746876]\n",
      " [0.30330384]\n",
      " [0.01583269]\n",
      " [0.01374891]\n",
      " [0.46033093]\n",
      " [0.15524277]\n",
      " [0.0189583 ]\n",
      " [0.09538528]\n",
      " [0.1143049 ]\n",
      " [0.1169861 ]\n",
      " [0.05175439]\n",
      " [0.09050974]\n",
      " [0.12787518]\n",
      " [0.0629442 ]\n",
      " [0.09963882]\n",
      " [0.22635227]\n",
      " [0.08229223]\n",
      " [0.01681766]\n",
      " [0.00995198]\n",
      " [0.19982064]\n",
      " [0.10229796]\n",
      " [0.06245542]\n",
      " [0.0422003 ]\n",
      " [0.07715037]\n",
      " [0.01651403]\n",
      " [0.02402791]\n",
      " [0.1299274 ]\n",
      " [0.13297582]\n",
      " [0.01943117]\n",
      " [0.02562657]\n",
      " [0.04854354]\n",
      " [0.00259686]\n",
      " [0.13384777]\n",
      " [0.41772947]\n",
      " [0.4807724 ]\n",
      " [0.4512832 ]\n",
      " [0.07592174]\n",
      " [0.14049911]\n",
      " [0.13426545]\n",
      " [0.21102497]\n",
      " [0.02724242]\n",
      " [0.01977253]\n",
      " [0.03683862]\n",
      " [0.04066694]\n",
      " [0.01582703]\n",
      " [0.00704187]\n",
      " [0.38357693]\n",
      " [0.15497273]\n",
      " [0.0022088 ]\n",
      " [0.04920265]\n",
      " [0.23193586]\n",
      " [0.05221695]\n",
      " [0.08177871]\n",
      " [0.11408484]\n",
      " [0.10933784]\n",
      " [0.16083464]\n",
      " [0.08492851]\n",
      " [0.17971721]\n",
      " [0.20636386]\n",
      " [0.07131258]\n",
      " [0.02563536]\n",
      " [0.06196481]\n",
      " [0.19565257]\n",
      " [0.14386642]\n",
      " [0.25041562]\n",
      " [0.00717193]\n",
      " [0.09790522]\n",
      " [0.10627612]\n",
      " [0.2546237 ]\n",
      " [0.01701868]\n",
      " [0.00652131]\n",
      " [0.09186551]\n",
      " [0.0697543 ]\n",
      " [0.15384156]\n",
      " [0.06447074]\n",
      " [0.09421936]\n",
      " [0.10212651]\n",
      " [0.29955965]\n",
      " [0.1480639 ]\n",
      " [0.14508542]\n",
      " [0.27276218]\n",
      " [0.12743783]\n",
      " [0.05737758]\n",
      " [0.3142022 ]\n",
      " [0.491259  ]\n",
      " [0.03287098]\n",
      " [0.01654822]\n",
      " [0.14025989]\n",
      " [0.26951712]\n",
      " [0.03984407]\n",
      " [0.31040472]\n",
      " [0.14749339]\n",
      " [0.11891577]\n",
      " [0.15390313]\n",
      " [0.2243182 ]\n",
      " [0.43664962]\n",
      " [0.02230206]\n",
      " [0.02870515]\n",
      " [0.1121918 ]\n",
      " [0.13016942]\n",
      " [0.42046663]\n",
      " [0.05997151]\n",
      " [0.3024339 ]\n",
      " [0.14775679]\n",
      " [0.33254808]\n",
      " [0.04769769]\n",
      " [0.10241291]\n",
      " [0.02804348]\n",
      " [0.04052532]\n",
      " [0.02144313]\n",
      " [0.11400336]\n",
      " [0.03116879]\n",
      " [0.05623075]\n",
      " [0.15986064]\n",
      " [0.2290043 ]\n",
      " [0.19902483]\n",
      " [0.16070628]\n",
      " [0.00985122]\n",
      " [0.12193647]\n",
      " [0.01451084]\n",
      " [0.10677457]\n",
      " [0.03882053]\n",
      " [0.04678637]\n",
      " [0.06733385]\n",
      " [0.19725302]\n",
      " [0.18526503]\n",
      " [0.29845983]\n",
      " [0.08665735]\n",
      " [0.00723416]\n",
      " [0.22755876]\n",
      " [0.13598886]\n",
      " [0.03727409]\n",
      " [0.20282704]\n",
      " [0.01433086]\n",
      " [0.08027601]\n",
      " [0.09465316]\n",
      " [0.07192758]\n",
      " [0.0709838 ]\n",
      " [0.12587139]\n",
      " [0.01479369]\n",
      " [0.02320367]\n",
      " [0.12825179]\n",
      " [0.1653882 ]\n",
      " [0.0896157 ]\n",
      " [0.12633145]\n",
      " [0.14606053]\n",
      " [0.04702941]\n",
      " [0.4518381 ]\n",
      " [0.05617291]\n",
      " [0.07471254]\n",
      " [0.09480405]\n",
      " [0.16481727]\n",
      " [0.39433146]\n",
      " [0.04564053]\n",
      " [0.02540323]\n",
      " [0.398355  ]\n",
      " [0.05764925]\n",
      " [0.07610503]\n",
      " [0.12111637]\n",
      " [0.1475775 ]\n",
      " [0.16119877]\n",
      " [0.20792004]\n",
      " [0.26099658]\n",
      " [0.04008055]\n",
      " [0.47852483]\n",
      " [0.12931833]\n",
      " [0.10156009]\n",
      " [0.04088837]\n",
      " [0.06733763]\n",
      " [0.46854302]\n",
      " [0.35124555]\n",
      " [0.12003013]\n",
      " [0.08078377]\n",
      " [0.07606779]\n",
      " [0.0671716 ]\n",
      " [0.14179493]\n",
      " [0.01469419]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 276us/step - loss: 0.4401 - acc: 0.8492 - val_loss: 0.4371 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.4107 - acc: 0.8583 - val_loss: 0.4643 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.4086 - acc: 0.8583 - val_loss: 0.4334 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4044 - acc: 0.8583 - val_loss: 0.4275 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.4064 - acc: 0.8583 - val_loss: 0.4322 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.4079 - acc: 0.8583 - val_loss: 0.4335 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.4050 - acc: 0.8583 - val_loss: 0.4219 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.4004 - acc: 0.8583 - val_loss: 0.4202 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3987 - acc: 0.8583 - val_loss: 0.4201 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.3887 - acc: 0.8583 - val_loss: 0.4124 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3858 - acc: 0.8600 - val_loss: 0.4398 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 64us/step - loss: 0.3827 - acc: 0.8600 - val_loss: 0.4027 - val_acc: 0.8433\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3778 - acc: 0.8646 - val_loss: 0.3968 - val_acc: 0.8433\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3754 - acc: 0.8642 - val_loss: 0.3952 - val_acc: 0.8467\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3739 - acc: 0.8633 - val_loss: 0.3969 - val_acc: 0.8417\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3686 - acc: 0.8642 - val_loss: 0.3895 - val_acc: 0.8450\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3701 - acc: 0.8646 - val_loss: 0.3915 - val_acc: 0.8417\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3713 - acc: 0.8646 - val_loss: 0.3909 - val_acc: 0.8450\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3647 - acc: 0.8675 - val_loss: 0.4030 - val_acc: 0.8467\n",
      "y2_pred:  [[0.10223067]\n",
      " [0.20655513]\n",
      " [0.17962909]\n",
      " [0.19053721]\n",
      " [0.07608804]\n",
      " [0.49588358]\n",
      " [0.04741085]\n",
      " [0.09250543]\n",
      " [0.147181  ]\n",
      " [0.08547777]\n",
      " [0.11093467]\n",
      " [0.13564232]\n",
      " [0.04531786]\n",
      " [0.10581645]\n",
      " [0.07998607]\n",
      " [0.01951042]\n",
      " [0.07748914]\n",
      " [0.05170473]\n",
      " [0.0715268 ]\n",
      " [0.04870898]\n",
      " [0.0667364 ]\n",
      " [0.09825385]\n",
      " [0.10738423]\n",
      " [0.17245576]\n",
      " [0.02241728]\n",
      " [0.0294469 ]\n",
      " [0.0466589 ]\n",
      " [0.11784777]\n",
      " [0.10647509]\n",
      " [0.09604296]\n",
      " [0.0327858 ]\n",
      " [0.00583243]\n",
      " [0.03324977]\n",
      " [0.06027636]\n",
      " [0.0714632 ]\n",
      " [0.03784978]\n",
      " [0.16377202]\n",
      " [0.02721423]\n",
      " [0.05413565]\n",
      " [0.09743294]\n",
      " [0.03227791]\n",
      " [0.04965416]\n",
      " [0.12293741]\n",
      " [0.10232872]\n",
      " [0.06350729]\n",
      " [0.08741176]\n",
      " [0.08257255]\n",
      " [0.06703791]\n",
      " [0.07645607]\n",
      " [0.25787836]\n",
      " [0.2966867 ]\n",
      " [0.11682492]\n",
      " [0.05495632]\n",
      " [0.07879019]\n",
      " [0.08672908]\n",
      " [0.08303109]\n",
      " [0.01669666]\n",
      " [0.0121125 ]\n",
      " [0.01461896]\n",
      " [0.22310561]\n",
      " [0.22437933]\n",
      " [0.08064464]\n",
      " [0.18391278]\n",
      " [0.03207228]\n",
      " [0.09291512]\n",
      " [0.152946  ]\n",
      " [0.08187738]\n",
      " [0.02716324]\n",
      " [0.09857482]\n",
      " [0.6847075 ]\n",
      " [0.10270533]\n",
      " [0.09951502]\n",
      " [0.06668282]\n",
      " [0.0486787 ]\n",
      " [0.06546277]\n",
      " [0.05440882]\n",
      " [0.5828596 ]\n",
      " [0.22620147]\n",
      " [0.0471732 ]\n",
      " [0.22535193]\n",
      " [0.22856599]\n",
      " [0.07442576]\n",
      " [0.07562518]\n",
      " [0.04357103]\n",
      " [0.18636298]\n",
      " [0.07072985]\n",
      " [0.11723891]\n",
      " [0.05786386]\n",
      " [0.08588365]\n",
      " [0.07667133]\n",
      " [0.04402757]\n",
      " [0.0212366 ]\n",
      " [0.05340284]\n",
      " [0.06795612]\n",
      " [0.17800686]\n",
      " [0.03304058]\n",
      " [0.24370319]\n",
      " [0.06486508]\n",
      " [0.02055788]\n",
      " [0.05309749]\n",
      " [0.26819578]\n",
      " [0.05893499]\n",
      " [0.15469414]\n",
      " [0.0453077 ]\n",
      " [0.07043463]\n",
      " [0.60980874]\n",
      " [0.02617535]\n",
      " [0.03306687]\n",
      " [0.06227541]\n",
      " [0.06999275]\n",
      " [0.12558737]\n",
      " [0.05181617]\n",
      " [0.03457913]\n",
      " [0.32514155]\n",
      " [0.12209138]\n",
      " [0.06290731]\n",
      " [0.0514234 ]\n",
      " [0.03401643]\n",
      " [0.26945412]\n",
      " [0.06451923]\n",
      " [0.02728266]\n",
      " [0.05898711]\n",
      " [0.04756403]\n",
      " [0.0804067 ]\n",
      " [0.1239351 ]\n",
      " [0.08505735]\n",
      " [0.03466466]\n",
      " [0.08308482]\n",
      " [0.0395568 ]\n",
      " [0.06943521]\n",
      " [0.04339463]\n",
      " [0.0397093 ]\n",
      " [0.06574082]\n",
      " [0.05848041]\n",
      " [0.15431336]\n",
      " [0.07930136]\n",
      " [0.12300935]\n",
      " [0.03869274]\n",
      " [0.08143082]\n",
      " [0.12155849]\n",
      " [0.05793884]\n",
      " [0.0602237 ]\n",
      " [0.04330933]\n",
      " [0.03109428]\n",
      " [0.08995762]\n",
      " [0.30157977]\n",
      " [0.06276372]\n",
      " [0.09131554]\n",
      " [0.01950303]\n",
      " [0.08292502]\n",
      " [0.04210505]\n",
      " [0.06822354]\n",
      " [0.0664773 ]\n",
      " [0.02466649]\n",
      " [0.13889396]\n",
      " [0.38340902]\n",
      " [0.11714709]\n",
      " [0.08204603]\n",
      " [0.02592254]\n",
      " [0.05397376]\n",
      " [0.20582569]\n",
      " [0.19092068]\n",
      " [0.0696665 ]\n",
      " [0.10810801]\n",
      " [0.02741146]\n",
      " [0.02196449]\n",
      " [0.04319164]\n",
      " [0.07553646]\n",
      " [0.11347997]\n",
      " [0.16262418]\n",
      " [0.05838498]\n",
      " [0.0568299 ]\n",
      " [0.1299707 ]\n",
      " [0.30808014]\n",
      " [0.11848944]\n",
      " [0.05918506]\n",
      " [0.08046854]\n",
      " [0.0586358 ]\n",
      " [0.13489053]\n",
      " [0.05284896]\n",
      " [0.0959774 ]\n",
      " [0.04641062]\n",
      " [0.1345661 ]\n",
      " [0.15254578]\n",
      " [0.05475911]\n",
      " [0.09338123]\n",
      " [0.07026079]\n",
      " [0.07367349]\n",
      " [0.11482438]\n",
      " [0.02277595]\n",
      " [0.19751963]\n",
      " [0.07285857]\n",
      " [0.14076495]\n",
      " [0.06509635]\n",
      " [0.082131  ]\n",
      " [0.029484  ]\n",
      " [0.05359483]\n",
      " [0.17766282]\n",
      " [0.33562022]\n",
      " [0.05311927]\n",
      " [0.06549999]\n",
      " [0.0413582 ]\n",
      " [0.8478007 ]\n",
      " [0.13537246]\n",
      " [0.16232446]\n",
      " [0.05366406]\n",
      " [0.0514524 ]\n",
      " [0.15732381]\n",
      " [0.04501781]\n",
      " [0.12959379]\n",
      " [0.11640117]\n",
      " [0.11201724]\n",
      " [0.06924406]\n",
      " [0.06046283]\n",
      " [0.10596827]\n",
      " [0.19687185]\n",
      " [0.05225408]\n",
      " [0.12377423]\n",
      " [0.06903526]\n",
      " [0.02283922]\n",
      " [0.02097639]\n",
      " [0.06019738]\n",
      " [0.05242831]\n",
      " [0.05084845]\n",
      " [0.08055541]\n",
      " [0.09125382]\n",
      " [0.14013004]\n",
      " [0.12274712]\n",
      " [0.02000937]\n",
      " [0.12269163]\n",
      " [0.06630257]\n",
      " [0.02402195]\n",
      " [0.04957539]\n",
      " [0.05480245]\n",
      " [0.02560562]\n",
      " [0.13064352]\n",
      " [0.03417191]\n",
      " [0.04746047]\n",
      " [0.03454587]\n",
      " [0.25351757]\n",
      " [0.0539639 ]\n",
      " [0.08782509]\n",
      " [0.05728292]\n",
      " [0.06431642]\n",
      " [0.04944408]\n",
      " [0.02094713]\n",
      " [0.02349555]\n",
      " [0.05788189]\n",
      " [0.04030052]\n",
      " [0.07078996]\n",
      " [0.08036658]\n",
      " [0.10562947]\n",
      " [0.05930737]\n",
      " [0.5070714 ]\n",
      " [0.01565871]\n",
      " [0.03303626]\n",
      " [0.03013474]\n",
      " [0.08857384]\n",
      " [0.29393914]\n",
      " [0.06455967]\n",
      " [0.13355428]\n",
      " [0.00492013]\n",
      " [0.14797229]\n",
      " [0.10262066]\n",
      " [0.06609923]\n",
      " [0.01598221]\n",
      " [0.30084148]\n",
      " [0.3084388 ]\n",
      " [0.0570434 ]\n",
      " [0.21299282]\n",
      " [0.05996868]\n",
      " [0.07678294]\n",
      " [0.08425555]\n",
      " [0.04091009]\n",
      " [0.06559604]\n",
      " [0.5915993 ]\n",
      " [0.0410367 ]\n",
      " [0.18862462]\n",
      " [0.1212694 ]\n",
      " [0.10648555]\n",
      " [0.11424449]\n",
      " [0.0602704 ]\n",
      " [0.17021361]\n",
      " [0.03100672]\n",
      " [0.14466733]\n",
      " [0.03002962]\n",
      " [0.06901664]\n",
      " [0.05445629]\n",
      " [0.07796964]\n",
      " [0.11771023]\n",
      " [0.01553082]\n",
      " [0.10419831]\n",
      " [0.1130555 ]\n",
      " [0.05271482]\n",
      " [0.15461513]\n",
      " [0.20455411]\n",
      " [0.27812228]\n",
      " [0.06517392]\n",
      " [0.18454501]\n",
      " [0.77334535]\n",
      " [0.6268375 ]\n",
      " [0.5970186 ]\n",
      " [0.05719942]\n",
      " [0.09469494]\n",
      " [0.0504733 ]\n",
      " [0.13178462]\n",
      " [0.08225432]\n",
      " [0.18248624]\n",
      " [0.05111861]\n",
      " [0.0650126 ]\n",
      " [0.20563704]\n",
      " [0.25056726]\n",
      " [0.06680632]\n",
      " [0.0625267 ]\n",
      " [0.19978514]\n",
      " [0.06835857]\n",
      " [0.10669225]\n",
      " [0.25425616]\n",
      " [0.8189615 ]\n",
      " [0.0710859 ]\n",
      " [0.27836883]\n",
      " [0.8595145 ]\n",
      " [0.13999215]\n",
      " [0.19325265]\n",
      " [0.09145936]\n",
      " [0.19181225]\n",
      " [0.7889586 ]\n",
      " [0.05119395]\n",
      " [0.11853465]\n",
      " [0.6961762 ]\n",
      " [0.14598915]\n",
      " [0.0267298 ]\n",
      " [0.25135586]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod 1st:  0.16666666666666666\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 305us/step - loss: 0.4495 - acc: 0.8500 - val_loss: 0.4271 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.4078 - acc: 0.8583 - val_loss: 0.4167 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3957 - acc: 0.8583 - val_loss: 0.4133 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3920 - acc: 0.8583 - val_loss: 0.4019 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3871 - acc: 0.8583 - val_loss: 0.4143 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3782 - acc: 0.8579 - val_loss: 0.3944 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3845 - acc: 0.8588 - val_loss: 0.4206 - val_acc: 0.8433\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.3774 - acc: 0.8592 - val_loss: 0.3921 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3704 - acc: 0.8588 - val_loss: 0.3929 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3797 - acc: 0.8629 - val_loss: 0.3990 - val_acc: 0.8433\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3703 - acc: 0.8596 - val_loss: 0.3893 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3675 - acc: 0.8592 - val_loss: 0.4325 - val_acc: 0.8433\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3705 - acc: 0.8612 - val_loss: 0.3870 - val_acc: 0.8467\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3680 - acc: 0.8617 - val_loss: 0.3932 - val_acc: 0.8467\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3659 - acc: 0.8642 - val_loss: 0.3865 - val_acc: 0.8400\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3664 - acc: 0.8608 - val_loss: 0.3935 - val_acc: 0.8483\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 57us/step - loss: 0.3661 - acc: 0.8621 - val_loss: 0.3839 - val_acc: 0.8417\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3578 - acc: 0.8625 - val_loss: 0.3869 - val_acc: 0.8433\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3618 - acc: 0.8625 - val_loss: 0.3875 - val_acc: 0.8433\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3595 - acc: 0.8625 - val_loss: 0.3818 - val_acc: 0.8417\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3600 - acc: 0.8633 - val_loss: 0.3829 - val_acc: 0.8450\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 57us/step - loss: 0.3637 - acc: 0.8637 - val_loss: 0.3864 - val_acc: 0.8417\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3567 - acc: 0.8658 - val_loss: 0.3977 - val_acc: 0.8367\n",
      "y2_pred:  [[0.20066532]\n",
      " [0.09111005]\n",
      " [0.02169293]\n",
      " [0.06773469]\n",
      " [0.13147452]\n",
      " [0.01509342]\n",
      " [0.12750736]\n",
      " [0.13791904]\n",
      " [0.20395067]\n",
      " [0.34078193]\n",
      " [0.0498431 ]\n",
      " [0.11205804]\n",
      " [0.06638601]\n",
      " [0.05794427]\n",
      " [0.17785737]\n",
      " [0.03826016]\n",
      " [0.03167585]\n",
      " [0.08763751]\n",
      " [0.05187026]\n",
      " [0.04372466]\n",
      " [0.11293691]\n",
      " [0.01594895]\n",
      " [0.07592288]\n",
      " [0.13674879]\n",
      " [0.01313591]\n",
      " [0.23266351]\n",
      " [0.00614646]\n",
      " [0.0485149 ]\n",
      " [0.08769041]\n",
      " [0.09972101]\n",
      " [0.03982541]\n",
      " [0.07770088]\n",
      " [0.09550861]\n",
      " [0.03530625]\n",
      " [0.04112548]\n",
      " [0.07074136]\n",
      " [0.13626006]\n",
      " [0.1419721 ]\n",
      " [0.03700653]\n",
      " [0.09208354]\n",
      " [0.02313507]\n",
      " [0.05488044]\n",
      " [0.12125978]\n",
      " [0.02817789]\n",
      " [0.00149736]\n",
      " [0.07179415]\n",
      " [0.07466835]\n",
      " [0.18008587]\n",
      " [0.03275797]\n",
      " [0.04003838]\n",
      " [0.11048388]\n",
      " [0.01992193]\n",
      " [0.03902796]\n",
      " [0.04172751]\n",
      " [0.04169309]\n",
      " [0.09794438]\n",
      " [0.11105692]\n",
      " [0.03498769]\n",
      " [0.22094995]\n",
      " [0.0804714 ]\n",
      " [0.0451009 ]\n",
      " [0.10694191]\n",
      " [0.20706886]\n",
      " [0.04476613]\n",
      " [0.2020059 ]\n",
      " [0.09115148]\n",
      " [0.1864309 ]\n",
      " [0.179488  ]\n",
      " [0.34262702]\n",
      " [0.00617799]\n",
      " [0.04336241]\n",
      " [0.08402917]\n",
      " [0.10126641]\n",
      " [0.06095445]\n",
      " [0.10946333]\n",
      " [0.09301418]\n",
      " [0.04959583]\n",
      " [0.09350124]\n",
      " [0.10022631]\n",
      " [0.05983803]\n",
      " [0.08850291]\n",
      " [0.07501361]\n",
      " [0.03767511]\n",
      " [0.08567497]\n",
      " [0.01077738]\n",
      " [0.02462402]\n",
      " [0.06154588]\n",
      " [0.02241865]\n",
      " [0.03850058]\n",
      " [0.01494926]\n",
      " [0.02748188]\n",
      " [0.21574056]\n",
      " [0.0061895 ]\n",
      " [0.18211862]\n",
      " [0.01967359]\n",
      " [0.11953777]\n",
      " [0.04121256]\n",
      " [0.02518663]\n",
      " [0.12449962]\n",
      " [0.06194317]\n",
      " [0.11235538]\n",
      " [0.5534451 ]\n",
      " [0.4555055 ]\n",
      " [0.5692289 ]\n",
      " [0.04454467]\n",
      " [0.01730713]\n",
      " [0.09457102]\n",
      " [0.04842451]\n",
      " [0.02009749]\n",
      " [0.03817934]\n",
      " [0.16070989]\n",
      " [0.03647438]\n",
      " [0.18989503]\n",
      " [0.04886228]\n",
      " [0.02000308]\n",
      " [0.06570783]\n",
      " [0.5816092 ]\n",
      " [0.22037598]\n",
      " [0.01710302]\n",
      " [0.03791606]\n",
      " [0.01998281]\n",
      " [0.04017279]\n",
      " [0.00939077]\n",
      " [0.0470233 ]\n",
      " [0.16763496]\n",
      " [0.01732382]\n",
      " [0.03656241]\n",
      " [0.00467864]\n",
      " [0.0499301 ]\n",
      " [0.0315477 ]\n",
      " [0.04528654]\n",
      " [0.08567953]\n",
      " [0.09875801]\n",
      " [0.03300843]\n",
      " [0.06923255]\n",
      " [0.01183516]\n",
      " [0.09230912]\n",
      " [0.01101068]\n",
      " [0.11039034]\n",
      " [0.10016245]\n",
      " [0.08597615]\n",
      " [0.10679495]\n",
      " [0.16148871]\n",
      " [0.00441206]\n",
      " [0.11447847]\n",
      " [0.06965914]\n",
      " [0.32303154]\n",
      " [0.2801783 ]\n",
      " [0.09676597]\n",
      " [0.01800367]\n",
      " [0.1010389 ]\n",
      " [0.47086057]\n",
      " [0.04621178]\n",
      " [0.05343404]\n",
      " [0.007956  ]\n",
      " [0.18125144]\n",
      " [0.13535973]\n",
      " [0.11173812]\n",
      " [0.02652052]\n",
      " [0.11654621]\n",
      " [0.05264181]\n",
      " [0.11613169]\n",
      " [0.03510824]\n",
      " [0.01324791]\n",
      " [0.16789043]\n",
      " [0.16665626]\n",
      " [0.12615526]\n",
      " [0.12413689]\n",
      " [0.00876617]\n",
      " [0.16849273]\n",
      " [0.11844921]\n",
      " [0.06060687]\n",
      " [0.06089631]\n",
      " [0.00824219]\n",
      " [0.07249647]\n",
      " [0.01044124]\n",
      " [0.03213948]\n",
      " [0.07160404]\n",
      " [0.15296698]\n",
      " [0.09173664]\n",
      " [0.16347268]\n",
      " [0.04468429]\n",
      " [0.0415417 ]\n",
      " [0.36945522]\n",
      " [0.0135318 ]\n",
      " [0.01217628]\n",
      " [0.09729528]\n",
      " [0.09710217]\n",
      " [0.04779649]\n",
      " [0.09208307]\n",
      " [0.04520658]\n",
      " [0.01112646]\n",
      " [0.03944722]\n",
      " [0.28304273]\n",
      " [0.37056825]\n",
      " [0.36182564]\n",
      " [0.03186089]\n",
      " [0.32968643]\n",
      " [0.08668882]\n",
      " [0.28334552]\n",
      " [0.21421307]\n",
      " [0.07741743]\n",
      " [0.01020372]\n",
      " [0.01656631]\n",
      " [0.6082151 ]\n",
      " [0.08210635]\n",
      " [0.08548021]\n",
      " [0.07383442]\n",
      " [0.14263037]\n",
      " [0.6580512 ]\n",
      " [0.15336728]\n",
      " [0.09457791]\n",
      " [0.22817895]\n",
      " [0.08568874]\n",
      " [0.33695212]\n",
      " [0.03169724]\n",
      " [0.20291698]\n",
      " [0.11147982]\n",
      " [0.02815217]\n",
      " [0.2773766 ]\n",
      " [0.09947279]\n",
      " [0.07232714]\n",
      " [0.26161447]\n",
      " [0.1837967 ]\n",
      " [0.2962142 ]\n",
      " [0.04964513]\n",
      " [0.18939328]\n",
      " [0.0043093 ]\n",
      " [0.03007117]\n",
      " [0.05892658]\n",
      " [0.11608219]\n",
      " [0.01461151]\n",
      " [0.09760714]\n",
      " [0.09391284]\n",
      " [0.01093209]\n",
      " [0.48420596]\n",
      " [0.08492288]\n",
      " [0.20049912]\n",
      " [0.04896787]\n",
      " [0.10049739]\n",
      " [0.01264176]\n",
      " [0.02159899]\n",
      " [0.0209277 ]\n",
      " [0.11213341]\n",
      " [0.3015005 ]\n",
      " [0.09644806]\n",
      " [0.12826684]\n",
      " [0.05216801]\n",
      " [0.1459721 ]\n",
      " [0.13331413]\n",
      " [0.12719554]\n",
      " [0.15863669]\n",
      " [0.11198398]\n",
      " [0.06743518]\n",
      " [0.17589438]\n",
      " [0.03389621]\n",
      " [0.04035312]\n",
      " [0.1381723 ]\n",
      " [0.16421989]\n",
      " [0.29040128]\n",
      " [0.05795518]\n",
      " [0.04360366]\n",
      " [0.1108183 ]\n",
      " [0.35883877]\n",
      " [0.09659848]\n",
      " [0.11715144]\n",
      " [0.02127102]\n",
      " [0.61765367]\n",
      " [0.114072  ]\n",
      " [0.03479165]\n",
      " [0.02457663]\n",
      " [0.02700517]\n",
      " [0.06982893]\n",
      " [0.09566817]\n",
      " [0.19060105]\n",
      " [0.04592055]\n",
      " [0.00930774]\n",
      " [0.0854876 ]\n",
      " [0.05689114]\n",
      " [0.01692382]\n",
      " [0.03982529]\n",
      " [0.03262269]\n",
      " [0.20497638]\n",
      " [0.3529158 ]\n",
      " [0.09265164]\n",
      " [0.04209992]\n",
      " [0.05353394]\n",
      " [0.06014255]\n",
      " [0.10683581]\n",
      " [0.08481964]\n",
      " [0.22057754]\n",
      " [0.07938144]\n",
      " [0.07342497]\n",
      " [0.08364934]\n",
      " [0.13267529]\n",
      " [0.04162499]\n",
      " [0.08860973]\n",
      " [0.146507  ]\n",
      " [0.08360186]\n",
      " [0.07235286]\n",
      " [0.06049505]\n",
      " [0.05152559]\n",
      " [0.19229996]\n",
      " [0.00773841]\n",
      " [0.12944144]\n",
      " [0.10325828]\n",
      " [0.08458409]\n",
      " [0.12458161]\n",
      " [0.05858159]\n",
      " [0.45808464]\n",
      " [0.5459029 ]\n",
      " [0.0544661 ]\n",
      " [0.26256484]\n",
      " [0.17824116]\n",
      " [0.08531886]\n",
      " [0.14278862]\n",
      " [0.22446817]\n",
      " [0.1217865 ]\n",
      " [0.07664374]\n",
      " [0.17598683]\n",
      " [0.08549109]\n",
      " [0.74229145]\n",
      " [0.17283079]\n",
      " [0.21944186]\n",
      " [0.23201981]\n",
      " [0.11763284]\n",
      " [0.17245075]\n",
      " [0.19304603]\n",
      " [0.32946494]\n",
      " [0.35810643]\n",
      " [0.0158484 ]\n",
      " [0.46410918]\n",
      " [0.08251181]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod 1st:  0.0625\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 331us/step - loss: 0.4461 - acc: 0.8467 - val_loss: 0.4401 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.4110 - acc: 0.8583 - val_loss: 0.4325 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4039 - acc: 0.8583 - val_loss: 0.4248 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3965 - acc: 0.8583 - val_loss: 0.4168 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3981 - acc: 0.8583 - val_loss: 0.4145 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3912 - acc: 0.8583 - val_loss: 0.4297 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3873 - acc: 0.8583 - val_loss: 0.4020 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.3797 - acc: 0.8583 - val_loss: 0.3899 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3730 - acc: 0.8583 - val_loss: 0.3960 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3824 - acc: 0.8596 - val_loss: 0.3960 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3718 - acc: 0.8604 - val_loss: 0.3840 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3677 - acc: 0.8629 - val_loss: 0.3853 - val_acc: 0.8433\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.3644 - acc: 0.8617 - val_loss: 0.3855 - val_acc: 0.8400\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3615 - acc: 0.8617 - val_loss: 0.3850 - val_acc: 0.8417\n",
      "y2_pred:  [[0.05413538]\n",
      " [0.05300626]\n",
      " [0.09060922]\n",
      " [0.05125645]\n",
      " [0.02566546]\n",
      " [0.03442818]\n",
      " [0.07000241]\n",
      " [0.04582214]\n",
      " [0.12266794]\n",
      " [0.08031416]\n",
      " [0.24660122]\n",
      " [0.02065289]\n",
      " [0.08107558]\n",
      " [0.09658208]\n",
      " [0.04644454]\n",
      " [0.27499607]\n",
      " [0.05190018]\n",
      " [0.02570948]\n",
      " [0.1810135 ]\n",
      " [0.15372646]\n",
      " [0.33072042]\n",
      " [0.21358195]\n",
      " [0.08068091]\n",
      " [0.02634215]\n",
      " [0.21007463]\n",
      " [0.16068387]\n",
      " [0.04573554]\n",
      " [0.05376381]\n",
      " [0.11760247]\n",
      " [0.07838061]\n",
      " [0.16717803]\n",
      " [0.1682795 ]\n",
      " [0.11999071]\n",
      " [0.14309224]\n",
      " [0.06399077]\n",
      " [0.00548375]\n",
      " [0.067496  ]\n",
      " [0.14089543]\n",
      " [0.0693672 ]\n",
      " [0.04801971]\n",
      " [0.1428164 ]\n",
      " [0.08383349]\n",
      " [0.13116872]\n",
      " [0.0963352 ]\n",
      " [0.34112924]\n",
      " [0.03679711]\n",
      " [0.09305531]\n",
      " [0.0937829 ]\n",
      " [0.13039756]\n",
      " [0.13169032]\n",
      " [0.12815651]\n",
      " [0.06278166]\n",
      " [0.0427838 ]\n",
      " [0.01399475]\n",
      " [0.0755631 ]\n",
      " [0.06978312]\n",
      " [0.07891527]\n",
      " [0.17175472]\n",
      " [0.28680885]\n",
      " [0.06167084]\n",
      " [0.1530078 ]\n",
      " [0.0783523 ]\n",
      " [0.10025844]\n",
      " [0.13607088]\n",
      " [0.49306387]\n",
      " [0.09821096]\n",
      " [0.07070976]\n",
      " [0.12849426]\n",
      " [0.19514829]\n",
      " [0.09802344]\n",
      " [0.09664896]\n",
      " [0.09110975]\n",
      " [0.00859472]\n",
      " [0.04905635]\n",
      " [0.07551947]\n",
      " [0.13357702]\n",
      " [0.0948633 ]\n",
      " [0.11337242]\n",
      " [0.02987534]\n",
      " [0.296499  ]\n",
      " [0.19828269]\n",
      " [0.10439101]\n",
      " [0.0299584 ]\n",
      " [0.11401325]\n",
      " [0.03842646]\n",
      " [0.09894785]\n",
      " [0.06595716]\n",
      " [0.09176195]\n",
      " [0.08031204]\n",
      " [0.16442877]\n",
      " [0.05544519]\n",
      " [0.06835073]\n",
      " [0.04219857]\n",
      " [0.08349627]\n",
      " [0.06871834]\n",
      " [0.03037888]\n",
      " [0.05683902]\n",
      " [0.17964578]\n",
      " [0.22601312]\n",
      " [0.05913246]\n",
      " [0.1092315 ]\n",
      " [0.11700505]\n",
      " [0.19929162]\n",
      " [0.05081123]\n",
      " [0.06982943]\n",
      " [0.17891395]\n",
      " [0.02400127]\n",
      " [0.13637793]\n",
      " [0.08849299]\n",
      " [0.01809978]\n",
      " [0.01585177]\n",
      " [0.11673373]\n",
      " [0.10464725]\n",
      " [0.07754475]\n",
      " [0.04688722]\n",
      " [0.07210177]\n",
      " [0.05757067]\n",
      " [0.06652629]\n",
      " [0.15979066]\n",
      " [0.22531116]\n",
      " [0.12909588]\n",
      " [0.07987347]\n",
      " [0.07119259]\n",
      " [0.04047975]\n",
      " [0.08697566]\n",
      " [0.0504486 ]\n",
      " [0.02686003]\n",
      " [0.06179813]\n",
      " [0.12359732]\n",
      " [0.08665922]\n",
      " [0.02230561]\n",
      " [0.10508174]\n",
      " [0.05840993]\n",
      " [0.05056742]\n",
      " [0.04991478]\n",
      " [0.14578769]\n",
      " [0.02987662]\n",
      " [0.0637486 ]\n",
      " [0.08497199]\n",
      " [0.129311  ]\n",
      " [0.1561028 ]\n",
      " [0.06218159]\n",
      " [0.26989093]\n",
      " [0.08389825]\n",
      " [0.10065702]\n",
      " [0.1049991 ]\n",
      " [0.21918923]\n",
      " [0.04899544]\n",
      " [0.02943724]\n",
      " [0.11768049]\n",
      " [0.13781488]\n",
      " [0.33333433]\n",
      " [0.08940834]\n",
      " [0.23393378]\n",
      " [0.08081812]\n",
      " [0.1101172 ]\n",
      " [0.11914831]\n",
      " [0.04199097]\n",
      " [0.08517835]\n",
      " [0.39419276]\n",
      " [0.07165596]\n",
      " [0.04282835]\n",
      " [0.04169539]\n",
      " [0.666593  ]\n",
      " [0.18373191]\n",
      " [0.19804281]\n",
      " [0.03372127]\n",
      " [0.08710244]\n",
      " [0.01799193]\n",
      " [0.06355041]\n",
      " [0.13716793]\n",
      " [0.04122818]\n",
      " [0.14441612]\n",
      " [0.12365586]\n",
      " [0.13733703]\n",
      " [0.09312734]\n",
      " [0.18547818]\n",
      " [0.03142834]\n",
      " [0.10586774]\n",
      " [0.08124277]\n",
      " [0.07774609]\n",
      " [0.00555035]\n",
      " [0.09494859]\n",
      " [0.01167077]\n",
      " [0.09895784]\n",
      " [0.20883551]\n",
      " [0.13734144]\n",
      " [0.07340747]\n",
      " [0.12466311]\n",
      " [0.04424804]\n",
      " [0.05613211]\n",
      " [0.10496175]\n",
      " [0.14027384]\n",
      " [0.19531608]\n",
      " [0.02928451]\n",
      " [0.03728774]\n",
      " [0.16156182]\n",
      " [0.04896846]\n",
      " [0.10236725]\n",
      " [0.06402072]\n",
      " [0.12216499]\n",
      " [0.4702584 ]\n",
      " [0.5438075 ]\n",
      " [0.20891467]\n",
      " [0.11134759]\n",
      " [0.0808292 ]\n",
      " [0.05539855]\n",
      " [0.09014508]\n",
      " [0.5332622 ]\n",
      " [0.05365479]\n",
      " [0.08256564]\n",
      " [0.02493206]\n",
      " [0.05995804]\n",
      " [0.14832306]\n",
      " [0.14634305]\n",
      " [0.09512407]\n",
      " [0.07134834]\n",
      " [0.25045025]\n",
      " [0.06580314]\n",
      " [0.14233312]\n",
      " [0.09083471]\n",
      " [0.03320208]\n",
      " [0.31640103]\n",
      " [0.14241934]\n",
      " [0.11012021]\n",
      " [0.10842791]\n",
      " [0.12228829]\n",
      " [0.13140282]\n",
      " [0.08823115]\n",
      " [0.613474  ]\n",
      " [0.02853808]\n",
      " [0.00888583]\n",
      " [0.05891186]\n",
      " [0.13536835]\n",
      " [0.06916988]\n",
      " [0.15158346]\n",
      " [0.16021755]\n",
      " [0.16334179]\n",
      " [0.24216777]\n",
      " [0.0387525 ]\n",
      " [0.02790681]\n",
      " [0.1575338 ]\n",
      " [0.09217718]\n",
      " [0.08468392]\n",
      " [0.10236526]\n",
      " [0.09868115]\n",
      " [0.09564602]\n",
      " [0.07885945]\n",
      " [0.07870913]\n",
      " [0.0672456 ]\n",
      " [0.11910072]\n",
      " [0.02571711]\n",
      " [0.19256294]\n",
      " [0.0816403 ]\n",
      " [0.04195479]\n",
      " [0.05033237]\n",
      " [0.05525666]\n",
      " [0.3145317 ]\n",
      " [0.14822304]\n",
      " [0.3456995 ]\n",
      " [0.17486802]\n",
      " [0.04604414]\n",
      " [0.05490965]\n",
      " [0.30456948]\n",
      " [0.01848343]\n",
      " [0.06236029]\n",
      " [0.24112478]\n",
      " [0.01844421]\n",
      " [0.00825924]\n",
      " [0.06200922]\n",
      " [0.03287166]\n",
      " [0.08281064]\n",
      " [0.22658905]\n",
      " [0.16696721]\n",
      " [0.22437221]\n",
      " [0.12552235]\n",
      " [0.02209738]\n",
      " [0.07308993]\n",
      " [0.07318828]\n",
      " [0.08837113]\n",
      " [0.01941431]\n",
      " [0.18365276]\n",
      " [0.14155054]\n",
      " [0.11960682]\n",
      " [0.15063316]\n",
      " [0.02119786]\n",
      " [0.15545902]\n",
      " [0.09511727]\n",
      " [0.38962296]\n",
      " [0.21112204]\n",
      " [0.08514601]\n",
      " [0.11253431]\n",
      " [0.40743542]\n",
      " [0.04764691]\n",
      " [0.05709884]\n",
      " [0.06146762]\n",
      " [0.11050791]\n",
      " [0.0660769 ]\n",
      " [0.01679674]\n",
      " [0.02562928]\n",
      " [0.11373109]\n",
      " [0.07497439]\n",
      " [0.02844971]\n",
      " [0.02496192]\n",
      " [0.20801777]\n",
      " [0.24732634]\n",
      " [0.10654348]\n",
      " [0.3436455 ]\n",
      " [0.6876552 ]\n",
      " [0.34557098]\n",
      " [0.29726946]\n",
      " [0.18385273]\n",
      " [0.13421178]\n",
      " [0.07093191]\n",
      " [0.1855154 ]\n",
      " [0.14820135]\n",
      " [0.03433949]\n",
      " [0.432318  ]\n",
      " [0.44603422]\n",
      " [0.25884563]\n",
      " [0.08943889]\n",
      " [0.06304297]\n",
      " [0.19894949]\n",
      " [0.48828852]\n",
      " [0.18857905]\n",
      " [0.0146566 ]\n",
      " [0.21452129]\n",
      " [0.12086996]\n",
      " [0.287695  ]\n",
      " [0.11980505]\n",
      " [0.66677606]\n",
      " [0.2972867 ]\n",
      " [0.30012035]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.08333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 387us/step - loss: 0.4359 - acc: 0.8521 - val_loss: 0.4459 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4150 - acc: 0.8583 - val_loss: 0.4498 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.4113 - acc: 0.8583 - val_loss: 0.4541 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4110 - acc: 0.8583 - val_loss: 0.4455 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.4071 - acc: 0.8583 - val_loss: 0.4279 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.4030 - acc: 0.8583 - val_loss: 0.4216 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4034 - acc: 0.8583 - val_loss: 0.4342 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 57us/step - loss: 0.3986 - acc: 0.8583 - val_loss: 0.4151 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3897 - acc: 0.8583 - val_loss: 0.4400 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3794 - acc: 0.8583 - val_loss: 0.4182 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 81us/step - loss: 0.3776 - acc: 0.8592 - val_loss: 0.4092 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 90us/step - loss: 0.3779 - acc: 0.8612 - val_loss: 0.4093 - val_acc: 0.8300\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 81us/step - loss: 0.3736 - acc: 0.8612 - val_loss: 0.4181 - val_acc: 0.8417\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.3686 - acc: 0.8608 - val_loss: 0.3980 - val_acc: 0.8400\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3682 - acc: 0.8571 - val_loss: 0.3941 - val_acc: 0.8417\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.3655 - acc: 0.8592 - val_loss: 0.3910 - val_acc: 0.8417\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3656 - acc: 0.8617 - val_loss: 0.4289 - val_acc: 0.8400\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3674 - acc: 0.8621 - val_loss: 0.3965 - val_acc: 0.8333\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3629 - acc: 0.8600 - val_loss: 0.3931 - val_acc: 0.8400\n",
      "y2_pred:  [[0.09353566]\n",
      " [0.18546817]\n",
      " [0.09120911]\n",
      " [0.34489748]\n",
      " [0.07948458]\n",
      " [0.07680184]\n",
      " [0.06435582]\n",
      " [0.2728639 ]\n",
      " [0.08743438]\n",
      " [0.23913476]\n",
      " [0.27035925]\n",
      " [0.23101991]\n",
      " [0.0659115 ]\n",
      " [0.16022375]\n",
      " [0.1475083 ]\n",
      " [0.01479688]\n",
      " [0.06334278]\n",
      " [0.08912346]\n",
      " [0.047333  ]\n",
      " [0.05517778]\n",
      " [0.01407486]\n",
      " [0.09890971]\n",
      " [0.07053834]\n",
      " [0.07685792]\n",
      " [0.19055489]\n",
      " [0.04975227]\n",
      " [0.05347708]\n",
      " [0.24835995]\n",
      " [0.12369373]\n",
      " [0.08684164]\n",
      " [0.01626489]\n",
      " [0.02908757]\n",
      " [0.21865556]\n",
      " [0.190703  ]\n",
      " [0.03900325]\n",
      " [0.10048741]\n",
      " [0.0072009 ]\n",
      " [0.08520296]\n",
      " [0.11561772]\n",
      " [0.08451855]\n",
      " [0.07498744]\n",
      " [0.48181444]\n",
      " [0.17994314]\n",
      " [0.06845906]\n",
      " [0.04439551]\n",
      " [0.16510564]\n",
      " [0.2121476 ]\n",
      " [0.1644035 ]\n",
      " [0.06210431]\n",
      " [0.01355708]\n",
      " [0.04282328]\n",
      " [0.05328682]\n",
      " [0.15992162]\n",
      " [0.09853855]\n",
      " [0.24910069]\n",
      " [0.07030407]\n",
      " [0.16369838]\n",
      " [0.10214975]\n",
      " [0.2039938 ]\n",
      " [0.09722307]\n",
      " [0.20805797]\n",
      " [0.23036486]\n",
      " [0.04313442]\n",
      " [0.09897327]\n",
      " [0.04730496]\n",
      " [0.25293633]\n",
      " [0.10110426]\n",
      " [0.0738416 ]\n",
      " [0.07384521]\n",
      " [0.07146984]\n",
      " [0.02117321]\n",
      " [0.15196866]\n",
      " [0.1722433 ]\n",
      " [0.3313579 ]\n",
      " [0.1297898 ]\n",
      " [0.13651526]\n",
      " [0.145453  ]\n",
      " [0.11958161]\n",
      " [0.14085299]\n",
      " [0.19208437]\n",
      " [0.11709449]\n",
      " [0.02556524]\n",
      " [0.08636186]\n",
      " [0.08221713]\n",
      " [0.08275065]\n",
      " [0.39428574]\n",
      " [0.07389137]\n",
      " [0.07452235]\n",
      " [0.0065406 ]\n",
      " [0.1002357 ]\n",
      " [0.1524531 ]\n",
      " [0.04450592]\n",
      " [0.05991247]\n",
      " [0.07476693]\n",
      " [0.07651359]\n",
      " [0.08386767]\n",
      " [0.02476183]\n",
      " [0.04574272]\n",
      " [0.18333563]\n",
      " [0.21416616]\n",
      " [0.02494809]\n",
      " [0.07124507]\n",
      " [0.19670627]\n",
      " [0.00394592]\n",
      " [0.07792711]\n",
      " [0.08931622]\n",
      " [0.08470047]\n",
      " [0.0287374 ]\n",
      " [0.04303315]\n",
      " [0.06329119]\n",
      " [0.11894345]\n",
      " [0.07807466]\n",
      " [0.06593338]\n",
      " [0.20526281]\n",
      " [0.19246578]\n",
      " [0.08592194]\n",
      " [0.09132487]\n",
      " [0.21830943]\n",
      " [0.19051516]\n",
      " [0.03098878]\n",
      " [0.07661089]\n",
      " [0.07909125]\n",
      " [0.1604658 ]\n",
      " [0.05817562]\n",
      " [0.03001866]\n",
      " [0.1145412 ]\n",
      " [0.07385007]\n",
      " [0.07365605]\n",
      " [0.20724007]\n",
      " [0.04990599]\n",
      " [0.04398048]\n",
      " [0.12660095]\n",
      " [0.01500186]\n",
      " [0.40995508]\n",
      " [0.13966116]\n",
      " [0.14142495]\n",
      " [0.19000247]\n",
      " [0.02918181]\n",
      " [0.07319283]\n",
      " [0.00697979]\n",
      " [0.04064086]\n",
      " [0.01769918]\n",
      " [0.08260614]\n",
      " [0.09458172]\n",
      " [0.05388147]\n",
      " [0.35783935]\n",
      " [0.3008362 ]\n",
      " [0.1219002 ]\n",
      " [0.17321327]\n",
      " [0.07627285]\n",
      " [0.00876725]\n",
      " [0.06287608]\n",
      " [0.07088536]\n",
      " [0.06307647]\n",
      " [0.08604926]\n",
      " [0.18413517]\n",
      " [0.0209448 ]\n",
      " [0.03716242]\n",
      " [0.08360401]\n",
      " [0.25370625]\n",
      " [0.00792009]\n",
      " [0.11869556]\n",
      " [0.04402989]\n",
      " [0.04013911]\n",
      " [0.1239002 ]\n",
      " [0.20140079]\n",
      " [0.05826092]\n",
      " [0.03778651]\n",
      " [0.12985438]\n",
      " [0.05691141]\n",
      " [0.18647358]\n",
      " [0.20686582]\n",
      " [0.11942813]\n",
      " [0.07219103]\n",
      " [0.06834146]\n",
      " [0.10902724]\n",
      " [0.11963397]\n",
      " [0.16185063]\n",
      " [0.00687036]\n",
      " [0.07708755]\n",
      " [0.09242025]\n",
      " [0.27354318]\n",
      " [0.05538401]\n",
      " [0.23029292]\n",
      " [0.13791135]\n",
      " [0.20818785]\n",
      " [0.00907913]\n",
      " [0.1381093 ]\n",
      " [0.10158572]\n",
      " [0.16763839]\n",
      " [0.11165884]\n",
      " [0.07841164]\n",
      " [0.32738572]\n",
      " [0.09754729]\n",
      " [0.04231307]\n",
      " [0.11597744]\n",
      " [0.14628243]\n",
      " [0.10157862]\n",
      " [0.11449951]\n",
      " [0.14285186]\n",
      " [0.14992541]\n",
      " [0.12158221]\n",
      " [0.10727578]\n",
      " [0.19012052]\n",
      " [0.09677079]\n",
      " [0.31323165]\n",
      " [0.0152891 ]\n",
      " [0.17968628]\n",
      " [0.18227458]\n",
      " [0.04632786]\n",
      " [0.15882158]\n",
      " [0.05719152]\n",
      " [0.16340381]\n",
      " [0.11547667]\n",
      " [0.07267043]\n",
      " [0.44760063]\n",
      " [0.04674277]\n",
      " [0.15100563]\n",
      " [0.22183144]\n",
      " [0.21882364]\n",
      " [0.14475012]\n",
      " [0.1597814 ]\n",
      " [0.0961965 ]\n",
      " [0.07780296]\n",
      " [0.02437869]\n",
      " [0.03522617]\n",
      " [0.14793739]\n",
      " [0.01778579]\n",
      " [0.05958539]\n",
      " [0.10831693]\n",
      " [0.21151713]\n",
      " [0.03411743]\n",
      " [0.12398505]\n",
      " [0.29048103]\n",
      " [0.50487477]\n",
      " [0.14615971]\n",
      " [0.02682745]\n",
      " [0.03334302]\n",
      " [0.19816032]\n",
      " [0.12828743]\n",
      " [0.14322865]\n",
      " [0.12279087]\n",
      " [0.0874134 ]\n",
      " [0.16875237]\n",
      " [0.03709468]\n",
      " [0.09350458]\n",
      " [0.02241102]\n",
      " [0.1961141 ]\n",
      " [0.13784921]\n",
      " [0.11765766]\n",
      " [0.1272653 ]\n",
      " [0.200605  ]\n",
      " [0.18080747]\n",
      " [0.2136558 ]\n",
      " [0.08431783]\n",
      " [0.16327721]\n",
      " [0.08229581]\n",
      " [0.14084217]\n",
      " [0.18079305]\n",
      " [0.06902644]\n",
      " [0.41599903]\n",
      " [0.10591167]\n",
      " [0.07738104]\n",
      " [0.20015547]\n",
      " [0.07932189]\n",
      " [0.05977747]\n",
      " [0.11634797]\n",
      " [0.0039151 ]\n",
      " [0.43695158]\n",
      " [0.0864726 ]\n",
      " [0.30830455]\n",
      " [0.08223268]\n",
      " [0.1321091 ]\n",
      " [0.2094701 ]\n",
      " [0.08839461]\n",
      " [0.04031914]\n",
      " [0.05134666]\n",
      " [0.03773311]\n",
      " [0.1073603 ]\n",
      " [0.18149456]\n",
      " [0.44580463]\n",
      " [0.10404745]\n",
      " [0.02299798]\n",
      " [0.16152906]\n",
      " [0.34529695]\n",
      " [0.3635642 ]\n",
      " [0.0979597 ]\n",
      " [0.14701957]\n",
      " [0.07627648]\n",
      " [0.14523768]\n",
      " [0.08626303]\n",
      " [0.05837131]\n",
      " [0.07643369]\n",
      " [0.01275066]\n",
      " [0.2245503 ]\n",
      " [0.06428945]\n",
      " [0.15082508]\n",
      " [0.13474566]\n",
      " [0.04871458]\n",
      " [0.08697423]\n",
      " [0.02831098]\n",
      " [0.16686472]\n",
      " [0.11868694]\n",
      " [0.17190892]\n",
      " [0.06792566]\n",
      " [0.06229377]\n",
      " [0.08639833]\n",
      " [0.09857681]\n",
      " [0.1023722 ]\n",
      " [0.21736309]\n",
      " [0.01544949]\n",
      " [0.5295681 ]\n",
      " [0.28565   ]\n",
      " [0.10137135]\n",
      " [0.00853926]\n",
      " [0.1570848 ]\n",
      " [0.08758736]\n",
      " [0.31209856]\n",
      " [0.34248182]\n",
      " [0.27868465]\n",
      " [0.39368817]\n",
      " [0.43589127]\n",
      " [0.18919477]\n",
      " [0.13969827]\n",
      " [0.06908074]\n",
      " [0.45027155]\n",
      " [0.08913523]\n",
      " [0.25630155]\n",
      " [0.15713285]\n",
      " [0.16835551]\n",
      " [0.08998261]\n",
      " [0.1721509 ]\n",
      " [0.09774632]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.020833333333333332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 448us/step - loss: 0.4401 - acc: 0.8563 - val_loss: 0.5185 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 75us/step - loss: 0.4071 - acc: 0.8629 - val_loss: 0.4878 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 80us/step - loss: 0.4000 - acc: 0.8629 - val_loss: 0.4775 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3963 - acc: 0.8629 - val_loss: 0.4624 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3857 - acc: 0.8629 - val_loss: 0.4816 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3794 - acc: 0.8629 - val_loss: 0.4271 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3746 - acc: 0.8629 - val_loss: 0.4243 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.3837 - acc: 0.8629 - val_loss: 0.4320 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3722 - acc: 0.8629 - val_loss: 0.4191 - val_acc: 0.8233\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 76us/step - loss: 0.3645 - acc: 0.8629 - val_loss: 0.4123 - val_acc: 0.8233\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3696 - acc: 0.8629 - val_loss: 0.4180 - val_acc: 0.8233\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3623 - acc: 0.8633 - val_loss: 0.4370 - val_acc: 0.8233\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3636 - acc: 0.8637 - val_loss: 0.4073 - val_acc: 0.8250\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3595 - acc: 0.8629 - val_loss: 0.4202 - val_acc: 0.8233\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.3613 - acc: 0.8650 - val_loss: 0.4118 - val_acc: 0.8217\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.3584 - acc: 0.8633 - val_loss: 0.3987 - val_acc: 0.8217\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3556 - acc: 0.8654 - val_loss: 0.4075 - val_acc: 0.8233\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3581 - acc: 0.8637 - val_loss: 0.4139 - val_acc: 0.8233\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 69us/step - loss: 0.3534 - acc: 0.8654 - val_loss: 0.4446 - val_acc: 0.8250\n",
      "y2_pred:  [[0.13909557]\n",
      " [0.02479088]\n",
      " [0.00765297]\n",
      " [0.07463288]\n",
      " [0.09425285]\n",
      " [0.12328199]\n",
      " [0.18729907]\n",
      " [0.14306933]\n",
      " [0.0508661 ]\n",
      " [0.04060695]\n",
      " [0.03832868]\n",
      " [0.33840346]\n",
      " [0.05973575]\n",
      " [0.02828544]\n",
      " [0.05079079]\n",
      " [0.03314343]\n",
      " [0.0603241 ]\n",
      " [0.01814061]\n",
      " [0.02541921]\n",
      " [0.02618033]\n",
      " [0.12107596]\n",
      " [0.04361778]\n",
      " [0.02580947]\n",
      " [0.38707796]\n",
      " [0.19822368]\n",
      " [0.08637622]\n",
      " [0.14509311]\n",
      " [0.03168407]\n",
      " [0.07344562]\n",
      " [0.02193969]\n",
      " [0.09045649]\n",
      " [0.15658686]\n",
      " [0.39483717]\n",
      " [0.10188445]\n",
      " [0.05890974]\n",
      " [0.00822696]\n",
      " [0.04784542]\n",
      " [0.00662166]\n",
      " [0.25984383]\n",
      " [0.02609414]\n",
      " [0.02700436]\n",
      " [0.07073531]\n",
      " [0.15474191]\n",
      " [0.03541112]\n",
      " [0.04065508]\n",
      " [0.00580457]\n",
      " [0.0823878 ]\n",
      " [0.03927121]\n",
      " [0.04626146]\n",
      " [0.01379505]\n",
      " [0.02041554]\n",
      " [0.01821756]\n",
      " [0.0055126 ]\n",
      " [0.06898972]\n",
      " [0.02154943]\n",
      " [0.06907427]\n",
      " [0.11370024]\n",
      " [0.09353253]\n",
      " [0.0166879 ]\n",
      " [0.02444023]\n",
      " [0.17243311]\n",
      " [0.2458488 ]\n",
      " [0.1211431 ]\n",
      " [0.03994486]\n",
      " [0.01734498]\n",
      " [0.48722818]\n",
      " [0.12200829]\n",
      " [0.21158555]\n",
      " [0.07947582]\n",
      " [0.00215676]\n",
      " [0.05076349]\n",
      " [0.03040892]\n",
      " [0.01267624]\n",
      " [0.03712168]\n",
      " [0.05414715]\n",
      " [0.02534884]\n",
      " [0.13587403]\n",
      " [0.22491857]\n",
      " [0.02069029]\n",
      " [0.19512531]\n",
      " [0.04633173]\n",
      " [0.07048324]\n",
      " [0.02442825]\n",
      " [0.04920319]\n",
      " [0.04018715]\n",
      " [0.00174081]\n",
      " [0.01417807]\n",
      " [0.00885323]\n",
      " [0.04289553]\n",
      " [0.18135732]\n",
      " [0.06099069]\n",
      " [0.02165991]\n",
      " [0.03771558]\n",
      " [0.3110571 ]\n",
      " [0.04677758]\n",
      " [0.07327482]\n",
      " [0.05577755]\n",
      " [0.03286904]\n",
      " [0.06489646]\n",
      " [0.16667026]\n",
      " [0.05838707]\n",
      " [0.01198986]\n",
      " [0.0379478 ]\n",
      " [0.02489018]\n",
      " [0.01645374]\n",
      " [0.08310315]\n",
      " [0.042193  ]\n",
      " [0.17539746]\n",
      " [0.01836428]\n",
      " [0.0082539 ]\n",
      " [0.04502746]\n",
      " [0.04408225]\n",
      " [0.04011852]\n",
      " [0.07489222]\n",
      " [0.07655752]\n",
      " [0.09430417]\n",
      " [0.02034932]\n",
      " [0.14977825]\n",
      " [0.23726162]\n",
      " [0.02171621]\n",
      " [0.04109833]\n",
      " [0.05616686]\n",
      " [0.01810166]\n",
      " [0.01009849]\n",
      " [0.02809975]\n",
      " [0.03432781]\n",
      " [0.02707773]\n",
      " [0.33154613]\n",
      " [0.05038154]\n",
      " [0.10054222]\n",
      " [0.12509793]\n",
      " [0.01926798]\n",
      " [0.07206175]\n",
      " [0.22136483]\n",
      " [0.1983935 ]\n",
      " [0.08090159]\n",
      " [0.1390529 ]\n",
      " [0.03168902]\n",
      " [0.2728547 ]\n",
      " [0.0957329 ]\n",
      " [0.08205497]\n",
      " [0.01550606]\n",
      " [0.05898461]\n",
      " [0.00776905]\n",
      " [0.05956379]\n",
      " [0.01582488]\n",
      " [0.0983485 ]\n",
      " [0.04529116]\n",
      " [0.02958676]\n",
      " [0.06759626]\n",
      " [0.02459037]\n",
      " [0.2955193 ]\n",
      " [0.03069198]\n",
      " [0.02499339]\n",
      " [0.03653175]\n",
      " [0.2072191 ]\n",
      " [0.15497923]\n",
      " [0.04853189]\n",
      " [0.05649307]\n",
      " [0.06685406]\n",
      " [0.11238429]\n",
      " [0.38659567]\n",
      " [0.02986762]\n",
      " [0.04747808]\n",
      " [0.03686967]\n",
      " [0.04619429]\n",
      " [0.07659447]\n",
      " [0.07049161]\n",
      " [0.03713313]\n",
      " [0.08515447]\n",
      " [0.07240275]\n",
      " [0.04293475]\n",
      " [0.07860339]\n",
      " [0.00897682]\n",
      " [0.01586488]\n",
      " [0.01166075]\n",
      " [0.02502835]\n",
      " [0.0894196 ]\n",
      " [0.4302267 ]\n",
      " [0.04000574]\n",
      " [0.10286137]\n",
      " [0.05319667]\n",
      " [0.06781307]\n",
      " [0.0458515 ]\n",
      " [0.09661299]\n",
      " [0.05778465]\n",
      " [0.01980141]\n",
      " [0.06254256]\n",
      " [0.07378134]\n",
      " [0.03462943]\n",
      " [0.0771476 ]\n",
      " [0.00539896]\n",
      " [0.01415691]\n",
      " [0.07537752]\n",
      " [0.08353776]\n",
      " [0.00366396]\n",
      " [0.14706293]\n",
      " [0.07980976]\n",
      " [0.01834086]\n",
      " [0.06869689]\n",
      " [0.04440024]\n",
      " [0.26485932]\n",
      " [0.01727635]\n",
      " [0.04813567]\n",
      " [0.13495928]\n",
      " [0.13432801]\n",
      " [0.08270976]\n",
      " [0.02495581]\n",
      " [0.04127306]\n",
      " [0.1075063 ]\n",
      " [0.05617157]\n",
      " [0.00268987]\n",
      " [0.01638511]\n",
      " [0.12042964]\n",
      " [0.02906787]\n",
      " [0.4123302 ]\n",
      " [0.05165511]\n",
      " [0.05713665]\n",
      " [0.06613317]\n",
      " [0.05445087]\n",
      " [0.03914946]\n",
      " [0.00806737]\n",
      " [0.17495129]\n",
      " [0.01790765]\n",
      " [0.01849246]\n",
      " [0.02088112]\n",
      " [0.0082683 ]\n",
      " [0.23559111]\n",
      " [0.40664595]\n",
      " [0.08036363]\n",
      " [0.00548458]\n",
      " [0.09502015]\n",
      " [0.02008447]\n",
      " [0.04726732]\n",
      " [0.0446389 ]\n",
      " [0.00342914]\n",
      " [0.06476218]\n",
      " [0.28682643]\n",
      " [0.14489433]\n",
      " [0.00993532]\n",
      " [0.05382222]\n",
      " [0.11064106]\n",
      " [0.08106136]\n",
      " [0.06458637]\n",
      " [0.33889592]\n",
      " [0.03419223]\n",
      " [0.04822519]\n",
      " [0.03908721]\n",
      " [0.09112182]\n",
      " [0.06586385]\n",
      " [0.02527782]\n",
      " [0.27132428]\n",
      " [0.03095862]\n",
      " [0.05898583]\n",
      " [0.08623821]\n",
      " [0.06955206]\n",
      " [0.03877991]\n",
      " [0.05061659]\n",
      " [0.10403261]\n",
      " [0.16140127]\n",
      " [0.01851186]\n",
      " [0.12150419]\n",
      " [0.05407113]\n",
      " [0.06437817]\n",
      " [0.08649397]\n",
      " [0.13994166]\n",
      " [0.36387423]\n",
      " [0.20472705]\n",
      " [0.0642384 ]\n",
      " [0.04683158]\n",
      " [0.00602156]\n",
      " [0.07901353]\n",
      " [0.00349182]\n",
      " [0.08075905]\n",
      " [0.04822901]\n",
      " [0.38738975]\n",
      " [0.00882113]\n",
      " [0.04433241]\n",
      " [0.02363515]\n",
      " [0.02076063]\n",
      " [0.06560737]\n",
      " [0.44652072]\n",
      " [0.44155437]\n",
      " [0.02096429]\n",
      " [0.04199237]\n",
      " [0.08227393]\n",
      " [0.1254955 ]\n",
      " [0.07559443]\n",
      " [0.03427267]\n",
      " [0.04055795]\n",
      " [0.03119186]\n",
      " [0.15958741]\n",
      " [0.07685459]\n",
      " [0.12397081]\n",
      " [0.06852704]\n",
      " [0.07105309]\n",
      " [0.00646952]\n",
      " [0.12626019]\n",
      " [0.04893652]\n",
      " [0.04504031]\n",
      " [0.01101404]\n",
      " [0.09761518]\n",
      " [0.07988608]\n",
      " [0.01440212]\n",
      " [0.36420727]\n",
      " [0.03557652]\n",
      " [0.01484373]\n",
      " [0.053619  ]\n",
      " [0.01955345]\n",
      " [0.39128393]\n",
      " [0.04453412]\n",
      " [0.04548571]\n",
      " [0.12352547]\n",
      " [0.11445618]\n",
      " [0.04688004]\n",
      " [0.0626995 ]\n",
      " [0.06102523]\n",
      " [0.10035184]\n",
      " [0.20954314]\n",
      " [0.04342502]\n",
      " [0.31601053]\n",
      " [0.08549672]\n",
      " [0.3972065 ]\n",
      " [0.01556835]\n",
      " [0.35740492]\n",
      " [0.00190213]\n",
      " [0.07003468]\n",
      " [0.02948308]\n",
      " [0.00744597]\n",
      " [0.01763643]\n",
      " [0.06710475]\n",
      " [0.05325875]\n",
      " [0.11326656]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 432us/step - loss: 0.4471 - acc: 0.8504 - val_loss: 0.4744 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 64us/step - loss: 0.4117 - acc: 0.8629 - val_loss: 0.4650 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.4021 - acc: 0.8629 - val_loss: 0.4597 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.4006 - acc: 0.8629 - val_loss: 0.4599 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3960 - acc: 0.8629 - val_loss: 0.4897 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3891 - acc: 0.8629 - val_loss: 0.4452 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3866 - acc: 0.8629 - val_loss: 0.4735 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3851 - acc: 0.8629 - val_loss: 0.4488 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 72us/step - loss: 0.3903 - acc: 0.8629 - val_loss: 0.4486 - val_acc: 0.8233\n",
      "y2_pred:  [[0.08105099]\n",
      " [0.05838022]\n",
      " [0.10295263]\n",
      " [0.08775967]\n",
      " [0.12392247]\n",
      " [0.16097379]\n",
      " [0.10646752]\n",
      " [0.13465887]\n",
      " [0.07329181]\n",
      " [0.07930362]\n",
      " [0.0518854 ]\n",
      " [0.07743052]\n",
      " [0.10586393]\n",
      " [0.09163353]\n",
      " [0.0525901 ]\n",
      " [0.02735102]\n",
      " [0.08346429]\n",
      " [0.2600262 ]\n",
      " [0.16000831]\n",
      " [0.13947037]\n",
      " [0.04945737]\n",
      " [0.1483666 ]\n",
      " [0.01870969]\n",
      " [0.08486378]\n",
      " [0.10031104]\n",
      " [0.07104442]\n",
      " [0.11877677]\n",
      " [0.06741989]\n",
      " [0.09166077]\n",
      " [0.02244642]\n",
      " [0.23741853]\n",
      " [0.3454755 ]\n",
      " [0.06286898]\n",
      " [0.06848699]\n",
      " [0.06215116]\n",
      " [0.15220451]\n",
      " [0.12964869]\n",
      " [0.05967307]\n",
      " [0.05025047]\n",
      " [0.16987473]\n",
      " [0.05738753]\n",
      " [0.08375302]\n",
      " [0.07468694]\n",
      " [0.11066931]\n",
      " [0.11606836]\n",
      " [0.21551985]\n",
      " [0.04803783]\n",
      " [0.2207061 ]\n",
      " [0.10488644]\n",
      " [0.13715956]\n",
      " [0.14817134]\n",
      " [0.12494621]\n",
      " [0.14655223]\n",
      " [0.20446354]\n",
      " [0.05065981]\n",
      " [0.14425445]\n",
      " [0.11375457]\n",
      " [0.07843262]\n",
      " [0.25025496]\n",
      " [0.06019846]\n",
      " [0.13776577]\n",
      " [0.11841449]\n",
      " [0.06087658]\n",
      " [0.08593845]\n",
      " [0.19671217]\n",
      " [0.04411617]\n",
      " [0.12450406]\n",
      " [0.06720722]\n",
      " [0.08731532]\n",
      " [0.02260354]\n",
      " [0.14826682]\n",
      " [0.04495299]\n",
      " [0.09468678]\n",
      " [0.06279477]\n",
      " [0.06577238]\n",
      " [0.07570651]\n",
      " [0.15843377]\n",
      " [0.05481803]\n",
      " [0.08958957]\n",
      " [0.13924515]\n",
      " [0.07500774]\n",
      " [0.15438396]\n",
      " [0.172883  ]\n",
      " [0.06506088]\n",
      " [0.17969751]\n",
      " [0.20164925]\n",
      " [0.29019842]\n",
      " [0.06500667]\n",
      " [0.03388312]\n",
      " [0.06822413]\n",
      " [0.07645246]\n",
      " [0.07632831]\n",
      " [0.08474848]\n",
      " [0.18725741]\n",
      " [0.13026881]\n",
      " [0.03714144]\n",
      " [0.09784701]\n",
      " [0.11236838]\n",
      " [0.08662885]\n",
      " [0.17129013]\n",
      " [0.06818846]\n",
      " [0.06741494]\n",
      " [0.0276669 ]\n",
      " [0.14628619]\n",
      " [0.0576086 ]\n",
      " [0.11574578]\n",
      " [0.0667699 ]\n",
      " [0.15625912]\n",
      " [0.02604246]\n",
      " [0.09875673]\n",
      " [0.07235241]\n",
      " [0.05120316]\n",
      " [0.26997268]\n",
      " [0.1407153 ]\n",
      " [0.0899947 ]\n",
      " [0.160793  ]\n",
      " [0.11770689]\n",
      " [0.11276081]\n",
      " [0.03742725]\n",
      " [0.05648938]\n",
      " [0.08270139]\n",
      " [0.09252965]\n",
      " [0.27587986]\n",
      " [0.02799332]\n",
      " [0.10975012]\n",
      " [0.19079563]\n",
      " [0.08443445]\n",
      " [0.17400423]\n",
      " [0.26801896]\n",
      " [0.06775582]\n",
      " [0.09767836]\n",
      " [0.15359598]\n",
      " [0.14581332]\n",
      " [0.13474566]\n",
      " [0.17371613]\n",
      " [0.08917138]\n",
      " [0.0427396 ]\n",
      " [0.1402902 ]\n",
      " [0.14432025]\n",
      " [0.2753117 ]\n",
      " [0.18801412]\n",
      " [0.0376842 ]\n",
      " [0.16991034]\n",
      " [0.11785701]\n",
      " [0.2613294 ]\n",
      " [0.1808418 ]\n",
      " [0.08445647]\n",
      " [0.22867346]\n",
      " [0.16512975]\n",
      " [0.14410469]\n",
      " [0.10176298]\n",
      " [0.07699564]\n",
      " [0.09339479]\n",
      " [0.19338876]\n",
      " [0.10181195]\n",
      " [0.06714311]\n",
      " [0.15147081]\n",
      " [0.32769346]\n",
      " [0.18668875]\n",
      " [0.18665439]\n",
      " [0.08194199]\n",
      " [0.12453669]\n",
      " [0.07473397]\n",
      " [0.06378803]\n",
      " [0.13905805]\n",
      " [0.05015922]\n",
      " [0.21915653]\n",
      " [0.13383898]\n",
      " [0.08272263]\n",
      " [0.1246967 ]\n",
      " [0.13314733]\n",
      " [0.1228365 ]\n",
      " [0.14958891]\n",
      " [0.12607825]\n",
      " [0.03994101]\n",
      " [0.03636035]\n",
      " [0.07841486]\n",
      " [0.04888484]\n",
      " [0.06647918]\n",
      " [0.09882027]\n",
      " [0.19732013]\n",
      " [0.1989502 ]\n",
      " [0.09967014]\n",
      " [0.12492427]\n",
      " [0.10466215]\n",
      " [0.08808839]\n",
      " [0.20652369]\n",
      " [0.05183586]\n",
      " [0.21427062]\n",
      " [0.15338099]\n",
      " [0.17158148]\n",
      " [0.16554207]\n",
      " [0.09339166]\n",
      " [0.06584373]\n",
      " [0.04828075]\n",
      " [0.03736925]\n",
      " [0.10694033]\n",
      " [0.1388376 ]\n",
      " [0.07486722]\n",
      " [0.08047438]\n",
      " [0.1646592 ]\n",
      " [0.05150527]\n",
      " [0.09931183]\n",
      " [0.04753032]\n",
      " [0.05767602]\n",
      " [0.13465089]\n",
      " [0.06129032]\n",
      " [0.08081421]\n",
      " [0.15712592]\n",
      " [0.1424883 ]\n",
      " [0.18473288]\n",
      " [0.06429946]\n",
      " [0.02338275]\n",
      " [0.08007553]\n",
      " [0.20863062]\n",
      " [0.06527039]\n",
      " [0.02918705]\n",
      " [0.02310351]\n",
      " [0.06019831]\n",
      " [0.05060521]\n",
      " [0.03333744]\n",
      " [0.09472868]\n",
      " [0.12924415]\n",
      " [0.15426603]\n",
      " [0.10697591]\n",
      " [0.2554044 ]\n",
      " [0.15848348]\n",
      " [0.07052952]\n",
      " [0.24183342]\n",
      " [0.05293173]\n",
      " [0.08475256]\n",
      " [0.08447242]\n",
      " [0.09555316]\n",
      " [0.07798359]\n",
      " [0.06818694]\n",
      " [0.1009306 ]\n",
      " [0.04061708]\n",
      " [0.18586895]\n",
      " [0.12925151]\n",
      " [0.04944152]\n",
      " [0.13596472]\n",
      " [0.20351571]\n",
      " [0.02561092]\n",
      " [0.3056662 ]\n",
      " [0.07174331]\n",
      " [0.1532937 ]\n",
      " [0.06936136]\n",
      " [0.12268972]\n",
      " [0.08480865]\n",
      " [0.06858099]\n",
      " [0.09185028]\n",
      " [0.1656723 ]\n",
      " [0.0938569 ]\n",
      " [0.0257929 ]\n",
      " [0.03026444]\n",
      " [0.23300844]\n",
      " [0.14081052]\n",
      " [0.10076797]\n",
      " [0.10234141]\n",
      " [0.12191248]\n",
      " [0.15900308]\n",
      " [0.08368897]\n",
      " [0.0954212 ]\n",
      " [0.16474321]\n",
      " [0.03473538]\n",
      " [0.11988318]\n",
      " [0.06171677]\n",
      " [0.11623886]\n",
      " [0.14817372]\n",
      " [0.1499598 ]\n",
      " [0.16033778]\n",
      " [0.11270764]\n",
      " [0.14424846]\n",
      " [0.09014437]\n",
      " [0.09883213]\n",
      " [0.07224494]\n",
      " [0.06438693]\n",
      " [0.10860753]\n",
      " [0.1165317 ]\n",
      " [0.05792695]\n",
      " [0.2546925 ]\n",
      " [0.08678937]\n",
      " [0.09873715]\n",
      " [0.17851955]\n",
      " [0.08192083]\n",
      " [0.06419972]\n",
      " [0.03360635]\n",
      " [0.04012966]\n",
      " [0.07668611]\n",
      " [0.14740708]\n",
      " [0.19468695]\n",
      " [0.07803679]\n",
      " [0.10189503]\n",
      " [0.07698828]\n",
      " [0.06890389]\n",
      " [0.10933414]\n",
      " [0.19251755]\n",
      " [0.04122022]\n",
      " [0.07944787]\n",
      " [0.17403367]\n",
      " [0.04965323]\n",
      " [0.22620422]\n",
      " [0.26388174]\n",
      " [0.04672831]\n",
      " [0.313933  ]\n",
      " [0.0522221 ]\n",
      " [0.03416306]\n",
      " [0.14852157]\n",
      " [0.13261375]\n",
      " [0.22185701]\n",
      " [0.12320086]\n",
      " [0.08846647]\n",
      " [0.11799064]\n",
      " [0.05100849]\n",
      " [0.12621114]\n",
      " [0.02773994]\n",
      " [0.02176535]\n",
      " [0.15022498]\n",
      " [0.13788086]\n",
      " [0.09732687]\n",
      " [0.23510095]\n",
      " [0.15056992]\n",
      " [0.27550018]\n",
      " [0.11730886]\n",
      " [0.07756391]\n",
      " [0.15665472]\n",
      " [0.08514109]\n",
      " [0.11843348]\n",
      " [0.04557691]\n",
      " [0.14704412]\n",
      " [0.16700877]\n",
      " [0.23292185]\n",
      " [0.04555487]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.10204081632653061, 0.12244897959183673, 0.10204081632653061, 0.0, 0.16666666666666666, 0.0625, 0.08333333333333333, 0.020833333333333332, 0.0, 0.0]\n",
      "pof:  [0.017543859649122806, 0.0, 0.017543859649122806, 0.0, 0.017543859649122806, 0.017543859649122806, 0.007017543859649123, 0.0035087719298245615, 0.0, 0.0]\n",
      "auc:  [0.5422484783387038, 0.5612244897959183, 0.5422484783387038, 0.5, 0.5745614035087719, 0.5224780701754386, 0.5381578947368421, 0.5086622807017543, 0.5, 0.5]\n",
      "tn_list:  [280, 285, 280, 285, 280, 280, 283, 284, 285, 285]\n",
      "fp_list:  [5, 0, 5, 0, 5, 5, 2, 1, 0, 0]\n",
      "fn_list:  [44, 43, 44, 48, 40, 45, 44, 47, 48, 48]\n",
      "tp_list:  [5, 6, 5, 0, 8, 3, 4, 1, 0, 0]\n",
      "2827 23 451 32\n"
     ]
    }
   ],
   "source": [
    "df_x_train_chi = pd.DataFrame(x_train_chi)\n",
    "df_x_train_chi.head()\n",
    "\n",
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print('tn_list: ',tn_list)\n",
    "print ('fp_list: ',fp_list)\n",
    "print ('fn_list: ',fn_list)\n",
    "print ('tp_list: ',tp_list)\n",
    "\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21715 28723 14408 35154\n"
     ]
    }
   ],
   "source": [
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 645us/step - loss: 0.5591 - acc: 0.8212 - val_loss: 0.4372 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 85us/step - loss: 0.4075 - acc: 0.8587 - val_loss: 0.4374 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 88us/step - loss: 0.4053 - acc: 0.8587 - val_loss: 0.4419 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 84us/step - loss: 0.4072 - acc: 0.8587 - val_loss: 0.4355 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 87us/step - loss: 0.4029 - acc: 0.8587 - val_loss: 0.4350 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 674us/step - loss: 0.5316 - acc: 0.8433 - val_loss: 0.4364 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 80us/step - loss: 0.4077 - acc: 0.8587 - val_loss: 0.4415 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 82us/step - loss: 0.4076 - acc: 0.8587 - val_loss: 0.4347 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.4061 - acc: 0.8587 - val_loss: 0.4339 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.4064 - acc: 0.8587 - val_loss: 0.4328 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 746us/step - loss: 0.5386 - acc: 0.8162 - val_loss: 0.4360 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 85us/step - loss: 0.4089 - acc: 0.8587 - val_loss: 0.4485 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 90us/step - loss: 0.4069 - acc: 0.8587 - val_loss: 0.4354 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 86us/step - loss: 0.4053 - acc: 0.8587 - val_loss: 0.4333 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 86us/step - loss: 0.4036 - acc: 0.8587 - val_loss: 0.4328 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 841us/step - loss: 0.5251 - acc: 0.8533 - val_loss: 0.4428 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.4083 - acc: 0.8583 - val_loss: 0.4385 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.4081 - acc: 0.8583 - val_loss: 0.4355 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.4064 - acc: 0.8583 - val_loss: 0.4344 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.4031 - acc: 0.8583 - val_loss: 0.4335 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 922us/step - loss: 0.5328 - acc: 0.8458 - val_loss: 0.4351 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.4097 - acc: 0.8583 - val_loss: 0.4359 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 94us/step - loss: 0.4072 - acc: 0.8583 - val_loss: 0.4360 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.4052 - acc: 0.8583 - val_loss: 0.4355 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.4049 - acc: 0.8583 - val_loss: 0.4318 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 978us/step - loss: 0.5319 - acc: 0.8292 - val_loss: 0.4367 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 92us/step - loss: 0.4095 - acc: 0.8583 - val_loss: 0.4363 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.4078 - acc: 0.8583 - val_loss: 0.4344 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.4081 - acc: 0.8583 - val_loss: 0.4362 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 93us/step - loss: 0.4051 - acc: 0.8583 - val_loss: 0.4330 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 999us/step - loss: 0.5377 - acc: 0.8583 - val_loss: 0.4375 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.4066 - acc: 0.8583 - val_loss: 0.4406 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.4057 - acc: 0.8583 - val_loss: 0.4340 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 91us/step - loss: 0.4076 - acc: 0.8583 - val_loss: 0.4335 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.4031 - acc: 0.8583 - val_loss: 0.4358 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 988us/step - loss: 0.5174 - acc: 0.8583 - val_loss: 0.4381 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 94us/step - loss: 0.4106 - acc: 0.8583 - val_loss: 0.4386 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 91us/step - loss: 0.4092 - acc: 0.8583 - val_loss: 0.4415 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 90us/step - loss: 0.4068 - acc: 0.8583 - val_loss: 0.4379 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.4078 - acc: 0.8583 - val_loss: 0.4329 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5318 - acc: 0.8254 - val_loss: 0.4668 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3984 - acc: 0.8629 - val_loss: 0.4798 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3991 - acc: 0.8629 - val_loss: 0.4643 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.3972 - acc: 0.8629 - val_loss: 0.4625 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 93us/step - loss: 0.3971 - acc: 0.8629 - val_loss: 0.4617 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5039 - acc: 0.8629 - val_loss: 0.4685 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.4004 - acc: 0.8629 - val_loss: 0.4797 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.4001 - acc: 0.8629 - val_loss: 0.4685 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3981 - acc: 0.8629 - val_loss: 0.4976 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3981 - acc: 0.8629 - val_loss: 0.4612 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2850 0 483 0\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "def get_RNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    import pandas as pd\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Dropout, LSTM, GRU\n",
    "    from keras.layers import Embedding\n",
    "    max_features = 10000 # number of words to consider as features\n",
    "    import numpy as np\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_RNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    \n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
