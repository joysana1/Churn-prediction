{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"churn-data-3333.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  area_code  number_vmail_messages  total_day_minutes  \\\n",
       "0             128        415                     25              265.1   \n",
       "1             107        415                     26              161.6   \n",
       "2             137        415                      0              243.4   \n",
       "3              84        408                      0              299.4   \n",
       "4              75        415                      0              166.7   \n",
       "\n",
       "   total_day_calls  total_day_charge  total_eve_minutes  total_eve_calls  \\\n",
       "0              110             45.07              197.4               99   \n",
       "1              123             27.47              195.5              103   \n",
       "2              114             41.38              121.2              110   \n",
       "3               71             50.90               61.9               88   \n",
       "4              113             28.34              148.3              122   \n",
       "\n",
       "   total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0             16.78                244.7                 91   \n",
       "1             16.62                254.4                103   \n",
       "2             10.30                162.6                104   \n",
       "3              5.26                196.9                 89   \n",
       "4             12.61                186.9                121   \n",
       "\n",
       "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0               11.01                10.0                 3   \n",
       "1               11.45                13.7                 3   \n",
       "2                7.32                12.2                 5   \n",
       "3                8.86                 6.6                 7   \n",
       "4                8.41                10.1                 3   \n",
       "\n",
       "   total_intl_charge  number_customer_service_calls  \n",
       "0               2.70                              1  \n",
       "1               3.70                              1  \n",
       "2               3.29                              0  \n",
       "3               1.78                              2  \n",
       "4               2.73                              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "\n",
    "churn=cat_df['churn']\n",
    "cat_df=cat_df.drop(['churn'], axis=1)\n",
    "cat_df=cat_df.drop(['phone number'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#BOX-COX\n",
    "#lemda=0.5\n",
    "#num_df=(num_df**lemda)\n",
    "#num_df=num_df-1\n",
    "#num_df[num_df < 0]=0\n",
    "#num_df=num_df.div(lemda)\n",
    "#End BOX-COX\n",
    "#Z-score\n",
    "#num_df=(num_df-num_df.min())/(num_df.std(ddof=0)) ##Z-score\n",
    "\n",
    "#Log\n",
    "#num_df=round(np.log(num_df.add(1)),2)\n",
    "#num_df=num_df.replace([np.inf, -np.inf], np.nan)\n",
    "#End Log\n",
    "\n",
    "num_df=num_df.fillna(conData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_df.columns:\n",
    "    Bins=20\n",
    "    Omega=num_df[col].max()-num_df[col].min()\n",
    "    #Omega=num_df[col].max()-0\n",
    "    Omega=Omega/Bins\n",
    "    #print(num_df[col].min())\n",
    "    #BINValue=[1.1, 1.1]\n",
    "    BINValue=[]\n",
    "    BINValue.insert(0,num_df[col].min())\n",
    "    #BINValue.insert(0,-1)\n",
    "    for i in range(19):\n",
    "        BINValue.insert(i+1,BINValue[i]+Omega)\n",
    "        #print(BINValue[i+1])\n",
    "    #print(BINValue)\n",
    "    #print(num_df[col])\n",
    "    labels =[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "    cats=pd.cut(num_df[col], BINValue, labels=labels)\n",
    "    num_df[col]=cats\n",
    "    #print(cats)\n",
    "    #cats.to_csv('D://cats.csv')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df=num_df.fillna(1)\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "#result_df=result_df.replace([np.inf, -np.inf], np.nan)\n",
    "#result_df=result_df.fillna(-1)\n",
    "#result_df=result_df.abs()\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number_customer_service_calls</td>\n",
       "      <td>253.822022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>international_plan</td>\n",
       "      <td>203.244178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number_vmail_messages</td>\n",
       "      <td>167.085298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_day_charge</td>\n",
       "      <td>94.226803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_day_minutes</td>\n",
       "      <td>94.047195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>voice_mail_plan</td>\n",
       "      <td>25.156959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_intl_calls</td>\n",
       "      <td>15.885968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_eve_minutes</td>\n",
       "      <td>13.090907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_eve_charge</td>\n",
       "      <td>13.013255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_intl_minutes</td>\n",
       "      <td>9.186276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_intl_charge</td>\n",
       "      <td>9.145873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_night_minutes</td>\n",
       "      <td>3.660095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_night_charge</td>\n",
       "      <td>3.537456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>state</td>\n",
       "      <td>1.701057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account_length</td>\n",
       "      <td>1.485383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_day_calls</td>\n",
       "      <td>0.763031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_night_calls</td>\n",
       "      <td>0.144955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_eve_calls</td>\n",
       "      <td>0.039413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_code</td>\n",
       "      <td>0.023776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature      Scores\n",
       "15  number_customer_service_calls  253.822022\n",
       "17             international_plan  203.244178\n",
       "2           number_vmail_messages  167.085298\n",
       "5                total_day_charge   94.226803\n",
       "3               total_day_minutes   94.047195\n",
       "18                voice_mail_plan   25.156959\n",
       "13               total_intl_calls   15.885968\n",
       "6               total_eve_minutes   13.090907\n",
       "8                total_eve_charge   13.013255\n",
       "12             total_intl_minutes    9.186276\n",
       "14              total_intl_charge    9.145873\n",
       "9             total_night_minutes    3.660095\n",
       "11             total_night_charge    3.537456\n",
       "16                          state    1.701057\n",
       "0                  account_length    1.485383\n",
       "4                 total_day_calls    0.763031\n",
       "10              total_night_calls    0.144955\n",
       "7                 total_eve_calls    0.039413\n",
       "1                       area_code    0.023776"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X\n",
    "y_train=y\n",
    "#Univariate Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "select_feature = SelectKBest(chi2, k=15).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                     'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y\n",
    "x_train_chi = select_feature.transform(X_train)\n",
    "x_train_chi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622 228 222 261\n",
      "pod:  0.5403726708074534\n",
      "pof:  0.08\n",
      "AUC:  0.7301863354037267\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.0005336699231206307}\n",
      "GaussianNB(priors=None, var_smoothing=0.0005336699231206307)\n",
      "0.8832883288328833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:   16.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=5, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "classifier=GaussianNB();\n",
    "#params = {\n",
    "#          \"priors\" : \"None\",\n",
    "#          \"var_smoothing\" : 1e-9\n",
    "#}\n",
    "#create an list of var_smoothing to cross validate\n",
    "#steps = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "grid = GridSearchCV(estimator=classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    " \n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26710 23728 21590 27972\n",
      "pod:  0.5643840038739357\n",
      "pof:  0.4704389547563345\n",
      "AUC:  0.5469725245588006\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2741 109 281 202\n",
      "pod:  0.41821946169772256\n",
      "pof:  0.03824561403508772\n",
      "AUC:  0.6899869238313174\n",
      "accuracy:  0.882988298829883\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB(priors=None, var_smoothing=0.0005336699231206307)\n",
    "\n",
    "classifier.fit(x_train_chi,y_train)\n",
    "\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=5, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 5)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.54812\n"
     ]
    }
   ],
   "source": [
    " #accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "accuracy=(26836+27976)/(27976+22462+22726+26836)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:   18.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8592859285928592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   20.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},    \n",
    "    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}\n",
    "]\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2786 64 405 78\n",
      "pod:  0.16149068322981366\n",
      "pof:  0.02245614035087719\n",
      "AUC:  0.5695172714394683\n",
      "accuracy:  0.8592859285928592\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
    "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
    "          tol=0.0001, verbose=0, warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "0.8811881188118812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "param_grid ={\n",
    "   'n_neighbors': [3,5,11,19],\n",
    "   'weights': ['uniform', 'distance'],\n",
    "   'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=3, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 410.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 1993.6min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "# Specify parameters\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 1e-3, 1e-4]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'], \n",
    "                     'gamma': [0.001, 0.01, 0.1, 1, 1e-3, 1e-4], \n",
    "                     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} ]\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2820 30 362 121\n",
      "pod:  0.2505175983436853\n",
      "pof:  0.010526315789473684\n",
      "AUC:  0.6199956412771058\n",
      "accuracy:  0.8823882388238824\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "           weights='uniform' )  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2831 19 386 97\n",
      "pod:  0.20082815734989648\n",
      "pof:  0.006666666666666667\n",
      "AUC:  0.5970807453416149\n",
      "accuracy:  0.8784878487848785\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=100, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.946894689468947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "#clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "#parameters = {'n_estimators': [4, 6, 9], \n",
    "#              'max_features': ['log2', 'sqrt','auto'], \n",
    "#              'criterion': ['entropy', 'gini'],\n",
    "#              'max_depth': [2, 3, 5, 10], \n",
    "#              'min_samples_split': [2, 3, 5],\n",
    "#              'min_samples_leaf': [1,5,8]\n",
    "#             }\n",
    "\n",
    "#model_params = {\n",
    "#    'n_estimators': [50, 150, 250],\n",
    "#    'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "#    'min_samples_split': [2, 4, 6]\n",
    "#}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 110, 'max_features': 3, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=110, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.56987\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825 25 154 329\n",
      "pod:  0.6811594202898551\n",
      "pof:  0.008771929824561403\n",
      "AUC:  0.8361937452326468\n",
      "accuracy:  0.9462946294629463\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(\n",
    "bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=100, max_features=3, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=3, min_samples_split=10,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2850 0 480 3\n",
      "pod:  0.006211180124223602\n",
      "pof:  0.0\n",
      "AUC:  0.5031055900621118\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2699 151 124 359\n",
      "pod:  0.7432712215320911\n",
      "pof:  0.052982456140350874\n",
      "AUC:  0.8451443826958701\n",
      "accuracy:  0.9174917491749175\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2675 175 133 350\n",
      "pod:  0.7246376811594203\n",
      "pof:  0.06140350877192982\n",
      "AUC:  0.8316170861937453\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2807 43 137 346\n",
      "pod:  0.7163561076604554\n",
      "pof:  0.015087719298245613\n",
      "AUC:  0.8506341941811049\n",
      "accuracy:  0.945994599459946\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#classifier = GradientBoostingClassifier(max_features=None, max_depth=3, criterion='friedman_mse')\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2806 44 137 346\n",
      "pod:  0.7163561076604554\n",
      "pof:  0.015438596491228071\n",
      "AUC:  0.8504587555846137\n",
      "accuracy:  0.9456945694569457\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 5s 2ms/step - loss: 0.4345 - acc: 0.8579 - val_loss: 0.4805 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 151us/step - loss: 0.4170 - acc: 0.8587 - val_loss: 0.4360 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 150us/step - loss: 0.4101 - acc: 0.8587 - val_loss: 0.4217 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 136us/step - loss: 0.3984 - acc: 0.8587 - val_loss: 0.4169 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 143us/step - loss: 0.3955 - acc: 0.8587 - val_loss: 0.4082 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 148us/step - loss: 0.3877 - acc: 0.8587 - val_loss: 0.4050 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 139us/step - loss: 0.3818 - acc: 0.8583 - val_loss: 0.3993 - val_acc: 0.8450\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 133us/step - loss: 0.3746 - acc: 0.8612 - val_loss: 0.3875 - val_acc: 0.8450\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 146us/step - loss: 0.3764 - acc: 0.8599 - val_loss: 0.3817 - val_acc: 0.8467\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 131us/step - loss: 0.3693 - acc: 0.8587 - val_loss: 0.4029 - val_acc: 0.8450\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 134us/step - loss: 0.3659 - acc: 0.8620 - val_loss: 0.3874 - val_acc: 0.8467\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 144us/step - loss: 0.3628 - acc: 0.8633 - val_loss: 0.3771 - val_acc: 0.8517\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 131us/step - loss: 0.3578 - acc: 0.8629 - val_loss: 0.3756 - val_acc: 0.8517\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 131us/step - loss: 0.3582 - acc: 0.8608 - val_loss: 0.3794 - val_acc: 0.8483\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 139us/step - loss: 0.3538 - acc: 0.8591 - val_loss: 0.3697 - val_acc: 0.8550\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 142us/step - loss: 0.3492 - acc: 0.8662 - val_loss: 0.3646 - val_acc: 0.8617\n",
      "Epoch 17/30\n",
      "2399/2399 [==============================] - 0s 138us/step - loss: 0.3511 - acc: 0.8649 - val_loss: 0.3616 - val_acc: 0.8600\n",
      "Epoch 18/30\n",
      "2399/2399 [==============================] - 0s 136us/step - loss: 0.3466 - acc: 0.8641 - val_loss: 0.3621 - val_acc: 0.8550\n",
      "Epoch 19/30\n",
      "2399/2399 [==============================] - 0s 143us/step - loss: 0.3426 - acc: 0.8620 - val_loss: 0.3742 - val_acc: 0.8500\n",
      "Epoch 20/30\n",
      "2399/2399 [==============================] - 0s 139us/step - loss: 0.3403 - acc: 0.8687 - val_loss: 0.3620 - val_acc: 0.8483\n",
      "y2_pred:  [[0.11746982]\n",
      " [0.07974401]\n",
      " [0.04120988]\n",
      " [0.16434315]\n",
      " [0.26313493]\n",
      " [0.3271561 ]\n",
      " [0.15026572]\n",
      " [0.1069434 ]\n",
      " [0.16312987]\n",
      " [0.03092048]\n",
      " [0.17822045]\n",
      " [0.07455727]\n",
      " [0.1613535 ]\n",
      " [0.14075047]\n",
      " [0.15695289]\n",
      " [0.1820172 ]\n",
      " [0.13702959]\n",
      " [0.16797209]\n",
      " [0.04169348]\n",
      " [0.14547712]\n",
      " [0.06620798]\n",
      " [0.14499158]\n",
      " [0.01931226]\n",
      " [0.054488  ]\n",
      " [0.03630227]\n",
      " [0.1446633 ]\n",
      " [0.00663149]\n",
      " [0.25517637]\n",
      " [0.22709489]\n",
      " [0.11498109]\n",
      " [0.10170889]\n",
      " [0.1661506 ]\n",
      " [0.08438265]\n",
      " [0.2605725 ]\n",
      " [0.0421052 ]\n",
      " [0.1068835 ]\n",
      " [0.12020916]\n",
      " [0.05093631]\n",
      " [0.06585622]\n",
      " [0.04598927]\n",
      " [0.19487825]\n",
      " [0.12898254]\n",
      " [0.03336748]\n",
      " [0.21643439]\n",
      " [0.00966117]\n",
      " [0.14281482]\n",
      " [0.20972413]\n",
      " [0.06085002]\n",
      " [0.26949888]\n",
      " [0.01885813]\n",
      " [0.10378122]\n",
      " [0.30998105]\n",
      " [0.05435219]\n",
      " [0.10147566]\n",
      " [0.21196184]\n",
      " [0.09864217]\n",
      " [0.0754942 ]\n",
      " [0.13679036]\n",
      " [0.16528228]\n",
      " [0.17368847]\n",
      " [0.07782352]\n",
      " [0.09961355]\n",
      " [0.09769148]\n",
      " [0.12660685]\n",
      " [0.21467566]\n",
      " [0.02243736]\n",
      " [0.4738981 ]\n",
      " [0.09732762]\n",
      " [0.2541381 ]\n",
      " [0.2896725 ]\n",
      " [0.11476943]\n",
      " [0.11922511]\n",
      " [0.2552338 ]\n",
      " [0.29625896]\n",
      " [0.29754028]\n",
      " [0.13041446]\n",
      " [0.48865762]\n",
      " [0.16654763]\n",
      " [0.31291026]\n",
      " [0.10189909]\n",
      " [0.16105992]\n",
      " [0.17829496]\n",
      " [0.17988527]\n",
      " [0.03199977]\n",
      " [0.23737457]\n",
      " [0.00498289]\n",
      " [0.1678598 ]\n",
      " [0.11599895]\n",
      " [0.1818856 ]\n",
      " [0.1511853 ]\n",
      " [0.14001554]\n",
      " [0.14820927]\n",
      " [0.04852164]\n",
      " [0.36350107]\n",
      " [0.11185172]\n",
      " [0.15944886]\n",
      " [0.12919196]\n",
      " [0.16566175]\n",
      " [0.37702215]\n",
      " [0.24910694]\n",
      " [0.12382236]\n",
      " [0.23559034]\n",
      " [0.00884861]\n",
      " [0.04293007]\n",
      " [0.04708412]\n",
      " [0.11727828]\n",
      " [0.19630927]\n",
      " [0.07641628]\n",
      " [0.08067623]\n",
      " [0.14731768]\n",
      " [0.13273454]\n",
      " [0.10507107]\n",
      " [0.1318278 ]\n",
      " [0.03974175]\n",
      " [0.06689349]\n",
      " [0.01842961]\n",
      " [0.16736197]\n",
      " [0.5844746 ]\n",
      " [0.22520024]\n",
      " [0.20724395]\n",
      " [0.14895985]\n",
      " [0.01211813]\n",
      " [0.23366189]\n",
      " [0.28273684]\n",
      " [0.1439434 ]\n",
      " [0.10296154]\n",
      " [0.3340247 ]\n",
      " [0.13120693]\n",
      " [0.07533926]\n",
      " [0.19310638]\n",
      " [0.28305194]\n",
      " [0.10371506]\n",
      " [0.2707826 ]\n",
      " [0.18611011]\n",
      " [0.03334767]\n",
      " [0.14190638]\n",
      " [0.35227   ]\n",
      " [0.11535272]\n",
      " [0.04470843]\n",
      " [0.2571119 ]\n",
      " [0.07759482]\n",
      " [0.04028392]\n",
      " [0.1845111 ]\n",
      " [0.21635282]\n",
      " [0.11818165]\n",
      " [0.20678064]\n",
      " [0.07368347]\n",
      " [0.5139565 ]\n",
      " [0.16242182]\n",
      " [0.04684928]\n",
      " [0.11336324]\n",
      " [0.05065393]\n",
      " [0.11338058]\n",
      " [0.07696247]\n",
      " [0.21485582]\n",
      " [0.08941397]\n",
      " [0.05143964]\n",
      " [0.02971098]\n",
      " [0.27598286]\n",
      " [0.11959973]\n",
      " [0.03557765]\n",
      " [0.06995064]\n",
      " [0.05691478]\n",
      " [0.13544291]\n",
      " [0.21516138]\n",
      " [0.07367024]\n",
      " [0.03520074]\n",
      " [0.09049714]\n",
      " [0.11508933]\n",
      " [0.48978987]\n",
      " [0.17384157]\n",
      " [0.2552535 ]\n",
      " [0.11604837]\n",
      " [0.15564659]\n",
      " [0.13794103]\n",
      " [0.19253257]\n",
      " [0.10385773]\n",
      " [0.13847646]\n",
      " [0.07336912]\n",
      " [0.28780842]\n",
      " [0.13924402]\n",
      " [0.5375431 ]\n",
      " [0.06654668]\n",
      " [0.15280375]\n",
      " [0.23727411]\n",
      " [0.07760864]\n",
      " [0.05858189]\n",
      " [0.14774403]\n",
      " [0.01820531]\n",
      " [0.22512984]\n",
      " [0.09779698]\n",
      " [0.03199539]\n",
      " [0.2614572 ]\n",
      " [0.13030708]\n",
      " [0.05792946]\n",
      " [0.0664185 ]\n",
      " [0.01526716]\n",
      " [0.14330989]\n",
      " [0.127687  ]\n",
      " [0.03158572]\n",
      " [0.05306557]\n",
      " [0.10155571]\n",
      " [0.35587725]\n",
      " [0.15348586]\n",
      " [0.06177041]\n",
      " [0.13812   ]\n",
      " [0.24157065]\n",
      " [0.19447151]\n",
      " [0.08995059]\n",
      " [0.23200533]\n",
      " [0.14400092]\n",
      " [0.06978586]\n",
      " [0.09937736]\n",
      " [0.06262863]\n",
      " [0.07494009]\n",
      " [0.16000915]\n",
      " [0.08912796]\n",
      " [0.08110198]\n",
      " [0.2540902 ]\n",
      " [0.06273568]\n",
      " [0.08842403]\n",
      " [0.03562647]\n",
      " [0.05098778]\n",
      " [0.08713153]\n",
      " [0.1478323 ]\n",
      " [0.41654438]\n",
      " [0.2479501 ]\n",
      " [0.14071396]\n",
      " [0.26825333]\n",
      " [0.03867143]\n",
      " [0.35836458]\n",
      " [0.11318672]\n",
      " [0.2647996 ]\n",
      " [0.22622225]\n",
      " [0.16603342]\n",
      " [0.2671731 ]\n",
      " [0.0052788 ]\n",
      " [0.13507575]\n",
      " [0.00468203]\n",
      " [0.10248601]\n",
      " [0.0510681 ]\n",
      " [0.24116829]\n",
      " [0.4142703 ]\n",
      " [0.08827952]\n",
      " [0.05665928]\n",
      " [0.02779168]\n",
      " [0.00755161]\n",
      " [0.09969613]\n",
      " [0.11939278]\n",
      " [0.04559761]\n",
      " [0.06806284]\n",
      " [0.28793812]\n",
      " [0.27417433]\n",
      " [0.0139834 ]\n",
      " [0.13831732]\n",
      " [0.1580781 ]\n",
      " [0.05456281]\n",
      " [0.06538051]\n",
      " [0.1259113 ]\n",
      " [0.06340155]\n",
      " [0.01725289]\n",
      " [0.09735435]\n",
      " [0.18725613]\n",
      " [0.15673935]\n",
      " [0.18343127]\n",
      " [0.0255591 ]\n",
      " [0.16772038]\n",
      " [0.15726972]\n",
      " [0.13970292]\n",
      " [0.20929655]\n",
      " [0.12498954]\n",
      " [0.07522151]\n",
      " [0.01457563]\n",
      " [0.17281565]\n",
      " [0.05406478]\n",
      " [0.19555268]\n",
      " [0.18508834]\n",
      " [0.00229251]\n",
      " [0.00712469]\n",
      " [0.2577444 ]\n",
      " [0.1438739 ]\n",
      " [0.15814936]\n",
      " [0.12186617]\n",
      " [0.026434  ]\n",
      " [0.25563663]\n",
      " [0.06851986]\n",
      " [0.14319119]\n",
      " [0.03829354]\n",
      " [0.05332205]\n",
      " [0.59812534]\n",
      " [0.00326958]\n",
      " [0.08814177]\n",
      " [0.03433731]\n",
      " [0.18507048]\n",
      " [0.01092526]\n",
      " [0.07425255]\n",
      " [0.19406307]\n",
      " [0.03967914]\n",
      " [0.11468276]\n",
      " [0.09847608]\n",
      " [0.13140887]\n",
      " [0.55324304]\n",
      " [0.01086786]\n",
      " [0.08116171]\n",
      " [0.08751354]\n",
      " [0.11194611]\n",
      " [0.14439338]\n",
      " [0.16953945]\n",
      " [0.1725164 ]\n",
      " [0.36338124]\n",
      " [0.18806586]\n",
      " [0.03359535]\n",
      " [0.11895397]\n",
      " [0.05372408]\n",
      " [0.04250646]\n",
      " [0.2274136 ]\n",
      " [0.05015343]\n",
      " [0.2848636 ]\n",
      " [0.03036621]\n",
      " [0.25718188]\n",
      " [0.13452137]\n",
      " [0.01205033]\n",
      " [0.03271717]\n",
      " [0.06248185]\n",
      " [0.13467664]\n",
      " [0.05538651]\n",
      " [0.01755163]\n",
      " [0.0956167 ]\n",
      " [0.61238223]\n",
      " [0.5390974 ]\n",
      " [0.2172676 ]\n",
      " [0.21159637]\n",
      " [0.3941046 ]\n",
      " [0.17672443]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.12244897959183673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 5s 2ms/step - loss: 0.4981 - acc: 0.8495 - val_loss: 0.4732 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 196us/step - loss: 0.4116 - acc: 0.8587 - val_loss: 0.4273 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 196us/step - loss: 0.3948 - acc: 0.8587 - val_loss: 0.4088 - val_acc: 0.8433\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 168us/step - loss: 0.3844 - acc: 0.8649 - val_loss: 0.3879 - val_acc: 0.8433\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 146us/step - loss: 0.3691 - acc: 0.8666 - val_loss: 0.3853 - val_acc: 0.8433\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 139us/step - loss: 0.3622 - acc: 0.8712 - val_loss: 0.3871 - val_acc: 0.8533\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 140us/step - loss: 0.3746 - acc: 0.8624 - val_loss: 0.3495 - val_acc: 0.8600\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 150us/step - loss: 0.3642 - acc: 0.8658 - val_loss: 0.3727 - val_acc: 0.8550\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 135us/step - loss: 0.3540 - acc: 0.8712 - val_loss: 0.3441 - val_acc: 0.8633\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 136us/step - loss: 0.3461 - acc: 0.8704 - val_loss: 0.3423 - val_acc: 0.8683\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 159us/step - loss: 0.3383 - acc: 0.8766 - val_loss: 0.3323 - val_acc: 0.8683\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - ETA: 0s - loss: 0.3307 - acc: 0.878 - 0s 141us/step - loss: 0.3376 - acc: 0.8749 - val_loss: 0.3521 - val_acc: 0.8600\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 131us/step - loss: 0.3365 - acc: 0.8799 - val_loss: 0.3346 - val_acc: 0.8750\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 148us/step - loss: 0.3336 - acc: 0.8779 - val_loss: 0.3303 - val_acc: 0.8700\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 176us/step - loss: 0.3275 - acc: 0.8774 - val_loss: 0.3378 - val_acc: 0.8600\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 169us/step - loss: 0.3276 - acc: 0.8783 - val_loss: 0.3328 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "2399/2399 [==============================] - 0s 164us/step - loss: 0.3240 - acc: 0.8787 - val_loss: 0.3422 - val_acc: 0.8683\n",
      "y2_pred:  [[0.09472483]\n",
      " [0.02957433]\n",
      " [0.00604281]\n",
      " [0.079207  ]\n",
      " [0.11032677]\n",
      " [0.08240023]\n",
      " [0.05783215]\n",
      " [0.03921592]\n",
      " [0.22328264]\n",
      " [0.07499272]\n",
      " [0.02187887]\n",
      " [0.06585079]\n",
      " [0.0977641 ]\n",
      " [0.24356991]\n",
      " [0.07663244]\n",
      " [0.10583863]\n",
      " [0.02915484]\n",
      " [0.3944176 ]\n",
      " [0.13170788]\n",
      " [0.2941848 ]\n",
      " [0.18532145]\n",
      " [0.04180211]\n",
      " [0.2668125 ]\n",
      " [0.15634188]\n",
      " [0.17713141]\n",
      " [0.24861744]\n",
      " [0.08620098]\n",
      " [0.02060109]\n",
      " [0.08462387]\n",
      " [0.22831082]\n",
      " [0.04809389]\n",
      " [0.04826719]\n",
      " [0.2776545 ]\n",
      " [0.09653202]\n",
      " [0.04676086]\n",
      " [0.05832824]\n",
      " [0.06316924]\n",
      " [0.06435394]\n",
      " [0.21510091]\n",
      " [0.08794355]\n",
      " [0.04071143]\n",
      " [0.03940195]\n",
      " [0.1055117 ]\n",
      " [0.0494366 ]\n",
      " [0.12232023]\n",
      " [0.11763281]\n",
      " [0.11553776]\n",
      " [0.08548051]\n",
      " [0.09238002]\n",
      " [0.12981737]\n",
      " [0.06022722]\n",
      " [0.14380172]\n",
      " [0.02792406]\n",
      " [0.28288007]\n",
      " [0.05379975]\n",
      " [0.07247669]\n",
      " [0.03551286]\n",
      " [0.0587199 ]\n",
      " [0.60656124]\n",
      " [0.08514261]\n",
      " [0.23516476]\n",
      " [0.05607602]\n",
      " [0.03738105]\n",
      " [0.29825073]\n",
      " [0.119477  ]\n",
      " [0.0617148 ]\n",
      " [0.03902611]\n",
      " [0.1609132 ]\n",
      " [0.07445511]\n",
      " [0.08749217]\n",
      " [0.14741802]\n",
      " [0.16293547]\n",
      " [0.09175238]\n",
      " [0.21922314]\n",
      " [0.1247912 ]\n",
      " [0.07491118]\n",
      " [0.06345758]\n",
      " [0.11749622]\n",
      " [0.66776526]\n",
      " [0.2162826 ]\n",
      " [0.06746817]\n",
      " [0.28076595]\n",
      " [0.1120871 ]\n",
      " [0.13185215]\n",
      " [0.09385535]\n",
      " [0.03702563]\n",
      " [0.09362307]\n",
      " [0.31200045]\n",
      " [0.10523227]\n",
      " [0.2882195 ]\n",
      " [0.09661418]\n",
      " [0.15281025]\n",
      " [0.07565793]\n",
      " [0.07038379]\n",
      " [0.08603922]\n",
      " [0.05475453]\n",
      " [0.2129007 ]\n",
      " [0.06031522]\n",
      " [0.1090042 ]\n",
      " [0.06399477]\n",
      " [0.0954749 ]\n",
      " [0.12151825]\n",
      " [0.05880579]\n",
      " [0.35326546]\n",
      " [0.02919829]\n",
      " [0.12964466]\n",
      " [0.04662246]\n",
      " [0.05252776]\n",
      " [0.05151865]\n",
      " [0.11806983]\n",
      " [0.07787064]\n",
      " [0.02885768]\n",
      " [0.18800083]\n",
      " [0.33539844]\n",
      " [0.08318231]\n",
      " [0.26507658]\n",
      " [0.02069488]\n",
      " [0.03654233]\n",
      " [0.03905752]\n",
      " [0.01634157]\n",
      " [0.2991599 ]\n",
      " [0.25629407]\n",
      " [0.08907372]\n",
      " [0.05143988]\n",
      " [0.25679508]\n",
      " [0.04323983]\n",
      " [0.2091071 ]\n",
      " [0.05777928]\n",
      " [0.16664892]\n",
      " [0.05965751]\n",
      " [0.02934209]\n",
      " [0.33525112]\n",
      " [0.15764359]\n",
      " [0.05721521]\n",
      " [0.1855678 ]\n",
      " [0.03408688]\n",
      " [0.16276923]\n",
      " [0.41631198]\n",
      " [0.0824945 ]\n",
      " [0.22436392]\n",
      " [0.01846737]\n",
      " [0.05956003]\n",
      " [0.07155433]\n",
      " [0.22034925]\n",
      " [0.01030201]\n",
      " [0.13449055]\n",
      " [0.0636937 ]\n",
      " [0.06396878]\n",
      " [0.06984779]\n",
      " [0.02044907]\n",
      " [0.13718027]\n",
      " [0.0448631 ]\n",
      " [0.29759282]\n",
      " [0.1754748 ]\n",
      " [0.3436423 ]\n",
      " [0.04602528]\n",
      " [0.05394232]\n",
      " [0.08267346]\n",
      " [0.19318083]\n",
      " [0.08340636]\n",
      " [0.201172  ]\n",
      " [0.15060666]\n",
      " [0.1403068 ]\n",
      " [0.1043596 ]\n",
      " [0.5193894 ]\n",
      " [0.0276691 ]\n",
      " [0.34777927]\n",
      " [0.02924317]\n",
      " [0.17428654]\n",
      " [0.14759016]\n",
      " [0.0326933 ]\n",
      " [0.09480396]\n",
      " [0.09103179]\n",
      " [0.04865038]\n",
      " [0.02942026]\n",
      " [0.56641823]\n",
      " [0.0497486 ]\n",
      " [0.06670842]\n",
      " [0.03440386]\n",
      " [0.03795922]\n",
      " [0.0732713 ]\n",
      " [0.05479336]\n",
      " [0.11787012]\n",
      " [0.09203786]\n",
      " [0.06388053]\n",
      " [0.05818209]\n",
      " [0.08754545]\n",
      " [0.7338276 ]\n",
      " [0.5695684 ]\n",
      " [0.47516355]\n",
      " [0.22599348]\n",
      " [0.42011058]\n",
      " [0.17337722]\n",
      " [0.05595335]\n",
      " [0.1536395 ]\n",
      " [0.01739416]\n",
      " [0.15081862]\n",
      " [0.06801823]\n",
      " [0.09937721]\n",
      " [0.18132126]\n",
      " [0.18652737]\n",
      " [0.13341352]\n",
      " [0.13699657]\n",
      " [0.04252455]\n",
      " [0.03414699]\n",
      " [0.0818139 ]\n",
      " [0.07566765]\n",
      " [0.06944138]\n",
      " [0.07211035]\n",
      " [0.35695672]\n",
      " [0.22676748]\n",
      " [0.05494121]\n",
      " [0.08576542]\n",
      " [0.6742786 ]\n",
      " [0.00430834]\n",
      " [0.27767807]\n",
      " [0.20075035]\n",
      " [0.11254817]\n",
      " [0.3267846 ]\n",
      " [0.49003792]\n",
      " [0.06202769]\n",
      " [0.23039159]\n",
      " [0.04415339]\n",
      " [0.0456239 ]\n",
      " [0.07219365]\n",
      " [0.03072289]\n",
      " [0.04497686]\n",
      " [0.01272294]\n",
      " [0.03365153]\n",
      " [0.12446693]\n",
      " [0.07006857]\n",
      " [0.3733465 ]\n",
      " [0.03454226]\n",
      " [0.42859697]\n",
      " [0.2978757 ]\n",
      " [0.26684397]\n",
      " [0.11746836]\n",
      " [0.11095014]\n",
      " [0.25540906]\n",
      " [0.1555149 ]\n",
      " [0.05665007]\n",
      " [0.04818371]\n",
      " [0.09208938]\n",
      " [0.08532214]\n",
      " [0.06650648]\n",
      " [0.02226821]\n",
      " [0.37176442]\n",
      " [0.21915695]\n",
      " [0.05044171]\n",
      " [0.04584274]\n",
      " [0.21678802]\n",
      " [0.04877698]\n",
      " [0.08454236]\n",
      " [0.08006757]\n",
      " [0.86666477]\n",
      " [0.14586541]\n",
      " [0.14702356]\n",
      " [0.06141886]\n",
      " [0.1424546 ]\n",
      " [0.11256814]\n",
      " [0.0474053 ]\n",
      " [0.04981527]\n",
      " [0.31092715]\n",
      " [0.1134569 ]\n",
      " [0.076693  ]\n",
      " [0.04547465]\n",
      " [0.19047892]\n",
      " [0.10964364]\n",
      " [0.0791322 ]\n",
      " [0.4221528 ]\n",
      " [0.04550847]\n",
      " [0.17093232]\n",
      " [0.02052826]\n",
      " [0.11275405]\n",
      " [0.03734556]\n",
      " [0.13772759]\n",
      " [0.08481318]\n",
      " [0.13654086]\n",
      " [0.32411605]\n",
      " [0.19303751]\n",
      " [0.12850714]\n",
      " [0.075755  ]\n",
      " [0.11460266]\n",
      " [0.0837557 ]\n",
      " [0.04149532]\n",
      " [0.2126703 ]\n",
      " [0.04836509]\n",
      " [0.07727537]\n",
      " [0.20729524]\n",
      " [0.16534084]\n",
      " [0.05862877]\n",
      " [0.15385965]\n",
      " [0.14826971]\n",
      " [0.26527238]\n",
      " [0.03270042]\n",
      " [0.25587738]\n",
      " [0.04153129]\n",
      " [0.03575715]\n",
      " [0.1530723 ]\n",
      " [0.46279806]\n",
      " [0.0742217 ]\n",
      " [0.5257457 ]\n",
      " [0.02902734]\n",
      " [0.07498962]\n",
      " [0.12352926]\n",
      " [0.07316762]\n",
      " [0.09683332]\n",
      " [0.04464203]\n",
      " [0.03981853]\n",
      " [0.04581049]\n",
      " [0.02938792]\n",
      " [0.13051781]\n",
      " [0.01746589]\n",
      " [0.10248625]\n",
      " [0.17720726]\n",
      " [0.24456733]\n",
      " [0.1637305 ]\n",
      " [0.10064128]\n",
      " [0.27555436]\n",
      " [0.08563092]\n",
      " [0.04741073]\n",
      " [0.46377957]\n",
      " [0.10057864]\n",
      " [0.2193844 ]\n",
      " [0.02903411]\n",
      " [0.08028159]\n",
      " [0.31439587]\n",
      " [0.05187577]\n",
      " [0.12249674]\n",
      " [0.05433897]\n",
      " [0.05302283]\n",
      " [0.9447784 ]\n",
      " [0.05700629]\n",
      " [0.49975038]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.12244897959183673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 4s 2ms/step - loss: 0.4268 - acc: 0.8474 - val_loss: 0.4088 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 163us/step - loss: 0.4032 - acc: 0.8587 - val_loss: 0.4017 - val_acc: 0.8400\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 158us/step - loss: 0.3938 - acc: 0.8566 - val_loss: 0.3977 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 134us/step - loss: 0.3894 - acc: 0.8562 - val_loss: 0.4234 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 143us/step - loss: 0.3857 - acc: 0.8574 - val_loss: 0.3953 - val_acc: 0.8467\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 143us/step - loss: 0.3773 - acc: 0.8604 - val_loss: 0.3889 - val_acc: 0.8500\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 135us/step - loss: 0.3776 - acc: 0.8654 - val_loss: 0.3746 - val_acc: 0.8533\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 136us/step - loss: 0.3712 - acc: 0.8629 - val_loss: 0.3866 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 142us/step - loss: 0.3644 - acc: 0.8629 - val_loss: 0.3703 - val_acc: 0.8583\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 138us/step - loss: 0.3575 - acc: 0.8704 - val_loss: 0.3959 - val_acc: 0.8533\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 138us/step - loss: 0.3456 - acc: 0.8699 - val_loss: 0.3597 - val_acc: 0.8683\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 145us/step - loss: 0.3427 - acc: 0.8704 - val_loss: 0.3657 - val_acc: 0.8650\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 133us/step - loss: 0.3390 - acc: 0.8762 - val_loss: 0.3810 - val_acc: 0.8550\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 141us/step - loss: 0.3363 - acc: 0.8724 - val_loss: 0.3421 - val_acc: 0.8617\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 145us/step - loss: 0.3250 - acc: 0.8762 - val_loss: 0.3827 - val_acc: 0.8633\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 133us/step - loss: 0.3239 - acc: 0.8791 - val_loss: 0.3539 - val_acc: 0.8667\n",
      "Epoch 17/30\n",
      "2399/2399 [==============================] - 0s 136us/step - loss: 0.3161 - acc: 0.8795 - val_loss: 0.3625 - val_acc: 0.8550\n",
      "y2_pred:  [[0.02273703]\n",
      " [0.13871169]\n",
      " [0.05208752]\n",
      " [0.17180747]\n",
      " [0.16569254]\n",
      " [0.06065708]\n",
      " [0.19985512]\n",
      " [0.01142976]\n",
      " [0.19926828]\n",
      " [0.04837659]\n",
      " [0.13855717]\n",
      " [0.00917828]\n",
      " [0.1936003 ]\n",
      " [0.15534088]\n",
      " [0.28953683]\n",
      " [0.13963404]\n",
      " [0.16945738]\n",
      " [0.0332118 ]\n",
      " [0.17871967]\n",
      " [0.13210934]\n",
      " [0.06891096]\n",
      " [0.06912541]\n",
      " [0.10747516]\n",
      " [0.04059041]\n",
      " [0.08852914]\n",
      " [0.1982798 ]\n",
      " [0.13883054]\n",
      " [0.10995626]\n",
      " [0.11348346]\n",
      " [0.14721757]\n",
      " [0.8638049 ]\n",
      " [0.08018401]\n",
      " [0.11962652]\n",
      " [0.03571522]\n",
      " [0.09582686]\n",
      " [0.05772021]\n",
      " [0.02205476]\n",
      " [0.0307425 ]\n",
      " [0.15130234]\n",
      " [0.0644097 ]\n",
      " [0.14980745]\n",
      " [0.08947542]\n",
      " [0.3179245 ]\n",
      " [0.03837836]\n",
      " [0.13074097]\n",
      " [0.05854225]\n",
      " [0.05903873]\n",
      " [0.04944873]\n",
      " [0.22065389]\n",
      " [0.07875058]\n",
      " [0.06423008]\n",
      " [0.0841423 ]\n",
      " [0.2224769 ]\n",
      " [0.14127707]\n",
      " [0.09563729]\n",
      " [0.06517938]\n",
      " [0.17892781]\n",
      " [0.03599149]\n",
      " [0.12756479]\n",
      " [0.0448797 ]\n",
      " [0.03661957]\n",
      " [0.18439353]\n",
      " [0.10069242]\n",
      " [0.16943365]\n",
      " [0.05373308]\n",
      " [0.2588075 ]\n",
      " [0.06676349]\n",
      " [0.09695128]\n",
      " [0.02216581]\n",
      " [0.11903769]\n",
      " [0.13088936]\n",
      " [0.11986929]\n",
      " [0.03705004]\n",
      " [0.12533972]\n",
      " [0.4735079 ]\n",
      " [0.06901979]\n",
      " [0.14819151]\n",
      " [0.03173897]\n",
      " [0.1285496 ]\n",
      " [0.13973442]\n",
      " [0.32023144]\n",
      " [0.11290988]\n",
      " [0.04877535]\n",
      " [0.06928179]\n",
      " [0.16811845]\n",
      " [0.02971002]\n",
      " [0.09498698]\n",
      " [0.06228703]\n",
      " [0.01832652]\n",
      " [0.03564754]\n",
      " [0.12317285]\n",
      " [0.15663558]\n",
      " [0.13951448]\n",
      " [0.17543766]\n",
      " [0.0480746 ]\n",
      " [0.04950467]\n",
      " [0.068142  ]\n",
      " [0.0555881 ]\n",
      " [0.28145128]\n",
      " [0.09119532]\n",
      " [0.2249726 ]\n",
      " [0.27680197]\n",
      " [0.09150365]\n",
      " [0.52758634]\n",
      " [0.1139251 ]\n",
      " [0.18763375]\n",
      " [0.0663951 ]\n",
      " [0.12797064]\n",
      " [0.09365284]\n",
      " [0.10153735]\n",
      " [0.46585774]\n",
      " [0.31713378]\n",
      " [0.29449773]\n",
      " [0.02444002]\n",
      " [0.04345044]\n",
      " [0.18149942]\n",
      " [0.12803489]\n",
      " [0.16395262]\n",
      " [0.06618202]\n",
      " [0.25600243]\n",
      " [0.1479626 ]\n",
      " [0.11456791]\n",
      " [0.08977956]\n",
      " [0.0281516 ]\n",
      " [0.07183135]\n",
      " [0.0326122 ]\n",
      " [0.15096924]\n",
      " [0.14146376]\n",
      " [0.08022365]\n",
      " [0.03309792]\n",
      " [0.04935935]\n",
      " [0.05044195]\n",
      " [0.12332255]\n",
      " [0.36825   ]\n",
      " [0.05708775]\n",
      " [0.06043959]\n",
      " [0.3399927 ]\n",
      " [0.18713492]\n",
      " [0.01451713]\n",
      " [0.12661237]\n",
      " [0.06776738]\n",
      " [0.04535788]\n",
      " [0.24728817]\n",
      " [0.19240326]\n",
      " [0.03356472]\n",
      " [0.03455013]\n",
      " [0.06359214]\n",
      " [0.26040578]\n",
      " [0.18340537]\n",
      " [0.03441796]\n",
      " [0.10115135]\n",
      " [0.11342677]\n",
      " [0.02608424]\n",
      " [0.10764858]\n",
      " [0.11780566]\n",
      " [0.06656417]\n",
      " [0.01339468]\n",
      " [0.11565259]\n",
      " [0.02101612]\n",
      " [0.13829744]\n",
      " [0.22987083]\n",
      " [0.28777516]\n",
      " [0.39401016]\n",
      " [0.14621711]\n",
      " [0.38244513]\n",
      " [0.2719165 ]\n",
      " [0.20388553]\n",
      " [0.12147963]\n",
      " [0.13666761]\n",
      " [0.08958399]\n",
      " [0.03949013]\n",
      " [0.09241819]\n",
      " [0.07236946]\n",
      " [0.14796185]\n",
      " [0.26826555]\n",
      " [0.02078378]\n",
      " [0.11020389]\n",
      " [0.0848276 ]\n",
      " [0.10966051]\n",
      " [0.09805125]\n",
      " [0.17861897]\n",
      " [0.14215058]\n",
      " [0.06836677]\n",
      " [0.07825816]\n",
      " [0.15454966]\n",
      " [0.06158575]\n",
      " [0.03699136]\n",
      " [0.18987492]\n",
      " [0.02829251]\n",
      " [0.10012734]\n",
      " [0.05363849]\n",
      " [0.32114434]\n",
      " [0.0374648 ]\n",
      " [0.12296751]\n",
      " [0.1964485 ]\n",
      " [0.06357607]\n",
      " [0.01962724]\n",
      " [0.05824217]\n",
      " [0.08283249]\n",
      " [0.07088703]\n",
      " [0.22253293]\n",
      " [0.13579711]\n",
      " [0.0742701 ]\n",
      " [0.18925038]\n",
      " [0.2536413 ]\n",
      " [0.08702439]\n",
      " [0.04813433]\n",
      " [0.05976924]\n",
      " [0.04301783]\n",
      " [0.18697381]\n",
      " [0.23561168]\n",
      " [0.04824147]\n",
      " [0.01441053]\n",
      " [0.05147797]\n",
      " [0.1040282 ]\n",
      " [0.02113947]\n",
      " [0.06985149]\n",
      " [0.11067811]\n",
      " [0.0644387 ]\n",
      " [0.0488975 ]\n",
      " [0.06052178]\n",
      " [0.0729937 ]\n",
      " [0.04083204]\n",
      " [0.07857183]\n",
      " [0.094928  ]\n",
      " [0.14774522]\n",
      " [0.49556   ]\n",
      " [0.1899598 ]\n",
      " [0.04197031]\n",
      " [0.16662511]\n",
      " [0.07248613]\n",
      " [0.03759214]\n",
      " [0.0986253 ]\n",
      " [0.23189268]\n",
      " [0.571519  ]\n",
      " [0.04679066]\n",
      " [0.26531246]\n",
      " [0.03304669]\n",
      " [0.02579331]\n",
      " [0.0347414 ]\n",
      " [0.88074017]\n",
      " [0.05289742]\n",
      " [0.07746616]\n",
      " [0.02192077]\n",
      " [0.16304529]\n",
      " [0.05426577]\n",
      " [0.26443374]\n",
      " [0.09785032]\n",
      " [0.02740157]\n",
      " [0.10697463]\n",
      " [0.11327422]\n",
      " [0.03979975]\n",
      " [0.04421225]\n",
      " [0.03001365]\n",
      " [0.06578675]\n",
      " [0.09581238]\n",
      " [0.10677102]\n",
      " [0.08129418]\n",
      " [0.05187032]\n",
      " [0.04490924]\n",
      " [0.05502814]\n",
      " [0.2169564 ]\n",
      " [0.07586598]\n",
      " [0.03373343]\n",
      " [0.25921848]\n",
      " [0.12655947]\n",
      " [0.11443636]\n",
      " [0.20086765]\n",
      " [0.08576101]\n",
      " [0.23908785]\n",
      " [0.09138572]\n",
      " [0.04909387]\n",
      " [0.10637721]\n",
      " [0.0668599 ]\n",
      " [0.0773679 ]\n",
      " [0.10390383]\n",
      " [0.10120651]\n",
      " [0.10414362]\n",
      " [0.2791838 ]\n",
      " [0.11079678]\n",
      " [0.14449117]\n",
      " [0.26346588]\n",
      " [0.04012612]\n",
      " [0.09712207]\n",
      " [0.08781719]\n",
      " [0.02453154]\n",
      " [0.07236278]\n",
      " [0.09204051]\n",
      " [0.04919627]\n",
      " [0.03372523]\n",
      " [0.11431751]\n",
      " [0.05657849]\n",
      " [0.24403039]\n",
      " [0.26366025]\n",
      " [0.1454286 ]\n",
      " [0.07703018]\n",
      " [0.02660608]\n",
      " [0.09371382]\n",
      " [0.0879713 ]\n",
      " [0.04747751]\n",
      " [0.11377755]\n",
      " [0.10017005]\n",
      " [0.05012849]\n",
      " [0.07077196]\n",
      " [0.25503343]\n",
      " [0.05462512]\n",
      " [0.56836164]\n",
      " [0.29082078]\n",
      " [0.11519659]\n",
      " [0.34789497]\n",
      " [0.10399595]\n",
      " [0.06053492]\n",
      " [0.03454521]\n",
      " [0.05664417]\n",
      " [0.08015507]\n",
      " [0.1241408 ]\n",
      " [0.28847432]\n",
      " [0.10467508]\n",
      " [0.13575366]\n",
      " [0.09311035]\n",
      " [0.7105619 ]\n",
      " [0.14646843]\n",
      " [0.47082242]\n",
      " [0.11194372]\n",
      " [0.08275449]\n",
      " [0.05478868]\n",
      " [0.6677072 ]\n",
      " [0.10094717]\n",
      " [0.5792022 ]\n",
      " [0.03461964]\n",
      " [0.9090477 ]\n",
      " [0.3125155 ]\n",
      " [0.07587157]\n",
      " [0.16210242]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.10204081632653061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.4446 - acc: 0.8454 - val_loss: 0.4804 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 153us/step - loss: 0.4099 - acc: 0.8583 - val_loss: 0.4091 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 153us/step - loss: 0.4085 - acc: 0.8583 - val_loss: 0.4063 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3986 - acc: 0.8600 - val_loss: 0.4002 - val_acc: 0.8433\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3930 - acc: 0.8588 - val_loss: 0.3880 - val_acc: 0.8500\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3884 - acc: 0.8579 - val_loss: 0.3866 - val_acc: 0.8500\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3816 - acc: 0.8596 - val_loss: 0.3903 - val_acc: 0.8450\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 143us/step - loss: 0.3851 - acc: 0.8588 - val_loss: 0.3813 - val_acc: 0.8533\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 142us/step - loss: 0.3790 - acc: 0.8621 - val_loss: 0.3967 - val_acc: 0.8433\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 150us/step - loss: 0.3720 - acc: 0.8633 - val_loss: 0.3783 - val_acc: 0.8483\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3744 - acc: 0.8629 - val_loss: 0.3841 - val_acc: 0.8483\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 162us/step - loss: 0.3704 - acc: 0.8612 - val_loss: 0.3762 - val_acc: 0.8467\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 155us/step - loss: 0.3628 - acc: 0.8637 - val_loss: 0.3755 - val_acc: 0.8467\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 141us/step - loss: 0.3570 - acc: 0.8662 - val_loss: 0.3776 - val_acc: 0.8500\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 142us/step - loss: 0.3576 - acc: 0.8625 - val_loss: 0.3589 - val_acc: 0.8550\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 149us/step - loss: 0.3538 - acc: 0.8592 - val_loss: 0.3822 - val_acc: 0.8517\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 142us/step - loss: 0.3539 - acc: 0.8625 - val_loss: 0.3549 - val_acc: 0.8617\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 153us/step - loss: 0.3434 - acc: 0.8688 - val_loss: 0.3792 - val_acc: 0.8567\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 153us/step - loss: 0.3418 - acc: 0.8700 - val_loss: 0.3835 - val_acc: 0.8500\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 141us/step - loss: 0.3425 - acc: 0.8671 - val_loss: 0.3899 - val_acc: 0.8533\n",
      "y2_pred:  [[6.65384531e-03]\n",
      " [1.27649665e-01]\n",
      " [5.16749918e-02]\n",
      " [2.26038694e-03]\n",
      " [1.45180494e-01]\n",
      " [2.30480254e-01]\n",
      " [6.42928481e-03]\n",
      " [5.49422204e-02]\n",
      " [6.19156063e-02]\n",
      " [1.66440308e-02]\n",
      " [1.07537031e-01]\n",
      " [1.10073656e-01]\n",
      " [3.77173126e-02]\n",
      " [3.25870991e-01]\n",
      " [6.18365407e-02]\n",
      " [1.95967883e-01]\n",
      " [1.44320428e-02]\n",
      " [7.81449676e-03]\n",
      " [9.31471586e-03]\n",
      " [1.17022067e-01]\n",
      " [2.86048084e-01]\n",
      " [1.48093522e-01]\n",
      " [4.24688756e-02]\n",
      " [2.05851197e-02]\n",
      " [1.02460027e-01]\n",
      " [2.23236769e-01]\n",
      " [4.19161320e-02]\n",
      " [5.27418554e-02]\n",
      " [2.87905931e-02]\n",
      " [2.20187306e-02]\n",
      " [5.02044261e-02]\n",
      " [2.27661133e-02]\n",
      " [1.53446943e-01]\n",
      " [3.08827162e-02]\n",
      " [9.52363014e-03]\n",
      " [4.65097427e-02]\n",
      " [5.12326062e-02]\n",
      " [2.00244486e-02]\n",
      " [4.00602818e-03]\n",
      " [5.77766299e-02]\n",
      " [5.53309917e-04]\n",
      " [1.36010408e-01]\n",
      " [4.64644134e-02]\n",
      " [2.78037786e-02]\n",
      " [1.30822808e-01]\n",
      " [1.04035407e-01]\n",
      " [7.12150335e-03]\n",
      " [6.90060258e-02]\n",
      " [9.10217166e-02]\n",
      " [2.95840800e-02]\n",
      " [2.46030390e-02]\n",
      " [7.03975260e-02]\n",
      " [3.70443463e-02]\n",
      " [8.50322843e-03]\n",
      " [4.15036976e-02]\n",
      " [3.99760395e-01]\n",
      " [8.89703333e-02]\n",
      " [3.28344703e-02]\n",
      " [2.25258470e-02]\n",
      " [7.87187219e-02]\n",
      " [2.34977305e-02]\n",
      " [1.65570676e-02]\n",
      " [2.87005961e-01]\n",
      " [1.54305100e-02]\n",
      " [6.65275156e-02]\n",
      " [4.41063046e-02]\n",
      " [1.26958191e-01]\n",
      " [1.31373912e-01]\n",
      " [1.39807761e-02]\n",
      " [7.17896521e-02]\n",
      " [2.23523617e-01]\n",
      " [9.90584493e-02]\n",
      " [1.62973106e-02]\n",
      " [1.52871609e-02]\n",
      " [1.03441179e-02]\n",
      " [1.56898499e-02]\n",
      " [3.24063897e-02]\n",
      " [5.42849302e-03]\n",
      " [2.23002434e-02]\n",
      " [7.33232200e-02]\n",
      " [4.02328372e-02]\n",
      " [4.09031510e-02]\n",
      " [6.15581870e-02]\n",
      " [1.18369401e-01]\n",
      " [2.94045210e-02]\n",
      " [5.53219914e-02]\n",
      " [3.93478274e-02]\n",
      " [1.14309490e-02]\n",
      " [1.35023981e-01]\n",
      " [4.50910926e-02]\n",
      " [1.27287298e-01]\n",
      " [2.29594558e-01]\n",
      " [1.69067204e-01]\n",
      " [1.80300623e-01]\n",
      " [3.44521135e-01]\n",
      " [4.78429794e-02]\n",
      " [2.50236094e-02]\n",
      " [9.05236602e-03]\n",
      " [1.56100690e-01]\n",
      " [2.58657634e-02]\n",
      " [2.38873512e-01]\n",
      " [7.51611590e-02]\n",
      " [1.85433030e-02]\n",
      " [4.58887219e-03]\n",
      " [2.56385326e-01]\n",
      " [1.73278153e-02]\n",
      " [4.03754413e-02]\n",
      " [1.19843215e-01]\n",
      " [6.50789142e-02]\n",
      " [6.75696135e-03]\n",
      " [3.07526290e-02]\n",
      " [1.19661391e-02]\n",
      " [1.36000603e-01]\n",
      " [1.21865243e-01]\n",
      " [2.70577967e-02]\n",
      " [9.52222943e-02]\n",
      " [3.53946388e-02]\n",
      " [2.51923800e-02]\n",
      " [2.70758271e-02]\n",
      " [2.11161375e-03]\n",
      " [3.44475508e-02]\n",
      " [8.82712007e-03]\n",
      " [2.94360220e-02]\n",
      " [3.66842747e-02]\n",
      " [4.91996408e-02]\n",
      " [2.21251130e-01]\n",
      " [8.48163068e-02]\n",
      " [8.46228004e-03]\n",
      " [3.58701348e-02]\n",
      " [4.53191698e-02]\n",
      " [9.33632255e-03]\n",
      " [2.11159885e-02]\n",
      " [6.43241107e-02]\n",
      " [2.15229094e-02]\n",
      " [2.66621113e-02]\n",
      " [6.58538640e-02]\n",
      " [5.50356507e-03]\n",
      " [1.28414571e-01]\n",
      " [8.41947198e-02]\n",
      " [6.45786524e-03]\n",
      " [3.97926867e-02]\n",
      " [1.84403747e-01]\n",
      " [4.95668948e-02]\n",
      " [2.51435339e-02]\n",
      " [6.21998310e-03]\n",
      " [2.55544722e-01]\n",
      " [1.68811738e-01]\n",
      " [1.87825859e-02]\n",
      " [7.40522742e-02]\n",
      " [1.48690462e-01]\n",
      " [3.47135365e-02]\n",
      " [9.73007381e-02]\n",
      " [1.28026396e-01]\n",
      " [1.24979019e-02]\n",
      " [5.30908406e-02]\n",
      " [1.52997017e-01]\n",
      " [2.01603770e-02]\n",
      " [8.71652961e-02]\n",
      " [3.45728099e-02]\n",
      " [9.47707891e-03]\n",
      " [8.32364261e-02]\n",
      " [2.12103724e-02]\n",
      " [6.83397055e-03]\n",
      " [1.26089633e-01]\n",
      " [7.28858709e-02]\n",
      " [2.02507973e-02]\n",
      " [3.18370759e-02]\n",
      " [3.75116765e-02]\n",
      " [9.50793326e-02]\n",
      " [1.98011070e-01]\n",
      " [7.72735775e-02]\n",
      " [1.57629669e-01]\n",
      " [1.63936019e-02]\n",
      " [4.83316183e-03]\n",
      " [9.27050114e-02]\n",
      " [4.26599950e-01]\n",
      " [5.72848320e-03]\n",
      " [4.07888889e-02]\n",
      " [1.03405327e-01]\n",
      " [4.36313450e-02]\n",
      " [1.62874162e-02]\n",
      " [8.64254534e-02]\n",
      " [1.73111349e-01]\n",
      " [4.94887531e-02]\n",
      " [1.08102858e-02]\n",
      " [1.58727169e-03]\n",
      " [2.33024955e-02]\n",
      " [7.08761811e-03]\n",
      " [1.03733629e-01]\n",
      " [1.50611311e-01]\n",
      " [7.51471639e-01]\n",
      " [2.27651805e-01]\n",
      " [3.71152461e-02]\n",
      " [8.80247355e-02]\n",
      " [2.89128959e-01]\n",
      " [2.96706975e-01]\n",
      " [3.31456661e-02]\n",
      " [8.85409117e-03]\n",
      " [1.52736902e-02]\n",
      " [2.56106257e-02]\n",
      " [1.35712147e-01]\n",
      " [3.59818339e-03]\n",
      " [7.79970050e-01]\n",
      " [1.59021199e-01]\n",
      " [9.12025571e-03]\n",
      " [3.77272964e-02]\n",
      " [2.81261116e-01]\n",
      " [4.19053435e-03]\n",
      " [2.10723609e-01]\n",
      " [9.33591425e-02]\n",
      " [3.62515450e-02]\n",
      " [1.98000222e-01]\n",
      " [4.75610495e-02]\n",
      " [1.52545631e-01]\n",
      " [1.85648799e-01]\n",
      " [1.25891596e-01]\n",
      " [7.23755360e-02]\n",
      " [4.53113914e-02]\n",
      " [7.98953474e-02]\n",
      " [5.62297404e-02]\n",
      " [3.73100758e-01]\n",
      " [1.72933936e-02]\n",
      " [8.55827332e-03]\n",
      " [4.94440794e-02]\n",
      " [6.01660907e-02]\n",
      " [6.03702962e-02]\n",
      " [6.98387623e-03]\n",
      " [1.87684894e-02]\n",
      " [2.59135365e-02]\n",
      " [8.10552239e-02]\n",
      " [1.39078319e-01]\n",
      " [1.66713417e-01]\n",
      " [3.33594382e-02]\n",
      " [2.55672097e-01]\n",
      " [1.11433536e-01]\n",
      " [1.42463773e-01]\n",
      " [5.22368252e-02]\n",
      " [4.70969975e-02]\n",
      " [1.98926330e-02]\n",
      " [2.51907229e-01]\n",
      " [2.35977173e-01]\n",
      " [3.51893008e-02]\n",
      " [1.27108693e-02]\n",
      " [6.77610338e-02]\n",
      " [5.59355915e-01]\n",
      " [1.58157051e-02]\n",
      " [5.39338887e-02]\n",
      " [3.33136171e-01]\n",
      " [4.48453426e-02]\n",
      " [3.14077735e-02]\n",
      " [3.59806567e-01]\n",
      " [3.94176960e-01]\n",
      " [1.05005205e-02]\n",
      " [4.56562042e-02]\n",
      " [3.72100174e-02]\n",
      " [8.06515217e-02]\n",
      " [1.22158825e-01]\n",
      " [5.26762605e-02]\n",
      " [5.50119281e-02]\n",
      " [1.52681977e-01]\n",
      " [7.97710121e-02]\n",
      " [1.23369753e-01]\n",
      " [2.53569782e-02]\n",
      " [8.96328688e-03]\n",
      " [4.26328778e-02]\n",
      " [9.61074233e-03]\n",
      " [9.63427424e-02]\n",
      " [2.74372995e-02]\n",
      " [2.14700103e-02]\n",
      " [3.09585333e-02]\n",
      " [3.79513055e-01]\n",
      " [3.38526130e-01]\n",
      " [9.03755426e-02]\n",
      " [2.94604003e-02]\n",
      " [5.18105745e-01]\n",
      " [5.75146079e-03]\n",
      " [1.36905938e-01]\n",
      " [1.27003789e-02]\n",
      " [4.11429405e-02]\n",
      " [4.94053364e-02]\n",
      " [1.83939636e-01]\n",
      " [1.00431085e-01]\n",
      " [6.21935070e-01]\n",
      " [6.96832538e-02]\n",
      " [5.81112504e-03]\n",
      " [1.90838963e-01]\n",
      " [3.92870605e-01]\n",
      " [3.11410725e-02]\n",
      " [1.64967388e-01]\n",
      " [4.02191281e-03]\n",
      " [9.34543610e-02]\n",
      " [1.03649199e-02]\n",
      " [2.01019645e-02]\n",
      " [1.01512462e-01]\n",
      " [1.91838622e-01]\n",
      " [8.33889842e-03]\n",
      " [5.00428677e-03]\n",
      " [2.75706291e-01]\n",
      " [3.62141430e-01]\n",
      " [3.06815207e-02]\n",
      " [1.52738273e-01]\n",
      " [3.21694911e-02]\n",
      " [9.49910283e-03]\n",
      " [3.08125734e-01]\n",
      " [4.02915776e-02]\n",
      " [1.32726431e-02]\n",
      " [1.65760309e-01]\n",
      " [7.15276599e-02]\n",
      " [2.31521755e-01]\n",
      " [6.24915361e-02]\n",
      " [3.57560217e-02]\n",
      " [6.01278245e-02]\n",
      " [5.01474142e-02]\n",
      " [1.41317546e-02]\n",
      " [7.27030635e-03]\n",
      " [7.68316984e-02]\n",
      " [3.12061071e-01]\n",
      " [1.33884192e-01]\n",
      " [1.75314486e-01]\n",
      " [3.30925882e-02]\n",
      " [3.69906157e-01]\n",
      " [3.84320319e-02]\n",
      " [1.70382828e-01]\n",
      " [7.19878078e-03]\n",
      " [1.64360404e-02]\n",
      " [3.40629339e-01]\n",
      " [2.52565444e-02]\n",
      " [1.35482639e-01]\n",
      " [3.99182402e-02]\n",
      " [7.19672292e-02]\n",
      " [4.51011211e-02]\n",
      " [2.26893481e-02]\n",
      " [3.64539470e-03]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.08333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.4307 - acc: 0.8583 - val_loss: 0.4285 - val_acc: 0.8467\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 132us/step - loss: 0.3981 - acc: 0.8588 - val_loss: 0.4078 - val_acc: 0.8400\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 143us/step - loss: 0.3897 - acc: 0.8625 - val_loss: 0.4006 - val_acc: 0.8517\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3866 - acc: 0.8621 - val_loss: 0.3953 - val_acc: 0.8517\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 140us/step - loss: 0.3768 - acc: 0.8621 - val_loss: 0.3879 - val_acc: 0.8500\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 143us/step - loss: 0.3699 - acc: 0.8621 - val_loss: 0.3861 - val_acc: 0.8433\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3639 - acc: 0.8662 - val_loss: 0.3827 - val_acc: 0.8517\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 139us/step - loss: 0.3599 - acc: 0.8621 - val_loss: 0.3688 - val_acc: 0.8550\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 139us/step - loss: 0.3510 - acc: 0.8667 - val_loss: 0.3830 - val_acc: 0.8617\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3472 - acc: 0.8658 - val_loss: 0.3720 - val_acc: 0.8500\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 141us/step - loss: 0.3405 - acc: 0.8696 - val_loss: 0.3677 - val_acc: 0.8633\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 136us/step - loss: 0.3381 - acc: 0.8679 - val_loss: 0.3709 - val_acc: 0.8600\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3281 - acc: 0.8708 - val_loss: 0.3594 - val_acc: 0.8617\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 144us/step - loss: 0.3214 - acc: 0.8696 - val_loss: 0.3620 - val_acc: 0.8617\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 143us/step - loss: 0.3181 - acc: 0.8721 - val_loss: 0.3545 - val_acc: 0.8717\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3196 - acc: 0.8738 - val_loss: 0.3493 - val_acc: 0.8683\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 145us/step - loss: 0.3178 - acc: 0.8758 - val_loss: 0.3541 - val_acc: 0.8567\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 140us/step - loss: 0.3065 - acc: 0.8738 - val_loss: 0.3600 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 139us/step - loss: 0.2971 - acc: 0.8792 - val_loss: 0.3621 - val_acc: 0.8667\n",
      "y2_pred:  [[7.07235634e-02]\n",
      " [2.62479067e-01]\n",
      " [1.11848235e-01]\n",
      " [2.56384611e-02]\n",
      " [3.86271179e-02]\n",
      " [4.29137945e-02]\n",
      " [4.85948026e-02]\n",
      " [7.30161667e-02]\n",
      " [4.48121250e-01]\n",
      " [7.08550215e-04]\n",
      " [1.13084376e-01]\n",
      " [2.20565945e-01]\n",
      " [8.26186538e-02]\n",
      " [1.52730942e-03]\n",
      " [1.00060403e-02]\n",
      " [3.75769734e-02]\n",
      " [1.13277733e-02]\n",
      " [3.41642797e-02]\n",
      " [4.49977815e-02]\n",
      " [2.13380486e-01]\n",
      " [4.23990488e-02]\n",
      " [7.22321868e-03]\n",
      " [8.75288546e-02]\n",
      " [1.22907937e-01]\n",
      " [2.54536271e-02]\n",
      " [1.39767826e-02]\n",
      " [1.21670961e-03]\n",
      " [1.71077073e-01]\n",
      " [6.07199967e-02]\n",
      " [5.91268837e-02]\n",
      " [6.36059046e-03]\n",
      " [9.75137949e-03]\n",
      " [3.26402098e-01]\n",
      " [2.78337181e-01]\n",
      " [3.40133607e-02]\n",
      " [4.76470292e-02]\n",
      " [1.68124765e-01]\n",
      " [2.27159262e-02]\n",
      " [2.52423286e-02]\n",
      " [2.18048990e-02]\n",
      " [1.36501402e-01]\n",
      " [2.64383852e-02]\n",
      " [9.47269201e-02]\n",
      " [1.78029656e-01]\n",
      " [1.51378840e-01]\n",
      " [6.09576404e-02]\n",
      " [6.59208179e-01]\n",
      " [5.61078489e-02]\n",
      " [6.55261576e-02]\n",
      " [9.51895416e-02]\n",
      " [2.15957642e-01]\n",
      " [1.61999166e-02]\n",
      " [1.98607832e-01]\n",
      " [9.28854942e-02]\n",
      " [2.94434428e-02]\n",
      " [8.54489207e-03]\n",
      " [2.67550945e-02]\n",
      " [1.51222944e-02]\n",
      " [8.53744745e-02]\n",
      " [1.01025403e-02]\n",
      " [2.16271758e-01]\n",
      " [8.27819705e-02]\n",
      " [1.11037433e-01]\n",
      " [1.11202896e-02]\n",
      " [8.05183947e-02]\n",
      " [5.80102921e-01]\n",
      " [1.38187110e-02]\n",
      " [5.57863712e-03]\n",
      " [3.93342972e-03]\n",
      " [3.42131495e-01]\n",
      " [6.53385222e-02]\n",
      " [1.25360489e-02]\n",
      " [2.14903325e-01]\n",
      " [3.91469955e-01]\n",
      " [1.47560298e-01]\n",
      " [4.02662456e-02]\n",
      " [2.09998965e-01]\n",
      " [4.84013468e-01]\n",
      " [2.91227698e-02]\n",
      " [1.79309547e-01]\n",
      " [4.59761024e-01]\n",
      " [3.95616591e-02]\n",
      " [2.66781867e-01]\n",
      " [6.08950555e-02]\n",
      " [6.13355637e-03]\n",
      " [2.37659514e-02]\n",
      " [1.38789624e-01]\n",
      " [3.49047780e-03]\n",
      " [2.21978426e-02]\n",
      " [6.66802227e-02]\n",
      " [1.94383860e-02]\n",
      " [2.70028412e-02]\n",
      " [3.90883088e-02]\n",
      " [1.11206025e-01]\n",
      " [2.92096853e-01]\n",
      " [7.75866807e-02]\n",
      " [2.71708965e-02]\n",
      " [3.30061316e-02]\n",
      " [2.92942733e-01]\n",
      " [4.67521846e-02]\n",
      " [2.96416283e-02]\n",
      " [2.48534083e-02]\n",
      " [2.30579615e-01]\n",
      " [3.87449861e-02]\n",
      " [3.94340038e-01]\n",
      " [2.37999380e-01]\n",
      " [1.92889571e-02]\n",
      " [2.93937027e-02]\n",
      " [6.90773726e-02]\n",
      " [4.04357612e-02]\n",
      " [2.57408082e-01]\n",
      " [7.73128867e-03]\n",
      " [2.83058286e-01]\n",
      " [2.77468264e-02]\n",
      " [5.00363410e-02]\n",
      " [1.74126327e-02]\n",
      " [9.19544697e-03]\n",
      " [1.61190331e-02]\n",
      " [2.19204336e-01]\n",
      " [4.95624542e-03]\n",
      " [5.46440363e-01]\n",
      " [1.12789869e-01]\n",
      " [2.39234567e-02]\n",
      " [4.14377868e-01]\n",
      " [7.10221827e-02]\n",
      " [6.96166158e-02]\n",
      " [1.64965689e-02]\n",
      " [2.83004045e-02]\n",
      " [2.20553249e-01]\n",
      " [2.69045532e-02]\n",
      " [1.42990947e-02]\n",
      " [6.35001063e-03]\n",
      " [1.52872801e-02]\n",
      " [4.41048145e-02]\n",
      " [1.80193901e-01]\n",
      " [1.57196462e-01]\n",
      " [4.05708402e-01]\n",
      " [1.66996419e-02]\n",
      " [6.90157712e-02]\n",
      " [5.78947067e-02]\n",
      " [1.08994246e-02]\n",
      " [2.18988955e-02]\n",
      " [2.09782839e-01]\n",
      " [4.65241075e-03]\n",
      " [1.75234556e-01]\n",
      " [6.15856051e-01]\n",
      " [1.68992907e-01]\n",
      " [7.00819790e-01]\n",
      " [2.63420045e-02]\n",
      " [8.61546397e-02]\n",
      " [2.25680262e-01]\n",
      " [4.60804999e-02]\n",
      " [1.15791708e-01]\n",
      " [2.86279023e-02]\n",
      " [7.85840750e-02]\n",
      " [5.09897649e-01]\n",
      " [1.63258761e-01]\n",
      " [1.63874924e-02]\n",
      " [2.51743197e-03]\n",
      " [8.70047808e-02]\n",
      " [6.49361014e-02]\n",
      " [2.23627418e-01]\n",
      " [9.83063281e-02]\n",
      " [3.41382921e-01]\n",
      " [4.53327596e-02]\n",
      " [6.16845191e-02]\n",
      " [6.14593327e-02]\n",
      " [4.27730978e-02]\n",
      " [8.62465501e-02]\n",
      " [2.58671224e-01]\n",
      " [7.65772462e-02]\n",
      " [2.50993937e-01]\n",
      " [9.46874857e-01]\n",
      " [3.97960842e-02]\n",
      " [9.14684832e-02]\n",
      " [1.72751188e-01]\n",
      " [1.65802747e-01]\n",
      " [3.08870971e-02]\n",
      " [1.84754908e-01]\n",
      " [3.58549058e-02]\n",
      " [5.41139901e-01]\n",
      " [3.04995298e-01]\n",
      " [1.99262977e-01]\n",
      " [2.76407838e-01]\n",
      " [2.56340504e-02]\n",
      " [2.96939015e-02]\n",
      " [8.17220807e-02]\n",
      " [1.69435740e-02]\n",
      " [8.75796378e-02]\n",
      " [1.85598433e-02]\n",
      " [7.95504749e-02]\n",
      " [6.85251355e-02]\n",
      " [3.31720412e-02]\n",
      " [1.09428108e-01]\n",
      " [2.80254394e-01]\n",
      " [1.05355680e-02]\n",
      " [6.61730468e-02]\n",
      " [8.88133049e-02]\n",
      " [1.13738447e-01]\n",
      " [2.39919543e-01]\n",
      " [2.10880041e-02]\n",
      " [1.27955675e-02]\n",
      " [2.59682536e-01]\n",
      " [9.99538660e-01]\n",
      " [4.04868186e-01]\n",
      " [1.76983565e-01]\n",
      " [3.10232222e-01]\n",
      " [1.76245242e-01]\n",
      " [4.38778102e-02]\n",
      " [1.38260782e-01]\n",
      " [8.37644041e-02]\n",
      " [1.11873180e-01]\n",
      " [9.07719433e-02]\n",
      " [5.72981954e-01]\n",
      " [2.77457595e-01]\n",
      " [1.67901993e-01]\n",
      " [3.07458639e-02]\n",
      " [1.07102662e-01]\n",
      " [4.74530756e-02]\n",
      " [2.98389792e-03]\n",
      " [3.03405523e-02]\n",
      " [9.63041782e-02]\n",
      " [2.76152492e-02]\n",
      " [4.25556302e-03]\n",
      " [4.31595415e-01]\n",
      " [1.10966682e-01]\n",
      " [7.03121424e-02]\n",
      " [1.23965204e-01]\n",
      " [1.45338774e-02]\n",
      " [3.93033326e-02]\n",
      " [7.09596276e-03]\n",
      " [3.67105007e-04]\n",
      " [1.57169908e-01]\n",
      " [7.09277391e-02]\n",
      " [1.82120204e-02]\n",
      " [1.96410388e-01]\n",
      " [2.74151444e-01]\n",
      " [1.09453797e-02]\n",
      " [2.98797488e-02]\n",
      " [7.44385421e-02]\n",
      " [2.15384662e-02]\n",
      " [5.80605865e-02]\n",
      " [3.49152386e-02]\n",
      " [3.50284874e-02]\n",
      " [1.07228726e-01]\n",
      " [1.31901324e-01]\n",
      " [2.54869461e-04]\n",
      " [6.60768151e-03]\n",
      " [2.90208459e-02]\n",
      " [1.86581016e-02]\n",
      " [2.55211294e-02]\n",
      " [1.03909671e-02]\n",
      " [8.09938908e-02]\n",
      " [9.43756700e-02]\n",
      " [1.26962364e-02]\n",
      " [6.07233346e-02]\n",
      " [1.12235069e-01]\n",
      " [7.19099343e-02]\n",
      " [4.55884099e-01]\n",
      " [4.91542727e-01]\n",
      " [1.29581302e-01]\n",
      " [3.17839503e-01]\n",
      " [4.41060662e-02]\n",
      " [7.37011135e-02]\n",
      " [7.66960979e-02]\n",
      " [1.16344094e-02]\n",
      " [2.42637664e-01]\n",
      " [1.77450359e-01]\n",
      " [2.07776129e-02]\n",
      " [1.94453001e-01]\n",
      " [6.05270267e-02]\n",
      " [3.66319418e-02]\n",
      " [3.58353853e-02]\n",
      " [1.80527270e-02]\n",
      " [5.94996214e-02]\n",
      " [1.82238698e-01]\n",
      " [1.23758614e-02]\n",
      " [9.95963216e-02]\n",
      " [3.63316953e-01]\n",
      " [7.20676184e-02]\n",
      " [1.90580487e-02]\n",
      " [6.19310141e-02]\n",
      " [4.09875214e-02]\n",
      " [1.50002837e-02]\n",
      " [5.45527458e-01]\n",
      " [7.25060403e-02]\n",
      " [6.33382499e-02]\n",
      " [4.97808158e-02]\n",
      " [4.36210930e-02]\n",
      " [2.37697929e-01]\n",
      " [1.31649673e-02]\n",
      " [2.54090577e-01]\n",
      " [1.14314914e-01]\n",
      " [4.87512648e-02]\n",
      " [3.95441353e-02]\n",
      " [3.48767102e-01]\n",
      " [6.73381269e-01]\n",
      " [7.57732570e-01]\n",
      " [6.33388460e-02]\n",
      " [1.55116379e-01]\n",
      " [9.39413309e-01]\n",
      " [5.18900692e-01]\n",
      " [8.10045481e-01]\n",
      " [4.11802649e-01]\n",
      " [4.37413037e-01]\n",
      " [9.98587191e-01]\n",
      " [5.94118953e-01]\n",
      " [3.52364719e-01]\n",
      " [3.72650623e-01]\n",
      " [9.12469685e-01]\n",
      " [9.28513646e-01]\n",
      " [1.40751004e-01]\n",
      " [2.23663509e-01]\n",
      " [6.53336287e-01]\n",
      " [3.37846220e-01]\n",
      " [6.76225424e-02]\n",
      " [7.24861324e-02]\n",
      " [3.06638777e-02]\n",
      " [2.12693036e-01]\n",
      " [3.71853799e-01]\n",
      " [1.64451122e-01]\n",
      " [9.61850286e-02]\n",
      " [3.18621039e-01]\n",
      " [1.77414268e-01]\n",
      " [6.61782980e-01]\n",
      " [7.90627003e-02]\n",
      " [2.44003892e-01]\n",
      " [4.62423384e-01]\n",
      " [1.79714993e-01]\n",
      " [8.69443640e-02]\n",
      " [3.43964845e-01]\n",
      " [1.32094268e-02]\n",
      " [6.40813947e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.2916666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.4643 - acc: 0.8483 - val_loss: 0.4346 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 159us/step - loss: 0.4160 - acc: 0.8583 - val_loss: 0.4524 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.4064 - acc: 0.8583 - val_loss: 0.4256 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.4046 - acc: 0.8583 - val_loss: 0.4052 - val_acc: 0.8433\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 155us/step - loss: 0.4029 - acc: 0.8563 - val_loss: 0.4000 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 149us/step - loss: 0.3869 - acc: 0.8588 - val_loss: 0.4222 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3857 - acc: 0.8592 - val_loss: 0.3886 - val_acc: 0.8500\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 156us/step - loss: 0.3764 - acc: 0.8625 - val_loss: 0.3880 - val_acc: 0.8483\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3789 - acc: 0.8617 - val_loss: 0.3716 - val_acc: 0.8583\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 150us/step - loss: 0.3594 - acc: 0.8662 - val_loss: 0.3860 - val_acc: 0.8550\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 157us/step - loss: 0.3611 - acc: 0.8642 - val_loss: 0.3519 - val_acc: 0.8517\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 147us/step - loss: 0.3570 - acc: 0.8692 - val_loss: 0.3565 - val_acc: 0.8550\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 150us/step - loss: 0.3490 - acc: 0.8688 - val_loss: 0.3659 - val_acc: 0.8567\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 153us/step - loss: 0.3463 - acc: 0.8704 - val_loss: 0.3567 - val_acc: 0.8517\n",
      "y2_pred:  [[0.20551258]\n",
      " [0.03461304]\n",
      " [0.07531422]\n",
      " [0.04824626]\n",
      " [0.09430298]\n",
      " [0.07106429]\n",
      " [0.29225183]\n",
      " [0.114548  ]\n",
      " [0.13831532]\n",
      " [0.38174886]\n",
      " [0.04919025]\n",
      " [0.09996077]\n",
      " [0.0312888 ]\n",
      " [0.01310879]\n",
      " [0.05667162]\n",
      " [0.03247297]\n",
      " [0.04850063]\n",
      " [0.08515081]\n",
      " [0.16973132]\n",
      " [0.13916805]\n",
      " [0.08638245]\n",
      " [0.05138153]\n",
      " [0.03918448]\n",
      " [0.05230507]\n",
      " [0.04958987]\n",
      " [0.18693995]\n",
      " [0.01731274]\n",
      " [0.02466294]\n",
      " [0.10582206]\n",
      " [0.03387368]\n",
      " [0.03882188]\n",
      " [0.06987381]\n",
      " [0.08315673]\n",
      " [0.08596042]\n",
      " [0.07312486]\n",
      " [0.05380666]\n",
      " [0.06044015]\n",
      " [0.49528107]\n",
      " [0.02656126]\n",
      " [0.06526804]\n",
      " [0.06468779]\n",
      " [0.04171219]\n",
      " [0.09534109]\n",
      " [0.02610648]\n",
      " [0.01780915]\n",
      " [0.0892379 ]\n",
      " [0.17087942]\n",
      " [0.30379328]\n",
      " [0.01225752]\n",
      " [0.4391518 ]\n",
      " [0.34951067]\n",
      " [0.03465599]\n",
      " [0.0471769 ]\n",
      " [0.14625368]\n",
      " [0.03494558]\n",
      " [0.13419864]\n",
      " [0.08765683]\n",
      " [0.14335933]\n",
      " [0.33146018]\n",
      " [0.08333659]\n",
      " [0.03478289]\n",
      " [0.03582296]\n",
      " [0.45875832]\n",
      " [0.08624431]\n",
      " [0.20801383]\n",
      " [0.05086011]\n",
      " [0.06742978]\n",
      " [0.41455495]\n",
      " [0.22941399]\n",
      " [0.04202896]\n",
      " [0.09520343]\n",
      " [0.08103257]\n",
      " [0.05026281]\n",
      " [0.22401166]\n",
      " [0.07949236]\n",
      " [0.11045271]\n",
      " [0.03993595]\n",
      " [0.04485711]\n",
      " [0.0911257 ]\n",
      " [0.03592148]\n",
      " [0.10684323]\n",
      " [0.47777966]\n",
      " [0.19683346]\n",
      " [0.05666646]\n",
      " [0.0333499 ]\n",
      " [0.0299325 ]\n",
      " [0.0405165 ]\n",
      " [0.04719874]\n",
      " [0.03755158]\n",
      " [0.02727154]\n",
      " [0.11797497]\n",
      " [0.2413944 ]\n",
      " [0.2381565 ]\n",
      " [0.25970075]\n",
      " [0.10876355]\n",
      " [0.34419   ]\n",
      " [0.1076982 ]\n",
      " [0.04350647]\n",
      " [0.12656945]\n",
      " [0.03515071]\n",
      " [0.05064124]\n",
      " [0.21294394]\n",
      " [0.10498866]\n",
      " [0.19691092]\n",
      " [0.04231092]\n",
      " [0.07540858]\n",
      " [0.05658752]\n",
      " [0.1496506 ]\n",
      " [0.09837168]\n",
      " [0.04265663]\n",
      " [0.12051785]\n",
      " [0.04170504]\n",
      " [0.20915416]\n",
      " [0.048994  ]\n",
      " [0.06893894]\n",
      " [0.0520615 ]\n",
      " [0.08016291]\n",
      " [0.33536547]\n",
      " [0.06986862]\n",
      " [0.02798954]\n",
      " [0.04745054]\n",
      " [0.10242569]\n",
      " [0.04157478]\n",
      " [0.07404745]\n",
      " [0.15884852]\n",
      " [0.05544934]\n",
      " [0.06136355]\n",
      " [0.03023434]\n",
      " [0.17515367]\n",
      " [0.03729826]\n",
      " [0.11508805]\n",
      " [0.06236315]\n",
      " [0.0805575 ]\n",
      " [0.03252649]\n",
      " [0.04890293]\n",
      " [0.03384373]\n",
      " [0.03802606]\n",
      " [0.02189463]\n",
      " [0.1468297 ]\n",
      " [0.21925223]\n",
      " [0.28080153]\n",
      " [0.05684695]\n",
      " [0.38768378]\n",
      " [0.05625838]\n",
      " [0.05008379]\n",
      " [0.13118541]\n",
      " [0.33750355]\n",
      " [0.19513848]\n",
      " [0.03512314]\n",
      " [0.10251683]\n",
      " [0.14369977]\n",
      " [0.25931507]\n",
      " [0.1812042 ]\n",
      " [0.2010231 ]\n",
      " [0.02966434]\n",
      " [0.17522511]\n",
      " [0.06435242]\n",
      " [0.04090273]\n",
      " [0.06284964]\n",
      " [0.09129733]\n",
      " [0.08286601]\n",
      " [0.14176542]\n",
      " [0.02861688]\n",
      " [0.04451349]\n",
      " [0.14128122]\n",
      " [0.08604211]\n",
      " [0.06290942]\n",
      " [0.06222117]\n",
      " [0.02282193]\n",
      " [0.23124737]\n",
      " [0.6455677 ]\n",
      " [0.03737316]\n",
      " [0.09539604]\n",
      " [0.02588332]\n",
      " [0.03711584]\n",
      " [0.15238115]\n",
      " [0.04342154]\n",
      " [0.22560677]\n",
      " [0.12957796]\n",
      " [0.09569317]\n",
      " [0.09821036]\n",
      " [0.07335669]\n",
      " [0.08323136]\n",
      " [0.05246016]\n",
      " [0.04612926]\n",
      " [0.03339267]\n",
      " [0.29856503]\n",
      " [0.50815094]\n",
      " [0.03430018]\n",
      " [0.10464725]\n",
      " [0.08561695]\n",
      " [0.07834947]\n",
      " [0.1153875 ]\n",
      " [0.12170619]\n",
      " [0.3103665 ]\n",
      " [0.1337899 ]\n",
      " [0.15311503]\n",
      " [0.91663957]\n",
      " [0.05840537]\n",
      " [0.05117965]\n",
      " [0.08743599]\n",
      " [0.05675182]\n",
      " [0.2839206 ]\n",
      " [0.19518203]\n",
      " [0.17447951]\n",
      " [0.04264417]\n",
      " [0.05952209]\n",
      " [0.06916693]\n",
      " [0.08441985]\n",
      " [0.26914468]\n",
      " [0.52522576]\n",
      " [0.05247167]\n",
      " [0.12667209]\n",
      " [0.5061904 ]\n",
      " [0.03247488]\n",
      " [0.04068226]\n",
      " [0.04437011]\n",
      " [0.16545603]\n",
      " [0.04743823]\n",
      " [0.03045639]\n",
      " [0.10307044]\n",
      " [0.03782305]\n",
      " [0.37344578]\n",
      " [0.07850385]\n",
      " [0.06506026]\n",
      " [0.24801856]\n",
      " [0.24748921]\n",
      " [0.04050902]\n",
      " [0.02656591]\n",
      " [0.06002495]\n",
      " [0.12895948]\n",
      " [0.02211466]\n",
      " [0.08858117]\n",
      " [0.11962095]\n",
      " [0.07210028]\n",
      " [0.06496766]\n",
      " [0.68472224]\n",
      " [0.14572695]\n",
      " [0.0293892 ]\n",
      " [0.10666886]\n",
      " [0.08966169]\n",
      " [0.0602057 ]\n",
      " [0.04703119]\n",
      " [0.08395037]\n",
      " [0.9470149 ]\n",
      " [0.15584666]\n",
      " [0.3611129 ]\n",
      " [0.02370858]\n",
      " [0.07783902]\n",
      " [0.06955588]\n",
      " [0.04498518]\n",
      " [0.91663086]\n",
      " [0.14496836]\n",
      " [0.10359174]\n",
      " [0.13070723]\n",
      " [0.05842054]\n",
      " [0.01317599]\n",
      " [0.07337868]\n",
      " [0.11579779]\n",
      " [0.37214744]\n",
      " [0.04969889]\n",
      " [0.02565464]\n",
      " [0.06029519]\n",
      " [0.43378016]\n",
      " [0.07805452]\n",
      " [0.24340546]\n",
      " [0.5287608 ]\n",
      " [0.09757423]\n",
      " [0.3086186 ]\n",
      " [0.03327322]\n",
      " [0.03224576]\n",
      " [0.02773157]\n",
      " [0.02705401]\n",
      " [0.03210208]\n",
      " [0.09754416]\n",
      " [0.04166305]\n",
      " [0.02960971]\n",
      " [0.13253483]\n",
      " [0.19191727]\n",
      " [0.19107664]\n",
      " [0.0296447 ]\n",
      " [0.03908831]\n",
      " [0.41286558]\n",
      " [0.0942007 ]\n",
      " [0.07111987]\n",
      " [0.03967294]\n",
      " [0.24753013]\n",
      " [0.19589147]\n",
      " [0.10664794]\n",
      " [0.11772117]\n",
      " [0.5660577 ]\n",
      " [0.10719267]\n",
      " [0.05860728]\n",
      " [0.10863712]\n",
      " [0.11407515]\n",
      " [0.03722349]\n",
      " [0.09593016]\n",
      " [0.13278669]\n",
      " [0.07094559]\n",
      " [0.05752572]\n",
      " [0.10068253]\n",
      " [0.04719061]\n",
      " [0.8012967 ]\n",
      " [0.02873591]\n",
      " [0.19716543]\n",
      " [0.02867407]\n",
      " [0.46530002]\n",
      " [0.11678651]\n",
      " [0.10945103]\n",
      " [0.14908567]\n",
      " [0.27936727]\n",
      " [0.4037853 ]\n",
      " [0.21443608]\n",
      " [0.1625449 ]\n",
      " [0.12483886]\n",
      " [0.24863335]\n",
      " [0.03832281]\n",
      " [0.08634242]\n",
      " [0.08281434]\n",
      " [0.34465623]\n",
      " [0.28949952]\n",
      " [0.18087876]\n",
      " [0.22810856]\n",
      " [0.285308  ]\n",
      " [0.05581701]\n",
      " [0.08244985]\n",
      " [0.56110317]\n",
      " [0.28150487]\n",
      " [0.1160632 ]\n",
      " [0.05787548]\n",
      " [0.27072564]\n",
      " [0.0984083 ]\n",
      " [0.10032333]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.16666666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.4369 - acc: 0.8467 - val_loss: 0.4246 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 157us/step - loss: 0.4054 - acc: 0.8583 - val_loss: 0.4119 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3970 - acc: 0.8583 - val_loss: 0.4123 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3949 - acc: 0.8583 - val_loss: 0.4089 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 155us/step - loss: 0.3947 - acc: 0.8579 - val_loss: 0.4045 - val_acc: 0.8450\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 147us/step - loss: 0.3831 - acc: 0.8592 - val_loss: 0.3921 - val_acc: 0.8483\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 149us/step - loss: 0.3774 - acc: 0.8608 - val_loss: 0.3894 - val_acc: 0.8500\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 155us/step - loss: 0.3691 - acc: 0.8646 - val_loss: 0.3851 - val_acc: 0.8517\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3640 - acc: 0.8588 - val_loss: 0.3749 - val_acc: 0.8550\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 149us/step - loss: 0.3620 - acc: 0.8662 - val_loss: 0.3720 - val_acc: 0.8500\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 156us/step - loss: 0.3416 - acc: 0.8729 - val_loss: 0.3736 - val_acc: 0.8667\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 147us/step - loss: 0.3473 - acc: 0.8717 - val_loss: 0.3539 - val_acc: 0.8533\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 149us/step - loss: 0.3309 - acc: 0.8825 - val_loss: 0.3510 - val_acc: 0.8567\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 158us/step - loss: 0.3281 - acc: 0.8800 - val_loss: 0.3594 - val_acc: 0.8583\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 151us/step - loss: 0.3190 - acc: 0.8792 - val_loss: 0.3652 - val_acc: 0.8550\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 152us/step - loss: 0.3165 - acc: 0.8858 - val_loss: 0.3444 - val_acc: 0.8717\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 159us/step - loss: 0.3175 - acc: 0.8804 - val_loss: 0.3409 - val_acc: 0.8800\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3165 - acc: 0.8779 - val_loss: 0.3468 - val_acc: 0.8667\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 150us/step - loss: 0.3069 - acc: 0.8863 - val_loss: 0.3480 - val_acc: 0.8600\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 160us/step - loss: 0.2954 - acc: 0.8896 - val_loss: 0.3335 - val_acc: 0.8717\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3027 - acc: 0.8871 - val_loss: 0.3477 - val_acc: 0.8600\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.2833 - acc: 0.8937 - val_loss: 0.3344 - val_acc: 0.8650\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 161us/step - loss: 0.2812 - acc: 0.8954 - val_loss: 0.3397 - val_acc: 0.8717\n",
      "y2_pred:  [[0.06133831]\n",
      " [0.05810195]\n",
      " [0.10371935]\n",
      " [0.09894037]\n",
      " [0.14174783]\n",
      " [0.19628766]\n",
      " [0.14973792]\n",
      " [0.06691489]\n",
      " [0.09609962]\n",
      " [0.03419951]\n",
      " [0.06791162]\n",
      " [0.13769147]\n",
      " [0.02966511]\n",
      " [0.03665629]\n",
      " [0.2571751 ]\n",
      " [0.02434388]\n",
      " [0.11778989]\n",
      " [0.00397933]\n",
      " [0.08065215]\n",
      " [0.09825701]\n",
      " [0.11890841]\n",
      " [0.18776259]\n",
      " [0.06250304]\n",
      " [0.07986277]\n",
      " [0.03280345]\n",
      " [0.01720914]\n",
      " [0.01195678]\n",
      " [0.06643188]\n",
      " [0.04904968]\n",
      " [0.05646366]\n",
      " [0.11832908]\n",
      " [0.08434895]\n",
      " [0.00145817]\n",
      " [0.07607338]\n",
      " [0.14555502]\n",
      " [0.04609418]\n",
      " [0.05496028]\n",
      " [0.22196943]\n",
      " [0.03212023]\n",
      " [0.00995615]\n",
      " [0.05752885]\n",
      " [0.09957269]\n",
      " [0.1113835 ]\n",
      " [0.06734738]\n",
      " [0.05511358]\n",
      " [0.01609972]\n",
      " [0.29592058]\n",
      " [0.10541293]\n",
      " [0.07714251]\n",
      " [0.17460981]\n",
      " [0.04458198]\n",
      " [0.0235934 ]\n",
      " [0.07418758]\n",
      " [0.0870837 ]\n",
      " [0.04214433]\n",
      " [0.03565797]\n",
      " [0.10101902]\n",
      " [0.02441606]\n",
      " [0.03127933]\n",
      " [0.01443642]\n",
      " [0.07455692]\n",
      " [0.03940269]\n",
      " [0.02749562]\n",
      " [0.2534877 ]\n",
      " [0.56575984]\n",
      " [0.05515045]\n",
      " [0.37195385]\n",
      " [0.06599298]\n",
      " [0.08437011]\n",
      " [0.1419622 ]\n",
      " [0.09547293]\n",
      " [0.16546842]\n",
      " [0.01329595]\n",
      " [0.01490659]\n",
      " [0.14572448]\n",
      " [0.08884832]\n",
      " [0.03365967]\n",
      " [0.0703665 ]\n",
      " [0.01409546]\n",
      " [0.16164389]\n",
      " [0.06744751]\n",
      " [0.0826818 ]\n",
      " [0.11792853]\n",
      " [0.0205988 ]\n",
      " [0.04955876]\n",
      " [0.07066441]\n",
      " [0.08680019]\n",
      " [0.02965683]\n",
      " [0.03962651]\n",
      " [0.00488287]\n",
      " [0.28682402]\n",
      " [0.0097959 ]\n",
      " [0.02258024]\n",
      " [0.10007855]\n",
      " [0.05819452]\n",
      " [0.01015201]\n",
      " [0.02221283]\n",
      " [0.04221547]\n",
      " [0.07166225]\n",
      " [0.08317271]\n",
      " [0.09086844]\n",
      " [0.2699278 ]\n",
      " [0.03166983]\n",
      " [0.06427777]\n",
      " [0.06362098]\n",
      " [0.18916553]\n",
      " [0.11950004]\n",
      " [0.1392681 ]\n",
      " [0.06065521]\n",
      " [0.04587501]\n",
      " [0.08162728]\n",
      " [0.12542275]\n",
      " [0.07944816]\n",
      " [0.7090021 ]\n",
      " [0.14029723]\n",
      " [0.12828094]\n",
      " [0.15905285]\n",
      " [0.06806368]\n",
      " [0.04288009]\n",
      " [0.01657644]\n",
      " [0.08326152]\n",
      " [0.04168382]\n",
      " [0.02528363]\n",
      " [0.11225468]\n",
      " [0.02916491]\n",
      " [0.36396503]\n",
      " [0.01896247]\n",
      " [0.06417659]\n",
      " [0.07097185]\n",
      " [0.24293098]\n",
      " [0.05507377]\n",
      " [0.15338263]\n",
      " [0.01240593]\n",
      " [0.08390844]\n",
      " [0.09943345]\n",
      " [0.17524359]\n",
      " [0.2546698 ]\n",
      " [0.03837377]\n",
      " [0.5169198 ]\n",
      " [0.04435259]\n",
      " [0.08241767]\n",
      " [0.01585156]\n",
      " [0.02042013]\n",
      " [0.03729805]\n",
      " [0.16784701]\n",
      " [0.2487075 ]\n",
      " [0.06669661]\n",
      " [0.00602949]\n",
      " [0.0927712 ]\n",
      " [0.0614171 ]\n",
      " [0.09153697]\n",
      " [0.10867763]\n",
      " [0.09266818]\n",
      " [0.03283837]\n",
      " [0.12199694]\n",
      " [0.06744274]\n",
      " [0.02731475]\n",
      " [0.24428383]\n",
      " [0.03171822]\n",
      " [0.05689794]\n",
      " [0.08713487]\n",
      " [0.01418605]\n",
      " [0.1970475 ]\n",
      " [0.860814  ]\n",
      " [0.08553261]\n",
      " [0.07040241]\n",
      " [0.01983032]\n",
      " [0.01422381]\n",
      " [0.08043119]\n",
      " [0.25086716]\n",
      " [0.28832388]\n",
      " [0.12366953]\n",
      " [0.05832326]\n",
      " [0.09121346]\n",
      " [0.0935995 ]\n",
      " [0.02032274]\n",
      " [0.11040884]\n",
      " [0.00202984]\n",
      " [0.21033344]\n",
      " [0.02684328]\n",
      " [0.07413572]\n",
      " [0.01818573]\n",
      " [0.12625262]\n",
      " [0.02835792]\n",
      " [0.05496076]\n",
      " [0.32983935]\n",
      " [0.24700406]\n",
      " [0.01879802]\n",
      " [0.3271566 ]\n",
      " [0.02292985]\n",
      " [0.0112763 ]\n",
      " [0.0350354 ]\n",
      " [0.25250536]\n",
      " [0.12611422]\n",
      " [0.06009081]\n",
      " [0.02715427]\n",
      " [0.21853071]\n",
      " [0.03265917]\n",
      " [0.05918917]\n",
      " [0.00760895]\n",
      " [0.25769615]\n",
      " [0.15278101]\n",
      " [0.26300472]\n",
      " [0.0785808 ]\n",
      " [0.0168137 ]\n",
      " [0.0410029 ]\n",
      " [0.04840732]\n",
      " [0.15546134]\n",
      " [0.10672173]\n",
      " [0.49192905]\n",
      " [0.08492994]\n",
      " [0.63918364]\n",
      " [0.33607197]\n",
      " [0.16490668]\n",
      " [0.01268506]\n",
      " [0.2876244 ]\n",
      " [0.08984315]\n",
      " [0.93307364]\n",
      " [0.08000663]\n",
      " [0.10121036]\n",
      " [0.04376104]\n",
      " [0.06406021]\n",
      " [0.24907207]\n",
      " [0.08214948]\n",
      " [0.09361055]\n",
      " [0.1095174 ]\n",
      " [0.19574562]\n",
      " [0.09409291]\n",
      " [0.08393708]\n",
      " [0.1611501 ]\n",
      " [0.30874968]\n",
      " [0.02229017]\n",
      " [0.00978684]\n",
      " [0.0498755 ]\n",
      " [0.02546105]\n",
      " [0.00590193]\n",
      " [0.08943954]\n",
      " [0.0168899 ]\n",
      " [0.2627927 ]\n",
      " [0.01536497]\n",
      " [0.02501372]\n",
      " [0.09564275]\n",
      " [0.01581857]\n",
      " [0.11045048]\n",
      " [0.05801651]\n",
      " [0.07300374]\n",
      " [0.23400953]\n",
      " [0.18783176]\n",
      " [0.3827537 ]\n",
      " [0.06575206]\n",
      " [0.10299382]\n",
      " [0.1783449 ]\n",
      " [0.03489423]\n",
      " [0.05377227]\n",
      " [0.08022648]\n",
      " [0.01279882]\n",
      " [0.06324494]\n",
      " [0.56314933]\n",
      " [0.03544286]\n",
      " [0.21270457]\n",
      " [0.21819773]\n",
      " [0.16696388]\n",
      " [0.04047468]\n",
      " [0.345726  ]\n",
      " [0.02205342]\n",
      " [0.01124424]\n",
      " [0.72425675]\n",
      " [0.06518421]\n",
      " [0.039334  ]\n",
      " [0.11421102]\n",
      " [0.02086753]\n",
      " [0.02646446]\n",
      " [0.15617612]\n",
      " [0.1028513 ]\n",
      " [0.7644043 ]\n",
      " [0.01787969]\n",
      " [0.05287483]\n",
      " [0.10298178]\n",
      " [0.02491125]\n",
      " [0.01703325]\n",
      " [0.01681706]\n",
      " [0.18281364]\n",
      " [0.04034576]\n",
      " [0.09283295]\n",
      " [0.09283948]\n",
      " [0.00693271]\n",
      " [0.2456438 ]\n",
      " [0.1973477 ]\n",
      " [0.07693136]\n",
      " [0.219623  ]\n",
      " [0.4788106 ]\n",
      " [0.05523077]\n",
      " [0.06325713]\n",
      " [0.01914877]\n",
      " [0.01895979]\n",
      " [0.07971874]\n",
      " [0.14170325]\n",
      " [0.02155074]\n",
      " [0.02166551]\n",
      " [0.1857757 ]\n",
      " [0.08305627]\n",
      " [0.01993138]\n",
      " [0.27943742]\n",
      " [0.00393987]\n",
      " [0.4536593 ]\n",
      " [0.24468654]\n",
      " [0.342629  ]\n",
      " [0.9777012 ]\n",
      " [0.6547914 ]\n",
      " [0.15916035]\n",
      " [0.07166225]\n",
      " [0.01352227]\n",
      " [0.33651084]\n",
      " [0.01903474]\n",
      " [0.13237143]\n",
      " [0.45514756]\n",
      " [0.01235303]\n",
      " [0.19160497]\n",
      " [0.27352965]\n",
      " [0.96455926]\n",
      " [0.85164094]\n",
      " [0.15290236]\n",
      " [0.1230033 ]\n",
      " [0.7699201 ]\n",
      " [0.9250718 ]\n",
      " [0.02976733]\n",
      " [0.01932558]\n",
      " [0.15830371]\n",
      " [0.6455395 ]\n",
      " [0.43481648]\n",
      " [0.19344153]\n",
      " [0.20624048]\n",
      " [0.9747526 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.4468 - acc: 0.8538 - val_loss: 0.4316 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 155us/step - loss: 0.4083 - acc: 0.8583 - val_loss: 0.4298 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 157us/step - loss: 0.4072 - acc: 0.8583 - val_loss: 0.4178 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 163us/step - loss: 0.4004 - acc: 0.8583 - val_loss: 0.4034 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 173us/step - loss: 0.3942 - acc: 0.8588 - val_loss: 0.4065 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 164us/step - loss: 0.3879 - acc: 0.8575 - val_loss: 0.4057 - val_acc: 0.8433\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 156us/step - loss: 0.3842 - acc: 0.8596 - val_loss: 0.4048 - val_acc: 0.8433\n",
      "y2_pred:  [[0.22856879]\n",
      " [0.09146747]\n",
      " [0.13597661]\n",
      " [0.05904034]\n",
      " [0.05460823]\n",
      " [0.05066279]\n",
      " [0.08058238]\n",
      " [0.08265495]\n",
      " [0.02364156]\n",
      " [0.2259306 ]\n",
      " [0.10339531]\n",
      " [0.36097515]\n",
      " [0.03904939]\n",
      " [0.08525357]\n",
      " [0.1253201 ]\n",
      " [0.01915944]\n",
      " [0.08510351]\n",
      " [0.12690347]\n",
      " [0.11140898]\n",
      " [0.11411706]\n",
      " [0.07558286]\n",
      " [0.11786637]\n",
      " [0.34788102]\n",
      " [0.10475773]\n",
      " [0.11937746]\n",
      " [0.24234489]\n",
      " [0.02775443]\n",
      " [0.1245068 ]\n",
      " [0.13182506]\n",
      " [0.02446219]\n",
      " [0.05767107]\n",
      " [0.07160467]\n",
      " [0.19799617]\n",
      " [0.07381928]\n",
      " [0.3030488 ]\n",
      " [0.22909012]\n",
      " [0.03118575]\n",
      " [0.07571098]\n",
      " [0.0638386 ]\n",
      " [0.10499585]\n",
      " [0.04343837]\n",
      " [0.16490847]\n",
      " [0.12849271]\n",
      " [0.16497037]\n",
      " [0.03392342]\n",
      " [0.16955104]\n",
      " [0.3229095 ]\n",
      " [0.42360207]\n",
      " [0.03243163]\n",
      " [0.00604877]\n",
      " [0.02094638]\n",
      " [0.03684202]\n",
      " [0.3962274 ]\n",
      " [0.05064029]\n",
      " [0.25462216]\n",
      " [0.06903958]\n",
      " [0.09986588]\n",
      " [0.12422657]\n",
      " [0.04370645]\n",
      " [0.04735473]\n",
      " [0.07010728]\n",
      " [0.16555986]\n",
      " [0.03807762]\n",
      " [0.02905762]\n",
      " [0.05609319]\n",
      " [0.07106131]\n",
      " [0.13999325]\n",
      " [0.10234594]\n",
      " [0.07042232]\n",
      " [0.03223801]\n",
      " [0.07147479]\n",
      " [0.15360186]\n",
      " [0.28712922]\n",
      " [0.11849153]\n",
      " [0.0822947 ]\n",
      " [0.05340019]\n",
      " [0.01539001]\n",
      " [0.01792324]\n",
      " [0.02961192]\n",
      " [0.16426638]\n",
      " [0.25705552]\n",
      " [0.04821163]\n",
      " [0.09679654]\n",
      " [0.04792783]\n",
      " [0.08793142]\n",
      " [0.17967659]\n",
      " [0.09520739]\n",
      " [0.12447053]\n",
      " [0.08130667]\n",
      " [0.04809865]\n",
      " [0.08009523]\n",
      " [0.10633972]\n",
      " [0.07186639]\n",
      " [0.02551171]\n",
      " [0.12929654]\n",
      " [0.07025769]\n",
      " [0.02609107]\n",
      " [0.0334729 ]\n",
      " [0.06103709]\n",
      " [0.14868754]\n",
      " [0.10423896]\n",
      " [0.09066212]\n",
      " [0.14110693]\n",
      " [0.00276405]\n",
      " [0.10661256]\n",
      " [0.03067642]\n",
      " [0.18736908]\n",
      " [0.0709154 ]\n",
      " [0.04071552]\n",
      " [0.10505742]\n",
      " [0.0612233 ]\n",
      " [0.08010972]\n",
      " [0.13876086]\n",
      " [0.18723273]\n",
      " [0.19289076]\n",
      " [0.2448932 ]\n",
      " [0.07603568]\n",
      " [0.10271674]\n",
      " [0.07034567]\n",
      " [0.0327442 ]\n",
      " [0.05791903]\n",
      " [0.05311081]\n",
      " [0.07059532]\n",
      " [0.03335682]\n",
      " [0.04077229]\n",
      " [0.10719746]\n",
      " [0.11702263]\n",
      " [0.03620327]\n",
      " [0.13842547]\n",
      " [0.04219934]\n",
      " [0.03488925]\n",
      " [0.19557959]\n",
      " [0.02735507]\n",
      " [0.074175  ]\n",
      " [0.0148274 ]\n",
      " [0.05680868]\n",
      " [0.1490112 ]\n",
      " [0.0486185 ]\n",
      " [0.11385548]\n",
      " [0.00142595]\n",
      " [0.0424425 ]\n",
      " [0.02582011]\n",
      " [0.03918177]\n",
      " [0.11216429]\n",
      " [0.0395557 ]\n",
      " [0.04337105]\n",
      " [0.11227491]\n",
      " [0.05365765]\n",
      " [0.10799313]\n",
      " [0.04311585]\n",
      " [0.0155693 ]\n",
      " [0.06254995]\n",
      " [0.23622721]\n",
      " [0.03858691]\n",
      " [0.15911913]\n",
      " [0.06397843]\n",
      " [0.03402266]\n",
      " [0.05369249]\n",
      " [0.07842088]\n",
      " [0.47272483]\n",
      " [0.02668145]\n",
      " [0.1381076 ]\n",
      " [0.08230302]\n",
      " [0.0506779 ]\n",
      " [0.08433533]\n",
      " [0.08961064]\n",
      " [0.02263483]\n",
      " [0.08647338]\n",
      " [0.06036198]\n",
      " [0.10729823]\n",
      " [0.10061708]\n",
      " [0.11698234]\n",
      " [0.05652744]\n",
      " [0.03133178]\n",
      " [0.08210826]\n",
      " [0.14298218]\n",
      " [0.08298203]\n",
      " [0.07865104]\n",
      " [0.00055856]\n",
      " [0.16264257]\n",
      " [0.0541319 ]\n",
      " [0.3117352 ]\n",
      " [0.06388399]\n",
      " [0.07121819]\n",
      " [0.15687105]\n",
      " [0.15018731]\n",
      " [0.02746537]\n",
      " [0.07865563]\n",
      " [0.04697683]\n",
      " [0.09919354]\n",
      " [0.08012855]\n",
      " [0.08735874]\n",
      " [0.113594  ]\n",
      " [0.02919048]\n",
      " [0.0374296 ]\n",
      " [0.0542393 ]\n",
      " [0.05652276]\n",
      " [0.06162131]\n",
      " [0.08519   ]\n",
      " [0.09518084]\n",
      " [0.10667068]\n",
      " [0.05590379]\n",
      " [0.2120054 ]\n",
      " [0.1428473 ]\n",
      " [0.01884234]\n",
      " [0.07041204]\n",
      " [0.06670997]\n",
      " [0.15862525]\n",
      " [0.1511299 ]\n",
      " [0.03992459]\n",
      " [0.10116664]\n",
      " [0.08203763]\n",
      " [0.13054866]\n",
      " [0.03776827]\n",
      " [0.07979336]\n",
      " [0.08330393]\n",
      " [0.19389492]\n",
      " [0.40453956]\n",
      " [0.2317276 ]\n",
      " [0.51037735]\n",
      " [0.25643688]\n",
      " [0.12865537]\n",
      " [0.0381074 ]\n",
      " [0.05205798]\n",
      " [0.09698671]\n",
      " [0.02851281]\n",
      " [0.13327086]\n",
      " [0.0424259 ]\n",
      " [0.08155057]\n",
      " [0.0905309 ]\n",
      " [0.16036582]\n",
      " [0.0821659 ]\n",
      " [0.04968908]\n",
      " [0.18448162]\n",
      " [0.15052089]\n",
      " [0.0588761 ]\n",
      " [0.05625212]\n",
      " [0.13612679]\n",
      " [0.08057958]\n",
      " [0.06240752]\n",
      " [0.06730619]\n",
      " [0.09872821]\n",
      " [0.04732326]\n",
      " [0.13674596]\n",
      " [0.05976123]\n",
      " [0.12003648]\n",
      " [0.06785101]\n",
      " [0.0767059 ]\n",
      " [0.15875041]\n",
      " [0.07023066]\n",
      " [0.16793028]\n",
      " [0.14304495]\n",
      " [0.17370296]\n",
      " [0.13640875]\n",
      " [0.04076612]\n",
      " [0.1434092 ]\n",
      " [0.04951805]\n",
      " [0.1432144 ]\n",
      " [0.26292837]\n",
      " [0.02563557]\n",
      " [0.03775236]\n",
      " [0.0866465 ]\n",
      " [0.11465129]\n",
      " [0.15693873]\n",
      " [0.04350591]\n",
      " [0.07632238]\n",
      " [0.10206819]\n",
      " [0.00399473]\n",
      " [0.08302563]\n",
      " [0.12649438]\n",
      " [0.11242417]\n",
      " [0.02500644]\n",
      " [0.03596982]\n",
      " [0.15810332]\n",
      " [0.02090663]\n",
      " [0.03334171]\n",
      " [0.07902473]\n",
      " [0.09953561]\n",
      " [0.12180063]\n",
      " [0.18948105]\n",
      " [0.19551331]\n",
      " [0.03455406]\n",
      " [0.01582029]\n",
      " [0.0689275 ]\n",
      " [0.04865164]\n",
      " [0.08742839]\n",
      " [0.06823459]\n",
      " [0.04683596]\n",
      " [0.10181409]\n",
      " [0.06552646]\n",
      " [0.15211964]\n",
      " [0.14162728]\n",
      " [0.02504146]\n",
      " [0.02661681]\n",
      " [0.10202125]\n",
      " [0.06368971]\n",
      " [0.15656474]\n",
      " [0.1231572 ]\n",
      " [0.05465463]\n",
      " [0.08844209]\n",
      " [0.10158256]\n",
      " [0.17658797]\n",
      " [0.10003543]\n",
      " [0.17068154]\n",
      " [0.06996164]\n",
      " [0.03576967]\n",
      " [0.09244502]\n",
      " [0.00478476]\n",
      " [0.07090461]\n",
      " [0.12293488]\n",
      " [0.09196201]\n",
      " [0.14872977]\n",
      " [0.13556921]\n",
      " [0.15574285]\n",
      " [0.01280847]\n",
      " [0.17511252]\n",
      " [0.04142433]\n",
      " [0.20433277]\n",
      " [0.02926329]\n",
      " [0.05720973]\n",
      " [0.11231104]\n",
      " [0.14914751]\n",
      " [0.14123446]\n",
      " [0.46431637]\n",
      " [0.04686207]\n",
      " [0.04594818]\n",
      " [0.12732255]\n",
      " [0.1306175 ]\n",
      " [0.10986213]\n",
      " [0.12942737]\n",
      " [0.05198695]\n",
      " [0.07374803]\n",
      " [0.15944813]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4468 - acc: 0.8596 - val_loss: 0.4961 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 172us/step - loss: 0.4108 - acc: 0.8629 - val_loss: 0.4437 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 176us/step - loss: 0.3978 - acc: 0.8629 - val_loss: 0.4463 - val_acc: 0.8233\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 176us/step - loss: 0.3901 - acc: 0.8629 - val_loss: 0.4345 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 168us/step - loss: 0.3845 - acc: 0.8629 - val_loss: 0.4251 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 173us/step - loss: 0.3794 - acc: 0.8633 - val_loss: 0.4136 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 168us/step - loss: 0.3720 - acc: 0.8625 - val_loss: 0.4423 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 167us/step - loss: 0.3700 - acc: 0.8633 - val_loss: 0.4128 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 171us/step - loss: 0.3680 - acc: 0.8621 - val_loss: 0.3984 - val_acc: 0.8233\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 168us/step - loss: 0.3655 - acc: 0.8633 - val_loss: 0.4104 - val_acc: 0.8217\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 176us/step - loss: 0.3589 - acc: 0.8629 - val_loss: 0.4022 - val_acc: 0.8250\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 164us/step - loss: 0.3516 - acc: 0.8646 - val_loss: 0.4083 - val_acc: 0.8233\n",
      "y2_pred:  [[1.38861388e-01]\n",
      " [5.53814173e-02]\n",
      " [3.22363585e-01]\n",
      " [2.47761458e-01]\n",
      " [2.54032582e-01]\n",
      " [3.03046465e-01]\n",
      " [2.70849437e-01]\n",
      " [1.88839883e-01]\n",
      " [1.17968172e-01]\n",
      " [9.96944606e-02]\n",
      " [5.45892715e-02]\n",
      " [9.38329995e-02]\n",
      " [9.97671485e-02]\n",
      " [7.17648566e-02]\n",
      " [5.40582836e-02]\n",
      " [3.19279134e-02]\n",
      " [4.89728749e-02]\n",
      " [7.04743862e-02]\n",
      " [7.55436122e-02]\n",
      " [5.01261353e-02]\n",
      " [1.95950508e-01]\n",
      " [1.46741152e-01]\n",
      " [3.75082493e-02]\n",
      " [1.13110870e-01]\n",
      " [8.54514539e-02]\n",
      " [1.77815884e-01]\n",
      " [2.59670049e-01]\n",
      " [9.22274888e-02]\n",
      " [7.64391720e-02]\n",
      " [5.09429872e-02]\n",
      " [2.07001269e-01]\n",
      " [1.21939123e-01]\n",
      " [2.91385114e-01]\n",
      " [9.53617990e-02]\n",
      " [5.53361177e-02]\n",
      " [1.62889719e-01]\n",
      " [5.93761206e-02]\n",
      " [3.13795209e-02]\n",
      " [1.84599608e-01]\n",
      " [2.89195478e-02]\n",
      " [6.71966910e-01]\n",
      " [1.41462296e-01]\n",
      " [2.73828447e-01]\n",
      " [5.51548302e-02]\n",
      " [6.76566958e-02]\n",
      " [3.45396101e-02]\n",
      " [1.31292075e-01]\n",
      " [2.57657468e-02]\n",
      " [9.74585414e-02]\n",
      " [5.71393967e-02]\n",
      " [6.37847185e-02]\n",
      " [4.46048081e-02]\n",
      " [3.61928046e-02]\n",
      " [1.69216990e-01]\n",
      " [5.58122993e-02]\n",
      " [2.22383380e-01]\n",
      " [4.00714487e-01]\n",
      " [7.49017000e-02]\n",
      " [6.32993281e-02]\n",
      " [4.64237034e-02]\n",
      " [2.39794761e-01]\n",
      " [2.83531845e-01]\n",
      " [1.25976950e-01]\n",
      " [1.22321844e-02]\n",
      " [3.05981040e-02]\n",
      " [5.30314803e-01]\n",
      " [1.51824981e-01]\n",
      " [9.31300819e-02]\n",
      " [5.88492751e-02]\n",
      " [2.75078118e-01]\n",
      " [1.14529908e-01]\n",
      " [1.44751459e-01]\n",
      " [8.02046061e-03]\n",
      " [7.27937818e-02]\n",
      " [1.26040041e-01]\n",
      " [5.49009740e-02]\n",
      " [1.10124916e-01]\n",
      " [1.66663796e-01]\n",
      " [9.38077867e-02]\n",
      " [8.69754255e-02]\n",
      " [3.08983862e-01]\n",
      " [3.81182134e-02]\n",
      " [9.89993215e-02]\n",
      " [4.98629212e-02]\n",
      " [9.05321538e-02]\n",
      " [8.13782215e-04]\n",
      " [3.51121128e-02]\n",
      " [4.49084938e-02]\n",
      " [1.38114750e-01]\n",
      " [1.33222610e-01]\n",
      " [1.45142287e-01]\n",
      " [3.87837887e-02]\n",
      " [5.63288629e-02]\n",
      " [1.22840643e-01]\n",
      " [5.62798977e-02]\n",
      " [8.05011690e-02]\n",
      " [1.21926039e-01]\n",
      " [7.97936022e-02]\n",
      " [8.36059153e-02]\n",
      " [4.11438942e-02]\n",
      " [8.86955261e-02]\n",
      " [1.11323595e-01]\n",
      " [8.16362500e-02]\n",
      " [5.25656343e-02]\n",
      " [4.55479324e-02]\n",
      " [1.65840030e-01]\n",
      " [8.58404934e-02]\n",
      " [5.69020212e-02]\n",
      " [5.64146042e-03]\n",
      " [1.16062641e-01]\n",
      " [8.17209780e-02]\n",
      " [5.07598221e-02]\n",
      " [8.97389650e-02]\n",
      " [1.07649386e-01]\n",
      " [1.78910583e-01]\n",
      " [1.42663091e-01]\n",
      " [4.68151867e-02]\n",
      " [1.96903795e-01]\n",
      " [3.39232445e-01]\n",
      " [5.38517237e-02]\n",
      " [1.22353852e-01]\n",
      " [2.98104525e-01]\n",
      " [2.68137932e-01]\n",
      " [7.23415911e-02]\n",
      " [7.16125965e-02]\n",
      " [5.74916720e-01]\n",
      " [8.86124969e-02]\n",
      " [3.61588269e-01]\n",
      " [9.94278789e-02]\n",
      " [6.79136217e-02]\n",
      " [6.44702017e-02]\n",
      " [1.81674302e-01]\n",
      " [1.35759890e-01]\n",
      " [2.73573220e-01]\n",
      " [2.25424916e-01]\n",
      " [1.26371086e-01]\n",
      " [2.38262057e-01]\n",
      " [1.32126957e-01]\n",
      " [4.64880466e-02]\n",
      " [1.55966908e-01]\n",
      " [1.27269983e-01]\n",
      " [2.07718611e-02]\n",
      " [1.12750739e-01]\n",
      " [3.64685059e-02]\n",
      " [6.09758794e-02]\n",
      " [9.23806429e-03]\n",
      " [1.55517817e-01]\n",
      " [6.51673377e-02]\n",
      " [5.67296147e-02]\n",
      " [8.18657279e-02]\n",
      " [1.84285641e-02]\n",
      " [1.48106694e-01]\n",
      " [9.33235884e-03]\n",
      " [1.42672151e-01]\n",
      " [1.42781585e-01]\n",
      " [9.28521454e-02]\n",
      " [1.38571262e-01]\n",
      " [4.24388558e-01]\n",
      " [3.48876417e-02]\n",
      " [4.32087183e-02]\n",
      " [1.71279639e-01]\n",
      " [3.10028255e-01]\n",
      " [5.24771214e-02]\n",
      " [5.27134836e-02]\n",
      " [5.20682335e-02]\n",
      " [8.18503201e-02]\n",
      " [1.02640033e-01]\n",
      " [7.82569945e-02]\n",
      " [3.62196565e-02]\n",
      " [5.24209142e-02]\n",
      " [1.29672855e-01]\n",
      " [5.65262139e-02]\n",
      " [1.84996367e-01]\n",
      " [3.27998996e-02]\n",
      " [1.98332071e-01]\n",
      " [4.78492379e-02]\n",
      " [1.96065009e-02]\n",
      " [7.08115101e-02]\n",
      " [2.94262707e-01]\n",
      " [7.93280005e-02]\n",
      " [3.25502455e-02]\n",
      " [2.18452513e-01]\n",
      " [2.15068132e-01]\n",
      " [1.53734982e-02]\n",
      " [1.30162150e-01]\n",
      " [1.90531075e-01]\n",
      " [8.34300816e-02]\n",
      " [1.75466806e-01]\n",
      " [1.22175276e-01]\n",
      " [9.44032669e-02]\n",
      " [1.92815483e-01]\n",
      " [5.17079830e-02]\n",
      " [4.85887527e-02]\n",
      " [9.54328179e-02]\n",
      " [2.16955841e-02]\n",
      " [7.68725753e-01]\n",
      " [2.77605116e-01]\n",
      " [9.39477682e-02]\n",
      " [7.36979842e-02]\n",
      " [8.59438181e-02]\n",
      " [8.20649266e-02]\n",
      " [1.38058662e-01]\n",
      " [6.23344183e-02]\n",
      " [2.93299854e-02]\n",
      " [1.87520742e-01]\n",
      " [9.18498933e-02]\n",
      " [1.66433603e-01]\n",
      " [1.13227814e-01]\n",
      " [7.47893751e-02]\n",
      " [1.90056503e-01]\n",
      " [5.04550338e-02]\n",
      " [8.86343122e-02]\n",
      " [7.19182193e-02]\n",
      " [2.40842909e-01]\n",
      " [3.63037586e-02]\n",
      " [1.82345390e-01]\n",
      " [5.19476235e-02]\n",
      " [2.25131512e-01]\n",
      " [1.40775532e-01]\n",
      " [8.85515511e-02]\n",
      " [1.28069252e-01]\n",
      " [5.21646440e-02]\n",
      " [3.05461943e-01]\n",
      " [1.30962431e-01]\n",
      " [2.62756050e-02]\n",
      " [2.61371434e-02]\n",
      " [3.73168588e-02]\n",
      " [4.46122587e-02]\n",
      " [2.53874779e-01]\n",
      " [2.01933444e-01]\n",
      " [1.95801258e-04]\n",
      " [5.48770428e-02]\n",
      " [6.57449961e-02]\n",
      " [9.02544558e-02]\n",
      " [9.11164284e-02]\n",
      " [3.66515517e-02]\n",
      " [7.75550008e-02]\n",
      " [9.89565253e-02]\n",
      " [8.95187855e-02]\n",
      " [1.14773542e-01]\n",
      " [1.20203763e-01]\n",
      " [3.57994795e-01]\n",
      " [2.46248960e-01]\n",
      " [7.40851760e-02]\n",
      " [3.61624479e-01]\n",
      " [1.40234828e-02]\n",
      " [2.49064267e-02]\n",
      " [9.36750472e-02]\n",
      " [1.59552395e-01]\n",
      " [4.98313010e-02]\n",
      " [7.28430748e-02]\n",
      " [3.98403168e-01]\n",
      " [8.52184296e-02]\n",
      " [7.93907940e-02]\n",
      " [1.13690764e-01]\n",
      " [6.76647425e-02]\n",
      " [7.58874714e-02]\n",
      " [2.19847083e-01]\n",
      " [8.62850249e-02]\n",
      " [5.28689146e-01]\n",
      " [6.03937209e-02]\n",
      " [7.81098604e-02]\n",
      " [4.56285179e-02]\n",
      " [2.91848779e-02]\n",
      " [1.87373459e-01]\n",
      " [1.21180683e-01]\n",
      " [1.27418101e-01]\n",
      " [1.63576514e-01]\n",
      " [8.34319293e-02]\n",
      " [3.38397205e-01]\n",
      " [2.34445930e-03]\n",
      " [1.39271408e-01]\n",
      " [2.30649412e-02]\n",
      " [1.41918182e-01]\n",
      " [1.13962710e-01]\n",
      " [4.12892312e-01]\n",
      " [6.69771135e-02]\n",
      " [4.92773056e-02]\n",
      " [6.12104535e-02]\n",
      " [2.70502269e-02]\n",
      " [7.47269392e-02]\n",
      " [2.36890823e-01]\n",
      " [3.62220466e-01]\n",
      " [3.13325226e-02]\n",
      " [1.84473991e-02]\n",
      " [3.16092789e-01]\n",
      " [4.33928788e-01]\n",
      " [1.18788242e-01]\n",
      " [2.33355463e-02]\n",
      " [6.77216232e-01]\n",
      " [9.36088264e-02]\n",
      " [5.31244338e-01]\n",
      " [2.08730936e-01]\n",
      " [1.69665992e-01]\n",
      " [3.54746878e-01]\n",
      " [2.03581572e-01]\n",
      " [4.33587134e-02]\n",
      " [3.39383662e-01]\n",
      " [7.16698766e-02]\n",
      " [5.42654991e-02]\n",
      " [1.66336596e-02]\n",
      " [8.37493837e-02]\n",
      " [7.69340396e-02]\n",
      " [3.90539765e-02]\n",
      " [3.69693249e-01]\n",
      " [8.41746032e-02]\n",
      " [2.38880247e-01]\n",
      " [6.35274351e-02]\n",
      " [2.02744007e-02]\n",
      " [3.45773697e-02]\n",
      " [2.22269237e-01]\n",
      " [8.38493705e-02]\n",
      " [5.03350437e-01]\n",
      " [1.52364045e-01]\n",
      " [4.26157415e-02]\n",
      " [7.60412216e-02]\n",
      " [1.46405488e-01]\n",
      " [2.34942704e-01]\n",
      " [3.12352091e-01]\n",
      " [1.12623572e-01]\n",
      " [1.91494405e-01]\n",
      " [1.88806623e-01]\n",
      " [1.37005210e-01]\n",
      " [4.82868254e-02]\n",
      " [1.73083514e-01]\n",
      " [2.32267380e-02]\n",
      " [9.76746976e-02]\n",
      " [1.58872604e-02]\n",
      " [6.08363748e-02]\n",
      " [7.55025223e-02]\n",
      " [1.20082393e-01]\n",
      " [1.63820446e-01]\n",
      " [2.13986561e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.08333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 5s 2ms/step - loss: 0.4738 - acc: 0.8521 - val_loss: 0.4557 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 177us/step - loss: 0.3970 - acc: 0.8629 - val_loss: 0.4746 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 171us/step - loss: 0.3841 - acc: 0.8617 - val_loss: 0.4447 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 173us/step - loss: 0.3784 - acc: 0.8625 - val_loss: 0.4300 - val_acc: 0.8283\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 177us/step - loss: 0.3775 - acc: 0.8633 - val_loss: 0.4250 - val_acc: 0.8217\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 171us/step - loss: 0.3662 - acc: 0.8683 - val_loss: 0.4158 - val_acc: 0.8283\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 178us/step - loss: 0.3633 - acc: 0.8658 - val_loss: 0.4415 - val_acc: 0.8267\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 188us/step - loss: 0.3531 - acc: 0.8625 - val_loss: 0.4344 - val_acc: 0.8300\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 184us/step - loss: 0.3482 - acc: 0.8721 - val_loss: 0.4144 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 196us/step - loss: 0.3493 - acc: 0.8688 - val_loss: 0.4209 - val_acc: 0.8367\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 173us/step - loss: 0.3352 - acc: 0.8746 - val_loss: 0.3912 - val_acc: 0.8583\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 171us/step - loss: 0.3440 - acc: 0.8721 - val_loss: 0.3987 - val_acc: 0.8433\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 174us/step - loss: 0.3334 - acc: 0.8792 - val_loss: 0.4353 - val_acc: 0.8433\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 170us/step - loss: 0.3198 - acc: 0.8767 - val_loss: 0.3889 - val_acc: 0.8600\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 178us/step - loss: 0.3201 - acc: 0.8808 - val_loss: 0.3758 - val_acc: 0.8600\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 169us/step - loss: 0.3156 - acc: 0.8808 - val_loss: 0.3879 - val_acc: 0.8633\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 173us/step - loss: 0.3095 - acc: 0.8825 - val_loss: 0.3893 - val_acc: 0.8567\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 177us/step - loss: 0.3075 - acc: 0.8829 - val_loss: 0.3776 - val_acc: 0.8650\n",
      "y2_pred:  [[0.14053303]\n",
      " [0.06604543]\n",
      " [0.09737822]\n",
      " [0.01745477]\n",
      " [0.05145329]\n",
      " [0.06171146]\n",
      " [0.03268611]\n",
      " [0.26184797]\n",
      " [0.03540713]\n",
      " [0.54405844]\n",
      " [0.15246427]\n",
      " [0.00572884]\n",
      " [0.05067062]\n",
      " [0.03014296]\n",
      " [0.03844658]\n",
      " [0.00858417]\n",
      " [0.03071445]\n",
      " [0.8389839 ]\n",
      " [0.20279846]\n",
      " [0.17331779]\n",
      " [0.04099426]\n",
      " [0.04780301]\n",
      " [0.01352641]\n",
      " [0.46102467]\n",
      " [0.03898367]\n",
      " [0.02054042]\n",
      " [0.6823839 ]\n",
      " [0.10115609]\n",
      " [0.03273532]\n",
      " [0.02359027]\n",
      " [0.08456776]\n",
      " [0.7092682 ]\n",
      " [0.00744367]\n",
      " [0.0622707 ]\n",
      " [0.01377317]\n",
      " [0.3901529 ]\n",
      " [0.07271612]\n",
      " [0.0484257 ]\n",
      " [0.22580338]\n",
      " [0.05696046]\n",
      " [0.03679669]\n",
      " [0.01611796]\n",
      " [0.36498094]\n",
      " [0.1034399 ]\n",
      " [0.05493435]\n",
      " [0.44958034]\n",
      " [0.30121827]\n",
      " [0.05065522]\n",
      " [0.06522816]\n",
      " [0.29123482]\n",
      " [0.46536165]\n",
      " [0.12359121]\n",
      " [0.13716176]\n",
      " [0.04130101]\n",
      " [0.06399462]\n",
      " [0.12652844]\n",
      " [0.13576001]\n",
      " [0.04117596]\n",
      " [0.04464984]\n",
      " [0.21941021]\n",
      " [0.05965602]\n",
      " [0.03765345]\n",
      " [0.02139041]\n",
      " [0.04924354]\n",
      " [0.27851844]\n",
      " [0.03763303]\n",
      " [0.07877412]\n",
      " [0.01895246]\n",
      " [0.05992091]\n",
      " [0.04254878]\n",
      " [0.34904134]\n",
      " [0.01714361]\n",
      " [0.6698053 ]\n",
      " [0.06926063]\n",
      " [0.02323025]\n",
      " [0.00392562]\n",
      " [0.04115409]\n",
      " [0.00469455]\n",
      " [0.08148208]\n",
      " [0.8989736 ]\n",
      " [0.19474855]\n",
      " [0.9066434 ]\n",
      " [0.16855562]\n",
      " [0.02073503]\n",
      " [0.08484235]\n",
      " [0.49478352]\n",
      " [0.11792499]\n",
      " [0.01617095]\n",
      " [0.01288068]\n",
      " [0.18160588]\n",
      " [0.03519794]\n",
      " [0.02470469]\n",
      " [0.07337674]\n",
      " [0.24554002]\n",
      " [0.09385258]\n",
      " [0.00455338]\n",
      " [0.01861003]\n",
      " [0.02196851]\n",
      " [0.07088965]\n",
      " [0.02753085]\n",
      " [0.04633114]\n",
      " [0.00814331]\n",
      " [0.01962873]\n",
      " [0.05828381]\n",
      " [0.02812922]\n",
      " [0.25434828]\n",
      " [0.01761726]\n",
      " [0.01772755]\n",
      " [0.01730022]\n",
      " [0.02337953]\n",
      " [0.01234317]\n",
      " [0.04851791]\n",
      " [0.95369387]\n",
      " [0.08027706]\n",
      " [0.05263481]\n",
      " [0.12238806]\n",
      " [0.06454402]\n",
      " [0.05075106]\n",
      " [0.02689818]\n",
      " [0.01844966]\n",
      " [0.0153406 ]\n",
      " [0.02977511]\n",
      " [0.12106577]\n",
      " [0.02980796]\n",
      " [0.18239802]\n",
      " [0.42319337]\n",
      " [0.14894682]\n",
      " [0.5933044 ]\n",
      " [0.06254345]\n",
      " [0.06500259]\n",
      " [0.58196956]\n",
      " [0.87977433]\n",
      " [0.46527687]\n",
      " [0.04366076]\n",
      " [0.27105606]\n",
      " [0.01641694]\n",
      " [0.09737539]\n",
      " [0.07902369]\n",
      " [0.15510312]\n",
      " [0.03443456]\n",
      " [0.6677103 ]\n",
      " [0.03088677]\n",
      " [0.04568437]\n",
      " [0.20385736]\n",
      " [0.87578315]\n",
      " [0.09493017]\n",
      " [0.0451901 ]\n",
      " [0.2635939 ]\n",
      " [0.30293414]\n",
      " [0.12422058]\n",
      " [0.04445079]\n",
      " [0.13759586]\n",
      " [0.0396575 ]\n",
      " [0.07132083]\n",
      " [0.02454615]\n",
      " [0.05715212]\n",
      " [0.21785772]\n",
      " [0.8408079 ]\n",
      " [0.06352058]\n",
      " [0.6171077 ]\n",
      " [0.3277148 ]\n",
      " [0.03779104]\n",
      " [0.04992113]\n",
      " [0.05041739]\n",
      " [0.13978654]\n",
      " [0.04009736]\n",
      " [0.332547  ]\n",
      " [0.18387604]\n",
      " [0.06281811]\n",
      " [0.6492274 ]\n",
      " [0.01370844]\n",
      " [0.06572512]\n",
      " [0.06006244]\n",
      " [0.15338916]\n",
      " [0.04251835]\n",
      " [0.07646668]\n",
      " [0.04073641]\n",
      " [0.06271666]\n",
      " [0.11293742]\n",
      " [0.02584493]\n",
      " [0.14545348]\n",
      " [0.5802797 ]\n",
      " [0.02539518]\n",
      " [0.07588801]\n",
      " [0.17874661]\n",
      " [0.09937766]\n",
      " [0.09521437]\n",
      " [0.01262   ]\n",
      " [0.13367155]\n",
      " [0.36319792]\n",
      " [0.840642  ]\n",
      " [0.18677685]\n",
      " [0.06853816]\n",
      " [0.06811935]\n",
      " [0.0518012 ]\n",
      " [0.01518205]\n",
      " [0.05048606]\n",
      " [0.3461633 ]\n",
      " [0.03522441]\n",
      " [0.01846835]\n",
      " [0.30367595]\n",
      " [0.03507605]\n",
      " [0.04182449]\n",
      " [0.02049521]\n",
      " [0.09736517]\n",
      " [0.50565165]\n",
      " [0.01246428]\n",
      " [0.05597109]\n",
      " [0.12486422]\n",
      " [0.10486627]\n",
      " [0.1245918 ]\n",
      " [0.07131317]\n",
      " [0.00809082]\n",
      " [0.0131737 ]\n",
      " [0.14551148]\n",
      " [0.0121083 ]\n",
      " [0.01074979]\n",
      " [0.00986308]\n",
      " [0.02636033]\n",
      " [0.02751106]\n",
      " [0.01234651]\n",
      " [0.0221231 ]\n",
      " [0.31927496]\n",
      " [0.16400433]\n",
      " [0.04422301]\n",
      " [0.23866865]\n",
      " [0.2543124 ]\n",
      " [0.11636052]\n",
      " [0.29022068]\n",
      " [0.03786775]\n",
      " [0.03815857]\n",
      " [0.00791866]\n",
      " [0.06821644]\n",
      " [0.03685939]\n",
      " [0.02505842]\n",
      " [0.02736977]\n",
      " [0.00959995]\n",
      " [0.14489949]\n",
      " [0.23550245]\n",
      " [0.03282961]\n",
      " [0.09570813]\n",
      " [0.2211504 ]\n",
      " [0.01499468]\n",
      " [0.9441321 ]\n",
      " [0.20065984]\n",
      " [0.61562604]\n",
      " [0.04665872]\n",
      " [0.03700671]\n",
      " [0.04218727]\n",
      " [0.04044855]\n",
      " [0.08752903]\n",
      " [0.2249414 ]\n",
      " [0.09167314]\n",
      " [0.03345591]\n",
      " [0.01144543]\n",
      " [0.28281796]\n",
      " [0.10371369]\n",
      " [0.06036779]\n",
      " [0.0239585 ]\n",
      " [0.19002035]\n",
      " [0.25065777]\n",
      " [0.01354456]\n",
      " [0.03572604]\n",
      " [0.07586136]\n",
      " [0.01265875]\n",
      " [0.19686392]\n",
      " [0.16109121]\n",
      " [0.15455335]\n",
      " [0.3816013 ]\n",
      " [0.08856243]\n",
      " [0.0681251 ]\n",
      " [0.16352236]\n",
      " [0.13726431]\n",
      " [0.02818754]\n",
      " [0.30418494]\n",
      " [0.03624433]\n",
      " [0.04425481]\n",
      " [0.05758896]\n",
      " [0.06514636]\n",
      " [0.04557711]\n",
      " [0.06184953]\n",
      " [0.03068098]\n",
      " [0.01788282]\n",
      " [0.09220165]\n",
      " [0.02320153]\n",
      " [0.06525469]\n",
      " [0.01512453]\n",
      " [0.5095936 ]\n",
      " [0.00816879]\n",
      " [0.01973969]\n",
      " [0.0297744 ]\n",
      " [0.11122638]\n",
      " [0.06633812]\n",
      " [0.04218251]\n",
      " [0.21718532]\n",
      " [0.06333846]\n",
      " [0.16081852]\n",
      " [0.0487994 ]\n",
      " [0.14170471]\n",
      " [0.08250344]\n",
      " [0.01853499]\n",
      " [0.4328338 ]\n",
      " [0.2824988 ]\n",
      " [0.05448872]\n",
      " [0.65245676]\n",
      " [0.02393696]\n",
      " [0.00672063]\n",
      " [0.45281664]\n",
      " [0.08385256]\n",
      " [0.6646915 ]\n",
      " [0.02080527]\n",
      " [0.0428988 ]\n",
      " [0.08119479]\n",
      " [0.0473271 ]\n",
      " [0.18504173]\n",
      " [0.03646153]\n",
      " [0.01247776]\n",
      " [0.08555579]\n",
      " [0.08928874]\n",
      " [0.05238238]\n",
      " [0.7981703 ]\n",
      " [0.07822514]\n",
      " [0.41309696]\n",
      " [0.7075074 ]\n",
      " [0.02347776]\n",
      " [0.09185067]\n",
      " [0.04500157]\n",
      " [0.0451023 ]\n",
      " [0.00403946]\n",
      " [0.0497007 ]\n",
      " [0.04044588]\n",
      " [0.10416675]\n",
      " [0.0145038 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.2916666666666667\n",
      "pod:  [0.12244897959183673, 0.12244897959183673, 0.10204081632653061, 0.08333333333333333, 0.2916666666666667, 0.16666666666666666, 0.25, 0.0, 0.08333333333333333, 0.2916666666666667]\n",
      "pof:  [0.0035087719298245615, 0.014035087719298246, 0.014035087719298246, 0.0035087719298245615, 0.031578947368421054, 0.014035087719298246, 0.017543859649122806, 0.0035087719298245615, 0.014035087719298246, 0.042105263157894736]\n",
      "auc:  [0.559470103831006, 0.5542069459362692, 0.5440028643036161, 0.5399122807017543, 0.6300438596491228, 0.5763157894736842, 0.6162280701754386, 0.4982456140350877, 0.5346491228070175, 0.624780701754386]\n",
      "tn_list:  [284, 281, 281, 284, 276, 281, 280, 284, 281, 273]\n",
      "fp_list:  [1, 4, 4, 1, 9, 4, 5, 1, 4, 12]\n",
      "fn_list:  [43, 43, 44, 44, 34, 40, 36, 48, 44, 34]\n",
      "tp_list:  [6, 6, 5, 4, 14, 8, 12, 0, 4, 14]\n",
      "2805 45 410 73\n"
     ]
    }
   ],
   "source": [
    "df_x_train_chi = pd.DataFrame(x_train_chi)\n",
    "df_x_train_chi.head()\n",
    "\n",
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print('tn_list: ',tn_list)\n",
    "print ('fp_list: ',fp_list)\n",
    "print ('fn_list: ',fn_list)\n",
    "print ('tp_list: ',tp_list)\n",
    "\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 6s 2ms/step - loss: 0.5299 - acc: 0.8491 - val_loss: 0.4329 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 141us/step - loss: 0.3984 - acc: 0.8587 - val_loss: 0.4222 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 141us/step - loss: 0.3872 - acc: 0.8587 - val_loss: 0.4389 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 139us/step - loss: 0.3803 - acc: 0.8587 - val_loss: 0.4175 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 143us/step - loss: 0.3712 - acc: 0.8587 - val_loss: 0.3960 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 6s 2ms/step - loss: 0.5304 - acc: 0.8587 - val_loss: 0.4367 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 132us/step - loss: 0.3996 - acc: 0.8587 - val_loss: 0.4240 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 132us/step - loss: 0.3917 - acc: 0.8587 - val_loss: 0.4132 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 133us/step - loss: 0.3820 - acc: 0.8587 - val_loss: 0.4067 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 132us/step - loss: 0.3768 - acc: 0.8587 - val_loss: 0.3965 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 5s 2ms/step - loss: 0.5424 - acc: 0.8220 - val_loss: 0.4338 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 133us/step - loss: 0.3991 - acc: 0.8587 - val_loss: 0.4257 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 134us/step - loss: 0.3910 - acc: 0.8587 - val_loss: 0.4158 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 135us/step - loss: 0.3812 - acc: 0.8587 - val_loss: 0.4094 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 136us/step - loss: 0.3734 - acc: 0.8587 - val_loss: 0.3995 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 6s 2ms/step - loss: 0.5335 - acc: 0.8258 - val_loss: 0.4285 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 130us/step - loss: 0.3949 - acc: 0.8583 - val_loss: 0.4188 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 129us/step - loss: 0.3865 - acc: 0.8583 - val_loss: 0.4242 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 132us/step - loss: 0.3785 - acc: 0.8583 - val_loss: 0.4034 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 131us/step - loss: 0.3696 - acc: 0.8583 - val_loss: 0.4048 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 6s 2ms/step - loss: 0.5289 - acc: 0.8308 - val_loss: 0.4385 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.4006 - acc: 0.8583 - val_loss: 0.4253 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 134us/step - loss: 0.3924 - acc: 0.8583 - val_loss: 0.4202 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 137us/step - loss: 0.3841 - acc: 0.8583 - val_loss: 0.4144 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 135us/step - loss: 0.3778 - acc: 0.8583 - val_loss: 0.4038 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 6s 2ms/step - loss: 0.5148 - acc: 0.8500 - val_loss: 0.4308 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 138us/step - loss: 0.3978 - acc: 0.8583 - val_loss: 0.4213 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 141us/step - loss: 0.3877 - acc: 0.8583 - val_loss: 0.4197 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 142us/step - loss: 0.3820 - acc: 0.8583 - val_loss: 0.4088 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 138us/step - loss: 0.3761 - acc: 0.8583 - val_loss: 0.4243 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 6s 3ms/step - loss: 0.5339 - acc: 0.8575 - val_loss: 0.4317 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 145us/step - loss: 0.4016 - acc: 0.8583 - val_loss: 0.4245 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 142us/step - loss: 0.3913 - acc: 0.8583 - val_loss: 0.4146 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3834 - acc: 0.8583 - val_loss: 0.4089 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 149us/step - loss: 0.3771 - acc: 0.8583 - val_loss: 0.4078 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 6s 3ms/step - loss: 0.5376 - acc: 0.8583 - val_loss: 0.4322 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 144us/step - loss: 0.3995 - acc: 0.8583 - val_loss: 0.4270 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3911 - acc: 0.8583 - val_loss: 0.4127 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3822 - acc: 0.8583 - val_loss: 0.4105 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 144us/step - loss: 0.3797 - acc: 0.8583 - val_loss: 0.3984 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 6s 3ms/step - loss: 0.5283 - acc: 0.8529 - val_loss: 0.4639 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3952 - acc: 0.8629 - val_loss: 0.4746 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 148us/step - loss: 0.3861 - acc: 0.8629 - val_loss: 0.4462 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 144us/step - loss: 0.3770 - acc: 0.8629 - val_loss: 0.4628 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 145us/step - loss: 0.3714 - acc: 0.8629 - val_loss: 0.4581 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 7s 3ms/step - loss: 0.5323 - acc: 0.8458 - val_loss: 0.4714 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 145us/step - loss: 0.3925 - acc: 0.8629 - val_loss: 0.4548 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 146us/step - loss: 0.3819 - acc: 0.8629 - val_loss: 0.4705 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 141us/step - loss: 0.3773 - acc: 0.8629 - val_loss: 0.4325 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 150us/step - loss: 0.3701 - acc: 0.8629 - val_loss: 0.4294 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2850 0 483 0\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "def get_RNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    import pandas as pd\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Dropout, LSTM, GRU\n",
    "    from keras.layers import Embedding\n",
    "    max_features = 10000 # number of words to consider as features\n",
    "    import numpy as np\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_RNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    \n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
