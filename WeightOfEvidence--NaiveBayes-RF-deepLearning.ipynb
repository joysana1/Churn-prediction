{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"D:\\Thesis\\BIG DATA\\Database Churn\\joy work\\Telecom_customer churn (100000).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "change_mou=num_df['change_mou']\n",
    "change_rev=num_df['change_rev']\n",
    "num_df=num_df.drop(['change_mou'], axis=1)\n",
    "num_df=num_df.drop(['change_rev'], axis=1)\n",
    "\n",
    "num_df=num_df.drop(['Customer_ID'], axis=1)\n",
    "\n",
    "churn=num_df['churn']\n",
    "num_df=num_df.drop(['churn'], axis=1)\n",
    "\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "\n",
    "X=result_df_op\n",
    "y=churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>drop_vce_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>infobase</th>\n",
       "      <th>HHstatin</th>\n",
       "      <th>dwllsize</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.556517</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>-0.022460</td>\n",
       "      <td>-0.015257</td>\n",
       "      <td>-0.014783</td>\n",
       "      <td>-0.033784</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-0.011647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025602</td>\n",
       "      <td>-0.036986</td>\n",
       "      <td>-0.045587</td>\n",
       "      <td>-0.028551</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017520</td>\n",
       "      <td>-0.164801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.022460</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>-0.107643</td>\n",
       "      <td>-0.112533</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-0.060797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025602</td>\n",
       "      <td>-0.036986</td>\n",
       "      <td>-0.045587</td>\n",
       "      <td>-0.400201</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015816</td>\n",
       "      <td>0.751490</td>\n",
       "      <td>0.094113</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>-0.015257</td>\n",
       "      <td>-0.014783</td>\n",
       "      <td>-0.033784</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-0.028216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025602</td>\n",
       "      <td>-0.036986</td>\n",
       "      <td>-0.045587</td>\n",
       "      <td>-0.028551</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>0.043076</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.081092</td>\n",
       "      <td>0.199842</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>-0.015257</td>\n",
       "      <td>-0.014783</td>\n",
       "      <td>-0.033784</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.175511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025602</td>\n",
       "      <td>-0.036986</td>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.018434</td>\n",
       "      <td>0.095326</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.270162</td>\n",
       "      <td>-0.339154</td>\n",
       "      <td>-0.136630</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>-0.015257</td>\n",
       "      <td>-0.014783</td>\n",
       "      <td>-0.033784</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>0.063701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025602</td>\n",
       "      <td>-0.036986</td>\n",
       "      <td>-0.037101</td>\n",
       "      <td>0.066336</td>\n",
       "      <td>-0.002808</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.021631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean   da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0  0.000000  0.556517     0.017520 -0.022460    -0.015257    -0.014783   \n",
       "1  0.017520 -0.164801     0.000000 -0.022460     0.045300    -0.107643   \n",
       "2 -0.015816  0.751490     0.094113  0.047296    -0.015257    -0.014783   \n",
       "3 -1.081092  0.199842     0.017520  0.047296    -0.015257    -0.014783   \n",
       "4 -0.270162 -0.339154    -0.136630  0.047296    -0.015257    -0.014783   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  drop_vce_Mean  ...  infobase  \\\n",
       "0    -0.033784     0.018887   0.014593      -0.011647  ... -0.025602   \n",
       "1    -0.112533     0.018887   0.014593      -0.060797  ... -0.025602   \n",
       "2    -0.033784     0.018887   0.014593      -0.028216  ... -0.025602   \n",
       "3    -0.033784     0.018887   0.014593       0.175511  ... -0.025602   \n",
       "4    -0.033784     0.018887   0.014593       0.063701  ... -0.025602   \n",
       "\n",
       "   HHstatin  dwllsize    ethnic    kid0_2    kid3_5   kid6_10  kid11_15  \\\n",
       "0 -0.036986 -0.045587 -0.028551 -0.002808 -0.000904  0.002464   0.00339   \n",
       "1 -0.036986 -0.045587 -0.400201 -0.002808 -0.000904  0.002464   0.00339   \n",
       "2 -0.036986 -0.045587 -0.028551 -0.002808  0.043076  0.002464   0.00339   \n",
       "3 -0.036986  0.052330  0.018434  0.095326 -0.000904  0.002464   0.00339   \n",
       "4 -0.036986 -0.037101  0.066336 -0.002808 -0.000904  0.002464   0.00339   \n",
       "\n",
       "   kid16_17  creditcd  \n",
       "0 -0.001641 -0.021631  \n",
       "1 -0.001641 -0.021631  \n",
       "2 -0.001641 -0.021631  \n",
       "3 -0.001641 -0.021631  \n",
       "4 -0.001641 -0.021631  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlencoders.weight_of_evidence_encoder import WeightOfEvidenceEncoder\n",
    "\n",
    "enc = WeightOfEvidenceEncoder(cols=X.columns)\n",
    "X_encoded = enc.fit_transform(X, y)\n",
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4943 5078]\n",
      " [1635 8344]]\n",
      "pod:  0.83615592744764\n",
      "pof:  0.5067358547051193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.60     10021\n",
      "           1       0.62      0.84      0.71      9979\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     20000\n",
      "   macro avg       0.69      0.66      0.65     20000\n",
      "weighted avg       0.69      0.66      0.65     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6647100363712604"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "print(classification_report(y_test, y_pred))  \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8009 2012]\n",
      " [2955 7024]]\n",
      "pod:  0.7038781441026155\n",
      "pof:  0.20077836543259156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76     10021\n",
      "           1       0.78      0.70      0.74      9979\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     20000\n",
      "   macro avg       0.75      0.75      0.75     20000\n",
      "weighted avg       0.75      0.75      0.75     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7515498893350121"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "print(classification_report(y_test, y_pred)) \n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/30\n",
      "64000/64000 [==============================] - 4s 55us/step - loss: 0.3618 - acc: 0.8385 - val_loss: 0.3473 - val_acc: 0.8481\n",
      "Epoch 2/30\n",
      "64000/64000 [==============================] - 3s 51us/step - loss: 0.3359 - acc: 0.8532 - val_loss: 0.3326 - val_acc: 0.8524\n",
      "Epoch 3/30\n",
      "64000/64000 [==============================] - 3s 52us/step - loss: 0.3319 - acc: 0.8550 - val_loss: 0.3356 - val_acc: 0.8516\n",
      "Epoch 4/30\n",
      "64000/64000 [==============================] - 3s 50us/step - loss: 0.3297 - acc: 0.8566 - val_loss: 0.3321 - val_acc: 0.8538\n",
      "Epoch 5/30\n",
      "64000/64000 [==============================] - 3s 50us/step - loss: 0.3282 - acc: 0.8563 - val_loss: 0.3293 - val_acc: 0.8552\n",
      "Epoch 6/30\n",
      "64000/64000 [==============================] - 3s 50us/step - loss: 0.3268 - acc: 0.8574 - val_loss: 0.3309 - val_acc: 0.8552\n",
      "Epoch 7/30\n",
      "64000/64000 [==============================] - 3s 50us/step - loss: 0.3258 - acc: 0.8582 - val_loss: 0.3310 - val_acc: 0.8544\n",
      "Epoch 8/30\n",
      "64000/64000 [==============================] - 3s 52us/step - loss: 0.3248 - acc: 0.8582 - val_loss: 0.3312 - val_acc: 0.8558\n",
      "[[8009 2012]\n",
      " [2955 7024]]\n",
      "pod:  0.7038781441026155\n",
      "pof:  0.20077836543259156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76     10021\n",
      "           1       0.78      0.70      0.74      9979\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     20000\n",
      "   macro avg       0.75      0.75      0.75     20000\n",
      "weighted avg       0.75      0.75      0.75     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7515498893350121"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#get number of columns in training data\n",
    "n_cols = X_train.shape[1]\n",
    "\n",
    "#add model layers\n",
    "#model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "#model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dense(1))\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#compile model using mse as a measure of model performance\n",
    "#model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#train model\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "#model.fit(X_train, y_train,epochs=20, batch_size=1, verbose=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "print(classification_report(y_test, y_pred))  \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
