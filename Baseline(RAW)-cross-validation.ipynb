{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"Telecom_customer churn (100000).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "change_mou=num_df['change_mou']\n",
    "change_rev=num_df['change_rev']\n",
    "num_df=num_df.drop(['change_mou'], axis=1)\n",
    "num_df=num_df.drop(['change_rev'], axis=1)\n",
    "\n",
    "num_df=num_df.drop(['Customer_ID'], axis=1)\n",
    "\n",
    "churn=num_df['churn']\n",
    "num_df=num_df.drop(['churn'], axis=1)\n",
    "\n",
    "#no convertion\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "num_df[num_df < 0]=0\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn\n",
    "\n",
    "#from sklearn.model_selection import train_test_split  \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "X_train=X\n",
    "y_train=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>drop_vce_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>infobase</th>\n",
       "      <th>HHstatin</th>\n",
       "      <th>dwllsize</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.9975</td>\n",
       "      <td>219.25</td>\n",
       "      <td>22.500</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.4925</td>\n",
       "      <td>482.75</td>\n",
       "      <td>37.425</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.9900</td>\n",
       "      <td>10.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.2300</td>\n",
       "      <td>570.50</td>\n",
       "      <td>71.980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean  da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0   23.9975    219.25       22.500   0.2475         0.00          0.0   \n",
       "1   57.4925    482.75       37.425   0.2475        22.75          9.1   \n",
       "2   16.9900     10.25       16.990   0.0000         0.00          0.0   \n",
       "3   38.0000      7.50       38.000   0.0000         0.00          0.0   \n",
       "4   55.2300    570.50       71.980   0.0000         0.00          0.0   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  drop_vce_Mean  ...  infobase  \\\n",
       "0          0.0          0.0        0.0       0.666667  ...         1   \n",
       "1          9.1          0.0        0.0       8.333333  ...         1   \n",
       "2          0.0          0.0        0.0       0.333333  ...         1   \n",
       "3          0.0          0.0        0.0       0.000000  ...         1   \n",
       "4          0.0          0.0        0.0       9.666667  ...         1   \n",
       "\n",
       "   HHstatin  dwllsize  ethnic  kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  \\\n",
       "0         3         1      10       1       1        1         1         1   \n",
       "1         3         1      17       1       1        1         1         1   \n",
       "2         3         1      10       1       2        1         1         1   \n",
       "3         3         4      15       2       1        1         1         1   \n",
       "4         3        15       7       1       1        1         1         1   \n",
       "\n",
       "   creditcd  \n",
       "0         2  \n",
       "1         2  \n",
       "2         2  \n",
       "3         2  \n",
       "4         2  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8883 41555 7187 42375\n",
      "pod:  0.8549897098583592\n",
      "pof:  0.8238827867877394\n",
      "AUC:  0.5155534615353099\n",
      "roc_auc:  0.5596483312814653\n",
      "auc:  0.5155534615353099\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28292 22146 23977 25585\n",
      "pod:  0.5162221056454542\n",
      "pof:  0.43907371426305564\n",
      "AUC:  0.5385741956911992\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28297 22141 19940 29622\n",
      "pod:  0.5976756385940841\n",
      "pof:  0.43897458265593403\n",
      "AUC:  0.5793505279690749\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:  0.579350527969075\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "auc = auc(fpr, tpr)\n",
    "print('auc: ',auc)\n",
    "plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('NO DT-ROC Curve for RF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30114 20324 20552 29010\n",
      "pod:  0.5853274686251564\n",
      "pof:  0.40295015662793926\n",
      "AUC:  0.5911886559986086\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32500 17938 26540 23022\n",
      "pod:  0.4645090997134902\n",
      "pof:  0.35564455370950476\n",
      "AUC:  0.5544322730019927\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71999 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "71999/71999 [==============================] - 24s 333us/step - loss: 2.1958 - accuracy: 0.5149 - val_loss: 0.6974 - val_accuracy: 0.4277\n",
      "Epoch 2/30\n",
      "71999/71999 [==============================] - 25s 353us/step - loss: 0.6960 - accuracy: 0.5199 - val_loss: 0.7012 - val_accuracy: 0.4119\n",
      "Epoch 3/30\n",
      "71999/71999 [==============================] - 23s 320us/step - loss: 0.7049 - accuracy: 0.5180 - val_loss: 0.6973 - val_accuracy: 0.4206\n",
      "Epoch 4/30\n",
      "71999/71999 [==============================] - 22s 304us/step - loss: 0.7009 - accuracy: 0.5177 - val_loss: 0.7010 - val_accuracy: 0.4087\n",
      "Epoch 5/30\n",
      "71999/71999 [==============================] - 23s 319us/step - loss: 0.6940 - accuracy: 0.5173 - val_loss: 0.7008 - val_accuracy: 0.4087\n",
      "Epoch 6/30\n",
      "71999/71999 [==============================] - 22s 310us/step - loss: 0.6962 - accuracy: 0.5182 - val_loss: 0.7021 - val_accuracy: 0.4100\n",
      "y2_pred:  [[0.521973 ]\n",
      " [0.521973 ]\n",
      " [0.521973 ]\n",
      " ...\n",
      " [0.521973 ]\n",
      " [0.521973 ]\n",
      " [0.5219731]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.9997982650796853\n",
      "Train on 71999 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "71999/71999 [==============================] - 22s 301us/step - loss: 1.1781 - accuracy: 0.5143 - val_loss: 0.6985 - val_accuracy: 0.4671\n",
      "Epoch 2/30\n",
      "71999/71999 [==============================] - 22s 306us/step - loss: 0.6931 - accuracy: 0.5187 - val_loss: 0.7002 - val_accuracy: 0.4128\n",
      "Epoch 3/30\n",
      "71999/71999 [==============================] - 22s 301us/step - loss: 0.6927 - accuracy: 0.5173 - val_loss: 0.7011 - val_accuracy: 0.4090\n",
      "Epoch 4/30\n",
      "71999/71999 [==============================] - 22s 308us/step - loss: 0.6927 - accuracy: 0.5173 - val_loss: 0.6972 - val_accuracy: 0.4089\n",
      "Epoch 5/30\n",
      "71999/71999 [==============================] - 21s 293us/step - loss: 0.6926 - accuracy: 0.5173 - val_loss: 0.7041 - val_accuracy: 0.4087\n",
      "Epoch 6/30\n",
      "71999/71999 [==============================] - 23s 314us/step - loss: 0.6965 - accuracy: 0.5170 - val_loss: 0.7342 - val_accuracy: 0.4088\n",
      "Epoch 7/30\n",
      "71999/71999 [==============================] - 22s 312us/step - loss: 0.6931 - accuracy: 0.5173 - val_loss: 0.6993 - val_accuracy: 0.4088\n",
      "y2_pred:  [[0.5150611]\n",
      " [0.5150611]\n",
      " [0.5150611]\n",
      " ...\n",
      " [0.5150611]\n",
      " [0.5150611]\n",
      " [0.5150611]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  1.0\n",
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 23s 320us/step - loss: 1.6251 - accuracy: 0.5162 - val_loss: 0.6960 - val_accuracy: 0.4568\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 21s 298us/step - loss: 0.6950 - accuracy: 0.5189 - val_loss: 0.7011 - val_accuracy: 0.4279\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 22s 304us/step - loss: 0.6976 - accuracy: 0.5152 - val_loss: 0.7198 - val_accuracy: 0.4097\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 22s 307us/step - loss: 0.6926 - accuracy: 0.5163 - val_loss: 0.7483 - val_accuracy: 0.4087\n",
      "y2_pred:  [[0.5168826]\n",
      " [0.5168826]\n",
      " [0.5168826]\n",
      " ...\n",
      " [0.5168826]\n",
      " [0.5168826]\n",
      " [0.5168826]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  1.0\n",
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 24s 340us/step - loss: 2.0689 - accuracy: 0.5127 - val_loss: 0.7000 - val_accuracy: 0.4664\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 25s 343us/step - loss: 0.6970 - accuracy: 0.5166 - val_loss: 0.7056 - val_accuracy: 0.4094\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 24s 328us/step - loss: 0.7036 - accuracy: 0.5173 - val_loss: 0.7014 - val_accuracy: 0.4103\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 26s 364us/step - loss: 0.7030 - accuracy: 0.5157 - val_loss: 0.6983 - val_accuracy: 0.4104\n",
      "Epoch 5/30\n",
      "72000/72000 [==============================] - 26s 361us/step - loss: 0.6967 - accuracy: 0.5184 - val_loss: 0.6995 - val_accuracy: 0.4143\n",
      "Epoch 6/30\n",
      "72000/72000 [==============================] - 23s 325us/step - loss: 0.6932 - accuracy: 0.5168 - val_loss: 0.7010 - val_accuracy: 0.4099\n",
      "Epoch 7/30\n",
      "72000/72000 [==============================] - 24s 327us/step - loss: 0.6931 - accuracy: 0.5170 - val_loss: 0.7519 - val_accuracy: 0.4099\n",
      "y2_pred:  [[0.7303229 ]\n",
      " [0.6123557 ]\n",
      " [0.63418454]\n",
      " ...\n",
      " [0.6539581 ]\n",
      " [0.6360888 ]\n",
      " [0.6641042 ]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.9995964487489911\n",
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 25s 343us/step - loss: 1.4080 - accuracy: 0.5133 - val_loss: 0.6939 - val_accuracy: 0.4113\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 25s 347us/step - loss: 0.6953 - accuracy: 0.5163 - val_loss: 0.7018 - val_accuracy: 0.4087\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 24s 334us/step - loss: 0.6928 - accuracy: 0.5172 - val_loss: 0.6964 - val_accuracy: 0.4092\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 25s 346us/step - loss: 0.6961 - accuracy: 0.5172 - val_loss: 0.6979 - val_accuracy: 0.4141\n",
      "y2_pred:  [[0.5121283]\n",
      " [0.5121283]\n",
      " [0.5121283]\n",
      " ...\n",
      " [0.5121283]\n",
      " [0.5121283]\n",
      " [0.5121283]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.9792171105730427\n",
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 24s 337us/step - loss: 1.3790 - accuracy: 0.5145 - val_loss: 0.7125 - val_accuracy: 0.4097\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 25s 344us/step - loss: 0.6926 - accuracy: 0.5205 - val_loss: 0.7026 - val_accuracy: 0.4187\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 24s 333us/step - loss: 0.6937 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.4214\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 24s 338us/step - loss: 0.6936 - accuracy: 0.5201 - val_loss: 0.6986 - val_accuracy: 0.4365\n",
      "Epoch 5/30\n",
      "72000/72000 [==============================] - 26s 354us/step - loss: 0.6925 - accuracy: 0.5187 - val_loss: 0.7067 - val_accuracy: 0.4104\n",
      "Epoch 6/30\n",
      "72000/72000 [==============================] - 24s 332us/step - loss: 0.6926 - accuracy: 0.5172 - val_loss: 0.7016 - val_accuracy: 0.4088\n",
      "y2_pred:  [[0.5207709]\n",
      " [0.5207709]\n",
      " [0.5207709]\n",
      " ...\n",
      " [0.5207709]\n",
      " [0.5207709]\n",
      " [0.5207709]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  1.0\n",
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 25s 351us/step - loss: 1.6215 - accuracy: 0.5196 - val_loss: 0.6998 - val_accuracy: 0.4433\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 25s 346us/step - loss: 0.6937 - accuracy: 0.5187 - val_loss: 0.7134 - val_accuracy: 0.4087\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 26s 357us/step - loss: 0.6976 - accuracy: 0.5180 - val_loss: 0.6993 - val_accuracy: 0.4100\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 26s 361us/step - loss: 0.6978 - accuracy: 0.5168 - val_loss: 0.7012 - val_accuracy: 0.4082\n",
      "Epoch 5/30\n",
      "72000/72000 [==============================] - 24s 330us/step - loss: 0.6927 - accuracy: 0.5173 - val_loss: 0.6984 - val_accuracy: 0.4088\n",
      "Epoch 6/30\n",
      "72000/72000 [==============================] - 26s 355us/step - loss: 0.6959 - accuracy: 0.5170 - val_loss: 0.7006 - val_accuracy: 0.4087\n",
      "Epoch 7/30\n",
      "72000/72000 [==============================] - 24s 328us/step - loss: 0.6927 - accuracy: 0.5173 - val_loss: 0.6993 - val_accuracy: 0.4086\n",
      "Epoch 8/30\n",
      "72000/72000 [==============================] - 24s 336us/step - loss: 0.6937 - accuracy: 0.5169 - val_loss: 0.7049 - val_accuracy: 0.4087\n",
      "y2_pred:  [[0.5251714]\n",
      " [0.5251714]\n",
      " [0.5251714]\n",
      " ...\n",
      " [0.5251714]\n",
      " [0.5251714]\n",
      " [0.5251714]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  1.0\n",
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 25s 354us/step - loss: 1.2950 - accuracy: 0.5077 - val_loss: 0.6981 - val_accuracy: 0.4401\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 24s 335us/step - loss: 0.6934 - accuracy: 0.5093 - val_loss: 0.6967 - val_accuracy: 0.4408\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 23s 323us/step - loss: 0.6934 - accuracy: 0.5095 - val_loss: 0.6943 - val_accuracy: 0.4397\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 23s 319us/step - loss: 0.6957 - accuracy: 0.5081 - val_loss: 0.6943 - val_accuracy: 0.4397\n",
      "Epoch 5/30\n",
      "72000/72000 [==============================] - 23s 318us/step - loss: 0.6933 - accuracy: 0.5083 - val_loss: 0.6962 - val_accuracy: 0.4396\n",
      "Epoch 6/30\n",
      "72000/72000 [==============================] - 24s 337us/step - loss: 0.6940 - accuracy: 0.5089 - val_loss: 0.7073 - val_accuracy: 0.4399\n",
      "y2_pred:  [[0.5118424]\n",
      " [0.5118424]\n",
      " [0.5118424]\n",
      " ...\n",
      " [0.5118424]\n",
      " [0.5118424]\n",
      " [0.5118424]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.9997982243744956\n",
      "Train on 72000 samples, validate on 18001 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 23s 323us/step - loss: 1.7813 - accuracy: 0.5148 - val_loss: 0.7023 - val_accuracy: 0.4198\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 23s 320us/step - loss: 0.6939 - accuracy: 0.5173 - val_loss: 0.6981 - val_accuracy: 0.4103\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 22s 310us/step - loss: 0.7178 - accuracy: 0.5160 - val_loss: 0.7008 - val_accuracy: 0.4099\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 24s 330us/step - loss: 0.7012 - accuracy: 0.5155 - val_loss: 0.6992 - val_accuracy: 0.4093\n",
      "Epoch 5/30\n",
      "72000/72000 [==============================] - 23s 316us/step - loss: 0.6928 - accuracy: 0.5171 - val_loss: 0.6987 - val_accuracy: 0.4094\n",
      "y2_pred:  [[0.51412684]\n",
      " [0.51412684]\n",
      " [0.6497271 ]\n",
      " ...\n",
      " [0.5141268 ]\n",
      " [0.5141268 ]\n",
      " [0.5080745 ]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  1.0\n",
      "Train on 72000 samples, validate on 18001 samples\n",
      "Epoch 1/30\n",
      "72000/72000 [==============================] - 23s 319us/step - loss: 1.4508 - accuracy: 0.5137 - val_loss: 0.6952 - val_accuracy: 0.4166\n",
      "Epoch 2/30\n",
      "72000/72000 [==============================] - 24s 328us/step - loss: 0.6986 - accuracy: 0.5158 - val_loss: 0.7033 - val_accuracy: 0.4094\n",
      "Epoch 3/30\n",
      "72000/72000 [==============================] - 23s 318us/step - loss: 0.6942 - accuracy: 0.5177 - val_loss: 0.6979 - val_accuracy: 0.4331\n",
      "Epoch 4/30\n",
      "72000/72000 [==============================] - 23s 321us/step - loss: 0.6946 - accuracy: 0.5168 - val_loss: 0.6961 - val_accuracy: 0.4496\n",
      "y2_pred:  [[0.5152535]\n",
      " [0.5152535]\n",
      " [0.5152535]\n",
      " ...\n",
      " [0.5152535]\n",
      " [0.5152535]\n",
      " [0.5152535]]\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.8936642453591606\n",
      "pod:  [0.9997982650796853, 1.0, 1.0, 0.9995964487489911, 0.9792171105730427, 1.0, 1.0, 0.9997982243744956, 1.0, 0.8936642453591606]\n",
      "pof:  [0.9994052339413164, 1.0, 1.0, 1.0, 0.9732355273592387, 1.0, 1.0, 0.999603489294211, 1.0, 0.8580210192345826]\n",
      "auc:  [0.5001965155691844, 0.5, 0.5, 0.4997982243744956, 0.5029907916069021, 0.5, 0.5, 0.5000973675401423, 0.5, 0.517821613062289]\n",
      "856 49582 634 48928\n"
     ]
    }
   ],
   "source": [
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(X_train,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=X_train.iloc[train_index], X_train.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71999 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "71999/71999 [==============================] - 154s 2ms/step - loss: 0.6893 - acc: 0.5377 - val_loss: 0.6836 - val_acc: 0.5614\n",
      "Epoch 2/5\n",
      "71999/71999 [==============================] - 154s 2ms/step - loss: 0.6774 - acc: 0.5738 - val_loss: 0.7093 - val_acc: 0.5218\n",
      "Epoch 3/5\n",
      "71999/71999 [==============================] - 153s 2ms/step - loss: 0.6623 - acc: 0.6037 - val_loss: 0.7278 - val_acc: 0.5089\n",
      "Epoch 4/5\n",
      "71999/71999 [==============================] - 152s 2ms/step - loss: 0.6394 - acc: 0.6358 - val_loss: 0.7040 - val_acc: 0.5682\n",
      "Epoch 5/5\n",
      "71999/71999 [==============================] - 154s 2ms/step - loss: 0.6198 - acc: 0.6579 - val_loss: 0.6950 - val_acc: 0.5822\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.40084728666532177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71999 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "71999/71999 [==============================] - 157s 2ms/step - loss: 0.6879 - acc: 0.5403 - val_loss: 0.6682 - val_acc: 0.5966\n",
      "Epoch 2/5\n",
      "71999/71999 [==============================] - 153s 2ms/step - loss: 0.6773 - acc: 0.5747 - val_loss: 0.7302 - val_acc: 0.4840\n",
      "Epoch 3/5\n",
      "71999/71999 [==============================] - 156s 2ms/step - loss: 0.6636 - acc: 0.6020 - val_loss: 0.6838 - val_acc: 0.5633\n",
      "Epoch 4/5\n",
      "71999/71999 [==============================] - 152s 2ms/step - loss: 0.6392 - acc: 0.6377 - val_loss: 0.6824 - val_acc: 0.5721\n",
      "Epoch 5/5\n",
      "71999/71999 [==============================] - 153s 2ms/step - loss: 0.6164 - acc: 0.6616 - val_loss: 0.6826 - val_acc: 0.5825\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.5874520879564252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6863 - acc: 0.5464 - val_loss: 0.6722 - val_acc: 0.5849\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6711 - acc: 0.5872 - val_loss: 0.6712 - val_acc: 0.5899\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6505 - acc: 0.6212 - val_loss: 0.6752 - val_acc: 0.5852\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6284 - acc: 0.6468 - val_loss: 0.7081 - val_acc: 0.5764\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6081 - acc: 0.6685 - val_loss: 0.6953 - val_acc: 0.5892\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.5209846650524617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6876 - acc: 0.5425 - val_loss: 0.6911 - val_acc: 0.5435\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 149s 2ms/step - loss: 0.6747 - acc: 0.5803 - val_loss: 0.6741 - val_acc: 0.5821\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 148s 2ms/step - loss: 0.6547 - acc: 0.6165 - val_loss: 0.6745 - val_acc: 0.5822\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 148s 2ms/step - loss: 0.6294 - acc: 0.6474 - val_loss: 0.6755 - val_acc: 0.5947\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 149s 2ms/step - loss: 0.6085 - acc: 0.6671 - val_loss: 0.6944 - val_acc: 0.5771\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.5667877320419693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 154s 2ms/step - loss: 0.6870 - acc: 0.5436 - val_loss: 0.6906 - val_acc: 0.5458\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6726 - acc: 0.5846 - val_loss: 0.6700 - val_acc: 0.5853\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6484 - acc: 0.6243 - val_loss: 0.6744 - val_acc: 0.5793\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6256 - acc: 0.6524 - val_loss: 0.6804 - val_acc: 0.5863\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6027 - acc: 0.6749 - val_loss: 0.7358 - val_acc: 0.5417\n",
      "y22_pred:  [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "pod 1st:  0.7082324455205811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6875 - acc: 0.5427 - val_loss: 0.6690 - val_acc: 0.5890\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 154s 2ms/step - loss: 0.6751 - acc: 0.5785 - val_loss: 0.6809 - val_acc: 0.5622\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6596 - acc: 0.6093 - val_loss: 0.6870 - val_acc: 0.5636\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6343 - acc: 0.6430 - val_loss: 0.6923 - val_acc: 0.5686\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6123 - acc: 0.6642 - val_loss: 0.7215 - val_acc: 0.5735\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.5328894269572235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 154s 2ms/step - loss: 0.6862 - acc: 0.5454 - val_loss: 0.6945 - val_acc: 0.5299\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6718 - acc: 0.5823 - val_loss: 0.6868 - val_acc: 0.5707\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 154s 2ms/step - loss: 0.6502 - acc: 0.6179 - val_loss: 0.6791 - val_acc: 0.5766\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6271 - acc: 0.6472 - val_loss: 0.7232 - val_acc: 0.5508\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6060 - acc: 0.6676 - val_loss: 0.7031 - val_acc: 0.5670\n",
      "y22_pred:  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "pod 1st:  0.5062550443906376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6877 - acc: 0.5410 - val_loss: 0.6870 - val_acc: 0.5441\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 150s 2ms/step - loss: 0.6790 - acc: 0.5699 - val_loss: 0.6899 - val_acc: 0.5380\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6660 - acc: 0.5971 - val_loss: 0.7026 - val_acc: 0.5364\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 151s 2ms/step - loss: 0.6434 - acc: 0.6328 - val_loss: 0.7105 - val_acc: 0.5318\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 151s 2ms/step - loss: 0.6195 - acc: 0.6598 - val_loss: 0.7197 - val_acc: 0.5537\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "pod 1st:  0.46246973365617433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18001 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6889 - acc: 0.5389 - val_loss: 0.6788 - val_acc: 0.5764\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6771 - acc: 0.5774 - val_loss: 0.6871 - val_acc: 0.5475\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6604 - acc: 0.6060 - val_loss: 0.7289 - val_acc: 0.5040\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6370 - acc: 0.6375 - val_loss: 0.7110 - val_acc: 0.5609\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 153s 2ms/step - loss: 0.6170 - acc: 0.6577 - val_loss: 0.7102 - val_acc: 0.5545\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "pod 1st:  0.5659806295399515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72000 samples, validate on 18001 samples\n",
      "Epoch 1/5\n",
      "72000/72000 [==============================] - 151s 2ms/step - loss: 0.6885 - acc: 0.5374 - val_loss: 0.6776 - val_acc: 0.5742\n",
      "Epoch 2/5\n",
      "72000/72000 [==============================] - 152s 2ms/step - loss: 0.6768 - acc: 0.5756 - val_loss: 0.6714 - val_acc: 0.5780\n",
      "Epoch 3/5\n",
      "72000/72000 [==============================] - 151s 2ms/step - loss: 0.6604 - acc: 0.6061 - val_loss: 0.7294 - val_acc: 0.5091\n",
      "Epoch 4/5\n",
      "72000/72000 [==============================] - 151s 2ms/step - loss: 0.6375 - acc: 0.6364 - val_loss: 0.7185 - val_acc: 0.5324\n",
      "Epoch 5/5\n",
      "72000/72000 [==============================] - 151s 2ms/step - loss: 0.6161 - acc: 0.6600 - val_loss: 0.7393 - val_acc: 0.5388\n",
      "y22_pred:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.6364003228410008\n",
      "pod:  [0.40084728666532177, 0.5874520879564252, 0.5209846650524617, 0.5667877320419693, 0.7082324455205811, 0.5328894269572235, 0.5062550443906376, 0.46246973365617433, 0.5659806295399515, 0.6364003228410008]\n",
      "pof:  [0.3287073750991277, 0.5214115781126091, 0.4704599524187153, 0.5202220459952419, 0.669706582077716, 0.5041633624107851, 0.45975416336241076, 0.4351704996034893, 0.4558794368431489, 0.545310331152092]\n",
      "auc:  [0.5360699557830971, 0.5330202549219081, 0.5252623563168732, 0.5232828430233638, 0.5192629317214326, 0.5143630322732192, 0.5232504405141135, 0.5136496170263425, 0.5550505963484013, 0.5455449958444543]\n",
      "25669 24769 22361 27201\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "def get_RNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    import pandas as pd\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Dropout, LSTM, GRU\n",
    "    from keras.layers import Embedding\n",
    "    max_features = 400000 # number of words to consider as features\n",
    "    import numpy as np\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(X_train,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=X_train.iloc[train_index], X_train.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_RNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    \n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN - 1D CNN\n",
    "def get_CNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras import layers\n",
    "    from keras.optimizers import RMSprop\n",
    "    max_features = 400000 # number of words to consider as features\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(max_features, 128, input_length=96))\n",
    "    model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(5))\n",
    "    model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(X_train,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=X_train.iloc[train_index], X_train.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_CNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print ('tn mean: ',sum(tn_list) / len(tn_list))\n",
    "print ('fp mean: ',sum(fp_list) / len(fp_list))\n",
    "print ('fn mean: ',sum(fn_list) / len(fn_list))\n",
    "print ('tp mean: ',sum(tp_list) / len(tp_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26402 24036 23515 26047\n",
      "pod:  0.5255437633670957\n",
      "pof:  0.476545461755026\n",
      "AUC:  0.5244991508060348\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28087 22351 18218 31344\n",
      "pod:  0.63241999919293\n",
      "pof:  0.44313811015504184\n",
      "AUC:  0.5946409445189441\n",
      "accuracy:  0.59431\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
