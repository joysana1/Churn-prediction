{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"churn-data-3333.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>number_vmail_messages</th>\n",
       "      <th>total_day_minutes</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_day_charge</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_length  area_code  number_vmail_messages  total_day_minutes  \\\n",
       "0             128        415                     25              265.1   \n",
       "1             107        415                     26              161.6   \n",
       "2             137        415                      0              243.4   \n",
       "3              84        408                      0              299.4   \n",
       "4              75        415                      0              166.7   \n",
       "\n",
       "   total_day_calls  total_day_charge  total_eve_minutes  total_eve_calls  \\\n",
       "0              110             45.07              197.4               99   \n",
       "1              123             27.47              195.5              103   \n",
       "2              114             41.38              121.2              110   \n",
       "3               71             50.90               61.9               88   \n",
       "4              113             28.34              148.3              122   \n",
       "\n",
       "   total_eve_charge  total_night_minutes  total_night_calls  \\\n",
       "0             16.78                244.7                 91   \n",
       "1             16.62                254.4                103   \n",
       "2             10.30                162.6                104   \n",
       "3              5.26                196.9                 89   \n",
       "4             12.61                186.9                121   \n",
       "\n",
       "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
       "0               11.01                10.0                 3   \n",
       "1               11.45                13.7                 3   \n",
       "2                7.32                12.2                 5   \n",
       "3                8.86                 6.6                 7   \n",
       "4                8.41                10.1                 3   \n",
       "\n",
       "   total_intl_charge  number_customer_service_calls  \n",
       "0               2.70                              1  \n",
       "1               3.70                              1  \n",
       "2               3.29                              0  \n",
       "3               1.78                              2  \n",
       "4               2.73                              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "cat_df = df.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = cat_df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "import numpy as np\n",
    "#conData=np.log(0.00001 + 1)\n",
    "conData=0\n",
    "cat_df=cat_df.fillna(conData)\n",
    "num_df=num_df.fillna(conData)\n",
    "cat_df=cat_df.astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "#cat_df[categorical_cols].head(10)\n",
    "\n",
    "\n",
    "churn=cat_df['churn']\n",
    "cat_df=cat_df.drop(['churn'], axis=1)\n",
    "cat_df=cat_df.drop(['phone number'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#BOX-COX\n",
    "lemda=0.5\n",
    "num_df=(num_df**lemda)\n",
    "num_df=num_df-1\n",
    "num_df[num_df < 0]=0\n",
    "num_df=num_df.div(lemda)\n",
    "#End BOX-COX\n",
    "#Z-score\n",
    "#num_df=(num_df-num_df.min())/(num_df.std(ddof=0)) ##Z-score\n",
    "\n",
    "#Log\n",
    "#num_df=round(np.log(num_df.add(1)),2)\n",
    "#num_df=num_df.replace([np.inf, -np.inf], np.nan)\n",
    "#End Log\n",
    "\n",
    "num_df=num_df.fillna(conData)\n",
    "\n",
    "result_df = pd.concat([num_df, cat_df], axis=1)\n",
    "np.nan_to_num(result_df)\n",
    "\n",
    "result_df_op=result_df\n",
    "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
    "#result_df_op=np.nan_to_num(result_df_op)\n",
    "\n",
    "X=result_df_op\n",
    "#y=result_df['churn'] \n",
    "y=churn\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "X_train=X\n",
    "X_test=X\n",
    "y_train=y\n",
    "y_test=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>international_plan</td>\n",
       "      <td>203.244178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>number_vmail_messages</td>\n",
       "      <td>196.644554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number_customer_service_calls</td>\n",
       "      <td>150.736535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_day_minutes</td>\n",
       "      <td>77.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_day_charge</td>\n",
       "      <td>36.515370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>voice_mail_plan</td>\n",
       "      <td>25.156959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_eve_minutes</td>\n",
       "      <td>14.259848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_intl_calls</td>\n",
       "      <td>8.091901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_eve_charge</td>\n",
       "      <td>5.088664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_intl_minutes</td>\n",
       "      <td>2.906557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_night_minutes</td>\n",
       "      <td>2.608304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_intl_charge</td>\n",
       "      <td>2.222345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>state</td>\n",
       "      <td>1.701057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>account_length</td>\n",
       "      <td>1.095845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_night_charge</td>\n",
       "      <td>0.773380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_day_calls</td>\n",
       "      <td>0.133499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_eve_calls</td>\n",
       "      <td>0.079657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_night_calls</td>\n",
       "      <td>0.022241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>area_code</td>\n",
       "      <td>0.012412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Feature      Scores\n",
       "17             international_plan  203.244178\n",
       "2           number_vmail_messages  196.644554\n",
       "15  number_customer_service_calls  150.736535\n",
       "3               total_day_minutes   77.940600\n",
       "5                total_day_charge   36.515370\n",
       "18                voice_mail_plan   25.156959\n",
       "6               total_eve_minutes   14.259848\n",
       "13               total_intl_calls    8.091901\n",
       "8                total_eve_charge    5.088664\n",
       "12             total_intl_minutes    2.906557\n",
       "9             total_night_minutes    2.608304\n",
       "14              total_intl_charge    2.222345\n",
       "16                          state    1.701057\n",
       "0                  account_length    1.095845\n",
       "11             total_night_charge    0.773380\n",
       "4                 total_day_calls    0.133499\n",
       "7                 total_eve_calls    0.079657\n",
       "10              total_night_calls    0.022241\n",
       "1                       area_code    0.012412"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X\n",
    "y_train=y\n",
    "#Univariate Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "select_feature = SelectKBest(chi2, k=15).fit(X_train, y_train)\n",
    "selected_features_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                     'Scores':select_feature.scores_})\n",
    "selected_features_df.sort_values(by='Scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=y\n",
    "x_train_chi = select_feature.transform(X)\n",
    "x_train_chi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2620 230 262 221\n",
      "pod:  0.4575569358178054\n",
      "pof:  0.08070175438596491\n",
      "AUC:  0.6884275907159202\n",
      "accuracy:  0.8523852385238524\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB()\n",
    "\n",
    "classifier.fit(X,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.001873817422860383}\n",
      "GaussianNB(priors=None, var_smoothing=0.001873817422860383)\n",
      "0.8788878887888789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:    9.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=5, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "classifier=GaussianNB();\n",
    "#params = {\n",
    "#          \"priors\" : \"None\",\n",
    "#          \"var_smoothing\" : 1e-9\n",
    "#}\n",
    "#create an list of var_smoothing to cross validate\n",
    "#steps = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "grid = GridSearchCV(estimator=classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    " \n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26710 23728 21590 27972\n",
      "pod:  0.5643840038739357\n",
      "pof:  0.4704389547563345\n",
      "AUC:  0.5469725245588006\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2825 25 379 104\n",
      "pod:  0.2153209109730849\n",
      "pof:  0.008771929824561403\n",
      "AUC:  0.6032744905742617\n",
      "accuracy:  0.8787878787878788\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "classifier = GaussianNB(priors=None, var_smoothing=0.001873817422860383)\n",
    "\n",
    "classifier.fit(x_train_chi,y_train)\n",
    "\n",
    "\n",
    "cv_method = RepeatedKFold(n_splits=10, \n",
    "                          n_repeats=3, \n",
    "                          random_state=999)\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 5)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.54812\n"
     ]
    }
   ],
   "source": [
    " #accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "accuracy=(26836+27976)/(27976+22462+22726+26836)\n",
    "print ('accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 555.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 3133.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 3152.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 8, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression(C=8, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.57708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},    \n",
    "    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}\n",
    "]\n",
    " \n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2771 79 392 91\n",
      "pod:  0.18840579710144928\n",
      "pof:  0.027719298245614036\n",
      "AUC:  0.5803432494279176\n",
      "accuracy:  0.8586858685868587\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression(C=8, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2774 76 391 92\n",
      "pod:  0.19047619047619047\n",
      "pof:  0.02666666666666667\n",
      "AUC:  0.5819047619047619\n",
      "accuracy:  0.8598859885988599\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "classifier = LogisticRegression(C=8, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, max_iter=100,\n",
    "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 88.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
      "                     weights='uniform')\n",
      "0.54095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "\n",
    "# Specify parameters\n",
    "c_values = list(np.arange(1, 10))\n",
    "param_grid ={\n",
    "   'n_neighbors': [3,5,11,19],\n",
    "   'weights': ['uniform', 'distance'],\n",
    "   'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=3, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 42 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 410.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 1993.6min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "# Specify parameters\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 1e-3, 1e-4]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear'], \n",
    "                     'gamma': [0.001, 0.01, 0.1, 1, 1e-3, 1e-4], \n",
    "                     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]} ]\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2848 2 399 84\n",
      "pod:  0.17391304347826086\n",
      "pof:  0.0007017543859649122\n",
      "AUC:  0.5866056445461479\n",
      "accuracy:  0.8796879687968797\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(metric='manhattan', weights='uniform', n_neighbors=19 )  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813 37 387 96\n",
      "pod:  0.19875776397515527\n",
      "pof:  0.012982456140350877\n",
      "AUC:  0.5928876539174022\n",
      "accuracy:  0.8727872787278728\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier = KNeighborsClassifier(n_neighbors=5)  \n",
    "classifier.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=80, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=8,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.9516951695169517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "\n",
    "#clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "#parameters = {'n_estimators': [4, 6, 9], \n",
    "#              'max_features': ['log2', 'sqrt','auto'], \n",
    "#              'criterion': ['entropy', 'gini'],\n",
    "#              'max_depth': [2, 3, 5, 10], \n",
    "#              'min_samples_split': [2, 3, 5],\n",
    "#              'min_samples_leaf': [1,5,8]\n",
    "#             }\n",
    "\n",
    "#model_params = {\n",
    "#    'n_estimators': [50, 150, 250],\n",
    "#    'max_features': ['sqrt', 0.25, 0.5, 0.75, 1.0],\n",
    "#    'min_samples_split': [2, 4, 6]\n",
    "#}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2829 21 136 347\n",
      "pod:  0.7184265010351967\n",
      "pof:  0.007368421052631579\n",
      "AUC:  0.8555290399912826\n",
      "accuracy:  0.9528952895289529\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=80, max_features=3, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=3, min_samples_split=8,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2849 1 473 10\n",
      "pod:  0.020703933747412008\n",
      "pof:  0.0003508771929824561\n",
      "AUC:  0.5101765282772147\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier =RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"n_estimators\":[10]\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=10, n_jobs=-1)\n",
    "\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2711 139 131 352\n",
      "pod:  0.7287784679089027\n",
      "pof:  0.048771929824561404\n",
      "AUC:  0.8400032690421706\n",
      "accuracy:  0.918991899189919\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2713 137 133 350\n",
      "pod:  0.7246376811594203\n",
      "pof:  0.04807017543859649\n",
      "AUC:  0.8382837528604119\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2811 39 131 352\n",
      "pod:  0.7287784679089027\n",
      "pof:  0.01368421052631579\n",
      "AUC:  0.8575471286912935\n",
      "accuracy:  0.948994899489949\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#classifier = GradientBoostingClassifier(max_features=None, max_depth=3, criterion='friedman_mse')\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(x_train_chi, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2809 41 128 355\n",
      "pod:  0.7349896480331263\n",
      "pof:  0.014385964912280702\n",
      "AUC:  0.8603018415604229\n",
      "accuracy:  0.9492949294929492\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier.fit(X_train, y_train) \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred  = cross_val_predict(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_train, y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "pod=tp/(tp+fn)\n",
    "\n",
    "print('pod: ',pod)\n",
    "pof=fp/(fp+tn)\n",
    "print ('pof: ',pof)\n",
    "auc_val=(1+pod-pof)/2\n",
    "print ('AUC: ',auc_val)\n",
    "\n",
    "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
    "print ('accuracy: ',accuracy)\n",
    "\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#roc_auc = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10,  scoring='roc_auc')\n",
    "#print('roc_auc: ',roc_auc.mean())\n",
    "\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#fpr, tpr, thresholds = roc_curve(y_train, y_pred)\n",
    "#auc = auc(fpr, tpr)\n",
    "#print('auc: ',auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 0s 195us/step - loss: 0.4372 - acc: 0.8512 - val_loss: 0.4455 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.4151 - acc: 0.8587 - val_loss: 0.4712 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 54us/step - loss: 0.4211 - acc: 0.8587 - val_loss: 0.4694 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 55us/step - loss: 0.4217 - acc: 0.8587 - val_loss: 0.4471 - val_acc: 0.8417\n",
      "y2_pred:  [[0.22620884]\n",
      " [0.18191695]\n",
      " [0.28376943]\n",
      " [0.1968593 ]\n",
      " [0.23015067]\n",
      " [0.24896082]\n",
      " [0.21046281]\n",
      " [0.2776983 ]\n",
      " [0.28059313]\n",
      " [0.13973495]\n",
      " [0.2278344 ]\n",
      " [0.21063894]\n",
      " [0.35562384]\n",
      " [0.27536252]\n",
      " [0.21740815]\n",
      " [0.29969406]\n",
      " [0.17261985]\n",
      " [0.2610104 ]\n",
      " [0.1822336 ]\n",
      " [0.20870665]\n",
      " [0.28044158]\n",
      " [0.210527  ]\n",
      " [0.24769276]\n",
      " [0.21550852]\n",
      " [0.20670724]\n",
      " [0.2588492 ]\n",
      " [0.15451798]\n",
      " [0.2973212 ]\n",
      " [0.24741817]\n",
      " [0.26886743]\n",
      " [0.21936968]\n",
      " [0.23383239]\n",
      " [0.22267133]\n",
      " [0.17644095]\n",
      " [0.17990333]\n",
      " [0.16105765]\n",
      " [0.13822687]\n",
      " [0.24225771]\n",
      " [0.10452533]\n",
      " [0.2798962 ]\n",
      " [0.29581562]\n",
      " [0.1705077 ]\n",
      " [0.13697985]\n",
      " [0.30156517]\n",
      " [0.1764988 ]\n",
      " [0.19478384]\n",
      " [0.29240626]\n",
      " [0.28253567]\n",
      " [0.32413197]\n",
      " [0.25698492]\n",
      " [0.234943  ]\n",
      " [0.26647437]\n",
      " [0.12875414]\n",
      " [0.21281633]\n",
      " [0.18308717]\n",
      " [0.23942313]\n",
      " [0.2914158 ]\n",
      " [0.24168822]\n",
      " [0.23762721]\n",
      " [0.2511179 ]\n",
      " [0.32770064]\n",
      " [0.17337087]\n",
      " [0.22312102]\n",
      " [0.17848572]\n",
      " [0.24305558]\n",
      " [0.12622553]\n",
      " [0.20439276]\n",
      " [0.31398207]\n",
      " [0.28139922]\n",
      " [0.26038468]\n",
      " [0.21591833]\n",
      " [0.21100822]\n",
      " [0.29436487]\n",
      " [0.29194707]\n",
      " [0.29916793]\n",
      " [0.2910825 ]\n",
      " [0.25564128]\n",
      " [0.25628576]\n",
      " [0.27770847]\n",
      " [0.25293696]\n",
      " [0.24036637]\n",
      " [0.21190268]\n",
      " [0.19861284]\n",
      " [0.18033785]\n",
      " [0.25793433]\n",
      " [0.13607192]\n",
      " [0.29242903]\n",
      " [0.22449714]\n",
      " [0.16540802]\n",
      " [0.27942607]\n",
      " [0.2898487 ]\n",
      " [0.31614655]\n",
      " [0.19700715]\n",
      " [0.23679101]\n",
      " [0.25932115]\n",
      " [0.30998665]\n",
      " [0.27582133]\n",
      " [0.28960854]\n",
      " [0.31375855]\n",
      " [0.23470998]\n",
      " [0.22206724]\n",
      " [0.310834  ]\n",
      " [0.20249662]\n",
      " [0.21446285]\n",
      " [0.283989  ]\n",
      " [0.28309578]\n",
      " [0.19241783]\n",
      " [0.20003575]\n",
      " [0.20851365]\n",
      " [0.191109  ]\n",
      " [0.30782863]\n",
      " [0.28791285]\n",
      " [0.24056712]\n",
      " [0.22403124]\n",
      " [0.1888054 ]\n",
      " [0.15716165]\n",
      " [0.31754807]\n",
      " [0.27191776]\n",
      " [0.22101778]\n",
      " [0.31221265]\n",
      " [0.2293505 ]\n",
      " [0.1892713 ]\n",
      " [0.29151583]\n",
      " [0.34980035]\n",
      " [0.21772522]\n",
      " [0.23430678]\n",
      " [0.31539816]\n",
      " [0.18587655]\n",
      " [0.21260384]\n",
      " [0.19156972]\n",
      " [0.30499673]\n",
      " [0.23402128]\n",
      " [0.24360156]\n",
      " [0.223207  ]\n",
      " [0.23931903]\n",
      " [0.2220358 ]\n",
      " [0.20068467]\n",
      " [0.2889424 ]\n",
      " [0.13674712]\n",
      " [0.2288751 ]\n",
      " [0.26101816]\n",
      " [0.18394107]\n",
      " [0.29074973]\n",
      " [0.21463299]\n",
      " [0.17137891]\n",
      " [0.32245475]\n",
      " [0.21054497]\n",
      " [0.26763663]\n",
      " [0.3125593 ]\n",
      " [0.16105428]\n",
      " [0.29344064]\n",
      " [0.18286014]\n",
      " [0.19765565]\n",
      " [0.24988481]\n",
      " [0.19085696]\n",
      " [0.26929936]\n",
      " [0.25770712]\n",
      " [0.1878644 ]\n",
      " [0.2406565 ]\n",
      " [0.20711225]\n",
      " [0.25315243]\n",
      " [0.2106632 ]\n",
      " [0.18031585]\n",
      " [0.22173253]\n",
      " [0.2882589 ]\n",
      " [0.1813483 ]\n",
      " [0.21254387]\n",
      " [0.27028093]\n",
      " [0.13195658]\n",
      " [0.2804731 ]\n",
      " [0.23021057]\n",
      " [0.20332891]\n",
      " [0.15849817]\n",
      " [0.22382489]\n",
      " [0.31141466]\n",
      " [0.27191174]\n",
      " [0.26326302]\n",
      " [0.30268863]\n",
      " [0.22436306]\n",
      " [0.315251  ]\n",
      " [0.13750881]\n",
      " [0.24789712]\n",
      " [0.16640756]\n",
      " [0.19275051]\n",
      " [0.29720485]\n",
      " [0.20893091]\n",
      " [0.21877924]\n",
      " [0.12628475]\n",
      " [0.21319252]\n",
      " [0.16837567]\n",
      " [0.27250147]\n",
      " [0.20427611]\n",
      " [0.28447986]\n",
      " [0.30655402]\n",
      " [0.25760573]\n",
      " [0.24468213]\n",
      " [0.16852257]\n",
      " [0.2707554 ]\n",
      " [0.207566  ]\n",
      " [0.19092453]\n",
      " [0.15962154]\n",
      " [0.23558614]\n",
      " [0.2627526 ]\n",
      " [0.2860154 ]\n",
      " [0.24466228]\n",
      " [0.1892333 ]\n",
      " [0.28410682]\n",
      " [0.18189475]\n",
      " [0.24887604]\n",
      " [0.22081369]\n",
      " [0.2704072 ]\n",
      " [0.21307853]\n",
      " [0.2441388 ]\n",
      " [0.14981866]\n",
      " [0.23960605]\n",
      " [0.25812635]\n",
      " [0.29399836]\n",
      " [0.25388312]\n",
      " [0.31821364]\n",
      " [0.2594731 ]\n",
      " [0.16966346]\n",
      " [0.16744733]\n",
      " [0.27914822]\n",
      " [0.25236875]\n",
      " [0.20880747]\n",
      " [0.2732126 ]\n",
      " [0.30261886]\n",
      " [0.20884827]\n",
      " [0.23153111]\n",
      " [0.19859761]\n",
      " [0.29214922]\n",
      " [0.18578559]\n",
      " [0.27157438]\n",
      " [0.27483976]\n",
      " [0.2566375 ]\n",
      " [0.31198066]\n",
      " [0.14053455]\n",
      " [0.24483025]\n",
      " [0.21235722]\n",
      " [0.2541468 ]\n",
      " [0.243521  ]\n",
      " [0.2441161 ]\n",
      " [0.24296778]\n",
      " [0.19688863]\n",
      " [0.16707918]\n",
      " [0.17088318]\n",
      " [0.1657013 ]\n",
      " [0.2124292 ]\n",
      " [0.26204306]\n",
      " [0.2122463 ]\n",
      " [0.11481071]\n",
      " [0.25167036]\n",
      " [0.2801085 ]\n",
      " [0.17390281]\n",
      " [0.25983956]\n",
      " [0.16345909]\n",
      " [0.26300147]\n",
      " [0.20680639]\n",
      " [0.2335299 ]\n",
      " [0.22332785]\n",
      " [0.14925   ]\n",
      " [0.30314916]\n",
      " [0.28492677]\n",
      " [0.21721604]\n",
      " [0.31571263]\n",
      " [0.14209303]\n",
      " [0.17525601]\n",
      " [0.20148933]\n",
      " [0.20508069]\n",
      " [0.312585  ]\n",
      " [0.22493604]\n",
      " [0.25265998]\n",
      " [0.12258443]\n",
      " [0.21587709]\n",
      " [0.17838004]\n",
      " [0.25473502]\n",
      " [0.30601323]\n",
      " [0.1864106 ]\n",
      " [0.14126927]\n",
      " [0.21846941]\n",
      " [0.29889965]\n",
      " [0.27412742]\n",
      " [0.15584117]\n",
      " [0.21487102]\n",
      " [0.22941244]\n",
      " [0.17435858]\n",
      " [0.30194068]\n",
      " [0.25305265]\n",
      " [0.26211578]\n",
      " [0.2300325 ]\n",
      " [0.1929163 ]\n",
      " [0.32005918]\n",
      " [0.23304933]\n",
      " [0.1806429 ]\n",
      " [0.14674756]\n",
      " [0.30820817]\n",
      " [0.2409713 ]\n",
      " [0.21166274]\n",
      " [0.28444314]\n",
      " [0.2345469 ]\n",
      " [0.25503153]\n",
      " [0.302338  ]\n",
      " [0.22931483]\n",
      " [0.27369833]\n",
      " [0.17920348]\n",
      " [0.32302654]\n",
      " [0.22384518]\n",
      " [0.3243128 ]\n",
      " [0.26119792]\n",
      " [0.2945509 ]\n",
      " [0.24814585]\n",
      " [0.18475515]\n",
      " [0.14699918]\n",
      " [0.23779985]\n",
      " [0.24289119]\n",
      " [0.2556399 ]\n",
      " [0.1899327 ]\n",
      " [0.2502308 ]\n",
      " [0.23595989]\n",
      " [0.24224973]\n",
      " [0.25102222]\n",
      " [0.14197597]\n",
      " [0.2106883 ]\n",
      " [0.21855259]\n",
      " [0.1771999 ]\n",
      " [0.22567868]\n",
      " [0.11189699]\n",
      " [0.18643183]\n",
      " [0.27739558]\n",
      " [0.25377658]\n",
      " [0.2846463 ]\n",
      " [0.23471276]\n",
      " [0.28093395]\n",
      " [0.21134241]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2399/2399 [==============================] - 1s 218us/step - loss: 0.4226 - acc: 0.8583 - val_loss: 0.4430 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 52us/step - loss: 0.4166 - acc: 0.8587 - val_loss: 0.4368 - val_acc: 0.8417\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2399/2399 [==============================] - 0s 55us/step - loss: 0.4067 - acc: 0.8587 - val_loss: 0.4380 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 55us/step - loss: 0.4067 - acc: 0.8587 - val_loss: 0.4354 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.4011 - acc: 0.8587 - val_loss: 0.4308 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 57us/step - loss: 0.3969 - acc: 0.8587 - val_loss: 0.4633 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.4028 - acc: 0.8587 - val_loss: 0.4294 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.3962 - acc: 0.8587 - val_loss: 0.4287 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 54us/step - loss: 0.3937 - acc: 0.8587 - val_loss: 0.4232 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 54us/step - loss: 0.3877 - acc: 0.8595 - val_loss: 0.4289 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 54us/step - loss: 0.3856 - acc: 0.8595 - val_loss: 0.4250 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3828 - acc: 0.8599 - val_loss: 0.4297 - val_acc: 0.8367\n",
      "y2_pred:  [[0.08027998]\n",
      " [0.23932791]\n",
      " [0.13346261]\n",
      " [0.04774308]\n",
      " [0.19302413]\n",
      " [0.09942296]\n",
      " [0.1168361 ]\n",
      " [0.20515391]\n",
      " [0.2128821 ]\n",
      " [0.10485968]\n",
      " [0.08743629]\n",
      " [0.04105589]\n",
      " [0.02923536]\n",
      " [0.09082022]\n",
      " [0.12272272]\n",
      " [0.10444245]\n",
      " [0.1598301 ]\n",
      " [0.04370883]\n",
      " [0.11259133]\n",
      " [0.02985594]\n",
      " [0.16867739]\n",
      " [0.09028885]\n",
      " [0.16167122]\n",
      " [0.12772688]\n",
      " [0.12955752]\n",
      " [0.1148268 ]\n",
      " [0.06890795]\n",
      " [0.03901315]\n",
      " [0.04926726]\n",
      " [0.16957837]\n",
      " [0.26321527]\n",
      " [0.15402865]\n",
      " [0.3128836 ]\n",
      " [0.02872401]\n",
      " [0.12777078]\n",
      " [0.1262246 ]\n",
      " [0.16863182]\n",
      " [0.14024648]\n",
      " [0.09369928]\n",
      " [0.09880185]\n",
      " [0.06272089]\n",
      " [0.13814059]\n",
      " [0.1264219 ]\n",
      " [0.20455891]\n",
      " [0.12311894]\n",
      " [0.138742  ]\n",
      " [0.31117022]\n",
      " [0.13054985]\n",
      " [0.28544188]\n",
      " [0.04190478]\n",
      " [0.13359052]\n",
      " [0.15494964]\n",
      " [0.02446663]\n",
      " [0.28022867]\n",
      " [0.06999081]\n",
      " [0.10222071]\n",
      " [0.09062505]\n",
      " [0.04893589]\n",
      " [0.17173874]\n",
      " [0.2838806 ]\n",
      " [0.05800173]\n",
      " [0.01154655]\n",
      " [0.13069516]\n",
      " [0.21566159]\n",
      " [0.12926435]\n",
      " [0.05547965]\n",
      " [0.0152486 ]\n",
      " [0.10868424]\n",
      " [0.08128861]\n",
      " [0.17339954]\n",
      " [0.20538568]\n",
      " [0.1401397 ]\n",
      " [0.10294122]\n",
      " [0.11215556]\n",
      " [0.35820347]\n",
      " [0.15901   ]\n",
      " [0.2355333 ]\n",
      " [0.07251561]\n",
      " [0.2873097 ]\n",
      " [0.2921772 ]\n",
      " [0.21923491]\n",
      " [0.07472637]\n",
      " [0.12271181]\n",
      " [0.1169709 ]\n",
      " [0.07635835]\n",
      " [0.10272178]\n",
      " [0.14292896]\n",
      " [0.26674286]\n",
      " [0.11878356]\n",
      " [0.04532436]\n",
      " [0.04776832]\n",
      " [0.12546214]\n",
      " [0.16962236]\n",
      " [0.04539716]\n",
      " [0.11282513]\n",
      " [0.0423294 ]\n",
      " [0.12004322]\n",
      " [0.15465766]\n",
      " [0.11576816]\n",
      " [0.15404189]\n",
      " [0.18088254]\n",
      " [0.1552006 ]\n",
      " [0.13725322]\n",
      " [0.2763958 ]\n",
      " [0.07941008]\n",
      " [0.14823616]\n",
      " [0.02873275]\n",
      " [0.0743719 ]\n",
      " [0.0294998 ]\n",
      " [0.23719245]\n",
      " [0.13938767]\n",
      " [0.03179589]\n",
      " [0.14580992]\n",
      " [0.2763958 ]\n",
      " [0.11412016]\n",
      " [0.11535013]\n",
      " [0.03888974]\n",
      " [0.03684765]\n",
      " [0.07118464]\n",
      " [0.04664707]\n",
      " [0.17289484]\n",
      " [0.15156254]\n",
      " [0.03863215]\n",
      " [0.14132613]\n",
      " [0.04943457]\n",
      " [0.10704812]\n",
      " [0.1021452 ]\n",
      " [0.09709787]\n",
      " [0.1211552 ]\n",
      " [0.10800523]\n",
      " [0.06367794]\n",
      " [0.26083118]\n",
      " [0.03029248]\n",
      " [0.07673508]\n",
      " [0.01869908]\n",
      " [0.02484894]\n",
      " [0.21410978]\n",
      " [0.08683622]\n",
      " [0.10356316]\n",
      " [0.02855954]\n",
      " [0.08731708]\n",
      " [0.07041866]\n",
      " [0.17619413]\n",
      " [0.03693387]\n",
      " [0.04049191]\n",
      " [0.07463744]\n",
      " [0.16660258]\n",
      " [0.16558796]\n",
      " [0.0914456 ]\n",
      " [0.05865854]\n",
      " [0.08295688]\n",
      " [0.0900715 ]\n",
      " [0.18052462]\n",
      " [0.05803663]\n",
      " [0.24165389]\n",
      " [0.07285559]\n",
      " [0.05704993]\n",
      " [0.06984648]\n",
      " [0.09477445]\n",
      " [0.05614826]\n",
      " [0.21214917]\n",
      " [0.15250388]\n",
      " [0.04551479]\n",
      " [0.11043525]\n",
      " [0.28764504]\n",
      " [0.02896827]\n",
      " [0.08007407]\n",
      " [0.03006956]\n",
      " [0.12216988]\n",
      " [0.06107134]\n",
      " [0.21143445]\n",
      " [0.06739414]\n",
      " [0.07643378]\n",
      " [0.07678875]\n",
      " [0.03290004]\n",
      " [0.12837282]\n",
      " [0.07883874]\n",
      " [0.14897245]\n",
      " [0.16687015]\n",
      " [0.0313288 ]\n",
      " [0.06907693]\n",
      " [0.04773799]\n",
      " [0.08419758]\n",
      " [0.16279688]\n",
      " [0.11959657]\n",
      " [0.04159725]\n",
      " [0.09030032]\n",
      " [0.11780095]\n",
      " [0.11368209]\n",
      " [0.08742598]\n",
      " [0.2819054 ]\n",
      " [0.38998157]\n",
      " [0.17696407]\n",
      " [0.03213066]\n",
      " [0.09130368]\n",
      " [0.06459966]\n",
      " [0.09431738]\n",
      " [0.07366344]\n",
      " [0.1237264 ]\n",
      " [0.0293662 ]\n",
      " [0.2763958 ]\n",
      " [0.20773649]\n",
      " [0.10851336]\n",
      " [0.08408627]\n",
      " [0.25611407]\n",
      " [0.05744037]\n",
      " [0.03727639]\n",
      " [0.08602536]\n",
      " [0.0992195 ]\n",
      " [0.30604583]\n",
      " [0.08950189]\n",
      " [0.04688922]\n",
      " [0.08082566]\n",
      " [0.10051498]\n",
      " [0.01223579]\n",
      " [0.2035025 ]\n",
      " [0.1676341 ]\n",
      " [0.26905036]\n",
      " [0.15822259]\n",
      " [0.1019614 ]\n",
      " [0.09614789]\n",
      " [0.15134138]\n",
      " [0.07703194]\n",
      " [0.09092608]\n",
      " [0.11883175]\n",
      " [0.04794574]\n",
      " [0.0897713 ]\n",
      " [0.04167309]\n",
      " [0.06672239]\n",
      " [0.08376315]\n",
      " [0.02473184]\n",
      " [0.27920923]\n",
      " [0.01319328]\n",
      " [0.29266885]\n",
      " [0.26731336]\n",
      " [0.09145468]\n",
      " [0.06892511]\n",
      " [0.01867679]\n",
      " [0.07640347]\n",
      " [0.04723981]\n",
      " [0.15151855]\n",
      " [0.12154281]\n",
      " [0.07775649]\n",
      " [0.2401377 ]\n",
      " [0.03226793]\n",
      " [0.01739743]\n",
      " [0.05505392]\n",
      " [0.1288724 ]\n",
      " [0.22013181]\n",
      " [0.05325985]\n",
      " [0.2002509 ]\n",
      " [0.0590255 ]\n",
      " [0.22053966]\n",
      " [0.2763958 ]\n",
      " [0.27891663]\n",
      " [0.03547126]\n",
      " [0.11064309]\n",
      " [0.07815263]\n",
      " [0.2879451 ]\n",
      " [0.07932621]\n",
      " [0.16330901]\n",
      " [0.03485861]\n",
      " [0.20187476]\n",
      " [0.23614398]\n",
      " [0.08524933]\n",
      " [0.09029019]\n",
      " [0.12322921]\n",
      " [0.18481866]\n",
      " [0.08749247]\n",
      " [0.03368029]\n",
      " [0.10378093]\n",
      " [0.20580596]\n",
      " [0.18098104]\n",
      " [0.08480495]\n",
      " [0.06568936]\n",
      " [0.07475391]\n",
      " [0.3330878 ]\n",
      " [0.06734496]\n",
      " [0.28703892]\n",
      " [0.12890255]\n",
      " [0.03747723]\n",
      " [0.07184887]\n",
      " [0.06242841]\n",
      " [0.06329823]\n",
      " [0.12846532]\n",
      " [0.10705027]\n",
      " [0.06127608]\n",
      " [0.08563197]\n",
      " [0.13356456]\n",
      " [0.13024268]\n",
      " [0.04474649]\n",
      " [0.1688799 ]\n",
      " [0.13460156]\n",
      " [0.17410174]\n",
      " [0.07744718]\n",
      " [0.10437924]\n",
      " [0.20810384]\n",
      " [0.17039186]\n",
      " [0.04173723]\n",
      " [0.09442362]\n",
      " [0.09337109]\n",
      " [0.03044727]\n",
      " [0.12062019]\n",
      " [0.10554367]\n",
      " [0.08373547]\n",
      " [0.05043483]\n",
      " [0.2042214 ]\n",
      " [0.14194056]\n",
      " [0.11587527]\n",
      " [0.08110657]\n",
      " [0.02057198]\n",
      " [0.21694309]\n",
      " [0.10928342]\n",
      " [0.24135482]\n",
      " [0.05616799]\n",
      " [0.21347353]\n",
      " [0.24809128]\n",
      " [0.10907823]\n",
      " [0.03349045]\n",
      " [0.04088044]\n",
      " [0.02516466]\n",
      " [0.11169663]\n",
      " [0.10306606]\n",
      " [0.15790662]\n",
      " [0.09233063]\n",
      " [0.11696613]\n",
      " [0.19238916]\n",
      " [0.15771213]\n",
      " [0.12318849]\n",
      " [0.18841664]\n",
      " [0.0823647 ]\n",
      " [0.07271808]\n",
      " [0.11865582]\n",
      " [0.12239449]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2399/2399 [==============================] - 1s 248us/step - loss: 0.4631 - acc: 0.8495 - val_loss: 0.4496 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.4290 - acc: 0.8587 - val_loss: 0.4403 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2399/2399 [==============================] - 0s 51us/step - loss: 0.4158 - acc: 0.8587 - val_loss: 0.4400 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2399/2399 [==============================] - 0s 52us/step - loss: 0.4088 - acc: 0.8587 - val_loss: 0.4408 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2399/2399 [==============================] - 0s 52us/step - loss: 0.4133 - acc: 0.8587 - val_loss: 0.4273 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.4025 - acc: 0.8587 - val_loss: 0.4146 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2399/2399 [==============================] - 0s 53us/step - loss: 0.3958 - acc: 0.8579 - val_loss: 0.4325 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3907 - acc: 0.8591 - val_loss: 0.4091 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2399/2399 [==============================] - 0s 57us/step - loss: 0.3881 - acc: 0.8579 - val_loss: 0.4081 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2399/2399 [==============================] - 0s 58us/step - loss: 0.3868 - acc: 0.8591 - val_loss: 0.4056 - val_acc: 0.8450\n",
      "Epoch 11/30\n",
      "2399/2399 [==============================] - 0s 61us/step - loss: 0.3875 - acc: 0.8624 - val_loss: 0.3986 - val_acc: 0.8450\n",
      "Epoch 12/30\n",
      "2399/2399 [==============================] - 0s 57us/step - loss: 0.3798 - acc: 0.8591 - val_loss: 0.3904 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2399/2399 [==============================] - 0s 56us/step - loss: 0.3745 - acc: 0.8579 - val_loss: 0.3859 - val_acc: 0.8433\n",
      "Epoch 14/30\n",
      "2399/2399 [==============================] - 0s 59us/step - loss: 0.3752 - acc: 0.8591 - val_loss: 0.3781 - val_acc: 0.8417\n",
      "Epoch 15/30\n",
      "2399/2399 [==============================] - 0s 59us/step - loss: 0.3679 - acc: 0.8595 - val_loss: 0.3719 - val_acc: 0.8483\n",
      "Epoch 16/30\n",
      "2399/2399 [==============================] - 0s 69us/step - loss: 0.3711 - acc: 0.8624 - val_loss: 0.3638 - val_acc: 0.8500\n",
      "Epoch 17/30\n",
      "2399/2399 [==============================] - 0s 55us/step - loss: 0.3556 - acc: 0.8645 - val_loss: 0.3578 - val_acc: 0.8667\n",
      "Epoch 18/30\n",
      "2399/2399 [==============================] - 0s 57us/step - loss: 0.3676 - acc: 0.8641 - val_loss: 0.3628 - val_acc: 0.8567\n",
      "Epoch 19/30\n",
      "2399/2399 [==============================] - 0s 59us/step - loss: 0.3514 - acc: 0.8708 - val_loss: 0.3592 - val_acc: 0.8583\n",
      "Epoch 20/30\n",
      "2399/2399 [==============================] - 0s 56us/step - loss: 0.3519 - acc: 0.8633 - val_loss: 0.3951 - val_acc: 0.8417\n",
      "y2_pred:  [[0.03020796]\n",
      " [0.03245059]\n",
      " [0.01663369]\n",
      " [0.23692608]\n",
      " [0.23932955]\n",
      " [0.08563253]\n",
      " [0.01219207]\n",
      " [0.04883558]\n",
      " [0.06425282]\n",
      " [0.02662048]\n",
      " [0.11298102]\n",
      " [0.00816911]\n",
      " [0.08651561]\n",
      " [0.30381322]\n",
      " [0.24359381]\n",
      " [0.10661235]\n",
      " [0.02547988]\n",
      " [0.00981405]\n",
      " [0.07379997]\n",
      " [0.05078474]\n",
      " [0.03436074]\n",
      " [0.00257504]\n",
      " [0.26822364]\n",
      " [0.03135833]\n",
      " [0.23494089]\n",
      " [0.24709615]\n",
      " [0.03905854]\n",
      " [0.02895814]\n",
      " [0.1229181 ]\n",
      " [0.02901527]\n",
      " [0.20843711]\n",
      " [0.00811657]\n",
      " [0.01853353]\n",
      " [0.02433637]\n",
      " [0.0062764 ]\n",
      " [0.0347262 ]\n",
      " [0.02569467]\n",
      " [0.09267071]\n",
      " [0.01549673]\n",
      " [0.00605217]\n",
      " [0.15107712]\n",
      " [0.0118261 ]\n",
      " [0.05641031]\n",
      " [0.01895005]\n",
      " [0.03186783]\n",
      " [0.05136871]\n",
      " [0.09073585]\n",
      " [0.0466142 ]\n",
      " [0.04134795]\n",
      " [0.169321  ]\n",
      " [0.05474043]\n",
      " [0.10733905]\n",
      " [0.07916778]\n",
      " [0.02474812]\n",
      " [0.07209143]\n",
      " [0.01323685]\n",
      " [0.27788222]\n",
      " [0.02431634]\n",
      " [0.02356473]\n",
      " [0.05487698]\n",
      " [0.00914767]\n",
      " [0.13429534]\n",
      " [0.16789868]\n",
      " [0.0108889 ]\n",
      " [0.14974451]\n",
      " [0.32497573]\n",
      " [0.05460823]\n",
      " [0.15348473]\n",
      " [0.03714451]\n",
      " [0.13580316]\n",
      " [0.02444369]\n",
      " [0.01708183]\n",
      " [0.07194078]\n",
      " [0.04599673]\n",
      " [0.09008706]\n",
      " [0.02335039]\n",
      " [0.03230003]\n",
      " [0.02208269]\n",
      " [0.01770338]\n",
      " [0.02362314]\n",
      " [0.18417469]\n",
      " [0.25728562]\n",
      " [0.01726204]\n",
      " [0.00548857]\n",
      " [0.18256763]\n",
      " [0.03991187]\n",
      " [0.05056462]\n",
      " [0.2259362 ]\n",
      " [0.05471227]\n",
      " [0.01859674]\n",
      " [0.11696911]\n",
      " [0.01312774]\n",
      " [0.02615631]\n",
      " [0.19478124]\n",
      " [0.0797697 ]\n",
      " [0.00469425]\n",
      " [0.00649303]\n",
      " [0.06515545]\n",
      " [0.33001345]\n",
      " [0.029183  ]\n",
      " [0.40625602]\n",
      " [0.14903578]\n",
      " [0.01749632]\n",
      " [0.04703557]\n",
      " [0.02045786]\n",
      " [0.10558343]\n",
      " [0.02716482]\n",
      " [0.02600786]\n",
      " [0.04289296]\n",
      " [0.05407819]\n",
      " [0.07738808]\n",
      " [0.29248032]\n",
      " [0.3166772 ]\n",
      " [0.07377341]\n",
      " [0.02111763]\n",
      " [0.07845119]\n",
      " [0.03621182]\n",
      " [0.31789917]\n",
      " [0.10126352]\n",
      " [0.23215434]\n",
      " [0.16731802]\n",
      " [0.0856162 ]\n",
      " [0.1679442 ]\n",
      " [0.04940325]\n",
      " [0.2347838 ]\n",
      " [0.03188717]\n",
      " [0.07337528]\n",
      " [0.06726262]\n",
      " [0.02121687]\n",
      " [0.05266958]\n",
      " [0.03873187]\n",
      " [0.01026899]\n",
      " [0.120839  ]\n",
      " [0.10657009]\n",
      " [0.0395309 ]\n",
      " [0.03273323]\n",
      " [0.1074799 ]\n",
      " [0.16800746]\n",
      " [0.03207687]\n",
      " [0.0143058 ]\n",
      " [0.10155365]\n",
      " [0.01001716]\n",
      " [0.16799924]\n",
      " [0.17020375]\n",
      " [0.0093452 ]\n",
      " [0.03997302]\n",
      " [0.01332545]\n",
      " [0.2342945 ]\n",
      " [0.09386808]\n",
      " [0.02116346]\n",
      " [0.05692109]\n",
      " [0.01788634]\n",
      " [0.02853739]\n",
      " [0.01665047]\n",
      " [0.0158923 ]\n",
      " [0.0235174 ]\n",
      " [0.08502042]\n",
      " [0.02740324]\n",
      " [0.02613497]\n",
      " [0.00963867]\n",
      " [0.09399858]\n",
      " [0.29564548]\n",
      " [0.29341638]\n",
      " [0.09202918]\n",
      " [0.26450145]\n",
      " [0.14133513]\n",
      " [0.03223959]\n",
      " [0.07790139]\n",
      " [0.03344506]\n",
      " [0.00786114]\n",
      " [0.01306617]\n",
      " [0.02768549]\n",
      " [0.04000381]\n",
      " [0.39669347]\n",
      " [0.15442073]\n",
      " [0.03562078]\n",
      " [0.01573816]\n",
      " [0.05008888]\n",
      " [0.01279598]\n",
      " [0.00813141]\n",
      " [0.03179395]\n",
      " [0.24446502]\n",
      " [0.03513756]\n",
      " [0.3268041 ]\n",
      " [0.05986634]\n",
      " [0.04513112]\n",
      " [0.01069573]\n",
      " [0.2642681 ]\n",
      " [0.06023583]\n",
      " [0.0168187 ]\n",
      " [0.01533359]\n",
      " [0.2083982 ]\n",
      " [0.01326284]\n",
      " [0.02934444]\n",
      " [0.02262148]\n",
      " [0.01907557]\n",
      " [0.16503924]\n",
      " [0.2870137 ]\n",
      " [0.10743165]\n",
      " [0.02404663]\n",
      " [0.181555  ]\n",
      " [0.12831205]\n",
      " [0.01589066]\n",
      " [0.09842521]\n",
      " [0.03001681]\n",
      " [0.0137094 ]\n",
      " [0.17854756]\n",
      " [0.01302302]\n",
      " [0.03017032]\n",
      " [0.273669  ]\n",
      " [0.04535609]\n",
      " [0.15015209]\n",
      " [0.02425712]\n",
      " [0.02118459]\n",
      " [0.05250052]\n",
      " [0.01580143]\n",
      " [0.24120462]\n",
      " [0.13064295]\n",
      " [0.00763565]\n",
      " [0.0069375 ]\n",
      " [0.06991738]\n",
      " [0.08054593]\n",
      " [0.08498293]\n",
      " [0.01746356]\n",
      " [0.01072255]\n",
      " [0.11976784]\n",
      " [0.12663925]\n",
      " [0.04929432]\n",
      " [0.02280149]\n",
      " [0.01275274]\n",
      " [0.02031627]\n",
      " [0.01821822]\n",
      " [0.02563086]\n",
      " [0.30612513]\n",
      " [0.15811083]\n",
      " [0.05875587]\n",
      " [0.10131484]\n",
      " [0.04960051]\n",
      " [0.09538433]\n",
      " [0.01464918]\n",
      " [0.36185282]\n",
      " [0.00391367]\n",
      " [0.01561576]\n",
      " [0.20819113]\n",
      " [0.11109751]\n",
      " [0.0174143 ]\n",
      " [0.03486747]\n",
      " [0.03461236]\n",
      " [0.02611279]\n",
      " [0.00663474]\n",
      " [0.0245555 ]\n",
      " [0.08273572]\n",
      " [0.03899926]\n",
      " [0.00529549]\n",
      " [0.01971954]\n",
      " [0.03548536]\n",
      " [0.01642177]\n",
      " [0.03358871]\n",
      " [0.10222638]\n",
      " [0.02357769]\n",
      " [0.03642491]\n",
      " [0.23548159]\n",
      " [0.0192886 ]\n",
      " [0.01961294]\n",
      " [0.19384709]\n",
      " [0.0527854 ]\n",
      " [0.01074436]\n",
      " [0.14030933]\n",
      " [0.00694692]\n",
      " [0.23562685]\n",
      " [0.03418505]\n",
      " [0.01439378]\n",
      " [0.02038464]\n",
      " [0.05199021]\n",
      " [0.09922135]\n",
      " [0.04056975]\n",
      " [0.05589756]\n",
      " [0.02682051]\n",
      " [0.20619097]\n",
      " [0.01595607]\n",
      " [0.01256371]\n",
      " [0.10019758]\n",
      " [0.02496007]\n",
      " [0.18220365]\n",
      " [0.31800926]\n",
      " [0.01172379]\n",
      " [0.01767287]\n",
      " [0.0089938 ]\n",
      " [0.06343278]\n",
      " [0.03311563]\n",
      " [0.11010373]\n",
      " [0.059681  ]\n",
      " [0.27828017]\n",
      " [0.14740825]\n",
      " [0.21817309]\n",
      " [0.00528038]\n",
      " [0.02712697]\n",
      " [0.1041528 ]\n",
      " [0.01989943]\n",
      " [0.08254948]\n",
      " [0.04294509]\n",
      " [0.14643157]\n",
      " [0.06785432]\n",
      " [0.04327518]\n",
      " [0.15373486]\n",
      " [0.12768215]\n",
      " [0.0529919 ]\n",
      " [0.1751687 ]\n",
      " [0.00732532]\n",
      " [0.06718725]\n",
      " [0.30677816]\n",
      " [0.01743057]\n",
      " [0.12549096]\n",
      " [0.00565928]\n",
      " [0.2942831 ]\n",
      " [0.20528516]\n",
      " [0.3236029 ]\n",
      " [0.08655387]\n",
      " [0.22332081]\n",
      " [0.0474925 ]\n",
      " [0.15981051]\n",
      " [0.12804511]\n",
      " [0.3395051 ]\n",
      " [0.18489951]\n",
      " [0.12141645]\n",
      " [0.04527941]\n",
      " [0.123519  ]\n",
      " [0.01562229]\n",
      " [0.38854685]\n",
      " [0.05541254]\n",
      " [0.19067036]\n",
      " [0.16354758]\n",
      " [0.09285995]\n",
      " [0.2649344 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 269us/step - loss: 0.4594 - acc: 0.8579 - val_loss: 0.4402 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.4194 - acc: 0.8583 - val_loss: 0.4635 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.4086 - acc: 0.8583 - val_loss: 0.4228 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3994 - acc: 0.8583 - val_loss: 0.4047 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3886 - acc: 0.8583 - val_loss: 0.3980 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3867 - acc: 0.8575 - val_loss: 0.3952 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3834 - acc: 0.8608 - val_loss: 0.4113 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3848 - acc: 0.8579 - val_loss: 0.3922 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3727 - acc: 0.8596 - val_loss: 0.3827 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3745 - acc: 0.8596 - val_loss: 0.3818 - val_acc: 0.8433\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.3623 - acc: 0.8600 - val_loss: 0.3983 - val_acc: 0.8400\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3667 - acc: 0.8583 - val_loss: 0.3741 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3599 - acc: 0.8608 - val_loss: 0.4012 - val_acc: 0.8450\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 57us/step - loss: 0.3547 - acc: 0.8612 - val_loss: 0.3777 - val_acc: 0.8450\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3520 - acc: 0.8637 - val_loss: 0.3687 - val_acc: 0.8417\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 53us/step - loss: 0.3463 - acc: 0.8654 - val_loss: 0.3797 - val_acc: 0.8367\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 54us/step - loss: 0.3524 - acc: 0.8612 - val_loss: 0.3629 - val_acc: 0.8517\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3459 - acc: 0.8646 - val_loss: 0.3904 - val_acc: 0.8450\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 67us/step - loss: 0.3427 - acc: 0.8675 - val_loss: 0.3746 - val_acc: 0.8450\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3413 - acc: 0.8662 - val_loss: 0.4038 - val_acc: 0.8400\n",
      "y2_pred:  [[1.05147064e-02]\n",
      " [7.31524527e-02]\n",
      " [6.02611601e-02]\n",
      " [1.56161189e-03]\n",
      " [6.27919436e-02]\n",
      " [1.95098847e-01]\n",
      " [1.84370279e-02]\n",
      " [5.26261926e-02]\n",
      " [4.16525006e-02]\n",
      " [1.71602070e-02]\n",
      " [9.32002068e-02]\n",
      " [1.13361090e-01]\n",
      " [7.37947226e-03]\n",
      " [2.21692413e-01]\n",
      " [1.02740735e-01]\n",
      " [2.46291310e-01]\n",
      " [5.99479675e-03]\n",
      " [1.63942277e-02]\n",
      " [3.17279398e-02]\n",
      " [3.23530734e-02]\n",
      " [4.33836281e-01]\n",
      " [1.07730389e-01]\n",
      " [8.50316882e-03]\n",
      " [2.63032019e-02]\n",
      " [1.19630635e-01]\n",
      " [1.24660730e-01]\n",
      " [9.74729657e-03]\n",
      " [1.13827586e-02]\n",
      " [4.46945727e-02]\n",
      " [2.37781703e-02]\n",
      " [9.52421725e-02]\n",
      " [3.60341072e-02]\n",
      " [5.75785637e-02]\n",
      " [1.80766881e-02]\n",
      " [1.26174092e-02]\n",
      " [1.25760138e-02]\n",
      " [1.28954351e-02]\n",
      " [5.86041808e-02]\n",
      " [1.10833079e-01]\n",
      " [2.66512632e-02]\n",
      " [1.12822354e-02]\n",
      " [5.81962466e-02]\n",
      " [6.43351078e-02]\n",
      " [1.11005604e-02]\n",
      " [4.70989048e-02]\n",
      " [1.03356093e-01]\n",
      " [1.30288899e-02]\n",
      " [1.08199477e-01]\n",
      " [8.35361779e-02]\n",
      " [1.70467198e-01]\n",
      " [5.38564026e-02]\n",
      " [5.09554148e-02]\n",
      " [1.16065145e-02]\n",
      " [3.10971439e-02]\n",
      " [6.96619749e-02]\n",
      " [4.23204243e-01]\n",
      " [7.98564553e-02]\n",
      " [3.81107330e-02]\n",
      " [2.85525322e-02]\n",
      " [7.21670985e-02]\n",
      " [1.65128708e-02]\n",
      " [1.68129802e-02]\n",
      " [1.30807281e-01]\n",
      " [3.59566808e-02]\n",
      " [1.25997066e-01]\n",
      " [7.31878579e-02]\n",
      " [4.76326346e-02]\n",
      " [4.50462103e-02]\n",
      " [1.03670061e-02]\n",
      " [1.41758680e-01]\n",
      " [2.08950937e-01]\n",
      " [2.71416605e-02]\n",
      " [2.22677290e-02]\n",
      " [6.95168972e-03]\n",
      " [8.55356455e-03]\n",
      " [1.23438835e-02]\n",
      " [6.36262596e-02]\n",
      " [8.82068276e-03]\n",
      " [1.95866525e-02]\n",
      " [9.28553343e-02]\n",
      " [7.05057681e-02]\n",
      " [4.22094464e-02]\n",
      " [4.78253663e-02]\n",
      " [1.59690320e-01]\n",
      " [4.52668369e-02]\n",
      " [4.02260423e-02]\n",
      " [5.00143766e-02]\n",
      " [7.46577978e-04]\n",
      " [4.12949324e-02]\n",
      " [3.67781818e-02]\n",
      " [7.23612010e-02]\n",
      " [2.45151758e-01]\n",
      " [2.82309711e-01]\n",
      " [1.83662117e-01]\n",
      " [2.43429065e-01]\n",
      " [8.33682120e-02]\n",
      " [1.57048702e-02]\n",
      " [4.56061959e-03]\n",
      " [1.60220057e-01]\n",
      " [4.72843051e-02]\n",
      " [1.48930371e-01]\n",
      " [1.53091550e-02]\n",
      " [3.27159464e-02]\n",
      " [2.27581561e-02]\n",
      " [9.74551439e-02]\n",
      " [1.37886107e-02]\n",
      " [3.09237242e-02]\n",
      " [8.32909048e-02]\n",
      " [1.64978445e-01]\n",
      " [1.99529529e-02]\n",
      " [5.15864789e-02]\n",
      " [4.75869775e-02]\n",
      " [2.35510051e-01]\n",
      " [1.21473074e-01]\n",
      " [3.16481888e-02]\n",
      " [5.66599071e-02]\n",
      " [2.13164091e-02]\n",
      " [3.73088121e-02]\n",
      " [6.66057169e-02]\n",
      " [9.82019305e-03]\n",
      " [1.65742755e-01]\n",
      " [1.96481645e-02]\n",
      " [5.10606468e-02]\n",
      " [1.95471346e-01]\n",
      " [1.42795503e-01]\n",
      " [1.75911069e-01]\n",
      " [5.61824143e-02]\n",
      " [4.14544344e-03]\n",
      " [3.65608037e-02]\n",
      " [2.41257846e-02]\n",
      " [1.36981010e-02]\n",
      " [1.32234693e-02]\n",
      " [1.68854624e-01]\n",
      " [6.75886869e-02]\n",
      " [3.94562185e-02]\n",
      " [2.22878754e-02]\n",
      " [4.70465422e-03]\n",
      " [1.20525301e-01]\n",
      " [3.21072638e-02]\n",
      " [1.58471763e-02]\n",
      " [3.94203365e-02]\n",
      " [1.05791122e-01]\n",
      " [1.08960569e-02]\n",
      " [1.31995976e-02]\n",
      " [1.11118853e-02]\n",
      " [2.38196105e-01]\n",
      " [1.08851314e-01]\n",
      " [6.07854128e-03]\n",
      " [4.24645245e-02]\n",
      " [2.87941396e-02]\n",
      " [2.80916452e-01]\n",
      " [2.90235579e-02]\n",
      " [1.48655564e-01]\n",
      " [1.24628842e-02]\n",
      " [2.68986821e-02]\n",
      " [1.12358838e-01]\n",
      " [8.51649046e-03]\n",
      " [1.94505185e-01]\n",
      " [1.56349838e-02]\n",
      " [2.07626224e-02]\n",
      " [3.13763946e-01]\n",
      " [1.52227283e-02]\n",
      " [7.59559870e-03]\n",
      " [1.28544390e-01]\n",
      " [1.70658201e-01]\n",
      " [7.59284496e-02]\n",
      " [2.63971984e-02]\n",
      " [1.45535469e-02]\n",
      " [9.81595814e-02]\n",
      " [1.36599928e-01]\n",
      " [6.74284697e-02]\n",
      " [9.74340141e-02]\n",
      " [2.14505792e-02]\n",
      " [1.38527155e-03]\n",
      " [1.75198019e-02]\n",
      " [1.84596062e-01]\n",
      " [4.55166698e-02]\n",
      " [9.93741751e-02]\n",
      " [1.05791092e-02]\n",
      " [8.00236762e-02]\n",
      " [1.37789547e-02]\n",
      " [2.78429389e-02]\n",
      " [1.17133141e-01]\n",
      " [6.54612184e-02]\n",
      " [1.87307000e-02]\n",
      " [4.05526161e-03]\n",
      " [1.79230571e-02]\n",
      " [7.82775879e-03]\n",
      " [4.58505750e-03]\n",
      " [2.50861764e-01]\n",
      " [3.56068850e-01]\n",
      " [3.30077231e-01]\n",
      " [3.99944782e-02]\n",
      " [1.09518081e-01]\n",
      " [1.25862002e-01]\n",
      " [1.42976493e-01]\n",
      " [2.91839242e-02]\n",
      " [4.80273366e-03]\n",
      " [3.87467146e-02]\n",
      " [4.04528975e-02]\n",
      " [1.18424296e-02]\n",
      " [2.54854560e-03]\n",
      " [2.83005863e-01]\n",
      " [7.81866312e-02]\n",
      " [8.89000297e-03]\n",
      " [1.34770572e-02]\n",
      " [1.47103786e-01]\n",
      " [3.42494845e-02]\n",
      " [9.45201516e-02]\n",
      " [1.07390612e-01]\n",
      " [2.27654576e-02]\n",
      " [5.81238270e-02]\n",
      " [4.63612974e-02]\n",
      " [6.56645894e-02]\n",
      " [1.79483652e-01]\n",
      " [8.15641284e-02]\n",
      " [3.77821326e-02]\n",
      " [5.56289256e-02]\n",
      " [1.06959194e-01]\n",
      " [8.54408741e-02]\n",
      " [1.94634914e-01]\n",
      " [9.09382105e-03]\n",
      " [3.87978554e-02]\n",
      " [2.45043635e-02]\n",
      " [1.38094336e-01]\n",
      " [2.99316049e-02]\n",
      " [5.66214323e-03]\n",
      " [2.10384130e-02]\n",
      " [3.75060439e-02]\n",
      " [7.93962777e-02]\n",
      " [1.14504069e-01]\n",
      " [8.30536783e-02]\n",
      " [5.22202551e-02]\n",
      " [2.46673405e-01]\n",
      " [1.08001739e-01]\n",
      " [1.63193822e-01]\n",
      " [1.29394203e-01]\n",
      " [9.01025832e-02]\n",
      " [4.60315943e-02]\n",
      " [1.78998321e-01]\n",
      " [3.20929766e-01]\n",
      " [3.70220542e-02]\n",
      " [1.85738802e-02]\n",
      " [7.99109936e-02]\n",
      " [1.53492242e-01]\n",
      " [8.91336799e-03]\n",
      " [1.88617766e-01]\n",
      " [1.30834371e-01]\n",
      " [3.01127732e-02]\n",
      " [4.16823328e-02]\n",
      " [1.51666611e-01]\n",
      " [3.63923967e-01]\n",
      " [2.56186426e-02]\n",
      " [1.58463717e-02]\n",
      " [4.70715165e-02]\n",
      " [6.76751435e-02]\n",
      " [2.47721791e-01]\n",
      " [5.84275424e-02]\n",
      " [5.07377982e-02]\n",
      " [1.07337713e-01]\n",
      " [2.08276391e-01]\n",
      " [6.00800812e-02]\n",
      " [3.02162766e-02]\n",
      " [3.06414664e-02]\n",
      " [9.56203640e-02]\n",
      " [1.55330598e-02]\n",
      " [9.29930210e-02]\n",
      " [2.82765031e-02]\n",
      " [3.27768922e-02]\n",
      " [8.85080397e-02]\n",
      " [2.11951613e-01]\n",
      " [5.69818139e-01]\n",
      " [9.88393128e-02]\n",
      " [4.24712896e-04]\n",
      " [8.15434456e-02]\n",
      " [8.92734528e-03]\n",
      " [1.07297212e-01]\n",
      " [3.88118327e-02]\n",
      " [5.40325940e-02]\n",
      " [4.29845452e-02]\n",
      " [1.18580878e-01]\n",
      " [3.80596519e-02]\n",
      " [3.03733736e-01]\n",
      " [1.32403642e-01]\n",
      " [5.67129254e-03]\n",
      " [7.50484467e-02]\n",
      " [1.44930333e-01]\n",
      " [1.15825832e-02]\n",
      " [1.13463491e-01]\n",
      " [4.77901101e-03]\n",
      " [6.60167634e-02]\n",
      " [8.82369280e-03]\n",
      " [2.05119550e-02]\n",
      " [7.89771974e-02]\n",
      " [1.08583033e-01]\n",
      " [1.49972141e-02]\n",
      " [5.78957796e-03]\n",
      " [1.80963099e-01]\n",
      " [2.20817775e-01]\n",
      " [1.40306652e-02]\n",
      " [7.65975416e-02]\n",
      " [8.35924447e-02]\n",
      " [6.17092848e-03]\n",
      " [2.95195878e-01]\n",
      " [7.14358389e-02]\n",
      " [4.64573503e-03]\n",
      " [6.98204935e-02]\n",
      " [8.58848989e-02]\n",
      " [3.30534369e-01]\n",
      " [2.45257914e-02]\n",
      " [6.73926771e-02]\n",
      " [2.24501789e-01]\n",
      " [5.51035404e-02]\n",
      " [2.06652880e-02]\n",
      " [1.79797113e-02]\n",
      " [1.06479019e-01]\n",
      " [1.83616668e-01]\n",
      " [1.09962553e-01]\n",
      " [5.67162037e-02]\n",
      " [1.08549356e-01]\n",
      " [5.24126649e-01]\n",
      " [1.20231777e-01]\n",
      " [6.79114759e-02]\n",
      " [2.31533945e-02]\n",
      " [6.50020838e-02]\n",
      " [2.69246310e-01]\n",
      " [2.49039114e-01]\n",
      " [1.45327955e-01]\n",
      " [5.16985990e-02]\n",
      " [3.55591699e-02]\n",
      " [3.14366408e-02]\n",
      " [3.05584013e-01]\n",
      " [7.94227235e-03]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.041666666666666664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 284us/step - loss: 0.5951 - acc: 0.8462 - val_loss: 0.4471 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.4198 - acc: 0.8583 - val_loss: 0.4961 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 57us/step - loss: 0.4197 - acc: 0.8583 - val_loss: 0.4699 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.4034 - acc: 0.8583 - val_loss: 0.4228 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.4037 - acc: 0.8583 - val_loss: 0.4091 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3926 - acc: 0.8583 - val_loss: 0.4133 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 67us/step - loss: 0.3873 - acc: 0.8583 - val_loss: 0.4165 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3975 - acc: 0.8592 - val_loss: 0.4148 - val_acc: 0.8417\n",
      "y2_pred:  [[0.21415174]\n",
      " [0.05469942]\n",
      " [0.12709156]\n",
      " [0.20247516]\n",
      " [0.12394118]\n",
      " [0.15974554]\n",
      " [0.09819958]\n",
      " [0.08206132]\n",
      " [0.14223143]\n",
      " [0.17737481]\n",
      " [0.26801938]\n",
      " [0.20534196]\n",
      " [0.03513137]\n",
      " [0.17636234]\n",
      " [0.19154614]\n",
      " [0.03687555]\n",
      " [0.14339942]\n",
      " [0.06493333]\n",
      " [0.1053628 ]\n",
      " [0.08340818]\n",
      " [0.06166509]\n",
      " [0.03741679]\n",
      " [0.05588537]\n",
      " [0.20862725]\n",
      " [0.08320424]\n",
      " [0.10454446]\n",
      " [0.20529208]\n",
      " [0.16559404]\n",
      " [0.18085882]\n",
      " [0.0447408 ]\n",
      " [0.05376092]\n",
      " [0.03808436]\n",
      " [0.18532103]\n",
      " [0.11824837]\n",
      " [0.09217349]\n",
      " [0.0689294 ]\n",
      " [0.08102039]\n",
      " [0.05273506]\n",
      " [0.05273935]\n",
      " [0.1299766 ]\n",
      " [0.12640911]\n",
      " [0.04511037]\n",
      " [0.08544317]\n",
      " [0.17859197]\n",
      " [0.14581984]\n",
      " [0.13931331]\n",
      " [0.20401028]\n",
      " [0.04647699]\n",
      " [0.0913513 ]\n",
      " [0.1375624 ]\n",
      " [0.20066297]\n",
      " [0.16342306]\n",
      " [0.13698468]\n",
      " [0.11306137]\n",
      " [0.05040169]\n",
      " [0.04530749]\n",
      " [0.03603917]\n",
      " [0.04429021]\n",
      " [0.05836099]\n",
      " [0.0462285 ]\n",
      " [0.2516381 ]\n",
      " [0.13476524]\n",
      " [0.15753648]\n",
      " [0.03059825]\n",
      " [0.11496097]\n",
      " [0.04626539]\n",
      " [0.02893651]\n",
      " [0.13841444]\n",
      " [0.02341887]\n",
      " [0.23425332]\n",
      " [0.12327167]\n",
      " [0.15796947]\n",
      " [0.08029476]\n",
      " [0.07601458]\n",
      " [0.0726276 ]\n",
      " [0.14280516]\n",
      " [0.14022017]\n",
      " [0.06146371]\n",
      " [0.0534001 ]\n",
      " [0.09413382]\n",
      " [0.14203802]\n",
      " [0.10065964]\n",
      " [0.11308351]\n",
      " [0.13068509]\n",
      " [0.09704617]\n",
      " [0.04451248]\n",
      " [0.07819387]\n",
      " [0.13052389]\n",
      " [0.06377295]\n",
      " [0.09175703]\n",
      " [0.03662309]\n",
      " [0.05556142]\n",
      " [0.07149872]\n",
      " [0.090377  ]\n",
      " [0.22191885]\n",
      " [0.04054114]\n",
      " [0.20912293]\n",
      " [0.08459586]\n",
      " [0.09214979]\n",
      " [0.07026801]\n",
      " [0.10240689]\n",
      " [0.08429345]\n",
      " [0.12026674]\n",
      " [0.04737961]\n",
      " [0.14800534]\n",
      " [0.07975075]\n",
      " [0.10486215]\n",
      " [0.0792062 ]\n",
      " [0.11907768]\n",
      " [0.13811848]\n",
      " [0.17120856]\n",
      " [0.08190107]\n",
      " [0.06594896]\n",
      " [0.14983171]\n",
      " [0.1475721 ]\n",
      " [0.0743126 ]\n",
      " [0.07027924]\n",
      " [0.05286795]\n",
      " [0.165927  ]\n",
      " [0.16456246]\n",
      " [0.0593859 ]\n",
      " [0.07449397]\n",
      " [0.0513429 ]\n",
      " [0.1743812 ]\n",
      " [0.05798203]\n",
      " [0.07200173]\n",
      " [0.06776357]\n",
      " [0.13186777]\n",
      " [0.12517348]\n",
      " [0.02730221]\n",
      " [0.02777746]\n",
      " [0.05167469]\n",
      " [0.05413711]\n",
      " [0.10082898]\n",
      " [0.23065358]\n",
      " [0.0428088 ]\n",
      " [0.11393806]\n",
      " [0.04957345]\n",
      " [0.0698868 ]\n",
      " [0.074029  ]\n",
      " [0.04406387]\n",
      " [0.07094511]\n",
      " [0.12525046]\n",
      " [0.06210905]\n",
      " [0.08737409]\n",
      " [0.17120555]\n",
      " [0.05602506]\n",
      " [0.11928159]\n",
      " [0.04917711]\n",
      " [0.07254028]\n",
      " [0.08383122]\n",
      " [0.07053706]\n",
      " [0.07579443]\n",
      " [0.06258011]\n",
      " [0.33405   ]\n",
      " [0.17239901]\n",
      " [0.08710128]\n",
      " [0.05456164]\n",
      " [0.07379466]\n",
      " [0.06294   ]\n",
      " [0.05651608]\n",
      " [0.23517874]\n",
      " [0.07622507]\n",
      " [0.13426092]\n",
      " [0.05756199]\n",
      " [0.06744272]\n",
      " [0.03974602]\n",
      " [0.11910525]\n",
      " [0.10742322]\n",
      " [0.1552144 ]\n",
      " [0.0536592 ]\n",
      " [0.11504957]\n",
      " [0.19559726]\n",
      " [0.19777188]\n",
      " [0.11586434]\n",
      " [0.06763944]\n",
      " [0.13055551]\n",
      " [0.08380958]\n",
      " [0.09272808]\n",
      " [0.08649331]\n",
      " [0.1913118 ]\n",
      " [0.05391699]\n",
      " [0.21810883]\n",
      " [0.25239685]\n",
      " [0.09591156]\n",
      " [0.07733279]\n",
      " [0.06708315]\n",
      " [0.10194081]\n",
      " [0.05518329]\n",
      " [0.04156718]\n",
      " [0.15147033]\n",
      " [0.09720656]\n",
      " [0.07577369]\n",
      " [0.07174787]\n",
      " [0.07659456]\n",
      " [0.07686728]\n",
      " [0.07442892]\n",
      " [0.10846359]\n",
      " [0.16032642]\n",
      " [0.09349459]\n",
      " [0.10722035]\n",
      " [0.0306817 ]\n",
      " [0.16289312]\n",
      " [0.14847511]\n",
      " [0.23827511]\n",
      " [0.07053542]\n",
      " [0.116846  ]\n",
      " [0.10717553]\n",
      " [0.06438348]\n",
      " [0.10171089]\n",
      " [0.15885407]\n",
      " [0.12775272]\n",
      " [0.03850907]\n",
      " [0.1372729 ]\n",
      " [0.03944108]\n",
      " [0.11184487]\n",
      " [0.04116958]\n",
      " [0.17703444]\n",
      " [0.04924315]\n",
      " [0.05463779]\n",
      " [0.03625593]\n",
      " [0.04579711]\n",
      " [0.04918143]\n",
      " [0.02724734]\n",
      " [0.13133249]\n",
      " [0.09800294]\n",
      " [0.12521845]\n",
      " [0.12859198]\n",
      " [0.05481207]\n",
      " [0.06080255]\n",
      " [0.04999495]\n",
      " [0.08282518]\n",
      " [0.03291759]\n",
      " [0.05555332]\n",
      " [0.078998  ]\n",
      " [0.11912498]\n",
      " [0.0639706 ]\n",
      " [0.06515226]\n",
      " [0.03163934]\n",
      " [0.09663233]\n",
      " [0.10726959]\n",
      " [0.11521843]\n",
      " [0.08057886]\n",
      " [0.07162419]\n",
      " [0.05598962]\n",
      " [0.06386626]\n",
      " [0.05013326]\n",
      " [0.11397871]\n",
      " [0.08474946]\n",
      " [0.09216088]\n",
      " [0.11639264]\n",
      " [0.03926978]\n",
      " [0.12002978]\n",
      " [0.1510211 ]\n",
      " [0.03599575]\n",
      " [0.04338115]\n",
      " [0.05586696]\n",
      " [0.10455158]\n",
      " [0.09138128]\n",
      " [0.09023002]\n",
      " [0.19657102]\n",
      " [0.02299002]\n",
      " [0.10824725]\n",
      " [0.16415101]\n",
      " [0.08349425]\n",
      " [0.02922726]\n",
      " [0.05876648]\n",
      " [0.16467914]\n",
      " [0.10182902]\n",
      " [0.11037105]\n",
      " [0.06435886]\n",
      " [0.0397099 ]\n",
      " [0.14439407]\n",
      " [0.05671865]\n",
      " [0.09790054]\n",
      " [0.14159933]\n",
      " [0.07975087]\n",
      " [0.09131768]\n",
      " [0.07933182]\n",
      " [0.07193348]\n",
      " [0.05985984]\n",
      " [0.11441773]\n",
      " [0.09331238]\n",
      " [0.07819572]\n",
      " [0.10132745]\n",
      " [0.06868804]\n",
      " [0.05426496]\n",
      " [0.06025878]\n",
      " [0.08281049]\n",
      " [0.25895596]\n",
      " [0.04578552]\n",
      " [0.11711857]\n",
      " [0.24896532]\n",
      " [0.07392669]\n",
      " [0.0664081 ]\n",
      " [0.13304427]\n",
      " [0.23821151]\n",
      " [0.13352144]\n",
      " [0.18384966]\n",
      " [0.15123594]\n",
      " [0.09154198]\n",
      " [0.25086668]\n",
      " [0.15860349]\n",
      " [0.1995964 ]\n",
      " [0.12408337]\n",
      " [0.12662748]\n",
      " [0.16627607]\n",
      " [0.10038438]\n",
      " [0.07212877]\n",
      " [0.14299166]\n",
      " [0.17833856]\n",
      " [0.10014835]\n",
      " [0.09785885]\n",
      " [0.13663337]\n",
      " [0.23116851]\n",
      " [0.05692592]\n",
      " [0.11379176]\n",
      " [0.11690962]\n",
      " [0.30761623]\n",
      " [0.05583432]\n",
      " [0.19098264]\n",
      " [0.15541008]\n",
      " [0.15779564]\n",
      " [0.1036416 ]\n",
      " [0.1968306 ]\n",
      " [0.08834112]\n",
      " [0.08347905]\n",
      " [0.14742506]\n",
      " [0.11670903]\n",
      " [0.19069973]\n",
      " [0.24818954]\n",
      " [0.03133577]\n",
      " [0.26579767]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 319us/step - loss: 0.4462 - acc: 0.8496 - val_loss: 0.4590 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.4107 - acc: 0.8579 - val_loss: 0.4260 - val_acc: 0.8417\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.4008 - acc: 0.8583 - val_loss: 0.4225 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 55us/step - loss: 0.3932 - acc: 0.8579 - val_loss: 0.4670 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3969 - acc: 0.8579 - val_loss: 0.4229 - val_acc: 0.8383\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 67us/step - loss: 0.3923 - acc: 0.8600 - val_loss: 0.4345 - val_acc: 0.8417\n",
      "y2_pred:  [[0.2699577 ]\n",
      " [0.05879933]\n",
      " [0.08800837]\n",
      " [0.10183203]\n",
      " [0.09274095]\n",
      " [0.03968421]\n",
      " [0.11514696]\n",
      " [0.16837418]\n",
      " [0.11243838]\n",
      " [0.20656532]\n",
      " [0.06386945]\n",
      " [0.06062004]\n",
      " [0.06583127]\n",
      " [0.05318931]\n",
      " [0.15587655]\n",
      " [0.05988216]\n",
      " [0.06493142]\n",
      " [0.09065706]\n",
      " [0.04971203]\n",
      " [0.05097908]\n",
      " [0.06718186]\n",
      " [0.03160146]\n",
      " [0.06257495]\n",
      " [0.07820255]\n",
      " [0.10299706]\n",
      " [0.12891543]\n",
      " [0.07365873]\n",
      " [0.0509803 ]\n",
      " [0.07320705]\n",
      " [0.10759723]\n",
      " [0.05179816]\n",
      " [0.09408766]\n",
      " [0.1022982 ]\n",
      " [0.05612072]\n",
      " [0.05320334]\n",
      " [0.05045941]\n",
      " [0.08067036]\n",
      " [0.05968863]\n",
      " [0.06570327]\n",
      " [0.0762724 ]\n",
      " [0.05795917]\n",
      " [0.05406359]\n",
      " [0.14109299]\n",
      " [0.04489231]\n",
      " [0.04909718]\n",
      " [0.05855992]\n",
      " [0.11628959]\n",
      " [0.10673332]\n",
      " [0.04074427]\n",
      " [0.06254825]\n",
      " [0.07898125]\n",
      " [0.03746429]\n",
      " [0.05500004]\n",
      " [0.06910536]\n",
      " [0.0662263 ]\n",
      " [0.10800689]\n",
      " [0.11600247]\n",
      " [0.05773005]\n",
      " [0.1020391 ]\n",
      " [0.0450747 ]\n",
      " [0.06732917]\n",
      " [0.18639103]\n",
      " [0.16783512]\n",
      " [0.08943015]\n",
      " [0.15362135]\n",
      " [0.05499303]\n",
      " [0.1117667 ]\n",
      " [0.11072227]\n",
      " [0.15291506]\n",
      " [0.03943211]\n",
      " [0.08695105]\n",
      " [0.08269551]\n",
      " [0.11753803]\n",
      " [0.09578151]\n",
      " [0.10452968]\n",
      " [0.08713058]\n",
      " [0.05625343]\n",
      " [0.0800547 ]\n",
      " [0.06164604]\n",
      " [0.06600702]\n",
      " [0.0700573 ]\n",
      " [0.05914694]\n",
      " [0.06618628]\n",
      " [0.05461881]\n",
      " [0.03349969]\n",
      " [0.04002577]\n",
      " [0.07514265]\n",
      " [0.08634081]\n",
      " [0.06398591]\n",
      " [0.03378433]\n",
      " [0.08144587]\n",
      " [0.09379897]\n",
      " [0.03789815]\n",
      " [0.32193643]\n",
      " [0.04699844]\n",
      " [0.26912528]\n",
      " [0.09276712]\n",
      " [0.04271445]\n",
      " [0.06971496]\n",
      " [0.05367586]\n",
      " [0.08331144]\n",
      " [0.1248754 ]\n",
      " [0.09280133]\n",
      " [0.20467722]\n",
      " [0.07311687]\n",
      " [0.05693361]\n",
      " [0.07786819]\n",
      " [0.05566853]\n",
      " [0.08972996]\n",
      " [0.04057199]\n",
      " [0.1357044 ]\n",
      " [0.07755259]\n",
      " [0.22228771]\n",
      " [0.07148081]\n",
      " [0.03572983]\n",
      " [0.10094559]\n",
      " [0.09525982]\n",
      " [0.20784208]\n",
      " [0.04343739]\n",
      " [0.06524619]\n",
      " [0.04285091]\n",
      " [0.0791074 ]\n",
      " [0.0654346 ]\n",
      " [0.05683798]\n",
      " [0.14384991]\n",
      " [0.07589993]\n",
      " [0.0486522 ]\n",
      " [0.05422071]\n",
      " [0.07156339]\n",
      " [0.04088548]\n",
      " [0.15304524]\n",
      " [0.09283602]\n",
      " [0.10739577]\n",
      " [0.05215916]\n",
      " [0.05401236]\n",
      " [0.04964271]\n",
      " [0.08022422]\n",
      " [0.03610674]\n",
      " [0.12221685]\n",
      " [0.14391646]\n",
      " [0.1420106 ]\n",
      " [0.07057351]\n",
      " [0.0998235 ]\n",
      " [0.05661234]\n",
      " [0.08284593]\n",
      " [0.17104301]\n",
      " [0.26628536]\n",
      " [0.22073   ]\n",
      " [0.06652579]\n",
      " [0.06996527]\n",
      " [0.06081024]\n",
      " [0.1502083 ]\n",
      " [0.14510936]\n",
      " [0.24092945]\n",
      " [0.07110634]\n",
      " [0.12843189]\n",
      " [0.0853118 ]\n",
      " [0.06769842]\n",
      " [0.05467615]\n",
      " [0.08461589]\n",
      " [0.07926822]\n",
      " [0.11657968]\n",
      " [0.06638932]\n",
      " [0.06217614]\n",
      " [0.11651266]\n",
      " [0.07915291]\n",
      " [0.08799985]\n",
      " [0.0911279 ]\n",
      " [0.059506  ]\n",
      " [0.28321457]\n",
      " [0.04725978]\n",
      " [0.05781299]\n",
      " [0.13251385]\n",
      " [0.04263979]\n",
      " [0.05126691]\n",
      " [0.07489952]\n",
      " [0.10193989]\n",
      " [0.11683732]\n",
      " [0.06947273]\n",
      " [0.03916097]\n",
      " [0.11454964]\n",
      " [0.07516751]\n",
      " [0.02912298]\n",
      " [0.09332916]\n",
      " [0.05281276]\n",
      " [0.0407033 ]\n",
      " [0.07307345]\n",
      " [0.06276122]\n",
      " [0.07380593]\n",
      " [0.08899808]\n",
      " [0.10011283]\n",
      " [0.05237976]\n",
      " [0.07974103]\n",
      " [0.08376959]\n",
      " [0.23175383]\n",
      " [0.1181303 ]\n",
      " [0.10348877]\n",
      " [0.13431627]\n",
      " [0.06717655]\n",
      " [0.08240196]\n",
      " [0.13972688]\n",
      " [0.06831342]\n",
      " [0.07694879]\n",
      " [0.06673527]\n",
      " [0.10971808]\n",
      " [0.04558724]\n",
      " [0.07880846]\n",
      " [0.08024773]\n",
      " [0.11753491]\n",
      " [0.21843821]\n",
      " [0.3279068 ]\n",
      " [0.07824978]\n",
      " [0.12849039]\n",
      " [0.2114645 ]\n",
      " [0.0693801 ]\n",
      " [0.05122247]\n",
      " [0.07617193]\n",
      " [0.09788677]\n",
      " [0.03819308]\n",
      " [0.08003351]\n",
      " [0.08669659]\n",
      " [0.07595193]\n",
      " [0.1824551 ]\n",
      " [0.07548061]\n",
      " [0.09227023]\n",
      " [0.08637309]\n",
      " [0.08941013]\n",
      " [0.05775651]\n",
      " [0.05345866]\n",
      " [0.06554788]\n",
      " [0.08287871]\n",
      " [0.03633052]\n",
      " [0.08913022]\n",
      " [0.10616902]\n",
      " [0.07997701]\n",
      " [0.08259857]\n",
      " [0.05139515]\n",
      " [0.16301492]\n",
      " [0.09422797]\n",
      " [0.07780436]\n",
      " [0.0326657 ]\n",
      " [0.04371935]\n",
      " [0.03310549]\n",
      " [0.06532714]\n",
      " [0.10091758]\n",
      " [0.13486272]\n",
      " [0.04865003]\n",
      " [0.04719093]\n",
      " [0.1263656 ]\n",
      " [0.07599539]\n",
      " [0.1155147 ]\n",
      " [0.07917827]\n",
      " [0.12552202]\n",
      " [0.06280276]\n",
      " [0.1633453 ]\n",
      " [0.06408095]\n",
      " [0.03618541]\n",
      " [0.08804172]\n",
      " [0.1118584 ]\n",
      " [0.12405017]\n",
      " [0.08129743]\n",
      " [0.06165528]\n",
      " [0.10267428]\n",
      " [0.2437368 ]\n",
      " [0.06673956]\n",
      " [0.17141032]\n",
      " [0.1218904 ]\n",
      " [0.05971247]\n",
      " [0.07903317]\n",
      " [0.13813487]\n",
      " [0.0335736 ]\n",
      " [0.06319225]\n",
      " [0.0586884 ]\n",
      " [0.0637334 ]\n",
      " [0.08880067]\n",
      " [0.07358781]\n",
      " [0.04115528]\n",
      " [0.09344009]\n",
      " [0.17466223]\n",
      " [0.07885864]\n",
      " [0.05106285]\n",
      " [0.07341328]\n",
      " [0.09117463]\n",
      " [0.07025948]\n",
      " [0.08249161]\n",
      " [0.06618866]\n",
      " [0.10313246]\n",
      " [0.12467679]\n",
      " [0.09657973]\n",
      " [0.13175386]\n",
      " [0.10603777]\n",
      " [0.0772495 ]\n",
      " [0.0635106 ]\n",
      " [0.08167189]\n",
      " [0.06210291]\n",
      " [0.08465874]\n",
      " [0.09638304]\n",
      " [0.15341741]\n",
      " [0.06182986]\n",
      " [0.06431586]\n",
      " [0.11120152]\n",
      " [0.06356534]\n",
      " [0.09342292]\n",
      " [0.03692988]\n",
      " [0.12447888]\n",
      " [0.12754932]\n",
      " [0.05484229]\n",
      " [0.07678258]\n",
      " [0.07090336]\n",
      " [0.12507287]\n",
      " [0.14131242]\n",
      " [0.15089291]\n",
      " [0.10173282]\n",
      " [0.12359804]\n",
      " [0.08971021]\n",
      " [0.14243901]\n",
      " [0.093602  ]\n",
      " [0.08139151]\n",
      " [0.08923727]\n",
      " [0.14113733]\n",
      " [0.19841775]\n",
      " [0.26720324]\n",
      " [0.13721055]\n",
      " [0.2842363 ]\n",
      " [0.08790085]\n",
      " [0.09939542]\n",
      " [0.1083709 ]\n",
      " [0.21270126]\n",
      " [0.12389515]\n",
      " [0.11106351]\n",
      " [0.09040757]\n",
      " [0.10965972]\n",
      " [0.09703845]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 335us/step - loss: 0.4555 - acc: 0.8521 - val_loss: 0.4416 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.4308 - acc: 0.8583 - val_loss: 0.4390 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.4097 - acc: 0.8583 - val_loss: 0.4282 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.4022 - acc: 0.8583 - val_loss: 0.4444 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.4052 - acc: 0.8583 - val_loss: 0.4219 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3984 - acc: 0.8583 - val_loss: 0.4183 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3945 - acc: 0.8583 - val_loss: 0.4228 - val_acc: 0.8417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3903 - acc: 0.8583 - val_loss: 0.4144 - val_acc: 0.8417\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3886 - acc: 0.8583 - val_loss: 0.4135 - val_acc: 0.8417\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3870 - acc: 0.8583 - val_loss: 0.4279 - val_acc: 0.8417\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3838 - acc: 0.8579 - val_loss: 0.4053 - val_acc: 0.8417\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.3829 - acc: 0.8579 - val_loss: 0.4109 - val_acc: 0.8417\n",
      "Epoch 13/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3822 - acc: 0.8583 - val_loss: 0.4009 - val_acc: 0.8417\n",
      "Epoch 14/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3749 - acc: 0.8583 - val_loss: 0.4114 - val_acc: 0.8417\n",
      "Epoch 15/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.3756 - acc: 0.8583 - val_loss: 0.4174 - val_acc: 0.8417\n",
      "Epoch 16/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3755 - acc: 0.8592 - val_loss: 0.3950 - val_acc: 0.8417\n",
      "Epoch 17/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3663 - acc: 0.8588 - val_loss: 0.3960 - val_acc: 0.8417\n",
      "Epoch 18/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3641 - acc: 0.8592 - val_loss: 0.3923 - val_acc: 0.8417\n",
      "Epoch 19/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3646 - acc: 0.8579 - val_loss: 0.3942 - val_acc: 0.8433\n",
      "Epoch 20/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.3687 - acc: 0.8592 - val_loss: 0.3862 - val_acc: 0.8433\n",
      "Epoch 21/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.3567 - acc: 0.8596 - val_loss: 0.3879 - val_acc: 0.8433\n",
      "Epoch 22/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3505 - acc: 0.8633 - val_loss: 0.3792 - val_acc: 0.8517\n",
      "Epoch 23/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3462 - acc: 0.8617 - val_loss: 0.3714 - val_acc: 0.8533\n",
      "Epoch 24/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3482 - acc: 0.8658 - val_loss: 0.3815 - val_acc: 0.8500\n",
      "Epoch 25/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.3475 - acc: 0.8571 - val_loss: 0.3855 - val_acc: 0.8483\n",
      "Epoch 26/30\n",
      "2400/2400 [==============================] - 0s 59us/step - loss: 0.3417 - acc: 0.8633 - val_loss: 0.3999 - val_acc: 0.8500\n",
      "y2_pred:  [[4.43398952e-03]\n",
      " [3.63985300e-02]\n",
      " [1.32207513e-01]\n",
      " [1.57904625e-02]\n",
      " [1.42989457e-02]\n",
      " [3.11551392e-02]\n",
      " [4.19754088e-02]\n",
      " [1.20463967e-02]\n",
      " [1.80608928e-02]\n",
      " [1.00621283e-02]\n",
      " [2.22874194e-01]\n",
      " [5.63447773e-02]\n",
      " [8.98225307e-02]\n",
      " [7.14594424e-02]\n",
      " [6.64791465e-03]\n",
      " [1.93547308e-01]\n",
      " [1.09050870e-02]\n",
      " [8.83522630e-03]\n",
      " [3.46051037e-01]\n",
      " [1.96511805e-01]\n",
      " [3.66254926e-01]\n",
      " [6.86032474e-02]\n",
      " [8.09193254e-02]\n",
      " [6.10888302e-02]\n",
      " [1.55561328e-01]\n",
      " [5.52520752e-02]\n",
      " [1.69992447e-02]\n",
      " [4.03500795e-02]\n",
      " [7.28993416e-02]\n",
      " [1.25385195e-01]\n",
      " [2.44132757e-01]\n",
      " [1.66490793e-01]\n",
      " [3.80964041e-01]\n",
      " [2.13890344e-01]\n",
      " [5.50231934e-02]\n",
      " [9.35107470e-04]\n",
      " [4.49402034e-02]\n",
      " [2.95609206e-01]\n",
      " [4.29966450e-02]\n",
      " [3.56078148e-03]\n",
      " [7.72434175e-02]\n",
      " [1.06806993e-01]\n",
      " [5.01814485e-02]\n",
      " [8.14675689e-02]\n",
      " [5.19648492e-02]\n",
      " [2.91877389e-02]\n",
      " [4.94549572e-02]\n",
      " [5.42309880e-02]\n",
      " [6.06733263e-02]\n",
      " [8.64931643e-02]\n",
      " [6.52621984e-02]\n",
      " [2.84055471e-02]\n",
      " [1.97732449e-02]\n",
      " [2.20910609e-02]\n",
      " [1.05829537e-02]\n",
      " [3.19491625e-02]\n",
      " [5.05366325e-02]\n",
      " [6.81730509e-02]\n",
      " [2.81276554e-01]\n",
      " [1.27198696e-02]\n",
      " [1.90735221e-01]\n",
      " [4.48325872e-02]\n",
      " [1.07301801e-01]\n",
      " [1.97820842e-01]\n",
      " [2.45430619e-01]\n",
      " [2.15337843e-01]\n",
      " [3.90248597e-02]\n",
      " [6.72502518e-02]\n",
      " [1.93440408e-01]\n",
      " [5.05240858e-02]\n",
      " [1.06891692e-01]\n",
      " [9.87651944e-03]\n",
      " [1.87614262e-02]\n",
      " [9.78252292e-03]\n",
      " [1.50551796e-02]\n",
      " [5.08898497e-02]\n",
      " [7.80347586e-02]\n",
      " [7.02625513e-02]\n",
      " [1.18060112e-02]\n",
      " [7.78990984e-02]\n",
      " [1.52965188e-02]\n",
      " [8.89047086e-02]\n",
      " [1.09714270e-03]\n",
      " [2.50164270e-02]\n",
      " [9.37563181e-03]\n",
      " [1.01758540e-02]\n",
      " [6.70594871e-02]\n",
      " [1.54938638e-01]\n",
      " [4.26137447e-03]\n",
      " [8.09800327e-02]\n",
      " [2.12364793e-02]\n",
      " [1.54180825e-02]\n",
      " [6.17574155e-02]\n",
      " [5.75525463e-02]\n",
      " [4.42501307e-02]\n",
      " [1.65950358e-02]\n",
      " [1.26603842e-02]\n",
      " [1.31789654e-01]\n",
      " [3.23217094e-01]\n",
      " [3.47226858e-04]\n",
      " [6.04265928e-02]\n",
      " [1.49990708e-01]\n",
      " [3.00136447e-01]\n",
      " [1.76048577e-02]\n",
      " [7.40512311e-02]\n",
      " [5.76909482e-02]\n",
      " [3.93129587e-02]\n",
      " [5.76466322e-02]\n",
      " [1.39027834e-02]\n",
      " [8.24034214e-05]\n",
      " [2.64462829e-03]\n",
      " [7.35211670e-02]\n",
      " [3.33046615e-02]\n",
      " [1.59686625e-01]\n",
      " [3.43268514e-02]\n",
      " [5.65049946e-02]\n",
      " [2.68031955e-02]\n",
      " [1.52181596e-01]\n",
      " [1.24988645e-01]\n",
      " [3.02548230e-01]\n",
      " [7.55839348e-02]\n",
      " [3.04802656e-02]\n",
      " [2.25198567e-02]\n",
      " [5.46659529e-02]\n",
      " [5.04376590e-02]\n",
      " [2.50752866e-02]\n",
      " [1.81853771e-03]\n",
      " [6.49383664e-02]\n",
      " [3.14682961e-01]\n",
      " [4.27001119e-02]\n",
      " [1.80213749e-02]\n",
      " [1.40275985e-01]\n",
      " [3.21867466e-02]\n",
      " [1.09374970e-01]\n",
      " [2.85388827e-02]\n",
      " [3.92842591e-02]\n",
      " [1.06520355e-02]\n",
      " [2.18761861e-02]\n",
      " [1.79123521e-01]\n",
      " [6.49460852e-02]\n",
      " [2.66046584e-01]\n",
      " [2.64796317e-02]\n",
      " [1.43591553e-01]\n",
      " [9.76160169e-03]\n",
      " [1.33497059e-01]\n",
      " [1.00159943e-01]\n",
      " [2.27951199e-01]\n",
      " [9.68459249e-03]\n",
      " [3.32222581e-02]\n",
      " [9.49184299e-02]\n",
      " [9.80879962e-02]\n",
      " [1.52918875e-01]\n",
      " [2.46488452e-02]\n",
      " [1.25883818e-01]\n",
      " [2.57371068e-02]\n",
      " [2.55414099e-01]\n",
      " [2.58989930e-02]\n",
      " [4.26034331e-02]\n",
      " [4.52170670e-02]\n",
      " [1.15536690e-01]\n",
      " [1.09749168e-01]\n",
      " [1.62584782e-02]\n",
      " [1.45743191e-02]\n",
      " [3.21903586e-01]\n",
      " [1.11217260e-01]\n",
      " [1.84819311e-01]\n",
      " [1.20681524e-03]\n",
      " [1.86070800e-03]\n",
      " [3.08690965e-02]\n",
      " [1.20086640e-01]\n",
      " [3.01250517e-01]\n",
      " [2.47747302e-02]\n",
      " [2.65447199e-02]\n",
      " [8.86878073e-02]\n",
      " [1.76252216e-01]\n",
      " [8.82287920e-02]\n",
      " [1.70938373e-01]\n",
      " [9.30035114e-03]\n",
      " [4.05545235e-02]\n",
      " [2.20636427e-02]\n",
      " [9.62439179e-03]\n",
      " [1.25249028e-02]\n",
      " [3.09374928e-03]\n",
      " [7.15222955e-03]\n",
      " [1.98945999e-02]\n",
      " [2.66214907e-01]\n",
      " [7.56283700e-02]\n",
      " [4.93327975e-02]\n",
      " [1.14414603e-01]\n",
      " [8.65298510e-03]\n",
      " [2.74966657e-02]\n",
      " [6.23030663e-02]\n",
      " [1.78669363e-01]\n",
      " [1.86127722e-02]\n",
      " [1.75157785e-02]\n",
      " [4.63827848e-02]\n",
      " [1.41748190e-01]\n",
      " [8.12950134e-02]\n",
      " [9.39395726e-02]\n",
      " [4.85846400e-03]\n",
      " [1.54937595e-01]\n",
      " [2.44927943e-01]\n",
      " [2.19413072e-01]\n",
      " [2.92713135e-01]\n",
      " [4.67951000e-02]\n",
      " [3.42739522e-02]\n",
      " [1.15325511e-01]\n",
      " [1.18998587e-02]\n",
      " [2.57369637e-01]\n",
      " [3.05625200e-01]\n",
      " [5.33837676e-02]\n",
      " [7.94276595e-03]\n",
      " [9.31387544e-02]\n",
      " [8.35984945e-04]\n",
      " [2.10696936e-01]\n",
      " [1.30711198e-01]\n",
      " [1.72014832e-02]\n",
      " [7.89109766e-02]\n",
      " [6.26198351e-02]\n",
      " [4.11184430e-02]\n",
      " [2.70568132e-02]\n",
      " [5.36060333e-03]\n",
      " [5.70187807e-01]\n",
      " [1.40108198e-01]\n",
      " [1.15975499e-01]\n",
      " [4.00416553e-02]\n",
      " [3.06455493e-01]\n",
      " [2.44904071e-01]\n",
      " [7.98924267e-02]\n",
      " [2.92731643e-01]\n",
      " [4.91221547e-02]\n",
      " [9.03132558e-03]\n",
      " [1.27972066e-02]\n",
      " [3.55829000e-02]\n",
      " [5.77588677e-02]\n",
      " [1.20709270e-01]\n",
      " [1.84062481e-01]\n",
      " [3.44143569e-01]\n",
      " [1.74521059e-01]\n",
      " [3.61019373e-03]\n",
      " [1.48898363e-03]\n",
      " [1.73207819e-02]\n",
      " [3.58350277e-02]\n",
      " [6.79019690e-02]\n",
      " [2.12964118e-02]\n",
      " [3.84583175e-02]\n",
      " [4.82537448e-02]\n",
      " [2.28211135e-01]\n",
      " [7.64160156e-02]\n",
      " [1.75646842e-01]\n",
      " [1.14837766e-01]\n",
      " [1.13630742e-01]\n",
      " [9.69026387e-02]\n",
      " [3.49862278e-02]\n",
      " [8.67344737e-02]\n",
      " [2.15683877e-02]\n",
      " [1.23165548e-02]\n",
      " [3.99365574e-01]\n",
      " [1.06019258e-01]\n",
      " [7.15737045e-02]\n",
      " [1.01938218e-01]\n",
      " [6.63697720e-05]\n",
      " [7.15509057e-03]\n",
      " [2.38230318e-01]\n",
      " [8.25566053e-03]\n",
      " [8.82473588e-03]\n",
      " [2.82110572e-01]\n",
      " [2.88698077e-03]\n",
      " [0.00000000e+00]\n",
      " [2.58412361e-02]\n",
      " [7.95331597e-03]\n",
      " [4.09189165e-02]\n",
      " [1.41516507e-01]\n",
      " [6.52269423e-02]\n",
      " [2.76942670e-01]\n",
      " [4.61927056e-02]\n",
      " [1.49968565e-02]\n",
      " [7.06225634e-02]\n",
      " [5.47961295e-02]\n",
      " [1.04982853e-02]\n",
      " [2.70378888e-02]\n",
      " [3.48088145e-02]\n",
      " [1.43836051e-01]\n",
      " [8.27425718e-02]\n",
      " [1.11889303e-01]\n",
      " [9.01427865e-03]\n",
      " [3.77697349e-01]\n",
      " [3.42737466e-01]\n",
      " [7.35242665e-02]\n",
      " [2.57149965e-01]\n",
      " [2.39451528e-01]\n",
      " [1.87411904e-02]\n",
      " [1.83680564e-01]\n",
      " [1.99694037e-02]\n",
      " [2.52428353e-02]\n",
      " [1.50180757e-02]\n",
      " [6.48778677e-02]\n",
      " [1.08800232e-02]\n",
      " [4.05263603e-02]\n",
      " [5.38614392e-03]\n",
      " [7.71418512e-02]\n",
      " [1.52776241e-02]\n",
      " [7.78687596e-02]\n",
      " [6.99132681e-04]\n",
      " [2.39610106e-01]\n",
      " [9.52135026e-02]\n",
      " [2.79247373e-01]\n",
      " [2.63931543e-01]\n",
      " [4.62661535e-01]\n",
      " [9.19862688e-02]\n",
      " [3.91591787e-02]\n",
      " [2.24320978e-01]\n",
      " [6.56149983e-02]\n",
      " [1.20249987e-02]\n",
      " [1.99374855e-01]\n",
      " [1.93092883e-01]\n",
      " [1.28043592e-02]\n",
      " [4.15453047e-01]\n",
      " [2.88735658e-01]\n",
      " [4.16768581e-01]\n",
      " [1.90505177e-01]\n",
      " [4.62861061e-02]\n",
      " [1.87828064e-01]\n",
      " [2.83750266e-01]\n",
      " [1.70805871e-01]\n",
      " [2.03418434e-02]\n",
      " [1.17175698e-01]\n",
      " [4.42406535e-02]\n",
      " [1.94475189e-01]\n",
      " [1.18153080e-01]\n",
      " [2.68765330e-01]\n",
      " [1.62962869e-01]\n",
      " [1.13107622e-01]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 355us/step - loss: 0.5221 - acc: 0.8408 - val_loss: 0.4549 - val_acc: 0.8417\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4131 - acc: 0.8583 - val_loss: 0.4434 - val_acc: 0.8417\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 57us/step - loss: 0.4052 - acc: 0.8583 - val_loss: 0.4213 - val_acc: 0.8417\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4062 - acc: 0.8583 - val_loss: 0.4231 - val_acc: 0.8417\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 58us/step - loss: 0.4028 - acc: 0.8579 - val_loss: 0.4124 - val_acc: 0.8417\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 56us/step - loss: 0.3961 - acc: 0.8592 - val_loss: 0.4282 - val_acc: 0.8417\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.4062 - acc: 0.8579 - val_loss: 0.4322 - val_acc: 0.8417\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3876 - acc: 0.8579 - val_loss: 0.4437 - val_acc: 0.8417\n",
      "y2_pred:  [[0.07643384]\n",
      " [0.11212236]\n",
      " [0.12037206]\n",
      " [0.06206521]\n",
      " [0.03912371]\n",
      " [0.03143272]\n",
      " [0.03869465]\n",
      " [0.15815938]\n",
      " [0.02538332]\n",
      " [0.12435314]\n",
      " [0.06938401]\n",
      " [0.08739829]\n",
      " [0.05194718]\n",
      " [0.0718528 ]\n",
      " [0.08710474]\n",
      " [0.02713352]\n",
      " [0.03423828]\n",
      " [0.11760467]\n",
      " [0.06990191]\n",
      " [0.04038957]\n",
      " [0.0324803 ]\n",
      " [0.07034579]\n",
      " [0.01110056]\n",
      " [0.06090033]\n",
      " [0.09195533]\n",
      " [0.09732026]\n",
      " [0.02684215]\n",
      " [0.0634166 ]\n",
      " [0.07488561]\n",
      " [0.04407063]\n",
      " [0.04056156]\n",
      " [0.05498356]\n",
      " [0.12015676]\n",
      " [0.03136656]\n",
      " [0.12422603]\n",
      " [0.09056237]\n",
      " [0.02708018]\n",
      " [0.12988329]\n",
      " [0.08332664]\n",
      " [0.07395917]\n",
      " [0.06500641]\n",
      " [0.08188576]\n",
      " [0.0844304 ]\n",
      " [0.07522199]\n",
      " [0.02688161]\n",
      " [0.18644863]\n",
      " [0.09240246]\n",
      " [0.19880652]\n",
      " [0.03900373]\n",
      " [0.01494545]\n",
      " [0.01942804]\n",
      " [0.02350077]\n",
      " [0.12064725]\n",
      " [0.0412876 ]\n",
      " [0.17955562]\n",
      " [0.05343264]\n",
      " [0.07787263]\n",
      " [0.05908945]\n",
      " [0.04916757]\n",
      " [0.05807582]\n",
      " [0.13602588]\n",
      " [0.1560528 ]\n",
      " [0.01140794]\n",
      " [0.04717383]\n",
      " [0.02804005]\n",
      " [0.11689684]\n",
      " [0.07903063]\n",
      " [0.0682252 ]\n",
      " [0.0506866 ]\n",
      " [0.04396889]\n",
      " [0.02633154]\n",
      " [0.14168599]\n",
      " [0.09846985]\n",
      " [0.0455766 ]\n",
      " [0.06908512]\n",
      " [0.07073101]\n",
      " [0.03355399]\n",
      " [0.05201033]\n",
      " [0.04795146]\n",
      " [0.09153968]\n",
      " [0.12073916]\n",
      " [0.02138305]\n",
      " [0.03847954]\n",
      " [0.05389625]\n",
      " [0.04937014]\n",
      " [0.11291486]\n",
      " [0.05245942]\n",
      " [0.07629031]\n",
      " [0.06975105]\n",
      " [0.06191733]\n",
      " [0.02762184]\n",
      " [0.05019614]\n",
      " [0.04191998]\n",
      " [0.03786325]\n",
      " [0.09193483]\n",
      " [0.07401529]\n",
      " [0.0199427 ]\n",
      " [0.02494004]\n",
      " [0.12116572]\n",
      " [0.17071736]\n",
      " [0.04240823]\n",
      " [0.04789835]\n",
      " [0.11409464]\n",
      " [0.01891485]\n",
      " [0.08049572]\n",
      " [0.04214585]\n",
      " [0.09857106]\n",
      " [0.036075  ]\n",
      " [0.04612297]\n",
      " [0.05781108]\n",
      " [0.03814811]\n",
      " [0.06122988]\n",
      " [0.08094275]\n",
      " [0.10445479]\n",
      " [0.07111144]\n",
      " [0.09675503]\n",
      " [0.0382908 ]\n",
      " [0.12465876]\n",
      " [0.07711834]\n",
      " [0.01835936]\n",
      " [0.05059409]\n",
      " [0.06313404]\n",
      " [0.09812561]\n",
      " [0.02307856]\n",
      " [0.02057749]\n",
      " [0.13014823]\n",
      " [0.06896794]\n",
      " [0.0412237 ]\n",
      " [0.1370213 ]\n",
      " [0.03048745]\n",
      " [0.01967347]\n",
      " [0.13134602]\n",
      " [0.0149346 ]\n",
      " [0.06758705]\n",
      " [0.01768255]\n",
      " [0.05831313]\n",
      " [0.12693495]\n",
      " [0.04069951]\n",
      " [0.04657257]\n",
      " [0.01243636]\n",
      " [0.0192087 ]\n",
      " [0.16078869]\n",
      " [0.03368527]\n",
      " [0.05774534]\n",
      " [0.01742154]\n",
      " [0.03177658]\n",
      " [0.06744647]\n",
      " [0.05977955]\n",
      " [0.0728153 ]\n",
      " [0.02824605]\n",
      " [0.00914535]\n",
      " [0.06256768]\n",
      " [0.09350953]\n",
      " [0.042133  ]\n",
      " [0.08761424]\n",
      " [0.13014582]\n",
      " [0.03736845]\n",
      " [0.0340634 ]\n",
      " [0.06061885]\n",
      " [0.08744413]\n",
      " [0.03186512]\n",
      " [0.04220697]\n",
      " [0.03766021]\n",
      " [0.02718621]\n",
      " [0.05933803]\n",
      " [0.05916697]\n",
      " [0.01886448]\n",
      " [0.04398587]\n",
      " [0.04898778]\n",
      " [0.06169188]\n",
      " [0.09709916]\n",
      " [0.10457897]\n",
      " [0.06039348]\n",
      " [0.03747866]\n",
      " [0.03136662]\n",
      " [0.0859029 ]\n",
      " [0.05738091]\n",
      " [0.13029793]\n",
      " [0.01822194]\n",
      " [0.09017545]\n",
      " [0.0550884 ]\n",
      " [0.13393545]\n",
      " [0.02488771]\n",
      " [0.06049299]\n",
      " [0.1139048 ]\n",
      " [0.11030957]\n",
      " [0.01183364]\n",
      " [0.06316799]\n",
      " [0.075376  ]\n",
      " [0.09058544]\n",
      " [0.05966353]\n",
      " [0.07270169]\n",
      " [0.04331025]\n",
      " [0.05601507]\n",
      " [0.05499664]\n",
      " [0.054791  ]\n",
      " [0.07519484]\n",
      " [0.06115615]\n",
      " [0.06341711]\n",
      " [0.05518514]\n",
      " [0.04661411]\n",
      " [0.08536884]\n",
      " [0.07662991]\n",
      " [0.12295532]\n",
      " [0.04042622]\n",
      " [0.05877882]\n",
      " [0.01961675]\n",
      " [0.06817243]\n",
      " [0.05797306]\n",
      " [0.02191588]\n",
      " [0.07102042]\n",
      " [0.04399553]\n",
      " [0.09247714]\n",
      " [0.06161129]\n",
      " [0.02858326]\n",
      " [0.05938628]\n",
      " [0.06275904]\n",
      " [0.03923959]\n",
      " [0.14668792]\n",
      " [0.11883935]\n",
      " [0.08666018]\n",
      " [0.07954898]\n",
      " [0.0526323 ]\n",
      " [0.05188322]\n",
      " [0.06006643]\n",
      " [0.02940613]\n",
      " [0.12191296]\n",
      " [0.01549554]\n",
      " [0.0739907 ]\n",
      " [0.03663844]\n",
      " [0.14095476]\n",
      " [0.07527474]\n",
      " [0.07253689]\n",
      " [0.09800354]\n",
      " [0.22604772]\n",
      " [0.08059379]\n",
      " [0.02794892]\n",
      " [0.05708313]\n",
      " [0.13945282]\n",
      " [0.04640332]\n",
      " [0.08637062]\n",
      " [0.0406118 ]\n",
      " [0.05974466]\n",
      " [0.09461379]\n",
      " [0.07387736]\n",
      " [0.07114345]\n",
      " [0.02859476]\n",
      " [0.13653138]\n",
      " [0.04941767]\n",
      " [0.06338611]\n",
      " [0.1416519 ]\n",
      " [0.12318555]\n",
      " [0.1262056 ]\n",
      " [0.15485159]\n",
      " [0.05095595]\n",
      " [0.08826038]\n",
      " [0.04867145]\n",
      " [0.09904316]\n",
      " [0.11434677]\n",
      " [0.06119278]\n",
      " [0.16997212]\n",
      " [0.08092639]\n",
      " [0.06071132]\n",
      " [0.10211739]\n",
      " [0.04748556]\n",
      " [0.05215967]\n",
      " [0.03316522]\n",
      " [0.01343799]\n",
      " [0.13632637]\n",
      " [0.09624216]\n",
      " [0.20623562]\n",
      " [0.04108059]\n",
      " [0.02815932]\n",
      " [0.10311902]\n",
      " [0.02938753]\n",
      " [0.01096004]\n",
      " [0.04833737]\n",
      " [0.05795109]\n",
      " [0.11835203]\n",
      " [0.1993669 ]\n",
      " [0.1253038 ]\n",
      " [0.04972643]\n",
      " [0.01298845]\n",
      " [0.08226565]\n",
      " [0.02671051]\n",
      " [0.04930821]\n",
      " [0.03308919]\n",
      " [0.07607186]\n",
      " [0.05644336]\n",
      " [0.06604162]\n",
      " [0.10713845]\n",
      " [0.07785243]\n",
      " [0.03150296]\n",
      " [0.03471303]\n",
      " [0.0829846 ]\n",
      " [0.04520547]\n",
      " [0.08371118]\n",
      " [0.07960236]\n",
      " [0.02821934]\n",
      " [0.07445019]\n",
      " [0.05920866]\n",
      " [0.11248586]\n",
      " [0.05064368]\n",
      " [0.0916999 ]\n",
      " [0.04711106]\n",
      " [0.04029697]\n",
      " [0.06037936]\n",
      " [0.01960045]\n",
      " [0.05228919]\n",
      " [0.12910488]\n",
      " [0.05717504]\n",
      " [0.22609109]\n",
      " [0.24458426]\n",
      " [0.09964362]\n",
      " [0.01498038]\n",
      " [0.11060274]\n",
      " [0.05604249]\n",
      " [0.17057204]\n",
      " [0.08351833]\n",
      " [0.03891316]\n",
      " [0.03657991]\n",
      " [0.11371356]\n",
      " [0.11930665]\n",
      " [0.31696838]\n",
      " [0.05382773]\n",
      " [0.03571725]\n",
      " [0.11122185]\n",
      " [0.21271324]\n",
      " [0.10906674]\n",
      " [0.13947317]\n",
      " [0.04770931]\n",
      " [0.09453673]\n",
      " [0.07919233]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 404us/step - loss: 0.4331 - acc: 0.8629 - val_loss: 0.4673 - val_acc: 0.8233\n",
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 79us/step - loss: 0.4027 - acc: 0.8629 - val_loss: 0.4598 - val_acc: 0.8233\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2400 [==============================] - 0s 82us/step - loss: 0.3957 - acc: 0.8621 - val_loss: 0.4797 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 83us/step - loss: 0.3988 - acc: 0.8621 - val_loss: 0.4592 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 80us/step - loss: 0.3904 - acc: 0.8633 - val_loss: 0.4659 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 68us/step - loss: 0.3889 - acc: 0.8621 - val_loss: 0.4429 - val_acc: 0.8217\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3896 - acc: 0.8625 - val_loss: 0.4437 - val_acc: 0.8233\n",
      "Epoch 8/30\n",
      "2400/2400 [==============================] - 0s 71us/step - loss: 0.3822 - acc: 0.8646 - val_loss: 0.4670 - val_acc: 0.8233\n",
      "Epoch 9/30\n",
      "2400/2400 [==============================] - 0s 73us/step - loss: 0.3801 - acc: 0.8625 - val_loss: 0.4364 - val_acc: 0.8217\n",
      "Epoch 10/30\n",
      "2400/2400 [==============================] - 0s 78us/step - loss: 0.3780 - acc: 0.8642 - val_loss: 0.4374 - val_acc: 0.8233\n",
      "Epoch 11/30\n",
      "2400/2400 [==============================] - 0s 70us/step - loss: 0.3789 - acc: 0.8621 - val_loss: 0.4767 - val_acc: 0.8217\n",
      "Epoch 12/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.3795 - acc: 0.8633 - val_loss: 0.4549 - val_acc: 0.8200\n",
      "y2_pred:  [[0.12378806]\n",
      " [0.12147558]\n",
      " [0.04560587]\n",
      " [0.17207989]\n",
      " [0.42231816]\n",
      " [0.25405332]\n",
      " [0.13107732]\n",
      " [0.13346618]\n",
      " [0.11471793]\n",
      " [0.08754563]\n",
      " [0.06822643]\n",
      " [0.15521777]\n",
      " [0.07456732]\n",
      " [0.05172938]\n",
      " [0.09103474]\n",
      " [0.05077547]\n",
      " [0.10315025]\n",
      " [0.13379845]\n",
      " [0.10628977]\n",
      " [0.10357916]\n",
      " [0.56608695]\n",
      " [0.04204059]\n",
      " [0.06593281]\n",
      " [0.22584108]\n",
      " [0.1094833 ]\n",
      " [0.33012652]\n",
      " [0.26548707]\n",
      " [0.05523089]\n",
      " [0.0793128 ]\n",
      " [0.16657314]\n",
      " [0.43915522]\n",
      " [0.10519028]\n",
      " [0.11243328]\n",
      " [0.10300696]\n",
      " [0.10856372]\n",
      " [0.03729352]\n",
      " [0.0871574 ]\n",
      " [0.09749338]\n",
      " [0.27935654]\n",
      " [0.02501559]\n",
      " [0.08202267]\n",
      " [0.12501931]\n",
      " [0.17269829]\n",
      " [0.05971357]\n",
      " [0.17050278]\n",
      " [0.03664383]\n",
      " [0.13127372]\n",
      " [0.07082698]\n",
      " [0.0703581 ]\n",
      " [0.04126287]\n",
      " [0.06962016]\n",
      " [0.03610399]\n",
      " [0.03921959]\n",
      " [0.21621644]\n",
      " [0.06572279]\n",
      " [0.07359555]\n",
      " [0.1923739 ]\n",
      " [0.15482134]\n",
      " [0.07379374]\n",
      " [0.09102947]\n",
      " [0.213644  ]\n",
      " [0.3143221 ]\n",
      " [0.10785481]\n",
      " [0.06776452]\n",
      " [0.05137646]\n",
      " [0.11738992]\n",
      " [0.09715438]\n",
      " [0.05697945]\n",
      " [0.07929173]\n",
      " [0.06781197]\n",
      " [0.09806839]\n",
      " [0.10739246]\n",
      " [0.06461501]\n",
      " [0.07887486]\n",
      " [0.23309645]\n",
      " [0.04172668]\n",
      " [0.12726218]\n",
      " [0.21010232]\n",
      " [0.07785645]\n",
      " [0.11018825]\n",
      " [0.09536648]\n",
      " [0.11891273]\n",
      " [0.10611826]\n",
      " [0.09068644]\n",
      " [0.10065323]\n",
      " [0.05776569]\n",
      " [0.45884523]\n",
      " [0.05712199]\n",
      " [0.13923118]\n",
      " [0.15567666]\n",
      " [0.14278519]\n",
      " [0.08001131]\n",
      " [0.12281397]\n",
      " [0.10359916]\n",
      " [0.15043673]\n",
      " [0.14104414]\n",
      " [0.07861015]\n",
      " [0.08060986]\n",
      " [0.10806409]\n",
      " [0.06663856]\n",
      " [0.06015816]\n",
      " [0.03552869]\n",
      " [0.0590044 ]\n",
      " [0.06977081]\n",
      " [0.07237691]\n",
      " [0.10964286]\n",
      " [0.05689055]\n",
      " [0.08244079]\n",
      " [0.06044036]\n",
      " [0.04804525]\n",
      " [0.11552185]\n",
      " [0.08486149]\n",
      " [0.10563427]\n",
      " [0.14953569]\n",
      " [0.15657645]\n",
      " [0.12779358]\n",
      " [0.06320766]\n",
      " [0.15041396]\n",
      " [0.33038658]\n",
      " [0.05969048]\n",
      " [0.13459313]\n",
      " [0.12232152]\n",
      " [0.03936595]\n",
      " [0.08809349]\n",
      " [0.07473567]\n",
      " [0.09002084]\n",
      " [0.07653469]\n",
      " [0.23988184]\n",
      " [0.13345146]\n",
      " [0.2417638 ]\n",
      " [0.10191581]\n",
      " [0.15630996]\n",
      " [0.11478031]\n",
      " [0.39032358]\n",
      " [0.27720731]\n",
      " [0.1669617 ]\n",
      " [0.21664721]\n",
      " [0.16079563]\n",
      " [0.05608812]\n",
      " [0.5407802 ]\n",
      " [0.13664618]\n",
      " [0.07396185]\n",
      " [0.08376268]\n",
      " [0.04778424]\n",
      " [0.0869047 ]\n",
      " [0.04892561]\n",
      " [0.1883089 ]\n",
      " [0.10212651]\n",
      " [0.07053283]\n",
      " [0.10438439]\n",
      " [0.14022449]\n",
      " [0.20954445]\n",
      " [0.05340719]\n",
      " [0.07618764]\n",
      " [0.12396032]\n",
      " [0.08491048]\n",
      " [0.2980464 ]\n",
      " [0.44996455]\n",
      " [0.08179626]\n",
      " [0.14846364]\n",
      " [0.15410319]\n",
      " [0.17539433]\n",
      " [0.05888543]\n",
      " [0.12834963]\n",
      " [0.09749281]\n",
      " [0.22169358]\n",
      " [0.07948592]\n",
      " [0.10353175]\n",
      " [0.09198502]\n",
      " [0.11081791]\n",
      " [0.232954  ]\n",
      " [0.04650044]\n",
      " [0.20057878]\n",
      " [0.05693704]\n",
      " [0.10830554]\n",
      " [0.06324324]\n",
      " [0.12118533]\n",
      " [0.12121898]\n",
      " [0.2056965 ]\n",
      " [0.08915707]\n",
      " [0.0529286 ]\n",
      " [0.13289106]\n",
      " [0.09979498]\n",
      " [0.06585154]\n",
      " [0.14719805]\n",
      " [0.10712615]\n",
      " [0.05986547]\n",
      " [0.14618745]\n",
      " [0.11532852]\n",
      " [0.09578237]\n",
      " [0.09841177]\n",
      " [0.0324319 ]\n",
      " [0.53348607]\n",
      " [0.16904905]\n",
      " [0.08375633]\n",
      " [0.05518836]\n",
      " [0.2835489 ]\n",
      " [0.0786356 ]\n",
      " [0.06973696]\n",
      " [0.12729764]\n",
      " [0.11397716]\n",
      " [0.26335382]\n",
      " [0.05003515]\n",
      " [0.0811235 ]\n",
      " [0.18147188]\n",
      " [0.10714656]\n",
      " [0.24216121]\n",
      " [0.18971685]\n",
      " [0.05286571]\n",
      " [0.17619175]\n",
      " [0.10005414]\n",
      " [0.03847316]\n",
      " [0.12460721]\n",
      " [0.10567865]\n",
      " [0.07911935]\n",
      " [0.10373715]\n",
      " [0.11430129]\n",
      " [0.09595671]\n",
      " [0.09233817]\n",
      " [0.09055701]\n",
      " [0.03096464]\n",
      " [0.03170931]\n",
      " [0.12737066]\n",
      " [0.0753445 ]\n",
      " [0.08174437]\n",
      " [0.05668724]\n",
      " [0.05270672]\n",
      " [0.16718975]\n",
      " [0.19350833]\n",
      " [0.19880405]\n",
      " [0.03604585]\n",
      " [0.10774213]\n",
      " [0.04646277]\n",
      " [0.13490584]\n",
      " [0.11123735]\n",
      " [0.05891123]\n",
      " [0.06781229]\n",
      " [0.20730272]\n",
      " [0.14642853]\n",
      " [0.0535408 ]\n",
      " [0.11892453]\n",
      " [0.1591011 ]\n",
      " [0.10371053]\n",
      " [0.07407743]\n",
      " [0.38478026]\n",
      " [0.04820079]\n",
      " [0.07509771]\n",
      " [0.07777935]\n",
      " [0.12479591]\n",
      " [0.13474256]\n",
      " [0.17571425]\n",
      " [0.1540274 ]\n",
      " [0.13853067]\n",
      " [0.10139576]\n",
      " [0.1563285 ]\n",
      " [0.09343237]\n",
      " [0.10062116]\n",
      " [0.23519742]\n",
      " [0.10721007]\n",
      " [0.14462343]\n",
      " [0.04512778]\n",
      " [0.09203908]\n",
      " [0.14681864]\n",
      " [0.13699627]\n",
      " [0.18910548]\n",
      " [0.0027357 ]\n",
      " [0.10001901]\n",
      " [0.17708853]\n",
      " [0.09097761]\n",
      " [0.40085003]\n",
      " [0.04945427]\n",
      " [0.09722477]\n",
      " [0.10827488]\n",
      " [0.11781627]\n",
      " [0.07369545]\n",
      " [0.14117277]\n",
      " [0.04655728]\n",
      " [0.08445647]\n",
      " [0.07247651]\n",
      " [0.08328101]\n",
      " [0.11856762]\n",
      " [0.22133598]\n",
      " [0.18782344]\n",
      " [0.09127399]\n",
      " [0.10979024]\n",
      " [0.21198362]\n",
      " [0.14171308]\n",
      " [0.12983444]\n",
      " [0.08874977]\n",
      " [0.10022151]\n",
      " [0.0865109 ]\n",
      " [0.1593301 ]\n",
      " [0.17779207]\n",
      " [0.04988751]\n",
      " [0.08600101]\n",
      " [0.1729218 ]\n",
      " [0.05375546]\n",
      " [0.2946452 ]\n",
      " [0.0478681 ]\n",
      " [0.0691745 ]\n",
      " [0.07281539]\n",
      " [0.08503386]\n",
      " [0.11688372]\n",
      " [0.07294378]\n",
      " [0.21812093]\n",
      " [0.05830178]\n",
      " [0.11944392]\n",
      " [0.09587279]\n",
      " [0.11295986]\n",
      " [0.10707715]\n",
      " [0.11692226]\n",
      " [0.17553124]\n",
      " [0.17464206]\n",
      " [0.185853  ]\n",
      " [0.13403216]\n",
      " [0.12329155]\n",
      " [0.08931848]\n",
      " [0.2635141 ]\n",
      " [0.37848315]\n",
      " [0.11677378]\n",
      " [0.19779956]\n",
      " [0.2655543 ]\n",
      " [0.13209444]\n",
      " [0.08734271]\n",
      " [0.17318818]\n",
      " [0.04102704]\n",
      " [0.11887872]\n",
      " [0.06316787]\n",
      " [0.04996447]\n",
      " [0.04776875]\n",
      " [0.12739958]\n",
      " [0.14598301]\n",
      " [0.1800083 ]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/30\n",
      "2400/2400 [==============================] - 1s 409us/step - loss: 0.4143 - acc: 0.8608 - val_loss: 0.5012 - val_acc: 0.8233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "2400/2400 [==============================] - 0s 62us/step - loss: 0.4103 - acc: 0.8625 - val_loss: 0.4580 - val_acc: 0.8233\n",
      "Epoch 3/30\n",
      "2400/2400 [==============================] - 0s 61us/step - loss: 0.4043 - acc: 0.8629 - val_loss: 0.4799 - val_acc: 0.8233\n",
      "Epoch 4/30\n",
      "2400/2400 [==============================] - 0s 60us/step - loss: 0.3977 - acc: 0.8629 - val_loss: 0.4525 - val_acc: 0.8233\n",
      "Epoch 5/30\n",
      "2400/2400 [==============================] - 0s 63us/step - loss: 0.3941 - acc: 0.8633 - val_loss: 0.4592 - val_acc: 0.8233\n",
      "Epoch 6/30\n",
      "2400/2400 [==============================] - 0s 66us/step - loss: 0.3984 - acc: 0.8625 - val_loss: 0.4556 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "2400/2400 [==============================] - 0s 65us/step - loss: 0.3835 - acc: 0.8629 - val_loss: 0.4582 - val_acc: 0.8233\n",
      "y2_pred:  [[0.05154076]\n",
      " [0.13198009]\n",
      " [0.04015043]\n",
      " [0.02710101]\n",
      " [0.04281691]\n",
      " [0.24785027]\n",
      " [0.13118508]\n",
      " [0.13587463]\n",
      " [0.13249439]\n",
      " [0.06251976]\n",
      " [0.09631184]\n",
      " [0.03943524]\n",
      " [0.08984181]\n",
      " [0.0318121 ]\n",
      " [0.13021347]\n",
      " [0.05156964]\n",
      " [0.02784747]\n",
      " [0.24591511]\n",
      " [0.15565035]\n",
      " [0.08053046]\n",
      " [0.08791006]\n",
      " [0.13645816]\n",
      " [0.08194715]\n",
      " [0.07555783]\n",
      " [0.0091584 ]\n",
      " [0.05818576]\n",
      " [0.0999707 ]\n",
      " [0.07353199]\n",
      " [0.07725078]\n",
      " [0.07638279]\n",
      " [0.17696705]\n",
      " [0.1735667 ]\n",
      " [0.00823894]\n",
      " [0.13300622]\n",
      " [0.08178037]\n",
      " [0.12272364]\n",
      " [0.07662502]\n",
      " [0.16275424]\n",
      " [0.04848179]\n",
      " [0.25005236]\n",
      " [0.1156165 ]\n",
      " [0.07678503]\n",
      " [0.27167845]\n",
      " [0.21285933]\n",
      " [0.15880036]\n",
      " [0.4011594 ]\n",
      " [0.05332792]\n",
      " [0.22711343]\n",
      " [0.18141213]\n",
      " [0.11224127]\n",
      " [0.09348091]\n",
      " [0.17525536]\n",
      " [0.12664345]\n",
      " [0.16569036]\n",
      " [0.19108441]\n",
      " [0.19922861]\n",
      " [0.29521126]\n",
      " [0.04495966]\n",
      " [0.19153613]\n",
      " [0.06491023]\n",
      " [0.14411739]\n",
      " [0.07818225]\n",
      " [0.06587684]\n",
      " [0.09723842]\n",
      " [0.2928401 ]\n",
      " [0.07865515]\n",
      " [0.11806217]\n",
      " [0.03183284]\n",
      " [0.10080385]\n",
      " [0.07390797]\n",
      " [0.18977582]\n",
      " [0.063833  ]\n",
      " [0.22920409]\n",
      " [0.08658189]\n",
      " [0.00794742]\n",
      " [0.02798811]\n",
      " [0.08661595]\n",
      " [0.05583233]\n",
      " [0.12371624]\n",
      " [0.035759  ]\n",
      " [0.19218054]\n",
      " [0.16832468]\n",
      " [0.25376585]\n",
      " [0.11155522]\n",
      " [0.17642108]\n",
      " [0.08167222]\n",
      " [0.30768758]\n",
      " [0.08099699]\n",
      " [0.05423045]\n",
      " [0.03408661]\n",
      " [0.04559588]\n",
      " [0.03215355]\n",
      " [0.12295431]\n",
      " [0.21739611]\n",
      " [0.16861814]\n",
      " [0.03925928]\n",
      " [0.0599122 ]\n",
      " [0.19247392]\n",
      " [0.21818131]\n",
      " [0.13241151]\n",
      " [0.15826395]\n",
      " [0.04542807]\n",
      " [0.05192429]\n",
      " [0.1815747 ]\n",
      " [0.06826696]\n",
      " [0.30453876]\n",
      " [0.05975673]\n",
      " [0.11192524]\n",
      " [0.05689663]\n",
      " [0.01165441]\n",
      " [0.07824168]\n",
      " [0.0655776 ]\n",
      " [0.21907586]\n",
      " [0.22373772]\n",
      " [0.14215958]\n",
      " [0.06548673]\n",
      " [0.14070585]\n",
      " [0.07806113]\n",
      " [0.06916261]\n",
      " [0.08408558]\n",
      " [0.07697761]\n",
      " [0.21376488]\n",
      " [0.15571842]\n",
      " [0.10174316]\n",
      " [0.12459627]\n",
      " [0.1802535 ]\n",
      " [0.19161046]\n",
      " [0.10879347]\n",
      " [0.20861718]\n",
      " [0.08947906]\n",
      " [0.09614855]\n",
      " [0.08076563]\n",
      " [0.297841  ]\n",
      " [0.13500372]\n",
      " [0.18031347]\n",
      " [0.04146904]\n",
      " [0.06200099]\n",
      " [0.14486507]\n",
      " [0.23428956]\n",
      " [0.16499642]\n",
      " [0.3180319 ]\n",
      " [0.09328416]\n",
      " [0.23852804]\n",
      " [0.06655297]\n",
      " [0.14724496]\n",
      " [0.2841376 ]\n",
      " [0.11360091]\n",
      " [0.22974095]\n",
      " [0.13850823]\n",
      " [0.19114617]\n",
      " [0.10867468]\n",
      " [0.21539772]\n",
      " [0.09705904]\n",
      " [0.25863922]\n",
      " [0.04440594]\n",
      " [0.11428598]\n",
      " [0.19320345]\n",
      " [0.23111245]\n",
      " [0.12754586]\n",
      " [0.24685606]\n",
      " [0.27953297]\n",
      " [0.10935611]\n",
      " [0.02835721]\n",
      " [0.10284761]\n",
      " [0.27673155]\n",
      " [0.07084739]\n",
      " [0.25970927]\n",
      " [0.19133598]\n",
      " [0.06049895]\n",
      " [0.15177214]\n",
      " [0.13974789]\n",
      " [0.13193902]\n",
      " [0.10287347]\n",
      " [0.07416546]\n",
      " [0.04960409]\n",
      " [0.13520417]\n",
      " [0.04821685]\n",
      " [0.06553614]\n",
      " [0.24285576]\n",
      " [0.05124125]\n",
      " [0.21474713]\n",
      " [0.27835423]\n",
      " [0.01615986]\n",
      " [0.2620468 ]\n",
      " [0.18232298]\n",
      " [0.05522341]\n",
      " [0.22210702]\n",
      " [0.09220409]\n",
      " [0.14959735]\n",
      " [0.08490044]\n",
      " [0.22554299]\n",
      " [0.32160997]\n",
      " [0.11796707]\n",
      " [0.18264458]\n",
      " [0.10049599]\n",
      " [0.08037528]\n",
      " [0.08943382]\n",
      " [0.13943943]\n",
      " [0.06149051]\n",
      " [0.00744733]\n",
      " [0.17522612]\n",
      " [0.09479213]\n",
      " [0.03611314]\n",
      " [0.070867  ]\n",
      " [0.21701041]\n",
      " [0.31077218]\n",
      " [0.00762948]\n",
      " [0.10221282]\n",
      " [0.3244431 ]\n",
      " [0.06506121]\n",
      " [0.12476987]\n",
      " [0.10120931]\n",
      " [0.02341697]\n",
      " [0.03209043]\n",
      " [0.10873923]\n",
      " [0.07313824]\n",
      " [0.04372966]\n",
      " [0.05756849]\n",
      " [0.06938171]\n",
      " [0.05667403]\n",
      " [0.01202601]\n",
      " [0.08308753]\n",
      " [0.06905729]\n",
      " [0.12051967]\n",
      " [0.23825583]\n",
      " [0.29037386]\n",
      " [0.2915941 ]\n",
      " [0.05909976]\n",
      " [0.2679069 ]\n",
      " [0.19428995]\n",
      " [0.23106849]\n",
      " [0.06258276]\n",
      " [0.02242664]\n",
      " [0.08184868]\n",
      " [0.0915747 ]\n",
      " [0.0663543 ]\n",
      " [0.03785422]\n",
      " [0.16181749]\n",
      " [0.1116918 ]\n",
      " [0.05325314]\n",
      " [0.13360003]\n",
      " [0.21438909]\n",
      " [0.08746809]\n",
      " [0.15730214]\n",
      " [0.24405658]\n",
      " [0.08256012]\n",
      " [0.06366318]\n",
      " [0.00880665]\n",
      " [0.12768736]\n",
      " [0.11517721]\n",
      " [0.15645272]\n",
      " [0.3243732 ]\n",
      " [0.2587083 ]\n",
      " [0.074754  ]\n",
      " [0.06138235]\n",
      " [0.11764362]\n",
      " [0.26999572]\n",
      " [0.06150386]\n",
      " [0.00672153]\n",
      " [0.13121986]\n",
      " [0.20368055]\n",
      " [0.00961059]\n",
      " [0.04581654]\n",
      " [0.2130292 ]\n",
      " [0.07381058]\n",
      " [0.27252048]\n",
      " [0.06201711]\n",
      " [0.26441243]\n",
      " [0.19260275]\n",
      " [0.02120492]\n",
      " [0.20154306]\n",
      " [0.04461747]\n",
      " [0.28372198]\n",
      " [0.12603578]\n",
      " [0.30464083]\n",
      " [0.09968424]\n",
      " [0.08760515]\n",
      " [0.06585342]\n",
      " [0.06570038]\n",
      " [0.0711996 ]\n",
      " [0.12123436]\n",
      " [0.06431159]\n",
      " [0.06494975]\n",
      " [0.22715217]\n",
      " [0.06006628]\n",
      " [0.1665524 ]\n",
      " [0.07115072]\n",
      " [0.06767991]\n",
      " [0.06347629]\n",
      " [0.03395486]\n",
      " [0.2050268 ]\n",
      " [0.05322692]\n",
      " [0.2146101 ]\n",
      " [0.09937212]\n",
      " [0.07132   ]\n",
      " [0.03249088]\n",
      " [0.29761717]\n",
      " [0.08440506]\n",
      " [0.12284982]\n",
      " [0.20359936]\n",
      " [0.05847719]\n",
      " [0.2986992 ]\n",
      " [0.3163937 ]\n",
      " [0.03674775]\n",
      " [0.2603588 ]\n",
      " [0.10456112]\n",
      " [0.04280493]\n",
      " [0.10230482]\n",
      " [0.16501972]\n",
      " [0.1354599 ]\n",
      " [0.0712378 ]\n",
      " [0.18584388]\n",
      " [0.06015483]\n",
      " [0.10949409]\n",
      " [0.26357824]\n",
      " [0.08993736]\n",
      " [0.05428743]\n",
      " [0.04211646]\n",
      " [0.14265314]\n",
      " [0.0363937 ]\n",
      " [0.25788757]\n",
      " [0.05589882]\n",
      " [0.42354017]\n",
      " [0.12661782]\n",
      " [0.01060125]\n",
      " [0.130463  ]\n",
      " [0.06763923]\n",
      " [0.07335284]\n",
      " [0.0363306 ]\n",
      " [0.05544707]\n",
      " [0.16181651]\n",
      " [0.18342485]\n",
      " [0.08911248]]\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.041666666666666664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0035087719298245615, 0.0, 0.010526315789473684, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5208333333333334, 0.5, 0.5, 0.4982456140350877, 0.5, 0.49473684210526314, 0.5]\n",
      "tn_list:  [285, 285, 285, 285, 285, 285, 284, 285, 282, 285]\n",
      "fp_list:  [0, 0, 0, 0, 0, 0, 1, 0, 3, 0]\n",
      "fn_list:  [49, 49, 49, 46, 48, 48, 48, 48, 48, 48]\n",
      "tp_list:  [0, 0, 0, 2, 0, 0, 0, 0, 0, 0]\n",
      "2846 4 481 2\n"
     ]
    }
   ],
   "source": [
    "df_x_train_chi = pd.DataFrame(x_train_chi)\n",
    "df_x_train_chi.head()\n",
    "\n",
    "#FNN\n",
    "def get_FNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #get number of columns in training data\n",
    "    n_cols = X2_train.shape[1]\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #compile model using mse as a measure of model performance\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    from keras.callbacks import EarlyStopping\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "    #train model\n",
    "    model.fit(X2_train, y2_train, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    print('y2_pred: ',y2_pred)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_FNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "print('tn_list: ',tn_list)\n",
    "print ('fp_list: ',fp_list)\n",
    "print ('fn_list: ',fn_list)\n",
    "print ('tp_list: ',tp_list)\n",
    "\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 911us/step - loss: 0.5269 - acc: 0.8320 - val_loss: 0.4348 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 81us/step - loss: 0.4024 - acc: 0.8587 - val_loss: 0.4252 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 80us/step - loss: 0.3949 - acc: 0.8587 - val_loss: 0.4164 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 86us/step - loss: 0.3861 - acc: 0.8587 - val_loss: 0.4132 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 84us/step - loss: 0.3789 - acc: 0.8587 - val_loss: 0.4027 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 674us/step - loss: 0.5396 - acc: 0.8145 - val_loss: 0.4305 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 78us/step - loss: 0.3980 - acc: 0.8587 - val_loss: 0.4243 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 80us/step - loss: 0.3913 - acc: 0.8587 - val_loss: 0.4171 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 82us/step - loss: 0.3816 - acc: 0.8587 - val_loss: 0.4063 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 79us/step - loss: 0.3805 - acc: 0.8587 - val_loss: 0.3989 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2399 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2399/2399 [==============================] - 2s 722us/step - loss: 0.5549 - acc: 0.8233 - val_loss: 0.4324 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2399/2399 [==============================] - 0s 82us/step - loss: 0.4039 - acc: 0.8587 - val_loss: 0.4265 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2399/2399 [==============================] - 0s 81us/step - loss: 0.3968 - acc: 0.8587 - val_loss: 0.4183 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2399/2399 [==============================] - 0s 79us/step - loss: 0.3910 - acc: 0.8587 - val_loss: 0.4079 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2399/2399 [==============================] - 0s 83us/step - loss: 0.3819 - acc: 0.8587 - val_loss: 0.4091 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 865us/step - loss: 0.5453 - acc: 0.8217 - val_loss: 0.4369 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.4049 - acc: 0.8583 - val_loss: 0.4336 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 82us/step - loss: 0.3981 - acc: 0.8583 - val_loss: 0.4292 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 81us/step - loss: 0.3882 - acc: 0.8583 - val_loss: 0.4130 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 82us/step - loss: 0.3790 - acc: 0.8583 - val_loss: 0.4050 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 846us/step - loss: 0.5331 - acc: 0.8250 - val_loss: 0.4347 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 83us/step - loss: 0.4024 - acc: 0.8583 - val_loss: 0.4269 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.3970 - acc: 0.8583 - val_loss: 0.4224 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 80us/step - loss: 0.3890 - acc: 0.8583 - val_loss: 0.4119 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 80us/step - loss: 0.3829 - acc: 0.8583 - val_loss: 0.4044 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 884us/step - loss: 0.5270 - acc: 0.8579 - val_loss: 0.4335 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 83us/step - loss: 0.4003 - acc: 0.8583 - val_loss: 0.4273 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.3934 - acc: 0.8583 - val_loss: 0.4261 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 83us/step - loss: 0.3823 - acc: 0.8583 - val_loss: 0.4106 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 80us/step - loss: 0.3772 - acc: 0.8583 - val_loss: 0.4038 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 945us/step - loss: 0.5402 - acc: 0.8458 - val_loss: 0.4309 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.4022 - acc: 0.8583 - val_loss: 0.4254 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3967 - acc: 0.8583 - val_loss: 0.4188 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3909 - acc: 0.8583 - val_loss: 0.4114 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.3859 - acc: 0.8583 - val_loss: 0.4050 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 2s 999us/step - loss: 0.5272 - acc: 0.8450 - val_loss: 0.4347 - val_acc: 0.8417\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.4058 - acc: 0.8583 - val_loss: 0.4286 - val_acc: 0.8417\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.4008 - acc: 0.8583 - val_loss: 0.4260 - val_acc: 0.8417\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3942 - acc: 0.8583 - val_loss: 0.4143 - val_acc: 0.8417\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 87us/step - loss: 0.3876 - acc: 0.8583 - val_loss: 0.4103 - val_acc: 0.8417\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5319 - acc: 0.8325 - val_loss: 0.4647 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 89us/step - loss: 0.3918 - acc: 0.8629 - val_loss: 0.4514 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.3848 - acc: 0.8629 - val_loss: 0.4654 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 84us/step - loss: 0.3761 - acc: 0.8629 - val_loss: 0.4258 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 85us/step - loss: 0.3675 - acc: 0.8629 - val_loss: 0.4165 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 600 samples\n",
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 3s 1ms/step - loss: 0.5054 - acc: 0.8292 - val_loss: 0.4870 - val_acc: 0.8233\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 0s 91us/step - loss: 0.3914 - acc: 0.8629 - val_loss: 0.4531 - val_acc: 0.8233\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 0s 88us/step - loss: 0.3831 - acc: 0.8629 - val_loss: 0.4639 - val_acc: 0.8233\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3753 - acc: 0.8629 - val_loss: 0.4433 - val_acc: 0.8233\n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 0s 86us/step - loss: 0.3706 - acc: 0.8629 - val_loss: 0.4506 - val_acc: 0.8233\n",
      "y22_pred:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "pod 1st:  0.0\n",
      "pod:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "pof:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "auc:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "2850 0 483 0\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "def get_RNN_Predict(X2_train, X2_test, y2_train, y2_test):\n",
    "    import pandas as pd\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense,Dropout, LSTM, GRU\n",
    "    from keras.layers import Embedding\n",
    "    max_features = 10000 # number of words to consider as features\n",
    "    import numpy as np\n",
    "    #create model \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(X2_train, y2_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "    y2_pred = model.predict(X2_test)\n",
    "    y22_pred=y2_pred.round()\n",
    "    print('y22_pred: ',y22_pred)\n",
    "    return y22_pred\n",
    "\n",
    "pod_list = []\n",
    "pof_list = []\n",
    "auc_val_list = []\n",
    "tn_list= []\n",
    "fp_list= []\n",
    "fn_list= []\n",
    "tp_list= []\n",
    "    \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=10)\n",
    "for train_index, test_index in folds.split(df_x_train_chi,y_train):\n",
    "    X2_train, X2_test, y2_train, y2_test=df_x_train_chi.iloc[train_index], df_x_train_chi.iloc[test_index],y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    y_pred = get_RNN_Predict(X2_train, X2_test, y2_train, y2_test)\n",
    "    tn, fp, fn, tp  = confusion_matrix(y2_test, y_pred).ravel()\n",
    "    tn_list.append(tn)\n",
    "    fp_list.append(fp)\n",
    "    fn_list.append(fn)\n",
    "    tp_list.append(tp)\n",
    "    \n",
    "    pod=tp/(tp+fn)\n",
    "    print('pod 1st: ',pod)\n",
    "    pof=fp/(fp+tn)\n",
    "    auc_val=(1+pod-pof)/2\n",
    "    #break\n",
    "    pod_list.append(pod)\n",
    "    pof_list.append(pof)\n",
    "    auc_val_list.append(auc_val)\n",
    "\n",
    "print('pod: ',pod_list)\n",
    "print ('pof: ',pof_list)\n",
    "print ('auc: ',auc_val_list)\n",
    "\n",
    "tn=sum(tn_list)\n",
    "fp=sum(fp_list) \n",
    "fn=sum(fn_list) \n",
    "tp=sum(tp_list)\n",
    "print(tn, fp, fn, tp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6dd550951f6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_chi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "# Specify parameters\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 1e-3, 1e-4]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf', 'linear']} ]\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), tuned_parameters, verbose=1, cv=10, n_jobs=-1)\n",
    "grid.fit(x_train_chi, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
